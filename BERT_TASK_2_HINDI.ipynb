{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_TASK_2_HINDI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38ab8ca7147e484ebafdd2b4355de10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bff9e13a33d7416a9cf79c8d35262aa6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f4ef12c34758493ca18090e4fd90ecb7",
              "IPY_MODEL_3551e06aae2b48588a1845771f114862"
            ]
          }
        },
        "bff9e13a33d7416a9cf79c8d35262aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4ef12c34758493ca18090e4fd90ecb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_52f70f8549154838b3382da34c042987",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5037a2fc167247d8a16342584164b61a"
          }
        },
        "3551e06aae2b48588a1845771f114862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f422addcfaf438ca885b818df857625",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 996k/996k [00:00&lt;00:00, 5.77MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4072b794ecc34922a06cd197daa103d5"
          }
        },
        "52f70f8549154838b3382da34c042987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5037a2fc167247d8a16342584164b61a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f422addcfaf438ca885b818df857625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4072b794ecc34922a06cd197daa103d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23e9e6a23fb54c3f9f9444974ede2254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_db28f26273fa44029fb361704e583d3e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_72cd646986dc4755aa7120593876cd03",
              "IPY_MODEL_2532cd647a0c45d28f4015f7f895d70d"
            ]
          }
        },
        "db28f26273fa44029fb361704e583d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72cd646986dc4755aa7120593876cd03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0b7eebd78f2460c82d6f1c5a577ac3c",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 569,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 569,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1dafda41d1c4b3bae0a47e5681385b0"
          }
        },
        "2532cd647a0c45d28f4015f7f895d70d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13cb1b7f618e4b53a73cf4794b0bf23f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 569/569 [00:00&lt;00:00, 12.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1954404ccdcd4786ada82a6e793b66a9"
          }
        },
        "a0b7eebd78f2460c82d6f1c5a577ac3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1dafda41d1c4b3bae0a47e5681385b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13cb1b7f618e4b53a73cf4794b0bf23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1954404ccdcd4786ada82a6e793b66a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cedb62ee79b24cb3a746e5d63a2de6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a1c3c162b444a73911dc9c66c4e78fb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_758f9c49abed41958704b8911ee2895e",
              "IPY_MODEL_84930880334e4d8fbc2eb5dd4f29b8b9"
            ]
          }
        },
        "9a1c3c162b444a73911dc9c66c4e78fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "758f9c49abed41958704b8911ee2895e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70e0c1115caf45988ef5d638275da79a",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b472c08f3b0b4993b53968677767b11a"
          }
        },
        "84930880334e4d8fbc2eb5dd4f29b8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_86d0593d44a14656865259d751787ed4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 714M/714M [00:15&lt;00:00, 46.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa0bca2108214920afd8b47a94ad1a16"
          }
        },
        "70e0c1115caf45988ef5d638275da79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b472c08f3b0b4993b53968677767b11a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86d0593d44a14656865259d751787ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa0bca2108214920afd8b47a94ad1a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakesh-SSN/FYP/blob/master/BERT_TASK_2_HINDI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN2gN6gr8nOJ",
        "colab_type": "code",
        "outputId": "a9555b77-fac3-4fc8-cc5b-3729a1a18fae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 3.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 34.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 15.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=cf346276be0452279813ce0fc19dd5dac02ba08562946c8d9d78b44404f1816d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agL2oUFJO9BM",
        "colab_type": "code",
        "outputId": "92c513fd-475b-4b6d-aa3d-d7e1ec7ab445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roq3nEGz9wvH",
        "colab_type": "code",
        "outputId": "302e50ec-40e1-48d1-d16b-e2ba2ee869bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/hindi/task2hindi.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 3,500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2463</th>\n",
              "      <td>HIN2464</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>वित्त मंत्री ने इस मसले पर बरकरार संशय को खत्म...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2174</th>\n",
              "      <td>HIN2175</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>इंडिया में रोज राजनेताओं के घर बजती है डॉन दाऊ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3237</th>\n",
              "      <td>HIN3238</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>पाक ने फिर तोड़ा भारत का विश्‍वास, गिरफ्तार नह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2185</th>\n",
              "      <td>HIN2186</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>दाऊद इब्राहिम के कट सकते हैं दोनों पैर, डॉन मर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1841</th>\n",
              "      <td>HIN1842</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "      <td>उन्होंने टाइम मैग्जीन के फ्रंट पेज के फोटो शूट...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1750</th>\n",
              "      <td>HIN1751</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "      <td>रिपोर्ट के मुताबिक, चीन एनएसजी मेंबरशिप ज्वाइन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>902</th>\n",
              "      <td>HIN0903</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>सदन की कार्यवाही हंगामे के कारण बारह बजे तक स्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>HIN0523</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>हाल ही में ट्विटर ने कश्मीर की भौगोलिक स्थिति ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994</th>\n",
              "      <td>HIN1995</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "      <td>अहमदनगर के मुला नदी में 20 साल बाद 86 हजार क्य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3345</th>\n",
              "      <td>HIN3346</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>अब हमारे गेंदबाजों को इस योजना को क्रियान्वित ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "2463         HIN2464  ...  वित्त मंत्री ने इस मसले पर बरकरार संशय को खत्म...\n",
              "2174         HIN2175  ...  इंडिया में रोज राजनेताओं के घर बजती है डॉन दाऊ...\n",
              "3237         HIN3238  ...  पाक ने फिर तोड़ा भारत का विश्‍वास, गिरफ्तार नह...\n",
              "2185         HIN2186  ...  दाऊद इब्राहिम के कट सकते हैं दोनों पैर, डॉन मर...\n",
              "1841         HIN1842  ...  उन्होंने टाइम मैग्जीन के फ्रंट पेज के फोटो शूट...\n",
              "1750         HIN1751  ...  रिपोर्ट के मुताबिक, चीन एनएसजी मेंबरशिप ज्वाइन...\n",
              "902          HIN0903  ...  सदन की कार्यवाही हंगामे के कारण बारह बजे तक स्...\n",
              "522          HIN0523  ...  हाल ही में ट्विटर ने कश्मीर की भौगोलिक स्थिति ...\n",
              "1994         HIN1995  ...  अहमदनगर के मुला नदी में 20 साल बाद 86 हजार क्य...\n",
              "3345         HIN3346  ...  अब हमारे गेंदबाजों को इस योजना को क्रियान्वित ...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK0Dm2839_fM",
        "colab_type": "code",
        "outputId": "23013546-ca96-4b51-9021-ac2b13dcabcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]\n",
        "print(df.label)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "3495    0\n",
            "3496    0\n",
            "3497    0\n",
            "3498    0\n",
            "3499    0\n",
            "Name: label, Length: 3500, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64AfSL-V-Ij5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60lFABu1-KAE",
        "colab_type": "code",
        "outputId": "cdc89178-d778-4839-e69b-0f5823cd9b6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "38ab8ca7147e484ebafdd2b4355de10d",
            "bff9e13a33d7416a9cf79c8d35262aa6",
            "f4ef12c34758493ca18090e4fd90ecb7",
            "3551e06aae2b48588a1845771f114862",
            "52f70f8549154838b3382da34c042987",
            "5037a2fc167247d8a16342584164b61a",
            "3f422addcfaf438ca885b818df857625",
            "4072b794ecc34922a06cd197daa103d5"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38ab8ca7147e484ebafdd2b4355de10d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqawKMwS-o5b",
        "colab_type": "code",
        "outputId": "b62b5011-a7fa-49d4-f27a-00f45692f477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  भारतीय मुस्लिमों की वजह से नहीं पनप सकता आईएस|<eol>भारत में कभी वर्चस्व कायम नहीं कर सकता आईएस|\n",
            "Tokenized:  ['भारतीय', 'म', '##स', '##ल', '##िम', '##ो', 'की', 'व', '##ज', '##ह', 'स', 'न', '##ही', 'प', '##न', '##प', 'सकता', 'आई', '##ए', '##स', '|', '<', 'eo', '##l', '>', 'भारत', 'म', 'कभी', 'व', '##र', '##च', '##स', '##व', 'का', '##यम', 'न', '##ही', 'कर', 'सकता', 'आई', '##ए', '##स', '|']\n",
            "Token IDs:  [18725, 889, 13432, 11714, 50419, 13718, 10826, 895, 17413, 17110, 898, 884, 24667, 885, 11453, 18187, 26886, 44881, 22599, 13432, 196, 133, 13934, 10161, 135, 14311, 889, 50058, 895, 11549, 16940, 13432, 15070, 11081, 87136, 884, 24667, 16192, 26886, 44881, 22599, 13432, 196]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKGzPxF1AUUM",
        "colab_type": "code",
        "outputId": "a8d961da-c958-4b7a-b6c7-af5c801fe785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  भारतीय मुस्लिमों की वजह से नहीं पनप सकता आईएस|<eol>भारत में कभी वर्चस्व कायम नहीं कर सकता आईएस|\n",
            "Token IDs: [101, 18725, 889, 13432, 11714, 50419, 13718, 10826, 895, 17413, 17110, 898, 884, 24667, 885, 11453, 18187, 26886, 44881, 22599, 13432, 196, 133, 13934, 10161, 135, 14311, 889, 50058, 895, 11549, 16940, 13432, 15070, 11081, 87136, 884, 24667, 16192, 26886, 44881, 22599, 13432, 196, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv39u2kLAo9b",
        "colab_type": "code",
        "outputId": "039955a0-e74d-4626-d75f-7b9cddde933a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH_GkPkFAsKR",
        "colab_type": "code",
        "outputId": "bbe5e678-19cf-4649-b798-601217b6d07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUKKZrYgAuTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfmeSm3zAxOP",
        "colab_type": "code",
        "outputId": "9e22e36b-7b88-4ba4-896e-9b1083de5e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 20% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.2)\n",
        "# print(train_inputs)\n",
        "# print(train_labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.2)\n",
        "\n",
        "print(labels)\n",
        "#print(train_masks)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6BSzcZ-A8JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2ab-k8GgLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvYAxocaGzaO",
        "colab_type": "code",
        "outputId": "b0268b76-bca8-47ee-ad2d-46dc00d5e16a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "23e9e6a23fb54c3f9f9444974ede2254",
            "db28f26273fa44029fb361704e583d3e",
            "72cd646986dc4755aa7120593876cd03",
            "2532cd647a0c45d28f4015f7f895d70d",
            "a0b7eebd78f2460c82d6f1c5a577ac3c",
            "a1dafda41d1c4b3bae0a47e5681385b0",
            "13cb1b7f618e4b53a73cf4794b0bf23f",
            "1954404ccdcd4786ada82a6e793b66a9",
            "cedb62ee79b24cb3a746e5d63a2de6cd",
            "9a1c3c162b444a73911dc9c66c4e78fb",
            "758f9c49abed41958704b8911ee2895e",
            "84930880334e4d8fbc2eb5dd4f29b8b9",
            "70e0c1115caf45988ef5d638275da79a",
            "b472c08f3b0b4993b53968677767b11a",
            "86d0593d44a14656865259d751787ed4",
            "fa0bca2108214920afd8b47a94ad1a16"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23e9e6a23fb54c3f9f9444974ede2254",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cedb62ee79b24cb3a746e5d63a2de6cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xB1woJrHCZ0",
        "colab_type": "code",
        "outputId": "83c6b69f-41fa-422b-f5fd-1f2717711e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NhjDCrtHGh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBK2E_PaHKQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOO83LgEHQYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2jmuLjzHUP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6dh8MSXHXCv",
        "colab_type": "code",
        "outputId": "ac974676-9282-4138-d372-6e5b8dd036bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     88.    Elapsed: 0:00:31.\n",
            "  Batch    80  of     88.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss: 0.76\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     88.    Elapsed: 0:00:30.\n",
            "  Batch    80  of     88.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     88.    Elapsed: 0:00:30.\n",
            "  Batch    80  of     88.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss: 0.40\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     88.    Elapsed: 0:00:30.\n",
            "  Batch    80  of     88.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3sCgA3MK9B2",
        "colab_type": "code",
        "outputId": "5b835367-ebbd-448c-919d-ffd3d6f4c423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/testdata/task2hindi-test.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "#print(len(labels))\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "#print(len(prediction_labels))\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 1,400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHsFeNFSLIkL",
        "colab_type": "code",
        "outputId": "a7867cd8-166b-4c73-c09f-e58fb32fad01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  #print(outputs)\n",
        "  # print(logits)\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "  # # print(predictions)\n",
        "  #print(true_labels)\n",
        "print('    DONE.')\n",
        "\n",
        "#print(true_labels)\n",
        "print(\"*************************\")\n",
        "\n",
        "print(len(predictions))\n",
        "#print(outputs)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,400 test sentences...\n",
            "    DONE.\n",
            "*************************\n",
            "44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCGGtb-jicKL",
        "colab_type": "code",
        "outputId": "605771ee-4d13-494d-a568-cf854c66384c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "count_NP=0\n",
        "count_P=0\n",
        "count_line=1\n",
        "x=-1\n",
        "true_count,false_count=0,0\n",
        "print(\"label \\t sno\\tlogit\\t\\t\\t\\t\\tindex\")\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    print(\"(\",end=\"\")\n",
        "    print(true_labels[i][j],end=\"\")\n",
        "    print(\")\",end=\"\")\n",
        "    print(\"\\t\",count_line,end=\"\")\n",
        "    # print(\"-  \",end=\"\")\n",
        "    if(predictions[i][j][0]>predictions[i][j][1] and predictions[i][j][0]>predictions[i][j][2]):\n",
        "      #count_P+=1 \n",
        "      #print(\" Non Paraphrase         \",end=\"\")\n",
        "      print(\"\\t\",predictions[i][j],\"\\t0\\t\",end=\"\")\n",
        "      x=0\n",
        "    elif(predictions[i][j][1]>predictions[i][j][0] and predictions[i][j][1]>predictions[i][j][2]):\n",
        "      #print(\" Paraphrase     \",end=\"\")\n",
        "     # count_NP+=1      \n",
        "      print(\"\\t\",predictions[i][j],\"\\t1\\t\",end=\"\")\n",
        "      x=1\n",
        "    elif(predictions[i][j][2]>predictions[i][j][0] and predictions[i][j][2]>predictions[i][j][1]):\n",
        "      #print(\" Semi Paraphrase     \",end=\"\")\n",
        "      #count_NP+=1      \n",
        "      print(\"\\t\",predictions[i][j],\"\\t2\\t\",end=\"\")\n",
        "      x=2\n",
        "    count_line+=1\n",
        "    #print(\"\\t\",predictions[i][j],\"\\t2\\t\",end=\"\")\n",
        "\n",
        "    if(true_labels[i][j]==x):\n",
        "      true_count+=1\n",
        "      print(\"true\")\n",
        "    else:\n",
        "      print(\"false\")\n",
        "      false_count+=1\n",
        "\n",
        "print(\"Number of true predictions:\",true_count)\n",
        "print(\"Number of false predictions:\",false_count)\n",
        "  \n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label \t sno\tlogit\t\t\t\t\tindex\n",
            "(1)\t 1\t [-1.9034923 -1.5362003  3.0470092] \t2\tfalse\n",
            "(1)\t 2\t [-1.2461517 -1.6160647  2.5145872] \t2\tfalse\n",
            "(1)\t 3\t [ 0.05676147  2.014721   -2.0221143 ] \t1\ttrue\n",
            "(0)\t 4\t [ 2.7524745 -1.4942547 -1.7634025] \t0\ttrue\n",
            "(1)\t 5\t [-1.7662977   2.09846    -0.82846004] \t1\ttrue\n",
            "(2)\t 6\t [-1.753245  -1.7882191  3.0425026] \t2\ttrue\n",
            "(1)\t 7\t [-2.0606105   2.1966598  -0.08677594] \t1\ttrue\n",
            "(2)\t 8\t [-1.3590918 -1.4149526  2.7801726] \t2\ttrue\n",
            "(2)\t 9\t [-0.60405    -0.18575723  0.08526754] \t2\ttrue\n",
            "(1)\t 10\t [-1.5397487  2.8215468 -1.0274972] \t1\ttrue\n",
            "(2)\t 11\t [-1.827611  -1.7558409  2.956873 ] \t2\ttrue\n",
            "(2)\t 12\t [-1.4246476 -1.884452   2.8926792] \t2\ttrue\n",
            "(1)\t 13\t [-2.116366   2.2208982 -0.3389399] \t1\ttrue\n",
            "(1)\t 14\t [-2.6224556   0.10237955  2.0901597 ] \t2\tfalse\n",
            "(2)\t 15\t [-1.4974906 -1.985936   2.8748834] \t2\ttrue\n",
            "(2)\t 16\t [-0.7144842  -0.844138    0.83519554] \t2\ttrue\n",
            "(1)\t 17\t [-2.3770163 -0.3764552  2.5401933] \t2\tfalse\n",
            "(1)\t 18\t [-1.9871213 -0.9859057  2.3695734] \t2\tfalse\n",
            "(1)\t 19\t [-1.5647386  2.4318867 -0.6383681] \t1\ttrue\n",
            "(1)\t 20\t [-2.24031    1.8152759  0.3527932] \t1\ttrue\n",
            "(1)\t 21\t [-2.4070678  1.4614162  0.7696089] \t1\ttrue\n",
            "(1)\t 22\t [-2.1131842  -0.29832634  1.8987269 ] \t2\tfalse\n",
            "(1)\t 23\t [-0.05411563  0.02570898 -0.4983407 ] \t1\ttrue\n",
            "(1)\t 24\t [-2.042296  -0.8784223  2.5048883] \t2\tfalse\n",
            "(2)\t 25\t [-1.8803924 -1.6678904  3.111902 ] \t2\ttrue\n",
            "(2)\t 26\t [-1.9288836 -1.565016   3.0700624] \t2\ttrue\n",
            "(1)\t 27\t [-1.7893711   2.5802324  -0.37501153] \t1\ttrue\n",
            "(1)\t 28\t [-2.42535     1.8641598   0.45734513] \t1\ttrue\n",
            "(0)\t 29\t [-0.04112311 -2.2441669   2.0192282 ] \t2\tfalse\n",
            "(2)\t 30\t [-1.6703917 -1.7692382  3.0549564] \t2\ttrue\n",
            "(2)\t 31\t [-1.3860257  -0.39888614  0.8836048 ] \t2\ttrue\n",
            "(2)\t 32\t [-1.3327118 -1.892578   2.649199 ] \t2\ttrue\n",
            "(1)\t 33\t [-2.3030493   2.1996696   0.07768144] \t1\ttrue\n",
            "(1)\t 34\t [ 1.6714026  -0.84796447 -1.3152058 ] \t0\tfalse\n",
            "(1)\t 35\t [-2.6610467   0.22292012  2.097806  ] \t2\tfalse\n",
            "(1)\t 36\t [-2.6579437   0.39739338  1.9521532 ] \t2\tfalse\n",
            "(2)\t 37\t [-1.9836558 -1.5101563  2.949433 ] \t2\ttrue\n",
            "(2)\t 38\t [-1.3989727 -2.0973852  2.7360115] \t2\ttrue\n",
            "(2)\t 39\t [-1.6152451 -1.9069388  2.9901447] \t2\ttrue\n",
            "(2)\t 40\t [-1.5134993 -1.6779242  3.0507202] \t2\ttrue\n",
            "(1)\t 41\t [-2.198085    1.8716526   0.39582786] \t1\ttrue\n",
            "(1)\t 42\t [-1.2966049  2.7916198 -1.3123558] \t1\ttrue\n",
            "(1)\t 43\t [-2.6096776  1.4658161  1.128878 ] \t1\ttrue\n",
            "(1)\t 44\t [-2.5053132  1.532275   0.6977385] \t1\ttrue\n",
            "(1)\t 45\t [-2.303952    2.1183333   0.03964472] \t1\ttrue\n",
            "(2)\t 46\t [-1.4004238 -1.8316321  2.805431 ] \t2\ttrue\n",
            "(1)\t 47\t [-2.235692    0.03758454  1.578569  ] \t2\tfalse\n",
            "(2)\t 48\t [-1.6669205 -1.6806967  2.6853902] \t2\ttrue\n",
            "(1)\t 49\t [-2.2298965 -1.0149416  2.9029272] \t2\tfalse\n",
            "(1)\t 50\t [-2.591992    0.47623807  1.8980485 ] \t2\tfalse\n",
            "(1)\t 51\t [-2.4463844 -0.3788635  2.4668448] \t2\tfalse\n",
            "(1)\t 52\t [-1.3192928   2.208044   -0.45574024] \t1\ttrue\n",
            "(2)\t 53\t [-1.9821998 -1.6517944  3.0684066] \t2\ttrue\n",
            "(1)\t 54\t [ 1.0477589   0.59741545 -1.9608748 ] \t0\tfalse\n",
            "(2)\t 55\t [ 0.67489445 -2.0653656   0.885021  ] \t2\ttrue\n",
            "(1)\t 56\t [-0.915694  -2.0725524  2.4658337] \t2\tfalse\n",
            "(2)\t 57\t [-1.52633   -1.9187746  3.0094879] \t2\ttrue\n",
            "(1)\t 58\t [-2.5461662   0.70698905  1.7705686 ] \t2\tfalse\n",
            "(1)\t 59\t [-2.7040653   1.7000735   0.80825996] \t1\ttrue\n",
            "(1)\t 60\t [-1.9422734  1.7671658  0.4907174] \t1\ttrue\n",
            "(1)\t 61\t [-2.7035894  0.7764667  1.8456855] \t2\tfalse\n",
            "(2)\t 62\t [-2.3905003 -0.0778898  2.2610762] \t2\ttrue\n",
            "(2)\t 63\t [-1.9455655 -1.4971858  3.076178 ] \t2\ttrue\n",
            "(2)\t 64\t [-1.9076768 -1.3705149  3.050734 ] \t2\ttrue\n",
            "(2)\t 65\t [-1.6351286 -1.843981   3.030298 ] \t2\ttrue\n",
            "(2)\t 66\t [-2.3137765 -0.860474   2.7335124] \t2\ttrue\n",
            "(2)\t 67\t [ 0.27955964 -0.2518999  -0.5964948 ] \t0\tfalse\n",
            "(2)\t 68\t [-1.8257354 -1.6429387  3.1014845] \t2\ttrue\n",
            "(1)\t 69\t [-2.4497077   1.5625906   0.65558493] \t1\ttrue\n",
            "(1)\t 70\t [-2.5873747  -0.05264549  2.425145  ] \t2\tfalse\n",
            "(1)\t 71\t [-2.178103    2.0635185   0.18110855] \t1\ttrue\n",
            "(2)\t 72\t [-1.6762711 -1.4245027  2.8192809] \t2\ttrue\n",
            "(2)\t 73\t [-2.315967  -0.8029794  2.769571 ] \t2\ttrue\n",
            "(1)\t 74\t [-1.7105685  2.5963798 -0.9516127] \t1\ttrue\n",
            "(1)\t 75\t [-1.80167   -1.6741201  3.0785568] \t2\tfalse\n",
            "(2)\t 76\t [ 2.4080873 -1.930435  -1.1299235] \t0\tfalse\n",
            "(1)\t 77\t [-2.2762208  -0.20079686  2.5229743 ] \t2\tfalse\n",
            "(2)\t 78\t [-2.22145   -1.1975892  2.9269538] \t2\ttrue\n",
            "(2)\t 79\t [-0.4502938 -2.0755281  2.099915 ] \t2\ttrue\n",
            "(2)\t 80\t [-2.1017432 -0.6254712  2.1663334] \t2\ttrue\n",
            "(1)\t 81\t [-2.4844375  1.1893579  1.2145046] \t2\tfalse\n",
            "(1)\t 82\t [-1.2677834  2.50515   -1.0975862] \t1\ttrue\n",
            "(2)\t 83\t [-1.981431  -1.546883   3.0427787] \t2\ttrue\n",
            "(2)\t 84\t [-2.3951209 -0.7141659  2.5745866] \t2\ttrue\n",
            "(0)\t 85\t [-1.4254701 -2.0028312  2.8873746] \t2\tfalse\n",
            "(2)\t 86\t [-2.1292791 -1.2301981  2.9733295] \t2\ttrue\n",
            "(2)\t 87\t [-0.24690266  0.32019404 -0.19296053] \t1\tfalse\n",
            "(2)\t 88\t [-2.291621   -0.58718663  2.3381102 ] \t2\ttrue\n",
            "(2)\t 89\t [ 2.4080293 -1.8230706 -0.9750719] \t0\tfalse\n",
            "(2)\t 90\t [ 1.9602182 -1.2006683 -1.0270789] \t0\tfalse\n",
            "(1)\t 91\t [-0.11701716  1.4766762  -0.9684937 ] \t1\ttrue\n",
            "(2)\t 92\t [-1.1088504   0.78553313 -0.39810142] \t1\tfalse\n",
            "(0)\t 93\t [-1.767117  -1.8114307  3.0700073] \t2\tfalse\n",
            "(2)\t 94\t [ 1.3553311 -1.96223    0.3165988] \t0\tfalse\n",
            "(0)\t 95\t [ 1.877952  -1.6736207 -0.4370799] \t0\ttrue\n",
            "(2)\t 96\t [-1.5272521  -0.96418357  1.7192256 ] \t2\ttrue\n",
            "(0)\t 97\t [-1.2902818 -2.048493   2.6168036] \t2\tfalse\n",
            "(0)\t 98\t [-1.8971733 -1.47326    2.8832262] \t2\tfalse\n",
            "(0)\t 99\t [-0.2297929 -1.8251023  1.5481958] \t2\tfalse\n",
            "(2)\t 100\t [-2.037759  -1.0920106  2.9870288] \t2\ttrue\n",
            "(0)\t 101\t [-0.9390345 -1.73689    1.9314625] \t2\tfalse\n",
            "(2)\t 102\t [-1.8646549 -1.4344254  3.1248908] \t2\ttrue\n",
            "(0)\t 103\t [ 1.1472751   0.28035542 -1.224019  ] \t0\ttrue\n",
            "(0)\t 104\t [-1.2086295 -1.8189167  2.6123896] \t2\tfalse\n",
            "(2)\t 105\t [-1.9199506 -1.5313686  3.0971694] \t2\ttrue\n",
            "(2)\t 106\t [ 2.321453  -1.8247397 -1.0496987] \t0\tfalse\n",
            "(2)\t 107\t [-1.9084687 -1.5839804  3.0823927] \t2\ttrue\n",
            "(0)\t 108\t [-0.86877906 -1.7644807   2.2078953 ] \t2\tfalse\n",
            "(0)\t 109\t [ 1.9931276 -1.3698756 -0.8550688] \t0\ttrue\n",
            "(2)\t 110\t [-1.9970027 -1.347519   3.0886602] \t2\ttrue\n",
            "(0)\t 111\t [-1.394777  -2.0134897  2.7747247] \t2\tfalse\n",
            "(2)\t 112\t [ 1.6360713  -0.16692972 -1.7595955 ] \t0\tfalse\n",
            "(0)\t 113\t [-0.6458874  -0.89666575  0.6922175 ] \t2\tfalse\n",
            "(2)\t 114\t [-1.0674691 -1.061427   1.5760112] \t2\ttrue\n",
            "(0)\t 115\t [ 1.7640293  -2.1081178   0.01370688] \t0\ttrue\n",
            "(0)\t 116\t [-0.68527913 -1.8859324   2.1071837 ] \t2\tfalse\n",
            "(2)\t 117\t [-2.4253974  -0.08836283  2.2591062 ] \t2\ttrue\n",
            "(2)\t 118\t [-1.2320249 -2.0958307  2.7459424] \t2\ttrue\n",
            "(0)\t 119\t [ 0.5651934  -1.532447    0.52644813] \t0\ttrue\n",
            "(2)\t 120\t [-1.145478  -1.8030865  2.4947486] \t2\ttrue\n",
            "(0)\t 121\t [-0.85012025 -2.061176    2.4469304 ] \t2\tfalse\n",
            "(0)\t 122\t [-1.3977379 -1.8870409  2.9672747] \t2\tfalse\n",
            "(2)\t 123\t [-1.7680777 -1.7433299  2.9221854] \t2\ttrue\n",
            "(0)\t 124\t [-1.4540111 -1.7342668  2.9193468] \t2\tfalse\n",
            "(1)\t 125\t [-2.5590096  1.3264308  0.8553328] \t1\ttrue\n",
            "(0)\t 126\t [ 0.25139356 -1.9146243   1.3196071 ] \t2\tfalse\n",
            "(0)\t 127\t [ 0.8745124  -1.5704545   0.34191334] \t0\ttrue\n",
            "(0)\t 128\t [ 1.8140734  -1.3972306  -0.85599786] \t0\ttrue\n",
            "(2)\t 129\t [-0.11169733 -0.9605886   0.6144009 ] \t2\ttrue\n",
            "(2)\t 130\t [ 1.0189755  0.4781524 -1.9178283] \t0\tfalse\n",
            "(2)\t 131\t [ 1.1696476  -0.25689983 -1.2679214 ] \t0\tfalse\n",
            "(0)\t 132\t [ 0.8052082 -1.149359   0.1050551] \t0\ttrue\n",
            "(2)\t 133\t [-1.2514693 -1.685961   2.3088212] \t2\ttrue\n",
            "(0)\t 134\t [-0.9392353 -2.0371273  2.3703012] \t2\tfalse\n",
            "(0)\t 135\t [ 0.96976644 -0.2707432  -0.15325661] \t0\ttrue\n",
            "(2)\t 136\t [-0.250609  -1.1303254  0.9775806] \t2\ttrue\n",
            "(0)\t 137\t [ 1.0154146  -0.97873837 -0.33983395] \t0\ttrue\n",
            "(0)\t 138\t [ 0.53374666 -0.6248104   0.8094659 ] \t2\tfalse\n",
            "(2)\t 139\t [-2.353801   -0.56899303  2.7023163 ] \t2\ttrue\n",
            "(0)\t 140\t [-1.1040127 -1.7955612  2.6439393] \t2\tfalse\n",
            "(0)\t 141\t [ 1.6821125  -1.1872514  -0.86507666] \t0\ttrue\n",
            "(2)\t 142\t [-1.6944804 -1.7661093  3.0643668] \t2\ttrue\n",
            "(2)\t 143\t [-1.5250236 -1.8595392  3.0282004] \t2\ttrue\n",
            "(1)\t 144\t [-2.6178348   0.22626919  2.2267485 ] \t2\tfalse\n",
            "(0)\t 145\t [ 1.091944   -1.0759392  -0.19024847] \t0\ttrue\n",
            "(2)\t 146\t [-2.0826907 -1.1673568  2.9224772] \t2\ttrue\n",
            "(0)\t 147\t [-1.4680096 -1.779565   2.983603 ] \t2\tfalse\n",
            "(2)\t 148\t [-1.8156108 -1.6405618  3.11308  ] \t2\ttrue\n",
            "(0)\t 149\t [-1.6071762 -1.65757    2.8923826] \t2\tfalse\n",
            "(1)\t 150\t [-2.5149841   0.45458215  2.0908806 ] \t2\tfalse\n",
            "(1)\t 151\t [-2.2305424 -1.2022539  2.892667 ] \t2\tfalse\n",
            "(0)\t 152\t [-1.5232124 -1.8940085  2.9994228] \t2\tfalse\n",
            "(1)\t 153\t [-2.1329873 -0.8909093  2.9334743] \t2\tfalse\n",
            "(1)\t 154\t [-2.534549   -0.53520113  2.4681053 ] \t2\tfalse\n",
            "(1)\t 155\t [-2.0275524 -1.3353028  3.013756 ] \t2\tfalse\n",
            "(0)\t 156\t [-1.77182   -1.7930844  2.9279454] \t2\tfalse\n",
            "(2)\t 157\t [ 0.15305322 -2.387285    1.7257752 ] \t2\ttrue\n",
            "(2)\t 158\t [-1.8506926 -1.4976653  3.0429814] \t2\ttrue\n",
            "(1)\t 159\t [-1.844988 -1.685731  3.12319 ] \t2\tfalse\n",
            "(1)\t 160\t [-2.4651663   1.9082525   0.39889753] \t1\ttrue\n",
            "(2)\t 161\t [-2.0464337 -1.3189534  2.9948847] \t2\ttrue\n",
            "(0)\t 162\t [ 2.144703   -1.9845078  -0.28578255] \t0\ttrue\n",
            "(2)\t 163\t [-1.7425112 -1.7463937  3.11361  ] \t2\ttrue\n",
            "(2)\t 164\t [-1.445714  -1.980937   2.9162974] \t2\ttrue\n",
            "(2)\t 165\t [-1.6245229 -1.8218839  2.9877489] \t2\ttrue\n",
            "(1)\t 166\t [-2.6355937  1.2162805  1.2558311] \t2\tfalse\n",
            "(1)\t 167\t [-0.3989385  2.1853142 -2.0770907] \t1\ttrue\n",
            "(1)\t 168\t [-1.0309131  2.714478  -1.8327631] \t1\ttrue\n",
            "(1)\t 169\t [-2.1546047   2.2726166  -0.59958875] \t1\ttrue\n",
            "(0)\t 170\t [ 0.74285036  0.37291712 -1.4709058 ] \t0\ttrue\n",
            "(2)\t 171\t [-1.1105263   1.1869644  -0.98814625] \t1\tfalse\n",
            "(2)\t 172\t [-1.6341902 -1.6576308  2.6622126] \t2\ttrue\n",
            "(0)\t 173\t [-1.743162  -1.8001089  2.86973  ] \t2\tfalse\n",
            "(1)\t 174\t [-1.5484656  2.6097093 -1.0408889] \t1\ttrue\n",
            "(1)\t 175\t [-1.3522836  2.7888925 -1.2502186] \t1\ttrue\n",
            "(1)\t 176\t [ 2.1366897 -0.5881211 -1.813088 ] \t0\tfalse\n",
            "(1)\t 177\t [-1.6401167  2.0593405 -0.5096906] \t1\ttrue\n",
            "(1)\t 178\t [-1.270702   2.3287508 -1.4331173] \t1\ttrue\n",
            "(1)\t 179\t [-2.1323779 -0.7213371  2.5850341] \t2\tfalse\n",
            "(1)\t 180\t [-0.97915876  2.6308146  -1.7143648 ] \t1\ttrue\n",
            "(1)\t 181\t [-2.2925324 -0.9063961  2.5547574] \t2\tfalse\n",
            "(1)\t 182\t [-2.35015   -0.7211984  2.7864804] \t2\tfalse\n",
            "(1)\t 183\t [-2.2670002  2.4162683 -0.1588022] \t1\ttrue\n",
            "(1)\t 184\t [ 2.0560606 -1.2135735 -1.2547783] \t0\tfalse\n",
            "(2)\t 185\t [-1.9630054 -1.5546713  2.987039 ] \t2\ttrue\n",
            "(0)\t 186\t [-1.4238123 -1.8475477  2.8900068] \t2\tfalse\n",
            "(0)\t 187\t [ 2.5271237 -1.7876904 -1.0893632] \t0\ttrue\n",
            "(2)\t 188\t [ 0.3097619   0.05911482 -0.920825  ] \t0\tfalse\n",
            "(2)\t 189\t [ 0.7894075  0.5312414 -1.7875147] \t0\tfalse\n",
            "(0)\t 190\t [ 1.2735599  -1.0718771  -0.32771885] \t0\ttrue\n",
            "(0)\t 191\t [ 0.6724066 -2.247394   1.1373175] \t2\tfalse\n",
            "(2)\t 192\t [-2.2861779   1.961855   -0.09527514] \t1\tfalse\n",
            "(0)\t 193\t [ 0.28861192 -1.9874966   1.0636789 ] \t2\tfalse\n",
            "(1)\t 194\t [ 1.2928826  -0.25456825 -1.2083431 ] \t0\tfalse\n",
            "(2)\t 195\t [-1.7705446 -1.8128419  2.9949954] \t2\ttrue\n",
            "(0)\t 196\t [ 0.383174  -2.2074785  1.3192053] \t2\tfalse\n",
            "(1)\t 197\t [-1.6245722  2.859581  -1.1779538] \t1\ttrue\n",
            "(0)\t 198\t [-1.6787575 -1.1855375  2.5919228] \t2\tfalse\n",
            "(0)\t 199\t [ 1.4997002  -1.9703815  -0.21806423] \t0\ttrue\n",
            "(2)\t 200\t [-1.5100086  -0.66507065  1.5340494 ] \t2\ttrue\n",
            "(0)\t 201\t [ 2.3043246 -1.8516822 -1.0132182] \t0\ttrue\n",
            "(2)\t 202\t [-2.1688917 -0.9626417  2.7356508] \t2\ttrue\n",
            "(1)\t 203\t [-2.0390134  -0.49855113  2.6201212 ] \t2\tfalse\n",
            "(0)\t 204\t [-1.4824874 -1.9201424  2.9767387] \t2\tfalse\n",
            "(2)\t 205\t [-1.8770638 -1.5808676  3.1291986] \t2\ttrue\n",
            "(0)\t 206\t [ 2.3222656 -1.5873009 -1.1229738] \t0\ttrue\n",
            "(1)\t 207\t [-1.9348701   2.099442   -0.20372456] \t1\ttrue\n",
            "(1)\t 208\t [-2.1671436   1.727248    0.33826354] \t1\ttrue\n",
            "(1)\t 209\t [-2.501602   1.7743077  0.6293447] \t1\ttrue\n",
            "(1)\t 210\t [-2.2043128 -1.0782223  2.919052 ] \t2\tfalse\n",
            "(1)\t 211\t [-0.43183136 -1.0532237   1.5680181 ] \t2\tfalse\n",
            "(1)\t 212\t [-2.6546278  -0.08787955  2.1950567 ] \t2\tfalse\n",
            "(2)\t 213\t [-2.3664339 -0.8051228  2.6927934] \t2\ttrue\n",
            "(0)\t 214\t [ 0.5291764 -2.2678728  1.2191285] \t2\tfalse\n",
            "(2)\t 215\t [-2.0197012 -1.3193941  2.9765975] \t2\ttrue\n",
            "(1)\t 216\t [-1.4291289  2.6031127 -1.3050519] \t1\ttrue\n",
            "(1)\t 217\t [-2.17136   -0.901754   2.9585698] \t2\tfalse\n",
            "(0)\t 218\t [-1.6641582 -1.8290653  3.0819364] \t2\tfalse\n",
            "(1)\t 219\t [-0.33970147  2.3935726  -1.8957597 ] \t1\ttrue\n",
            "(1)\t 220\t [-2.5474834  -0.37450013  2.255343  ] \t2\tfalse\n",
            "(1)\t 221\t [-1.5200835  2.44881   -0.9834289] \t1\ttrue\n",
            "(2)\t 222\t [-1.9186035 -1.4426346  2.9837444] \t2\ttrue\n",
            "(2)\t 223\t [-1.955431  -1.6112897  3.0713286] \t2\ttrue\n",
            "(2)\t 224\t [-2.1281917 -1.2602131  3.0125215] \t2\ttrue\n",
            "(0)\t 225\t [ 1.4366472 -2.1445563  0.2767963] \t0\ttrue\n",
            "(0)\t 226\t [-1.6157204 -1.810946   2.8937678] \t2\tfalse\n",
            "(2)\t 227\t [-2.288551  -0.8858344  2.9142272] \t2\ttrue\n",
            "(2)\t 228\t [-1.8280702 -1.681282   3.0019464] \t2\ttrue\n",
            "(0)\t 229\t [-1.4928265 -1.7844907  3.0022917] \t2\tfalse\n",
            "(0)\t 230\t [ 1.6262944  -0.92159474 -0.8844073 ] \t0\ttrue\n",
            "(1)\t 231\t [-2.1784987  -0.99749714  2.950168  ] \t2\tfalse\n",
            "(1)\t 232\t [-1.8410289  2.610886  -0.7891953] \t1\ttrue\n",
            "(0)\t 233\t [-1.599894  -1.8690693  2.8677323] \t2\tfalse\n",
            "(2)\t 234\t [-2.002981  -1.4634721  3.0751271] \t2\ttrue\n",
            "(0)\t 235\t [ 1.1227604  -0.6417535  -0.49351725] \t0\ttrue\n",
            "(1)\t 236\t [-2.3537128  -0.68477416  2.7193031 ] \t2\tfalse\n",
            "(2)\t 237\t [-2.3091688 -1.0043792  2.857598 ] \t2\ttrue\n",
            "(0)\t 238\t [ 1.9461919 -1.498562  -0.8214468] \t0\ttrue\n",
            "(0)\t 239\t [0.8351898  0.2182466  0.09695487] \t0\ttrue\n",
            "(1)\t 240\t [-1.8478016 -1.7140677  3.0214405] \t2\tfalse\n",
            "(0)\t 241\t [-1.7367415 -1.7501975  3.019712 ] \t2\tfalse\n",
            "(2)\t 242\t [-2.4185803  0.5991507  1.5690976] \t2\ttrue\n",
            "(1)\t 243\t [-0.7327012   0.36692184 -0.15262194] \t1\ttrue\n",
            "(2)\t 244\t [-1.6113869 -1.775521   3.070869 ] \t2\ttrue\n",
            "(0)\t 245\t [-0.82935476 -2.2167451   2.5474284 ] \t2\tfalse\n",
            "(2)\t 246\t [-1.6221893 -1.8193747  3.001924 ] \t2\ttrue\n",
            "(0)\t 247\t [-1.4634544 -1.9881977  2.9811568] \t2\tfalse\n",
            "(1)\t 248\t [-0.62042373  2.5327177  -1.6954157 ] \t1\ttrue\n",
            "(2)\t 249\t [-1.5872507 -1.6839579  2.6044805] \t2\ttrue\n",
            "(0)\t 250\t [-1.1509013 -1.3301809  1.5738735] \t2\tfalse\n",
            "(1)\t 251\t [-2.2282913  -0.99236065  2.8034306 ] \t2\tfalse\n",
            "(0)\t 252\t [ 1.8919886  -2.063643   -0.20163754] \t0\ttrue\n",
            "(0)\t 253\t [-0.5283665 -2.301626   2.3793616] \t2\tfalse\n",
            "(0)\t 254\t [ 1.7201083 -1.2625259 -0.8476718] \t0\ttrue\n",
            "(2)\t 255\t [-2.5100207  -0.42362362  2.506402  ] \t2\ttrue\n",
            "(2)\t 256\t [-0.6440437 -1.4042085  1.1571312] \t2\ttrue\n",
            "(2)\t 257\t [ 2.250063  -1.4090203 -1.1549841] \t0\tfalse\n",
            "(0)\t 258\t [-1.4867805 -1.9708003  2.7554793] \t2\tfalse\n",
            "(1)\t 259\t [-1.0219675  2.308325  -1.7653407] \t1\ttrue\n",
            "(1)\t 260\t [-1.7774348  2.2023296 -0.4843816] \t1\ttrue\n",
            "(2)\t 261\t [-1.9416192 -1.5469645  3.127311 ] \t2\ttrue\n",
            "(1)\t 262\t [-1.2719593  2.6318357 -1.3446077] \t1\ttrue\n",
            "(1)\t 263\t [-1.7111049  2.773139  -0.7854547] \t1\ttrue\n",
            "(2)\t 264\t [-1.850414  -1.6997709  3.0107148] \t2\ttrue\n",
            "(1)\t 265\t [-2.7257652   0.34265253  1.7529551 ] \t2\tfalse\n",
            "(1)\t 266\t [-1.9432766  2.076523  -0.5864156] \t1\ttrue\n",
            "(1)\t 267\t [-2.156944  -1.0922469  2.9623733] \t2\tfalse\n",
            "(1)\t 268\t [-1.4403733  2.6843526 -1.2419446] \t1\ttrue\n",
            "(1)\t 269\t [-0.72186184  1.9899507  -1.8093787 ] \t1\ttrue\n",
            "(1)\t 270\t [-1.1914759  2.7016697 -1.547875 ] \t1\ttrue\n",
            "(1)\t 271\t [ 0.3463291  1.6087996 -1.9939982] \t1\ttrue\n",
            "(0)\t 272\t [ 1.7909782  -2.09114    -0.10238982] \t0\ttrue\n",
            "(1)\t 273\t [-2.6625626   0.14488088  2.1528027 ] \t2\tfalse\n",
            "(1)\t 274\t [-2.3010883 -0.8861375  2.6558707] \t2\tfalse\n",
            "(2)\t 275\t [-1.5114179 -1.8447644  2.9004009] \t2\ttrue\n",
            "(2)\t 276\t [-1.5452085 -1.1274179  2.2229748] \t2\ttrue\n",
            "(0)\t 277\t [ 2.5037026 -1.9855816 -1.0305057] \t0\ttrue\n",
            "(1)\t 278\t [-1.5184745  2.2767737 -1.1818042] \t1\ttrue\n",
            "(1)\t 279\t [-1.9537017   0.28657705  1.8251529 ] \t2\tfalse\n",
            "(0)\t 280\t [ 1.3670925  -0.7119867  -0.96382266] \t0\ttrue\n",
            "(1)\t 281\t [-1.6697367 -1.7906095  2.8965127] \t2\tfalse\n",
            "(0)\t 282\t [ 0.9365671 -2.142188   0.6753089] \t0\ttrue\n",
            "(0)\t 283\t [ 1.6935942 -1.660711  -0.5409081] \t0\ttrue\n",
            "(1)\t 284\t [ 0.00913121 -0.34780663  0.09549721] \t2\tfalse\n",
            "(0)\t 285\t [ 1.1733903  -1.0846308  -0.45760998] \t0\ttrue\n",
            "(0)\t 286\t [ 1.9730355 -0.6619154 -1.7572964] \t0\ttrue\n",
            "(0)\t 287\t [ 2.37025   -1.4516484 -1.4662397] \t0\ttrue\n",
            "(1)\t 288\t [-2.0119035   2.316018   -0.52620804] \t1\ttrue\n",
            "(1)\t 289\t [-1.8219682   2.1930401  -0.07752375] \t1\ttrue\n",
            "(1)\t 290\t [-2.208217  -0.9213021  2.8359993] \t2\tfalse\n",
            "(1)\t 291\t [-0.53968567  1.7658882  -0.89697176] \t1\ttrue\n",
            "(1)\t 292\t [ 1.1454725  -1.7810135   0.18368311] \t0\tfalse\n",
            "(1)\t 293\t [-1.7485362   0.35198087  0.765185  ] \t2\tfalse\n",
            "(2)\t 294\t [-1.482324  -1.952638   2.9005575] \t2\ttrue\n",
            "(1)\t 295\t [-0.28283387 -1.0476925   0.28654736] \t2\tfalse\n",
            "(1)\t 296\t [-1.4268662  1.1674436  1.2311234] \t2\tfalse\n",
            "(2)\t 297\t [-1.6828543 -1.8162441  3.0798216] \t2\ttrue\n",
            "(2)\t 298\t [-1.4699129 -1.8865473  3.0167265] \t2\ttrue\n",
            "(0)\t 299\t [-1.5641098 -1.6130937  2.7071192] \t2\tfalse\n",
            "(1)\t 300\t [-2.1707087 -1.1301004  2.9805896] \t2\tfalse\n",
            "(1)\t 301\t [-1.8410436  2.6832032 -0.6897583] \t1\ttrue\n",
            "(0)\t 302\t [ 2.3678713 -2.077337  -0.74154  ] \t0\ttrue\n",
            "(1)\t 303\t [-0.38348398 -1.3531417   1.3521038 ] \t2\tfalse\n",
            "(1)\t 304\t [-1.1297038  2.5251994 -1.46876  ] \t1\ttrue\n",
            "(1)\t 305\t [-0.9137664  2.2736819 -1.653401 ] \t1\ttrue\n",
            "(1)\t 306\t [ 2.4194002 -1.4543489 -1.4203496] \t0\tfalse\n",
            "(0)\t 307\t [-0.8089953 -1.9921372  2.4934368] \t2\tfalse\n",
            "(2)\t 308\t [-1.6455357 -1.388135   2.3732557] \t2\ttrue\n",
            "(2)\t 309\t [-1.412784  -2.0493777  2.6515853] \t2\ttrue\n",
            "(2)\t 310\t [ 1.9047711 -1.915419  -0.340072 ] \t0\tfalse\n",
            "(1)\t 311\t [-1.2010102  2.621559  -1.4048914] \t1\ttrue\n",
            "(1)\t 312\t [-1.3871711  2.493331  -1.1867901] \t1\ttrue\n",
            "(0)\t 313\t [ 0.87761956 -2.3930082   0.9894324 ] \t2\tfalse\n",
            "(1)\t 314\t [-1.1080673  2.6350455 -1.727292 ] \t1\ttrue\n",
            "(1)\t 315\t [-1.8678068 -1.5237521  3.08348  ] \t2\tfalse\n",
            "(1)\t 316\t [-2.3175638  -0.77431977  2.7950656 ] \t2\tfalse\n",
            "(2)\t 317\t [-1.866786  -1.7058945  3.0758042] \t2\ttrue\n",
            "(0)\t 318\t [ 0.771192  -2.320483   1.1441225] \t2\tfalse\n",
            "(1)\t 319\t [-0.5065813  1.5175345 -1.6281971] \t1\ttrue\n",
            "(1)\t 320\t [-1.8633709   1.3192589  -0.30835068] \t1\ttrue\n",
            "(2)\t 321\t [-1.135167  -1.9899944  2.717614 ] \t2\ttrue\n",
            "(1)\t 322\t [-2.672087    0.33545423  2.215077  ] \t2\tfalse\n",
            "(0)\t 323\t [ 0.10475996 -2.4310882   1.7002994 ] \t2\tfalse\n",
            "(2)\t 324\t [-2.172401  -1.2062403  2.9731836] \t2\ttrue\n",
            "(0)\t 325\t [-1.1300707 -2.0916092  2.7373447] \t2\tfalse\n",
            "(2)\t 326\t [-1.9634556 -1.4751096  3.068786 ] \t2\ttrue\n",
            "(2)\t 327\t [-1.5363994 -1.8708307  3.0324671] \t2\ttrue\n",
            "(0)\t 328\t [-1.4368763 -1.9298148  2.9516885] \t2\tfalse\n",
            "(0)\t 329\t [-1.4604567 -1.9341146  2.98053  ] \t2\tfalse\n",
            "(1)\t 330\t [-1.6790216   2.0437772  -0.41729188] \t1\ttrue\n",
            "(1)\t 331\t [-0.5723024  2.0266583 -1.5947833] \t1\ttrue\n",
            "(1)\t 332\t [-2.760949   0.3140287  2.079948 ] \t2\tfalse\n",
            "(1)\t 333\t [-1.9633567 -1.5436165  2.9310095] \t2\tfalse\n",
            "(2)\t 334\t [ 1.0901272 -1.1947168 -0.0403368] \t0\tfalse\n",
            "(1)\t 335\t [-1.9891506   1.8659986  -0.37870994] \t1\ttrue\n",
            "(1)\t 336\t [-0.32066658  1.6836603  -0.46501273] \t1\ttrue\n",
            "(2)\t 337\t [-1.9790593 -1.2707968  2.9997008] \t2\ttrue\n",
            "(0)\t 338\t [ 2.5441444 -1.4630069 -1.5423656] \t0\ttrue\n",
            "(1)\t 339\t [-2.416843   1.0519664  1.2894019] \t2\tfalse\n",
            "(1)\t 340\t [-2.2111504   1.6528498   0.71358263] \t1\ttrue\n",
            "(1)\t 341\t [-1.8227786   2.2430184  -0.37954694] \t1\ttrue\n",
            "(1)\t 342\t [-2.5948687  1.4043964  1.1239259] \t1\ttrue\n",
            "(0)\t 343\t [-0.6495984 -2.3252494  2.109619 ] \t2\tfalse\n",
            "(1)\t 344\t [-0.62061334  2.2757843  -1.5659512 ] \t1\ttrue\n",
            "(0)\t 345\t [-1.4456319 -1.7030748  2.4030676] \t2\tfalse\n",
            "(2)\t 346\t [-2.4997478  -0.46083868  2.5752149 ] \t2\ttrue\n",
            "(1)\t 347\t [-0.80103725  1.7795954  -0.31251487] \t1\ttrue\n",
            "(1)\t 348\t [-0.92205286  2.566148   -1.666555  ] \t1\ttrue\n",
            "(2)\t 349\t [-2.155054  -1.2670565  2.8702679] \t2\ttrue\n",
            "(2)\t 350\t [-1.2824005   0.41308874  0.69011915] \t2\ttrue\n",
            "(0)\t 351\t [-1.08635   -2.0022032  2.7912788] \t2\tfalse\n",
            "(2)\t 352\t [ 1.3172798  -0.92035973 -0.68960845] \t0\tfalse\n",
            "(0)\t 353\t [ 1.0121845  -1.0333774  -0.14279331] \t0\ttrue\n",
            "(2)\t 354\t [ 1.1943543  -0.876873   -0.51695627] \t0\tfalse\n",
            "(0)\t 355\t [ 2.583859  -1.6361338 -1.3557605] \t0\ttrue\n",
            "(2)\t 356\t [-2.4392276   0.06151427  2.1635067 ] \t2\ttrue\n",
            "(1)\t 357\t [-1.5620313 -1.2747779  1.834281 ] \t2\tfalse\n",
            "(1)\t 358\t [-2.0238254   2.010148   -0.02328332] \t1\ttrue\n",
            "(1)\t 359\t [ 1.1222036   0.30779827 -0.28060812] \t0\tfalse\n",
            "(1)\t 360\t [-1.4416538  2.333206  -1.249731 ] \t1\ttrue\n",
            "(1)\t 361\t [-2.61315     0.10158106  2.1590455 ] \t2\tfalse\n",
            "(0)\t 362\t [-1.4148802 -2.0549026  2.871691 ] \t2\tfalse\n",
            "(2)\t 363\t [-1.8285435 -1.2114975  2.7647843] \t2\ttrue\n",
            "(0)\t 364\t [ 1.1184919  -2.3805978   0.84704435] \t0\ttrue\n",
            "(0)\t 365\t [-0.7190501 -2.1178246  2.535164 ] \t2\tfalse\n",
            "(1)\t 366\t [-0.8382888  2.6322272 -1.669437 ] \t1\ttrue\n",
            "(2)\t 367\t [-1.8273041 -1.613599   3.109252 ] \t2\ttrue\n",
            "(2)\t 368\t [ 0.75789523 -1.0172348   0.5047574 ] \t0\tfalse\n",
            "(2)\t 369\t [-1.8109249 -1.5026768  3.0374465] \t2\ttrue\n",
            "(2)\t 370\t [-1.8707944 -1.3731731  2.8559322] \t2\ttrue\n",
            "(2)\t 371\t [-1.4987736 -1.7735007  2.8931024] \t2\ttrue\n",
            "(2)\t 372\t [-0.15567774 -2.0384734   1.7185141 ] \t2\ttrue\n",
            "(2)\t 373\t [-1.5868646 -1.8759056  3.0384586] \t2\ttrue\n",
            "(2)\t 374\t [ 0.5818003 -1.815984   0.7555211] \t2\ttrue\n",
            "(2)\t 375\t [-1.9290867 -1.5450642  3.0062013] \t2\ttrue\n",
            "(2)\t 376\t [-1.5257071 -1.8558967  2.827657 ] \t2\ttrue\n",
            "(2)\t 377\t [ 0.318794  -2.2338     1.3171321] \t2\ttrue\n",
            "(2)\t 378\t [ 2.1107178  -1.8186828  -0.57549185] \t0\tfalse\n",
            "(2)\t 379\t [ 1.4948175  -0.8852888  -0.63335305] \t0\tfalse\n",
            "(2)\t 380\t [-1.1484989 -1.1394535  1.5319388] \t2\ttrue\n",
            "(2)\t 381\t [-0.815719  -2.036144   2.3643103] \t2\ttrue\n",
            "(0)\t 382\t [-1.3105383 -1.827856   2.939285 ] \t2\tfalse\n",
            "(2)\t 383\t [ 1.1267202 -2.0705853  0.4534493] \t0\tfalse\n",
            "(2)\t 384\t [-1.1709547 -1.9884168  2.7175195] \t2\ttrue\n",
            "(2)\t 385\t [-2.1423652 -1.320556   2.699234 ] \t2\ttrue\n",
            "(2)\t 386\t [-0.1648959  -1.0454383   0.90253896] \t2\ttrue\n",
            "(0)\t 387\t [-1.8341249 -1.6805983  3.086691 ] \t2\tfalse\n",
            "(2)\t 388\t [-1.3049561 -0.3746121  0.8049557] \t2\ttrue\n",
            "(2)\t 389\t [-1.9004785 -1.5641917  3.112341 ] \t2\ttrue\n",
            "(2)\t 390\t [-1.1233165 -1.5590365  1.8207835] \t2\ttrue\n",
            "(2)\t 391\t [-1.7796403 -1.7039472  3.0579643] \t2\ttrue\n",
            "(2)\t 392\t [ 2.3819587 -1.7337472 -1.1603179] \t0\tfalse\n",
            "(2)\t 393\t [-0.43549728 -1.1101464   1.6656295 ] \t2\ttrue\n",
            "(2)\t 394\t [-1.132856  -0.989348   1.4016944] \t2\ttrue\n",
            "(2)\t 395\t [-2.2041655 -0.9534421  2.729261 ] \t2\ttrue\n",
            "(2)\t 396\t [-2.0046275 -1.139188   2.8810544] \t2\ttrue\n",
            "(2)\t 397\t [-1.4795777 -1.6341044  2.7593293] \t2\ttrue\n",
            "(2)\t 398\t [-1.7266507 -1.7264961  3.0725756] \t2\ttrue\n",
            "(2)\t 399\t [-1.4009032 -1.8412693  2.8242478] \t2\ttrue\n",
            "(2)\t 400\t [-1.7798396 -1.6052784  2.9488244] \t2\ttrue\n",
            "(2)\t 401\t [ 1.1239989  -1.0935053  -0.03208841] \t0\tfalse\n",
            "(0)\t 402\t [-1.302415   -0.94605124  1.8405116 ] \t2\tfalse\n",
            "(2)\t 403\t [ 0.1558624 -0.7133082  1.3198816] \t2\ttrue\n",
            "(0)\t 404\t [ 0.68662345 -2.2472422   1.079529  ] \t2\tfalse\n",
            "(2)\t 405\t [-1.4018414 -1.6771765  2.4382784] \t2\ttrue\n",
            "(2)\t 406\t [-1.7867244  -0.83401936  2.1507502 ] \t2\ttrue\n",
            "(2)\t 407\t [ 2.2159967 -1.29436   -1.4951319] \t0\tfalse\n",
            "(2)\t 408\t [-1.8160915 -1.6482661  3.0165997] \t2\ttrue\n",
            "(2)\t 409\t [-0.44075537 -1.1336724   1.0840373 ] \t2\ttrue\n",
            "(2)\t 410\t [-1.893625  -1.5116276  3.0849628] \t2\ttrue\n",
            "(2)\t 411\t [ 1.7340164  -1.5885379  -0.42039824] \t0\tfalse\n",
            "(2)\t 412\t [-1.8609217 -1.4556623  3.0192633] \t2\ttrue\n",
            "(2)\t 413\t [-1.6334591 -1.5247006  2.6980283] \t2\ttrue\n",
            "(2)\t 414\t [-1.522727  -1.9234672  2.9698753] \t2\ttrue\n",
            "(0)\t 415\t [-1.6214378 -1.6687558  3.0703888] \t2\tfalse\n",
            "(0)\t 416\t [ 0.00635643 -0.9508765   0.47623926] \t2\tfalse\n",
            "(2)\t 417\t [ 0.05325028 -2.1913188   1.4868644 ] \t2\ttrue\n",
            "(0)\t 418\t [-0.21035871 -1.9378214   1.9673314 ] \t2\tfalse\n",
            "(2)\t 419\t [-1.6415263 -1.334292   2.3477812] \t2\ttrue\n",
            "(0)\t 420\t [-1.6790237 -1.4866002  2.7440245] \t2\tfalse\n",
            "(0)\t 421\t [-1.631948  -1.8565977  3.0186586] \t2\tfalse\n",
            "(2)\t 422\t [-1.5915    -1.7395205  2.869422 ] \t2\ttrue\n",
            "(0)\t 423\t [-1.5663494 -1.7818811  3.050581 ] \t2\tfalse\n",
            "(2)\t 424\t [-1.3877534 -1.9508138  2.9540882] \t2\ttrue\n",
            "(0)\t 425\t [-1.3913227 -2.0544188  2.8848424] \t2\tfalse\n",
            "(2)\t 426\t [-1.9302329 -1.0289865  2.9255612] \t2\ttrue\n",
            "(0)\t 427\t [-1.4285729 -1.6668375  2.9724374] \t2\tfalse\n",
            "(2)\t 428\t [-1.8134521 -1.4830407  2.987032 ] \t2\ttrue\n",
            "(0)\t 429\t [-1.3686217 -1.5456381  2.8542013] \t2\tfalse\n",
            "(2)\t 430\t [-1.849447  -1.5872676  3.0525763] \t2\ttrue\n",
            "(0)\t 431\t [-1.7392913 -1.566629   3.0880694] \t2\tfalse\n",
            "(0)\t 432\t [-1.6563545 -1.487619   2.7699993] \t2\tfalse\n",
            "(2)\t 433\t [-0.814959  -2.1415308  2.379605 ] \t2\ttrue\n",
            "(0)\t 434\t [-1.6010159 -1.8397298  2.9877088] \t2\tfalse\n",
            "(0)\t 435\t [-0.779658  -2.1474452  2.4834652] \t2\tfalse\n",
            "(2)\t 436\t [ 1.924811   -1.9388382  -0.39367643] \t0\tfalse\n",
            "(0)\t 437\t [-1.5575815 -1.9035033  2.9243321] \t2\tfalse\n",
            "(2)\t 438\t [-1.7223853 -1.6772633  3.1337967] \t2\ttrue\n",
            "(0)\t 439\t [-1.5542939 -1.8022068  3.01127  ] \t2\tfalse\n",
            "(0)\t 440\t [-1.2727126 -1.606433   2.593949 ] \t2\tfalse\n",
            "(0)\t 441\t [ 0.06216023 -2.2250235   1.7309115 ] \t2\tfalse\n",
            "(2)\t 442\t [-1.720822  -1.699105   3.1037018] \t2\ttrue\n",
            "(0)\t 443\t [-1.1111152 -2.1314516  2.7699018] \t2\tfalse\n",
            "(0)\t 444\t [-1.7536719 -1.5974735  2.842534 ] \t2\tfalse\n",
            "(0)\t 445\t [-1.6044393 -1.8345654  2.8669944] \t2\tfalse\n",
            "(2)\t 446\t [ 1.3671823  -0.8014     -0.49224877] \t0\tfalse\n",
            "(0)\t 447\t [ 2.788448  -1.7064039 -1.588409 ] \t0\ttrue\n",
            "(2)\t 448\t [-1.3796229 -1.8494711  2.9880533] \t2\ttrue\n",
            "(2)\t 449\t [-0.8069428 -1.9180089  2.0535834] \t2\ttrue\n",
            "(0)\t 450\t [-1.7023069 -1.773927   2.921496 ] \t2\tfalse\n",
            "(0)\t 451\t [-1.7005098 -1.7216057  3.0071838] \t2\tfalse\n",
            "(2)\t 452\t [-1.8894473 -1.614137   3.0761406] \t2\ttrue\n",
            "(0)\t 453\t [ 0.74285036  0.37291712 -1.4709058 ] \t0\ttrue\n",
            "(0)\t 454\t [ 1.5485318  -0.58718044 -0.19695042] \t0\ttrue\n",
            "(2)\t 455\t [-1.5746113 -1.8047647  2.8912528] \t2\ttrue\n",
            "(0)\t 456\t [-1.4714305 -1.9703889  2.689625 ] \t2\tfalse\n",
            "(2)\t 457\t [-1.4396325  0.6683107  1.3048573] \t2\ttrue\n",
            "(0)\t 458\t [ 1.9618491 -1.0504823 -1.1293447] \t0\ttrue\n",
            "(2)\t 459\t [-2.2848685 -0.520962   2.6278043] \t2\ttrue\n",
            "(0)\t 460\t [-1.323858  -1.9672816  2.6692848] \t2\tfalse\n",
            "(2)\t 461\t [-1.4941596 -1.938063   2.936466 ] \t2\ttrue\n",
            "(0)\t 462\t [-1.9123936 -1.3676101  2.7855425] \t2\tfalse\n",
            "(2)\t 463\t [-2.0355616 -1.244119   3.0667558] \t2\ttrue\n",
            "(0)\t 464\t [-1.4716989 -1.9021232  2.9485319] \t2\tfalse\n",
            "(2)\t 465\t [-2.6425629  0.9996605  1.6132996] \t2\ttrue\n",
            "(2)\t 466\t [-1.7100178  2.1494384 -0.5374153] \t1\tfalse\n",
            "(0)\t 467\t [ 1.8425366 -1.2774893 -1.0134178] \t0\ttrue\n",
            "(0)\t 468\t [-1.4268543 -1.8970987  2.994488 ] \t2\tfalse\n",
            "(2)\t 469\t [-2.5389066  1.02566    1.2798406] \t2\ttrue\n",
            "(0)\t 470\t [-1.6406125 -1.8424524  3.0020518] \t2\tfalse\n",
            "(2)\t 471\t [-1.9190742 -1.5126296  3.102778 ] \t2\ttrue\n",
            "(0)\t 472\t [ 2.6305602 -1.8135697 -1.2325848] \t0\ttrue\n",
            "(2)\t 473\t [-1.7972465 -1.6445118  3.0640476] \t2\ttrue\n",
            "(0)\t 474\t [-1.0215769 -2.1067743  2.7574992] \t2\tfalse\n",
            "(0)\t 475\t [ 1.7637926  -2.1239626  -0.06800494] \t0\ttrue\n",
            "(0)\t 476\t [-1.2201387 -2.0599363  2.8799899] \t2\tfalse\n",
            "(2)\t 477\t [ 0.3268444 -1.5996705  1.1780775] \t2\ttrue\n",
            "(2)\t 478\t [-1.9258988 -1.5705242  2.9532948] \t2\ttrue\n",
            "(0)\t 479\t [ 2.248731  -1.8831955 -0.84673  ] \t0\ttrue\n",
            "(0)\t 480\t [-1.600107  -1.8518237  3.015009 ] \t2\tfalse\n",
            "(2)\t 481\t [-1.6200553 -1.867672   2.9613774] \t2\ttrue\n",
            "(0)\t 482\t [-1.4103256 -2.0387032  2.94339  ] \t2\tfalse\n",
            "(2)\t 483\t [ 1.6750617 -2.11971    0.2155536] \t0\tfalse\n",
            "(2)\t 484\t [-1.7216228 -1.5949667  2.831314 ] \t2\ttrue\n",
            "(2)\t 485\t [-1.7494876 -1.6203997  2.7658696] \t2\ttrue\n",
            "(2)\t 486\t [-1.5187757 -1.8885186  3.0169296] \t2\ttrue\n",
            "(0)\t 487\t [-1.3959825 -1.7193859  2.9381363] \t2\tfalse\n",
            "(0)\t 488\t [ 1.5709249  -2.2610626   0.35112208] \t0\ttrue\n",
            "(2)\t 489\t [-1.6710793  -0.50336295  2.049931  ] \t2\ttrue\n",
            "(0)\t 490\t [-0.7373444   1.2045892   0.29119146] \t1\tfalse\n",
            "(2)\t 491\t [-2.3688724 -0.8885534  2.7566214] \t2\ttrue\n",
            "(0)\t 492\t [-1.7357941 -1.4042429  2.696202 ] \t2\tfalse\n",
            "(2)\t 493\t [-1.8049396 -1.6476032  3.1249523] \t2\ttrue\n",
            "(0)\t 494\t [-0.8708234 -2.1247056  2.6728942] \t2\tfalse\n",
            "(2)\t 495\t [-1.802584 -1.804792  3.077273] \t2\ttrue\n",
            "(0)\t 496\t [ 0.6258693 -2.3749313  1.2734238] \t2\tfalse\n",
            "(0)\t 497\t [ 2.3939073 -1.7861899 -1.0974572] \t0\ttrue\n",
            "(2)\t 498\t [-1.8213233 -1.5728428  3.1014416] \t2\ttrue\n",
            "(2)\t 499\t [-2.1044326 -1.0874195  2.9632998] \t2\ttrue\n",
            "(0)\t 500\t [ 2.281206  -1.4321494 -1.293583 ] \t0\ttrue\n",
            "(0)\t 501\t [-1.4056219   0.95821303 -0.01365988] \t1\tfalse\n",
            "(0)\t 502\t [ 1.270647  -2.201023   0.7348249] \t0\ttrue\n",
            "(2)\t 503\t [-2.250688  -1.1077225  2.8301551] \t2\ttrue\n",
            "(0)\t 504\t [-1.5750402 -1.2175682  2.5082383] \t2\tfalse\n",
            "(2)\t 505\t [-1.8905355 -1.266695   2.6312194] \t2\ttrue\n",
            "(0)\t 506\t [ 2.0750384 -0.8215263 -1.5785363] \t0\ttrue\n",
            "(0)\t 507\t [-0.8758956 -2.0832727  2.5039427] \t2\tfalse\n",
            "(2)\t 508\t [-2.0641026 -1.1171969  2.9644246] \t2\ttrue\n",
            "(0)\t 509\t [-1.135974  -1.6343126  2.1262023] \t2\tfalse\n",
            "(0)\t 510\t [ 1.2726792  -1.837222    0.31667864] \t0\ttrue\n",
            "(2)\t 511\t [ 1.1327449  -1.1402721   0.01809663] \t0\tfalse\n",
            "(2)\t 512\t [-1.8309005 -1.6913667  3.1394622] \t2\ttrue\n",
            "(0)\t 513\t [ 0.935961  -2.142535   0.9101434] \t0\ttrue\n",
            "(2)\t 514\t [-2.1275723 -0.1202688  2.3045177] \t2\ttrue\n",
            "(0)\t 515\t [ 1.9609725 -0.8158593 -1.5456915] \t0\ttrue\n",
            "(0)\t 516\t [-0.4804459 -1.8157556  1.6047426] \t2\tfalse\n",
            "(2)\t 517\t [-2.1195745 -1.3702801  2.9803088] \t2\ttrue\n",
            "(2)\t 518\t [-1.5516094 -1.890345   3.049317 ] \t2\ttrue\n",
            "(0)\t 519\t [-0.5824598 -2.3303235  2.365585 ] \t2\tfalse\n",
            "(0)\t 520\t [-0.16078047 -1.2850851   0.83829844] \t2\tfalse\n",
            "(2)\t 521\t [-2.2563853  -0.87282735  2.8366468 ] \t2\ttrue\n",
            "(0)\t 522\t [ 1.5061138  -2.236951    0.39063835] \t0\ttrue\n",
            "(2)\t 523\t [-2.2906272 -1.0035076  2.907122 ] \t2\ttrue\n",
            "(0)\t 524\t [-1.425       0.37393445  1.3919878 ] \t2\tfalse\n",
            "(0)\t 525\t [ 0.6526558  -1.9168063   0.75448996] \t2\tfalse\n",
            "(0)\t 526\t [-1.4431854 -1.940895   2.7880316] \t2\tfalse\n",
            "(2)\t 527\t [-2.3420012  -0.86033964  2.7596655 ] \t2\ttrue\n",
            "(2)\t 528\t [-1.6942434 -1.784527   2.9664078] \t2\ttrue\n",
            "(0)\t 529\t [-0.23183663 -1.1236682   1.0932723 ] \t2\tfalse\n",
            "(2)\t 530\t [-1.5635278 -1.7893227  3.0726624] \t2\ttrue\n",
            "(0)\t 531\t [ 2.553632  -1.9632386 -1.1173673] \t0\ttrue\n",
            "(2)\t 532\t [-2.1018744  -0.27170166  1.8752204 ] \t2\ttrue\n",
            "(2)\t 533\t [-2.5290174  0.5167131  1.9185625] \t2\ttrue\n",
            "(0)\t 534\t [ 2.1797264 -0.9394097 -1.7287936] \t0\ttrue\n",
            "(0)\t 535\t [ 2.5075572 -1.9503787 -1.0302247] \t0\ttrue\n",
            "(0)\t 536\t [-1.9450008 -1.189876   2.4313972] \t2\tfalse\n",
            "(2)\t 537\t [ 1.4847066  -1.3545259  -0.67197037] \t0\tfalse\n",
            "(0)\t 538\t [ 2.3029273 -1.3603628 -1.2599719] \t0\ttrue\n",
            "(2)\t 539\t [-2.4115872  0.5753975  1.496577 ] \t2\ttrue\n",
            "(0)\t 540\t [-1.8492712 -1.5484997  2.8892639] \t2\tfalse\n",
            "(0)\t 541\t [-0.2081551 -1.8961431  1.6539032] \t2\tfalse\n",
            "(0)\t 542\t [-1.7014446 -1.7086277  2.839599 ] \t2\tfalse\n",
            "(2)\t 543\t [-1.7665339 -1.5856423  2.955497 ] \t2\ttrue\n",
            "(2)\t 544\t [-1.921087   1.5321552  0.7676561] \t1\tfalse\n",
            "(0)\t 545\t [-1.6567408 -1.7609864  2.9905639] \t2\tfalse\n",
            "(0)\t 546\t [-1.9074539  -0.24718069  1.6569694 ] \t2\tfalse\n",
            "(2)\t 547\t [-2.2935297 -0.7532386  2.9219182] \t2\ttrue\n",
            "(0)\t 548\t [-1.5443135 -1.6441333  2.7062368] \t2\tfalse\n",
            "(0)\t 549\t [ 1.4265299  -2.1758747   0.27169797] \t0\ttrue\n",
            "(2)\t 550\t [-1.5584081 -1.1986941  2.645323 ] \t2\ttrue\n",
            "(2)\t 551\t [-0.1608084 -2.2845488  1.8865794] \t2\ttrue\n",
            "(2)\t 552\t [-1.4630456 -1.8936627  2.817231 ] \t2\ttrue\n",
            "(0)\t 553\t [-1.6044062 -1.8831488  2.8850186] \t2\tfalse\n",
            "(0)\t 554\t [-1.7000282   0.44387543  1.1075245 ] \t2\tfalse\n",
            "(2)\t 555\t [-0.85558915  0.91074944 -0.35860258] \t1\tfalse\n",
            "(2)\t 556\t [-1.8103331 -1.6898595  3.0897725] \t2\ttrue\n",
            "(0)\t 557\t [-1.6479018 -1.897133   2.923619 ] \t2\tfalse\n",
            "(0)\t 558\t [-0.00276601 -2.232227    1.8111936 ] \t2\tfalse\n",
            "(0)\t 559\t [ 2.538191  -1.9511273 -1.0396327] \t0\ttrue\n",
            "(2)\t 560\t [-1.3325248 -1.6012213  2.502313 ] \t2\ttrue\n",
            "(0)\t 561\t [-0.17981362 -2.0852923   1.8931164 ] \t2\tfalse\n",
            "(0)\t 562\t [ 0.57262856 -1.5431104   0.79142475] \t2\tfalse\n",
            "(2)\t 563\t [-1.3679425 -1.6800079  2.2169542] \t2\ttrue\n",
            "(2)\t 564\t [-1.169243  -1.7821674  2.6833503] \t2\ttrue\n",
            "(0)\t 565\t [-1.5256585 -1.9313866  2.8124096] \t2\tfalse\n",
            "(0)\t 566\t [-1.4648623 -1.1587218  2.3313937] \t2\tfalse\n",
            "(2)\t 567\t [-2.2192397 -0.530655   2.4196925] \t2\ttrue\n",
            "(0)\t 568\t [ 0.76966226 -2.0411575   1.0011238 ] \t2\tfalse\n",
            "(2)\t 569\t [-1.4882181 -1.9727688  2.9724302] \t2\ttrue\n",
            "(0)\t 570\t [-0.74980396 -2.1293685   2.320712  ] \t2\tfalse\n",
            "(2)\t 571\t [-2.0990741 -0.8367396  2.83701  ] \t2\ttrue\n",
            "(0)\t 572\t [-2.1946883 -0.3163861  2.109084 ] \t2\tfalse\n",
            "(2)\t 573\t [-2.0988753 -1.0968674  3.0358932] \t2\ttrue\n",
            "(2)\t 574\t [-2.4443743  -0.09282312  2.2149508 ] \t2\ttrue\n",
            "(0)\t 575\t [-1.2083459 -1.2697933  2.1984046] \t2\tfalse\n",
            "(2)\t 576\t [-1.4542564 -1.8912016  2.83236  ] \t2\ttrue\n",
            "(0)\t 577\t [ 2.272595  -2.0029469 -0.7561542] \t0\ttrue\n",
            "(0)\t 578\t [-1.4157956 -2.1037772  2.9259245] \t2\tfalse\n",
            "(2)\t 579\t [-2.431459   -0.24920684  2.5880837 ] \t2\ttrue\n",
            "(0)\t 580\t [ 2.653559  -1.9196838 -1.2306304] \t0\ttrue\n",
            "(2)\t 581\t [ 2.4308627 -1.843026  -0.8878745] \t0\tfalse\n",
            "(0)\t 582\t [-1.7728816 -1.6282737  2.9317646] \t2\tfalse\n",
            "(2)\t 583\t [-1.7759609 -0.8941208  2.5094757] \t2\ttrue\n",
            "(0)\t 584\t [-1.3666948 -1.8836813  2.9401627] \t2\tfalse\n",
            "(0)\t 585\t [-1.3040192 -2.0101116  2.9355853] \t2\tfalse\n",
            "(2)\t 586\t [-2.0289502 -1.3321227  2.9428089] \t2\ttrue\n",
            "(1)\t 587\t [-2.3406088   1.654507    0.67502654] \t1\ttrue\n",
            "(2)\t 588\t [-1.4428834  -0.77104646  1.4220234 ] \t2\ttrue\n",
            "(0)\t 589\t [ 2.3879108 -1.5893337 -1.326776 ] \t0\ttrue\n",
            "(2)\t 590\t [-1.8404775 -1.4938253  3.0134408] \t2\ttrue\n",
            "(2)\t 591\t [-1.2909105 -1.8498791  2.749423 ] \t2\ttrue\n",
            "(0)\t 592\t [-0.83594745 -1.8694017   2.3622808 ] \t2\tfalse\n",
            "(2)\t 593\t [-1.9972149 -1.5694983  3.0774426] \t2\ttrue\n",
            "(0)\t 594\t [ 2.2529318 -1.0066434 -1.6298778] \t0\ttrue\n",
            "(0)\t 595\t [-1.2336116 -1.9612123  2.6444612] \t2\tfalse\n",
            "(0)\t 596\t [-1.2961824 -1.8336415  2.8943205] \t2\tfalse\n",
            "(2)\t 597\t [-1.8334212 -1.5284313  2.9423206] \t2\ttrue\n",
            "(0)\t 598\t [ 0.19817059 -1.3287096   0.8044825 ] \t2\tfalse\n",
            "(0)\t 599\t [ 0.13556735 -2.3560877   1.6708412 ] \t2\tfalse\n",
            "(2)\t 600\t [-1.5167809 -1.7044724  3.0037599] \t2\ttrue\n",
            "(2)\t 601\t [ 0.45272282 -1.843856    0.9246939 ] \t2\ttrue\n",
            "(0)\t 602\t [-1.194482  -1.5476115  2.3929856] \t2\tfalse\n",
            "(0)\t 603\t [-0.9695072 -1.9128745  2.6133487] \t2\tfalse\n",
            "(2)\t 604\t [-2.5039442  -0.07121572  2.2811599 ] \t2\ttrue\n",
            "(0)\t 605\t [ 0.74277246 -1.8166724   0.8608523 ] \t2\tfalse\n",
            "(2)\t 606\t [-1.9112117 -1.6454792  3.1420274] \t2\ttrue\n",
            "(0)\t 607\t [-0.27089596 -2.1905315   2.0372891 ] \t2\tfalse\n",
            "(0)\t 608\t [-1.8292568 -1.7097659  3.0968447] \t2\tfalse\n",
            "(2)\t 609\t [-1.7146132 -1.4791867  2.930091 ] \t2\ttrue\n",
            "(2)\t 610\t [-1.2716942 -1.7889212  2.632576 ] \t2\ttrue\n",
            "(0)\t 611\t [-1.0111864 -2.050794   2.5625749] \t2\tfalse\n",
            "(0)\t 612\t [-1.5688587 -1.9343877  2.941281 ] \t2\tfalse\n",
            "(0)\t 613\t [-1.6467066 -1.6152017  2.8651803] \t2\tfalse\n",
            "(2)\t 614\t [-1.4573716 -1.5685651  2.449177 ] \t2\ttrue\n",
            "(0)\t 615\t [-1.838289  -1.611087   3.0107648] \t2\tfalse\n",
            "(2)\t 616\t [-2.6436284   0.78747445  1.481626  ] \t2\ttrue\n",
            "(2)\t 617\t [-1.8799881 -1.5966957  3.0060892] \t2\ttrue\n",
            "(0)\t 618\t [-1.5577699 -1.809505   2.897657 ] \t2\tfalse\n",
            "(0)\t 619\t [-0.5189934 -2.1947787  2.2959707] \t2\tfalse\n",
            "(2)\t 620\t [-2.0630434 -1.3286575  2.857775 ] \t2\ttrue\n",
            "(2)\t 621\t [-2.0583591 -1.2205385  2.903804 ] \t2\ttrue\n",
            "(0)\t 622\t [-1.0968657 -2.1543977  2.7413945] \t2\tfalse\n",
            "(2)\t 623\t [-1.8375974 -1.6413541  3.1012082] \t2\ttrue\n",
            "(0)\t 624\t [ 2.6336796 -1.8062445 -1.1423494] \t0\ttrue\n",
            "(2)\t 625\t [-1.8077776 -1.5367075  3.0488572] \t2\ttrue\n",
            "(0)\t 626\t [-0.9364681 -1.1775599  1.9600295] \t2\tfalse\n",
            "(2)\t 627\t [-1.921459  -1.637348   3.0900981] \t2\ttrue\n",
            "(0)\t 628\t [-1.483611  -1.7731025  3.007718 ] \t2\tfalse\n",
            "(2)\t 629\t [-2.009674  -1.097338   2.8730981] \t2\ttrue\n",
            "(0)\t 630\t [-1.3645992 -1.9249945  2.7901824] \t2\tfalse\n",
            "(2)\t 631\t [-1.8308359 -1.7381343  3.0563028] \t2\ttrue\n",
            "(0)\t 632\t [-1.3989642 -1.9049381  3.0024743] \t2\tfalse\n",
            "(2)\t 633\t [-1.9865162   1.5030203  -0.04005128] \t1\tfalse\n",
            "(0)\t 634\t [ 0.7377596 -1.7444029  0.6591433] \t0\ttrue\n",
            "(2)\t 635\t [-1.814682  -1.6363574  3.075544 ] \t2\ttrue\n",
            "(0)\t 636\t [-0.8470579 -1.1363518  2.2404542] \t2\tfalse\n",
            "(2)\t 637\t [-1.9481581 -1.337078   3.0437014] \t2\ttrue\n",
            "(0)\t 638\t [-1.6756943 -1.8186365  2.7423835] \t2\tfalse\n",
            "(0)\t 639\t [-1.8457173 -1.6354239  3.04516  ] \t2\tfalse\n",
            "(0)\t 640\t [-1.2934796 -2.0569315  2.7871487] \t2\tfalse\n",
            "(2)\t 641\t [-2.3302426  -0.04444376  2.3259933 ] \t2\ttrue\n",
            "(2)\t 642\t [-1.4663182 -1.9809122  2.778857 ] \t2\ttrue\n",
            "(0)\t 643\t [ 2.2411144 -1.4481739 -1.2009469] \t0\ttrue\n",
            "(0)\t 644\t [ 1.2610329  -2.2871206   0.66315275] \t0\ttrue\n",
            "(2)\t 645\t [-0.23706873 -2.3282979   2.0971014 ] \t2\ttrue\n",
            "(0)\t 646\t [ 2.4689763 -1.901205  -0.9301268] \t0\ttrue\n",
            "(2)\t 647\t [-1.5082463 -1.8815205  2.8937693] \t2\ttrue\n",
            "(0)\t 648\t [-1.3241085 -1.9125384  2.6683567] \t2\tfalse\n",
            "(2)\t 649\t [-2.3057134   0.15335709  2.276123  ] \t2\ttrue\n",
            "(0)\t 650\t [-1.8249458 -1.7925597  3.0399299] \t2\tfalse\n",
            "(2)\t 651\t [-2.0816572  -0.88207406  2.716084  ] \t2\ttrue\n",
            "(2)\t 652\t [-2.097037  -1.1310183  2.987617 ] \t2\ttrue\n",
            "(2)\t 653\t [-1.5123845 -1.7796745  2.655072 ] \t2\ttrue\n",
            "(2)\t 654\t [-0.86631525 -1.434953    1.5778519 ] \t2\ttrue\n",
            "(2)\t 655\t [-1.953204  -1.5863631  3.0156655] \t2\ttrue\n",
            "(0)\t 656\t [-1.9547459 -1.4215535  2.6957753] \t2\tfalse\n",
            "(2)\t 657\t [-2.3141823 -0.6280396  2.7666352] \t2\ttrue\n",
            "(2)\t 658\t [-2.5821116  -0.16351439  2.1939638 ] \t2\ttrue\n",
            "(0)\t 659\t [-0.21834764 -1.9350843   1.6844298 ] \t2\tfalse\n",
            "(2)\t 660\t [-2.1813734 -1.2553926  2.95519  ] \t2\ttrue\n",
            "(2)\t 661\t [ 1.5211922  -1.3809816  -0.39020705] \t0\tfalse\n",
            "(0)\t 662\t [-1.5591339 -1.8844826  3.023713 ] \t2\tfalse\n",
            "(0)\t 663\t [-1.618555  -1.7080188  3.1071584] \t2\tfalse\n",
            "(2)\t 664\t [-1.4642875 -1.9095347  2.9855566] \t2\ttrue\n",
            "(2)\t 665\t [-2.2562282 -0.6686263  2.6754482] \t2\ttrue\n",
            "(2)\t 666\t [-1.7299528 -1.8332379  3.0486653] \t2\ttrue\n",
            "(0)\t 667\t [ 2.7474964 -1.7047069 -1.5136265] \t0\ttrue\n",
            "(2)\t 668\t [-1.8848718 -1.4775409  3.0767376] \t2\ttrue\n",
            "(0)\t 669\t [-1.5984883 -1.826876   2.9941804] \t2\tfalse\n",
            "(2)\t 670\t [-1.6231531 -1.8127276  3.069544 ] \t2\ttrue\n",
            "(0)\t 671\t [ 0.5976449 -2.28303    1.3770113] \t2\tfalse\n",
            "(0)\t 672\t [-0.5802961  1.5422459 -1.3348151] \t1\tfalse\n",
            "(0)\t 673\t [-2.0619085 -0.6515608  2.1806056] \t2\tfalse\n",
            "(2)\t 674\t [-2.2273536 -0.971673   2.934578 ] \t2\ttrue\n",
            "(2)\t 675\t [-2.225462  -0.8573044  2.7702696] \t2\ttrue\n",
            "(0)\t 676\t [-1.2041805 -1.2927812  2.2343247] \t2\tfalse\n",
            "(2)\t 677\t [-1.9277438 -1.5629376  3.1425815] \t2\ttrue\n",
            "(0)\t 678\t [-1.4146689 -1.8085201  2.7014601] \t2\tfalse\n",
            "(2)\t 679\t [-1.9391829 -1.4826156  2.9148502] \t2\ttrue\n",
            "(0)\t 680\t [-1.63853   -1.7419404  2.890767 ] \t2\tfalse\n",
            "(2)\t 681\t [-1.7837064 -1.6457691  3.048943 ] \t2\ttrue\n",
            "(0)\t 682\t [-1.6851571 -1.7978077  3.0658994] \t2\tfalse\n",
            "(2)\t 683\t [-1.7488513 -1.6545368  3.0747979] \t2\ttrue\n",
            "(0)\t 684\t [ 1.4090041  -2.3792412   0.61486423] \t0\ttrue\n",
            "(0)\t 685\t [-1.4093266 -1.7894992  2.7301102] \t2\tfalse\n",
            "(0)\t 686\t [-1.0984762 -2.0443344  2.7462435] \t2\tfalse\n",
            "(2)\t 687\t [-1.5367576 -1.6655884  2.8717551] \t2\ttrue\n",
            "(2)\t 688\t [-1.825178  -1.6904384  3.0945415] \t2\ttrue\n",
            "(0)\t 689\t [-1.4758006 -1.936395   2.8036604] \t2\tfalse\n",
            "(2)\t 690\t [-1.5058151 -1.8671011  2.8869743] \t2\ttrue\n",
            "(0)\t 691\t [ 2.2801912 -1.2623153 -1.3495916] \t0\ttrue\n",
            "(2)\t 692\t [-1.9801307 -1.4197333  3.0961   ] \t2\ttrue\n",
            "(0)\t 693\t [ 0.1162179 -2.128051   1.4900367] \t2\tfalse\n",
            "(2)\t 694\t [-1.9240153 -1.5333104  2.9854164] \t2\ttrue\n",
            "(0)\t 695\t [-1.4941596 -1.938063   2.936466 ] \t2\tfalse\n",
            "(2)\t 696\t [-1.9476844 -1.6272546  3.0979683] \t2\ttrue\n",
            "(2)\t 697\t [-1.5633043 -1.9091134  3.0248382] \t2\ttrue\n",
            "(2)\t 698\t [ 1.7094655  -1.2916517  -0.70536673] \t0\tfalse\n",
            "(0)\t 699\t [-1.5920053 -1.9399313  2.9517684] \t2\tfalse\n",
            "(0)\t 700\t [ 1.3901983  -2.103041    0.18206118] \t0\ttrue\n",
            "(0)\t 701\t [-1.0825957 -2.0777571  2.8565068] \t2\tfalse\n",
            "(2)\t 702\t [-1.843699  -1.796257   3.0619266] \t2\ttrue\n",
            "(0)\t 703\t [ 1.3262256  -1.9368804   0.25054458] \t0\ttrue\n",
            "(0)\t 704\t [-0.4865677 -2.1439743  2.2479045] \t2\tfalse\n",
            "(0)\t 705\t [-0.14795779 -1.8141057   1.764166  ] \t2\tfalse\n",
            "(2)\t 706\t [-1.6772403 -1.7294345  2.895143 ] \t2\ttrue\n",
            "(0)\t 707\t [ 2.426652  -1.6127064 -1.2548879] \t0\ttrue\n",
            "(2)\t 708\t [-1.8269731 -1.4889867  2.9771497] \t2\ttrue\n",
            "(0)\t 709\t [ 0.7760433  -1.6460706   0.39195234] \t0\ttrue\n",
            "(0)\t 710\t [-0.7424702 -1.9442345  2.2235115] \t2\tfalse\n",
            "(2)\t 711\t [-1.873166   -0.82532984  2.5851157 ] \t2\ttrue\n",
            "(0)\t 712\t [-1.4980501 -1.9611073  2.934368 ] \t2\tfalse\n",
            "(2)\t 713\t [-2.1225152 -1.1962218  3.034929 ] \t2\ttrue\n",
            "(2)\t 714\t [-2.1965811   0.07191702  2.3117318 ] \t2\ttrue\n",
            "(0)\t 715\t [-1.3119876 -1.9687418  2.7961411] \t2\tfalse\n",
            "(2)\t 716\t [-2.2195294 -1.1013964  2.94725  ] \t2\ttrue\n",
            "(2)\t 717\t [-1.775227  -1.6934776  3.0974245] \t2\ttrue\n",
            "(0)\t 718\t [-1.256689  -1.9719056  2.9462917] \t2\tfalse\n",
            "(0)\t 719\t [-1.7448174 -1.7473655  2.8641636] \t2\tfalse\n",
            "(2)\t 720\t [-2.2265356 -0.645877   2.8050442] \t2\ttrue\n",
            "(2)\t 721\t [-2.0905292  -0.95062935  2.904401  ] \t2\ttrue\n",
            "(0)\t 722\t [-0.5150482 -2.344011   2.3568373] \t2\tfalse\n",
            "(2)\t 723\t [-1.6093826 -1.7001154  3.0802393] \t2\ttrue\n",
            "(2)\t 724\t [-2.0984106 -1.2654285  2.942647 ] \t2\ttrue\n",
            "(0)\t 725\t [-0.1243422 -1.8153423  1.5437119] \t2\tfalse\n",
            "(0)\t 726\t [-1.9685777 -1.5382215  3.0496933] \t2\tfalse\n",
            "(2)\t 727\t [-2.0945873 -0.975972   2.9105728] \t2\ttrue\n",
            "(2)\t 728\t [-1.9054832 -1.6082497  3.0939324] \t2\ttrue\n",
            "(0)\t 729\t [-1.0962923 -1.8988476  2.7034962] \t2\tfalse\n",
            "(2)\t 730\t [-1.9136491  -0.93612885  2.890924  ] \t2\ttrue\n",
            "(0)\t 731\t [-1.0185857 -2.0279152  2.6730568] \t2\tfalse\n",
            "(2)\t 732\t [-1.7444979 -1.820254   3.0837483] \t2\ttrue\n",
            "(0)\t 733\t [ 0.8052655 -1.7937987  0.809034 ] \t2\tfalse\n",
            "(2)\t 734\t [-1.7661235 -1.6979758  3.032462 ] \t2\ttrue\n",
            "(0)\t 735\t [-1.4330788 -1.9398025  2.732981 ] \t2\tfalse\n",
            "(2)\t 736\t [-2.1185217 -1.0034126  2.7508388] \t2\ttrue\n",
            "(0)\t 737\t [-1.8081722 -1.6845869  3.0113878] \t2\tfalse\n",
            "(1)\t 738\t [-1.5851637   2.6705742  -0.92464507] \t1\ttrue\n",
            "(0)\t 739\t [ 1.9256706  -1.9482573  -0.31949538] \t0\ttrue\n",
            "(2)\t 740\t [-1.9948199 -1.1295637  2.8490098] \t2\ttrue\n",
            "(2)\t 741\t [-1.8644037 -1.5861536  3.0360126] \t2\ttrue\n",
            "(0)\t 742\t [-0.6281643 -2.2456028  2.5627265] \t2\tfalse\n",
            "(2)\t 743\t [-1.75741   -1.7169368  3.0572126] \t2\ttrue\n",
            "(0)\t 744\t [-1.2847763 -2.0768864  2.740928 ] \t2\tfalse\n",
            "(2)\t 745\t [-2.288092    0.52123326  1.7716378 ] \t2\ttrue\n",
            "(0)\t 746\t [-1.6771582 -1.761165   2.9375265] \t2\tfalse\n",
            "(0)\t 747\t [-1.5380191 -1.9633462  2.8710198] \t2\tfalse\n",
            "(2)\t 748\t [-1.8720062 -1.6590271  3.0204313] \t2\ttrue\n",
            "(0)\t 749\t [-1.1914736 -2.0451286  2.7736366] \t2\tfalse\n",
            "(2)\t 750\t [-2.33629     0.09130514  2.0776582 ] \t2\ttrue\n",
            "(0)\t 751\t [-2.123067  -1.3628844  2.8462193] \t2\tfalse\n",
            "(0)\t 752\t [ 1.5699193  -1.6461108  -0.21936122] \t0\ttrue\n",
            "(2)\t 753\t [ 0.60963386 -2.1436243   1.1818627 ] \t2\ttrue\n",
            "(2)\t 754\t [-1.7869048 -1.6519085  3.025058 ] \t2\ttrue\n",
            "(0)\t 755\t [-1.6961662 -1.6953428  2.757215 ] \t2\tfalse\n",
            "(0)\t 756\t [-1.776296  -1.6776087  2.9919925] \t2\tfalse\n",
            "(1)\t 757\t [-2.3460798  -0.54286057  2.6639993 ] \t2\tfalse\n",
            "(0)\t 758\t [-1.0264773 -1.9484383  2.4688208] \t2\tfalse\n",
            "(0)\t 759\t [ 2.425193  -1.8032159 -0.9311653] \t0\ttrue\n",
            "(2)\t 760\t [-2.1145155 -1.2505919  3.0588021] \t2\ttrue\n",
            "(2)\t 761\t [-2.1502762 -1.0424099  2.8346155] \t2\ttrue\n",
            "(0)\t 762\t [ 2.5501928 -1.8689917 -1.056719 ] \t0\ttrue\n",
            "(0)\t 763\t [-2.3318908  -0.20082045  2.138565  ] \t2\tfalse\n",
            "(2)\t 764\t [-2.2959235 -0.5715048  2.7982035] \t2\ttrue\n",
            "(0)\t 765\t [-0.59527713 -0.89434785  0.6342239 ] \t2\tfalse\n",
            "(2)\t 766\t [-1.6814274 -1.8657043  3.0117702] \t2\ttrue\n",
            "(2)\t 767\t [-2.1197424  -0.42038375  2.3044844 ] \t2\ttrue\n",
            "(0)\t 768\t [ 2.5959926 -1.8679733 -1.0565292] \t0\ttrue\n",
            "(2)\t 769\t [-2.5162172  0.3185402  2.0987406] \t2\ttrue\n",
            "(0)\t 770\t [-1.9616028 -1.5973431  3.0450428] \t2\tfalse\n",
            "(0)\t 771\t [-1.4321678 -1.8335159  2.9895713] \t2\tfalse\n",
            "(0)\t 772\t [ 1.5094593  -2.4826427   0.42928776] \t0\ttrue\n",
            "(0)\t 773\t [ 1.8659536 -1.2098794 -0.9797173] \t0\ttrue\n",
            "(0)\t 774\t [-1.7402928 -1.7666175  3.0256214] \t2\tfalse\n",
            "(2)\t 775\t [-2.0829535  -0.30733293  2.345999  ] \t2\ttrue\n",
            "(2)\t 776\t [-1.7278453 -1.8276777  2.9903257] \t2\ttrue\n",
            "(0)\t 777\t [ 1.4250848  -0.73849535 -0.8279211 ] \t0\ttrue\n",
            "(0)\t 778\t [ 2.247647  -2.121088  -0.5420491] \t0\ttrue\n",
            "(2)\t 779\t [-0.30869675 -2.2903714   2.1668522 ] \t2\ttrue\n",
            "(0)\t 780\t [ 0.19332105 -1.9972255   1.3803431 ] \t2\tfalse\n",
            "(2)\t 781\t [-2.3222668  -0.12405166  2.3275025 ] \t2\ttrue\n",
            "(0)\t 782\t [ 0.53085065 -2.308988    1.1162188 ] \t2\tfalse\n",
            "(0)\t 783\t [ 1.5376195  -2.1077833   0.28057057] \t0\ttrue\n",
            "(2)\t 784\t [ 0.325994  -1.0214207  0.1571919] \t0\tfalse\n",
            "(0)\t 785\t [-1.3557613 -2.0315046  2.874922 ] \t2\tfalse\n",
            "(0)\t 786\t [-1.2959412   0.04735409  0.9773434 ] \t2\tfalse\n",
            "(2)\t 787\t [-2.2388175  -0.98754907  2.8984487 ] \t2\ttrue\n",
            "(2)\t 788\t [-2.4720807 -0.2338013  2.3469322] \t2\ttrue\n",
            "(0)\t 789\t [-0.6798251 -1.1675838  1.5861716] \t2\tfalse\n",
            "(0)\t 790\t [-1.7725011 -1.1106868  2.2855117] \t2\tfalse\n",
            "(2)\t 791\t [-2.1702306 -1.1173668  2.9648087] \t2\ttrue\n",
            "(2)\t 792\t [-2.166746  -1.1510578  2.9687374] \t2\ttrue\n",
            "(0)\t 793\t [-1.4285218 -1.6434549  2.8422556] \t2\tfalse\n",
            "(0)\t 794\t [-1.3327467 -1.9808975  2.9649444] \t2\tfalse\n",
            "(0)\t 795\t [-1.7200427 -1.5037353  2.60047  ] \t2\tfalse\n",
            "(2)\t 796\t [-1.8841999 -1.595428   3.0913494] \t2\ttrue\n",
            "(0)\t 797\t [-1.4196504 -2.0172513  2.932161 ] \t2\tfalse\n",
            "(0)\t 798\t [ 0.3572929 -2.2007906  1.3692242] \t2\tfalse\n",
            "(2)\t 799\t [-1.8841999 -1.595428   3.0913494] \t2\ttrue\n",
            "(2)\t 800\t [-1.7973362 -1.59842    3.0601575] \t2\ttrue\n",
            "(2)\t 801\t [-1.8224955 -1.5708256  3.0365145] \t2\ttrue\n",
            "(0)\t 802\t [-1.4776714 -1.9133596  3.0171568] \t2\tfalse\n",
            "(2)\t 803\t [-1.8725727 -1.5159005  3.1052625] \t2\ttrue\n",
            "(0)\t 804\t [-0.9091561 -2.0755382  2.3713071] \t2\tfalse\n",
            "(0)\t 805\t [-0.50918674 -1.9110627   2.255946  ] \t2\tfalse\n",
            "(2)\t 806\t [-1.8617055 -1.5916134  3.0542572] \t2\ttrue\n",
            "(0)\t 807\t [-1.2208269 -1.9735289  2.7577417] \t2\tfalse\n",
            "(2)\t 808\t [-1.9751258 -1.3443202  3.0529945] \t2\ttrue\n",
            "(2)\t 809\t [-2.0513206 -1.092363   2.918544 ] \t2\ttrue\n",
            "(0)\t 810\t [-0.8903495 -2.1640513  2.688054 ] \t2\tfalse\n",
            "(2)\t 811\t [-2.2079864  1.4003813  0.5639757] \t1\tfalse\n",
            "(0)\t 812\t [-1.5380038 -1.87979    2.8805904] \t2\tfalse\n",
            "(0)\t 813\t [ 2.0066113  -2.0769787  -0.23621906] \t0\ttrue\n",
            "(2)\t 814\t [-1.1220498 -1.1521597  1.4197785] \t2\ttrue\n",
            "(2)\t 815\t [-1.9480847 -1.3789517  3.039384 ] \t2\ttrue\n",
            "(0)\t 816\t [-1.9685844 -1.5229247  3.0430639] \t2\tfalse\n",
            "(2)\t 817\t [-1.7726156 -1.663773   3.0437653] \t2\ttrue\n",
            "(0)\t 818\t [-0.2665604 -2.1468678  2.010949 ] \t2\tfalse\n",
            "(0)\t 819\t [-1.6336247 -1.6564965  3.0882673] \t2\tfalse\n",
            "(2)\t 820\t [-1.8558184 -1.4953883  3.0878708] \t2\ttrue\n",
            "(0)\t 821\t [-1.0272826 -0.7059441  1.1862142] \t2\tfalse\n",
            "(0)\t 822\t [-1.5858194 -1.6028343  2.7593591] \t2\tfalse\n",
            "(0)\t 823\t [-0.7437192 -2.241391   2.4567797] \t2\tfalse\n",
            "(2)\t 824\t [-1.8518826 -0.8751265  2.420017 ] \t2\ttrue\n",
            "(0)\t 825\t [-1.2396095 -2.0686529  2.445626 ] \t2\tfalse\n",
            "(2)\t 826\t [-1.8091644  -0.83933705  2.4616675 ] \t2\ttrue\n",
            "(0)\t 827\t [-1.6860374 -1.7228165  2.8321576] \t2\tfalse\n",
            "(2)\t 828\t [-2.0973115 -1.2834499  3.0423155] \t2\ttrue\n",
            "(2)\t 829\t [-1.9676092 -1.4121552  2.8900566] \t2\ttrue\n",
            "(0)\t 830\t [ 0.19839849 -1.4155644   0.88945484] \t2\tfalse\n",
            "(2)\t 831\t [-1.8270786 -1.6077873  3.052266 ] \t2\ttrue\n",
            "(0)\t 832\t [-1.4960834 -1.9052263  3.0361114] \t2\tfalse\n",
            "(2)\t 833\t [-1.9423283 -1.595881   2.9786   ] \t2\ttrue\n",
            "(0)\t 834\t [-1.6063174 -1.8823004  3.0265496] \t2\tfalse\n",
            "(0)\t 835\t [-0.2730264   0.04711269 -0.38914752] \t1\tfalse\n",
            "(2)\t 836\t [-1.9722621 -1.0433472  2.8310373] \t2\ttrue\n",
            "(2)\t 837\t [-1.7123806 -1.8056674  3.019047 ] \t2\ttrue\n",
            "(0)\t 838\t [-1.3023703 -1.9984131  2.8824759] \t2\tfalse\n",
            "(0)\t 839\t [ 0.08541855 -2.0880618   1.6082747 ] \t2\tfalse\n",
            "(2)\t 840\t [-1.8795552  -0.37484965  2.4126542 ] \t2\ttrue\n",
            "(2)\t 841\t [ 1.5099149  -1.9476496   0.16008829] \t0\tfalse\n",
            "(0)\t 842\t [-1.4465662 -1.940361   2.9078827] \t2\tfalse\n",
            "(2)\t 843\t [ 2.0122995 -1.0046976 -1.5837865] \t0\tfalse\n",
            "(0)\t 844\t [-1.1026113 -2.0025096  2.7413967] \t2\tfalse\n",
            "(2)\t 845\t [-0.7856199  -0.7856089   0.79178923] \t2\ttrue\n",
            "(0)\t 846\t [-0.487021  -1.7105342  1.8088982] \t2\tfalse\n",
            "(2)\t 847\t [-1.4578111 -1.8081266  2.6397955] \t2\ttrue\n",
            "(0)\t 848\t [ 0.24234883 -1.4357775   0.77457196] \t2\tfalse\n",
            "(2)\t 849\t [-1.7500074 -1.7696667  2.9870079] \t2\ttrue\n",
            "(0)\t 850\t [ 0.98379636 -0.77996814 -0.72941935] \t0\ttrue\n",
            "(2)\t 851\t [-1.86264   -1.6613381  3.056278 ] \t2\ttrue\n",
            "(2)\t 852\t [-1.8896987 -1.4806482  3.0810714] \t2\ttrue\n",
            "(0)\t 853\t [-2.0926166  1.5067613  0.0040215] \t1\tfalse\n",
            "(0)\t 854\t [-0.7126238 -1.5074978  1.5572193] \t2\tfalse\n",
            "(0)\t 855\t [-1.5440999 -1.8092862  2.5692704] \t2\tfalse\n",
            "(2)\t 856\t [-2.031386    0.67162335  0.44697085] \t1\tfalse\n",
            "(2)\t 857\t [-1.399719  -1.9609661  2.7288084] \t2\ttrue\n",
            "(0)\t 858\t [ 2.0738053 -1.5837847 -0.7156736] \t0\ttrue\n",
            "(2)\t 859\t [ 2.1801908 -1.1550637 -1.5749072] \t0\tfalse\n",
            "(2)\t 860\t [-1.9850662 -1.4331391  2.9300113] \t2\ttrue\n",
            "(2)\t 861\t [-1.4307897 -1.8541136  2.9932492] \t2\ttrue\n",
            "(0)\t 862\t [-1.1508617 -2.0362866  2.8597653] \t2\tfalse\n",
            "(0)\t 863\t [-1.8144757 -1.6144685  3.0953593] \t2\tfalse\n",
            "(2)\t 864\t [-1.917337  -1.3175709  2.9820402] \t2\ttrue\n",
            "(0)\t 865\t [ 0.79955435 -2.0183303   1.0750583 ] \t2\tfalse\n",
            "(2)\t 866\t [-1.7407247 -1.7669306  3.0364802] \t2\ttrue\n",
            "(0)\t 867\t [-1.3201735 -1.9681648  2.8768842] \t2\tfalse\n",
            "(0)\t 868\t [-1.2750983 -1.9186118  2.952938 ] \t2\tfalse\n",
            "(0)\t 869\t [-1.6596127 -1.8560034  2.840092 ] \t2\tfalse\n",
            "(2)\t 870\t [-1.4631265 -1.9675171  2.845261 ] \t2\ttrue\n",
            "(0)\t 871\t [ 2.1503248 -1.0452431 -1.6755673] \t0\ttrue\n",
            "(0)\t 872\t [-1.7048988 -1.6046402  2.8952305] \t2\tfalse\n",
            "(2)\t 873\t [-2.037163  -1.3328742  2.9457762] \t2\ttrue\n",
            "(0)\t 874\t [ 0.8598053 -2.367016   0.9956326] \t2\tfalse\n",
            "(0)\t 875\t [-1.4970804 -1.6171657  2.7434943] \t2\tfalse\n",
            "(0)\t 876\t [-1.7524692 -1.8848591  2.985116 ] \t2\tfalse\n",
            "(0)\t 877\t [-1.7202016 -1.7261192  3.094155 ] \t2\tfalse\n",
            "(2)\t 878\t [-1.7622631 -1.6636692  3.0867617] \t2\ttrue\n",
            "(2)\t 879\t [-1.3647848 -2.0758605  2.8805246] \t2\ttrue\n",
            "(0)\t 880\t [ 1.4027936  -1.5200664  -0.35930014] \t0\ttrue\n",
            "(0)\t 881\t [ 1.6576482  -2.0580628   0.06791696] \t0\ttrue\n",
            "(2)\t 882\t [-0.19287005 -1.881259    1.6519345 ] \t2\ttrue\n",
            "(0)\t 883\t [-1.3238679 -2.0396457  2.8608243] \t2\tfalse\n",
            "(2)\t 884\t [-2.3907082  -0.48085356  2.403904  ] \t2\ttrue\n",
            "(2)\t 885\t [-0.9966098 -2.018348   2.262453 ] \t2\ttrue\n",
            "(2)\t 886\t [-1.4560088 -1.63947    2.7909305] \t2\ttrue\n",
            "(1)\t 887\t [-2.178752  -1.1504344  2.9986308] \t2\tfalse\n",
            "(1)\t 888\t [-2.401297   1.3392308  0.7741846] \t1\ttrue\n",
            "(1)\t 889\t [-2.6112201  1.4729333  1.0999825] \t1\ttrue\n",
            "(1)\t 890\t [-1.7971259   2.6255026  -0.70162535] \t1\ttrue\n",
            "(2)\t 891\t [ 2.1164465 -0.8087638 -1.6838201] \t0\tfalse\n",
            "(2)\t 892\t [-1.9228582 -1.641616   3.0759275] \t2\ttrue\n",
            "(0)\t 893\t [-1.3229368 -1.1388199  2.0683103] \t2\tfalse\n",
            "(2)\t 894\t [-0.38990754 -0.9725133   0.7833895 ] \t2\ttrue\n",
            "(2)\t 895\t [-1.7906092 -1.7120782  3.1353698] \t2\ttrue\n",
            "(1)\t 896\t [-2.205794    2.1230016   0.02987238] \t1\ttrue\n",
            "(1)\t 897\t [-1.9724348   2.185804    0.11568664] \t1\ttrue\n",
            "(2)\t 898\t [-1.9709461 -1.4874842  3.0710216] \t2\ttrue\n",
            "(1)\t 899\t [-2.6062124   0.76731396  1.6942439 ] \t2\tfalse\n",
            "(2)\t 900\t [-0.2480639 -2.0709631  1.7628264] \t2\ttrue\n",
            "(2)\t 901\t [-1.715812  -1.6435921  2.778505 ] \t2\ttrue\n",
            "(1)\t 902\t [-1.9945011 -1.4230691  2.7729602] \t2\tfalse\n",
            "(1)\t 903\t [-1.2074285 -1.6423796  2.5030372] \t2\tfalse\n",
            "(2)\t 904\t [-2.288089  -0.7293033  2.665088 ] \t2\ttrue\n",
            "(1)\t 905\t [-0.96181923  2.4039335  -0.8890048 ] \t1\ttrue\n",
            "(1)\t 906\t [-1.202925   2.4376335 -1.3506367] \t1\ttrue\n",
            "(1)\t 907\t [-0.6293918  2.3860593 -1.7250953] \t1\ttrue\n",
            "(0)\t 908\t [-1.8169204 -1.8082786  2.9915843] \t2\tfalse\n",
            "(2)\t 909\t [-2.1940348 -0.9875367  2.8399127] \t2\ttrue\n",
            "(2)\t 910\t [-1.7726523 -1.8023398  2.915025 ] \t2\ttrue\n",
            "(0)\t 911\t [ 1.7351427  -0.69636816 -1.0353941 ] \t0\ttrue\n",
            "(0)\t 912\t [ 1.6499037 -1.0833465 -0.6454927] \t0\ttrue\n",
            "(1)\t 913\t [ 2.6047966 -1.6447035 -1.3937975] \t0\tfalse\n",
            "(1)\t 914\t [-1.5926996   2.630646   -0.87575394] \t1\ttrue\n",
            "(1)\t 915\t [-2.3208523 -0.8398352  2.7222154] \t2\tfalse\n",
            "(1)\t 916\t [-0.5346621  2.414024  -2.1753635] \t1\ttrue\n",
            "(1)\t 917\t [-1.99582   -1.4650021  2.955044 ] \t2\tfalse\n",
            "(1)\t 918\t [-2.5630949  -0.27936077  2.5291886 ] \t2\tfalse\n",
            "(2)\t 919\t [-1.7747693 -1.483374   2.6682637] \t2\ttrue\n",
            "(2)\t 920\t [-1.1859862 -1.252857   2.3220546] \t2\ttrue\n",
            "(0)\t 921\t [-1.3320807 -1.8609453  2.8634174] \t2\tfalse\n",
            "(0)\t 922\t [ 2.0720234  -1.412193   -0.82234216] \t0\ttrue\n",
            "(2)\t 923\t [ 1.2052263e+00  1.1915133e-03 -1.0300260e+00] \t0\tfalse\n",
            "(0)\t 924\t [-1.3169659 -2.022351   2.9256873] \t2\tfalse\n",
            "(0)\t 925\t [ 2.1814167 -1.653427  -1.0845933] \t0\ttrue\n",
            "(1)\t 926\t [-2.4358284   0.26324466  2.0710366 ] \t2\tfalse\n",
            "(1)\t 927\t [-0.71613574  1.7221754  -0.9006118 ] \t1\ttrue\n",
            "(1)\t 928\t [-1.9418565 -0.7256296  2.7673414] \t2\tfalse\n",
            "(1)\t 929\t [-2.3066957  -0.19964658  2.119364  ] \t2\tfalse\n",
            "(1)\t 930\t [-1.3683462 -1.3538859  1.8929913] \t2\tfalse\n",
            "(2)\t 931\t [ 0.59112877 -0.8138622  -0.3686006 ] \t0\tfalse\n",
            "(0)\t 932\t [-1.6051787 -0.6122685  1.6417838] \t2\tfalse\n",
            "(1)\t 933\t [-2.675148    0.71616834  1.6318768 ] \t2\tfalse\n",
            "(1)\t 934\t [-2.2203217 -0.8942957  2.8138518] \t2\tfalse\n",
            "(1)\t 935\t [-2.2756755   2.0391772   0.02758497] \t1\ttrue\n",
            "(1)\t 936\t [-2.008363  -1.4240314  2.9665792] \t2\tfalse\n",
            "(2)\t 937\t [ 0.73795605  0.58178437 -1.9477327 ] \t0\tfalse\n",
            "(0)\t 938\t [ 2.1650288  -1.8865354  -0.96762383] \t0\ttrue\n",
            "(1)\t 939\t [-1.6157352   1.9319998  -0.01340484] \t1\ttrue\n",
            "(2)\t 940\t [-1.7807792 -1.7776848  2.997204 ] \t2\ttrue\n",
            "(2)\t 941\t [ 0.9880313  -1.7812802   0.29689828] \t0\tfalse\n",
            "(0)\t 942\t [-1.2632853 -1.8583536  2.779448 ] \t2\tfalse\n",
            "(2)\t 943\t [-2.0808797 -1.2328534  3.039273 ] \t2\ttrue\n",
            "(2)\t 944\t [-2.5618775   0.79383206  1.3707145 ] \t2\ttrue\n",
            "(0)\t 945\t [-1.6688712 -1.3856144  2.5166337] \t2\tfalse\n",
            "(1)\t 946\t [-2.449929    0.32027876  2.0941927 ] \t2\tfalse\n",
            "(1)\t 947\t [-2.5241125  0.6107817  1.8699027] \t2\tfalse\n",
            "(1)\t 948\t [-2.0218186 -1.5395949  2.7939014] \t2\tfalse\n",
            "(1)\t 949\t [-0.91281885  1.9662807  -1.2474961 ] \t1\ttrue\n",
            "(1)\t 950\t [-2.4483585 -0.3713485  2.5677826] \t2\tfalse\n",
            "(0)\t 951\t [0.01684678 0.64167166 0.0188457 ] \t1\tfalse\n",
            "(2)\t 952\t [-2.2856848 -0.7105187  2.5567083] \t2\ttrue\n",
            "(2)\t 953\t [-1.8353512 -1.6454178  2.9026659] \t2\ttrue\n",
            "(2)\t 954\t [-2.3588011 -0.9367147  2.8021584] \t2\ttrue\n",
            "(2)\t 955\t [-1.5792881 -1.902671   3.0510397] \t2\ttrue\n",
            "(0)\t 956\t [-1.5890014 -1.9776185  2.912563 ] \t2\tfalse\n",
            "(0)\t 957\t [ 0.57191706 -2.2158105   0.8631742 ] \t2\tfalse\n",
            "(2)\t 958\t [-1.9270506 -1.3897305  2.8541625] \t2\ttrue\n",
            "(1)\t 959\t [-2.0167832 -0.4305028  2.0966325] \t2\tfalse\n",
            "(2)\t 960\t [-1.7637324 -1.3902218  2.9555297] \t2\ttrue\n",
            "(0)\t 961\t [-0.11733234 -2.3577728   2.093261  ] \t2\tfalse\n",
            "(2)\t 962\t [-0.8511304 -1.9284989  2.050023 ] \t2\ttrue\n",
            "(2)\t 963\t [ 2.573086  -1.6950363 -1.3010205] \t0\tfalse\n",
            "(0)\t 964\t [-1.4619391   0.46581075  1.4068187 ] \t2\tfalse\n",
            "(1)\t 965\t [-1.8236197 -1.8359549  3.0440965] \t2\tfalse\n",
            "(1)\t 966\t [-2.438627    0.59023386  1.8622026 ] \t2\tfalse\n",
            "(2)\t 967\t [-1.4418046 -1.2548695  1.9154725] \t2\ttrue\n",
            "(0)\t 968\t [ 2.5738184 -1.8436356 -1.172457 ] \t0\ttrue\n",
            "(1)\t 969\t [-2.4467456  -0.26095146  2.393743  ] \t2\tfalse\n",
            "(1)\t 970\t [-0.6729741   0.96539146 -1.0346639 ] \t1\ttrue\n",
            "(1)\t 971\t [-0.7748346  1.9461964 -1.6310979] \t1\ttrue\n",
            "(1)\t 972\t [-1.9763846   2.218208   -0.38376698] \t1\ttrue\n",
            "(0)\t 973\t [ 1.9592227  -1.9791033  -0.34465846] \t0\ttrue\n",
            "(2)\t 974\t [-2.1708941 -1.3736718  2.7599092] \t2\ttrue\n",
            "(1)\t 975\t [-1.9411724 -1.3670553  3.076784 ] \t2\tfalse\n",
            "(1)\t 976\t [-2.2999806   0.15994455  1.6112084 ] \t2\tfalse\n",
            "(1)\t 977\t [-2.1012993   0.11150239  2.1382663 ] \t2\tfalse\n",
            "(1)\t 978\t [-2.265086    0.02234588  1.9861845 ] \t2\tfalse\n",
            "(1)\t 979\t [ 2.313136  -0.7349133 -2.1122649] \t0\tfalse\n",
            "(1)\t 980\t [-1.2643856  2.6291387 -1.2985997] \t1\ttrue\n",
            "(1)\t 981\t [-1.5544871  2.6037843 -0.9518164] \t1\ttrue\n",
            "(1)\t 982\t [-0.80609    2.4736753 -1.580412 ] \t1\ttrue\n",
            "(1)\t 983\t [-2.1203423   1.9285383   0.09406476] \t1\ttrue\n",
            "(1)\t 984\t [-1.3963094 -1.2921542  1.8144555] \t2\tfalse\n",
            "(0)\t 985\t [-1.5915    -1.7395205  2.869422 ] \t2\tfalse\n",
            "(2)\t 986\t [-1.4884093 -1.609437   2.7432692] \t2\ttrue\n",
            "(0)\t 987\t [-0.2681008 -2.0744402  2.03208  ] \t2\tfalse\n",
            "(0)\t 988\t [-1.0000179 -1.6689323  2.434466 ] \t2\tfalse\n",
            "(1)\t 989\t [-2.0572078 -0.8719116  2.966746 ] \t2\tfalse\n",
            "(0)\t 990\t [ 1.2757641 -2.4609811  0.7092802] \t0\ttrue\n",
            "(0)\t 991\t [ 2.0944095 -1.6731148 -0.8354562] \t0\ttrue\n",
            "(1)\t 992\t [-2.2382143  -0.89267737  2.8639748 ] \t2\tfalse\n",
            "(0)\t 993\t [-1.6714177 -1.7607224  2.928765 ] \t2\tfalse\n",
            "(0)\t 994\t [-2.1439605   0.67625237  1.1206512 ] \t2\tfalse\n",
            "(2)\t 995\t [-1.9491035  -0.74619395  2.2642846 ] \t2\ttrue\n",
            "(0)\t 996\t [-0.669042  -2.0347924  2.4162717] \t2\tfalse\n",
            "(1)\t 997\t [-0.18359521  2.325051   -2.1411426 ] \t1\ttrue\n",
            "(1)\t 998\t [ 1.0141641   0.29606372 -2.0757322 ] \t0\tfalse\n",
            "(0)\t 999\t [-0.88160557 -1.8234527   2.5164232 ] \t2\tfalse\n",
            "(2)\t 1000\t [-1.4063629  2.4761593 -0.9564601] \t1\tfalse\n",
            "(1)\t 1001\t [-0.7380249  2.28327   -1.6824106] \t1\ttrue\n",
            "(1)\t 1002\t [-2.587283   0.5656831  1.758579 ] \t2\tfalse\n",
            "(1)\t 1003\t [-1.9369879  2.6037762 -0.8417921] \t1\ttrue\n",
            "(1)\t 1004\t [-2.3249376   1.9448597   0.41603625] \t1\ttrue\n",
            "(0)\t 1005\t [ 1.2685251  -2.3406768   0.79498893] \t0\ttrue\n",
            "(0)\t 1006\t [-1.3809814 -1.9868445  2.6935174] \t2\tfalse\n",
            "(1)\t 1007\t [-2.6027951  1.7720321  0.7095215] \t1\ttrue\n",
            "(1)\t 1008\t [-2.4712026  -0.05040017  2.3479528 ] \t2\tfalse\n",
            "(1)\t 1009\t [-0.7942886  2.3560238 -1.6175658] \t1\ttrue\n",
            "(1)\t 1010\t [-2.6526384   0.65514416  1.6824863 ] \t2\tfalse\n",
            "(1)\t 1011\t [-2.3774784 -0.1745942  2.3275995] \t2\tfalse\n",
            "(1)\t 1012\t [-1.4582927   2.2118647  -0.26785538] \t1\ttrue\n",
            "(1)\t 1013\t [-2.6779716   1.5671557   0.97514206] \t1\ttrue\n",
            "(1)\t 1014\t [-1.5316702  2.74423   -1.3812793] \t1\ttrue\n",
            "(0)\t 1015\t [-1.4250547  -0.78698593  1.2071862 ] \t2\tfalse\n",
            "(1)\t 1016\t [-2.1683896   2.4093661  -0.30958295] \t1\ttrue\n",
            "(1)\t 1017\t [-0.1397686  1.3336158 -1.3968085] \t1\ttrue\n",
            "(1)\t 1018\t [ 0.85583043  0.52600694 -1.9116809 ] \t0\tfalse\n",
            "(1)\t 1019\t [-1.6039491  2.7702687 -1.0456223] \t1\ttrue\n",
            "(2)\t 1020\t [-1.1795359 -1.607428   2.2044423] \t2\ttrue\n",
            "(0)\t 1021\t [ 0.8413268 -2.3279514  1.1467519] \t2\tfalse\n",
            "(0)\t 1022\t [-0.6547495 -1.9952124  1.8402804] \t2\tfalse\n",
            "(1)\t 1023\t [-1.831913   2.6493351 -0.7758493] \t1\ttrue\n",
            "(1)\t 1024\t [-2.4640448  -0.46052837  2.6268353 ] \t2\tfalse\n",
            "(1)\t 1025\t [-1.8582299 -1.5232017  3.0715234] \t2\tfalse\n",
            "(1)\t 1026\t [-2.2715883   0.36171773  1.3737534 ] \t2\tfalse\n",
            "(1)\t 1027\t [-0.7203142  2.3755956 -1.5765617] \t1\ttrue\n",
            "(1)\t 1028\t [-0.326138   1.4479887 -0.1951992] \t1\ttrue\n",
            "(1)\t 1029\t [-1.9535146 -1.1236577  2.84601  ] \t2\tfalse\n",
            "(1)\t 1030\t [-0.76685023  2.0910902  -1.6345011 ] \t1\ttrue\n",
            "(0)\t 1031\t [ 2.7923214 -1.6661559 -1.739713 ] \t0\ttrue\n",
            "(2)\t 1032\t [ 0.08350728  0.98903704 -1.5197304 ] \t1\tfalse\n",
            "(0)\t 1033\t [ 0.8719139 -2.5681002  1.107311 ] \t2\tfalse\n",
            "(1)\t 1034\t [-1.8470163 -1.6788045  3.084985 ] \t2\tfalse\n",
            "(1)\t 1035\t [-2.7556574  0.817217   1.6960455] \t2\tfalse\n",
            "(1)\t 1036\t [-1.0527261  2.8347383 -1.57853  ] \t1\ttrue\n",
            "(1)\t 1037\t [-2.25732   -0.4367155  2.7141738] \t2\tfalse\n",
            "(1)\t 1038\t [-2.4076648   0.86987287  1.2507044 ] \t2\tfalse\n",
            "(0)\t 1039\t [-1.5051199 -1.7999284  2.9709423] \t2\tfalse\n",
            "(1)\t 1040\t [-2.4803271  1.557409   0.9293834] \t1\ttrue\n",
            "(0)\t 1041\t [-1.15214   -1.8849419  2.6752803] \t2\tfalse\n",
            "(2)\t 1042\t [-1.8993406 -1.3643528  3.0348206] \t2\ttrue\n",
            "(1)\t 1043\t [-1.3638897 -1.7146943  2.1874611] \t2\tfalse\n",
            "(1)\t 1044\t [-0.8963061  2.5544832 -1.8906014] \t1\ttrue\n",
            "(1)\t 1045\t [-0.61619854  2.4092143  -1.8768165 ] \t1\ttrue\n",
            "(0)\t 1046\t [ 1.7398553 -1.5924817 -0.7736363] \t0\ttrue\n",
            "(2)\t 1047\t [ 2.3912716 -1.1698585 -1.7355028] \t0\tfalse\n",
            "(0)\t 1048\t [-1.562159  -1.8616168  2.8159893] \t2\tfalse\n",
            "(2)\t 1049\t [ 0.7305976   0.41596732 -1.4409065 ] \t0\tfalse\n",
            "(0)\t 1050\t [-0.4997537 -2.1524575  2.3944023] \t2\tfalse\n",
            "(1)\t 1051\t [-1.9663389 -1.5871737  3.0890331] \t2\tfalse\n",
            "(0)\t 1052\t [-1.4920648 -1.787126   2.974498 ] \t2\tfalse\n",
            "(2)\t 1053\t [-2.4492795   0.71372926  1.5956281 ] \t2\ttrue\n",
            "(0)\t 1054\t [ 0.43045247 -2.2495716   1.1115706 ] \t2\tfalse\n",
            "(0)\t 1055\t [ 1.3505733 -1.8830208  0.0337291] \t0\ttrue\n",
            "(1)\t 1056\t [-2.4801884   0.23976052  2.2258658 ] \t2\tfalse\n",
            "(1)\t 1057\t [-2.4056363  -0.45181954  2.4334075 ] \t2\tfalse\n",
            "(1)\t 1058\t [-1.0596781  2.612031  -1.8188623] \t1\ttrue\n",
            "(2)\t 1059\t [-2.0362883 -1.1357831  2.4831164] \t2\ttrue\n",
            "(0)\t 1060\t [-0.2572102   0.43350196  0.67683697] \t2\tfalse\n",
            "(2)\t 1061\t [-1.6588806 -1.861812   3.0656059] \t2\ttrue\n",
            "(0)\t 1062\t [-1.5123335 -1.8649578  2.7295566] \t2\tfalse\n",
            "(1)\t 1063\t [-2.6387074  0.7662812  1.4480969] \t2\tfalse\n",
            "(0)\t 1064\t [ 2.6759174 -2.00546   -1.184003 ] \t0\ttrue\n",
            "(0)\t 1065\t [ 2.1508954  -2.1224983  -0.43975005] \t0\ttrue\n",
            "(1)\t 1066\t [ 2.6765797 -1.4923861 -1.8219409] \t0\tfalse\n",
            "(0)\t 1067\t [-1.3529488 -1.9322228  2.903577 ] \t2\tfalse\n",
            "(0)\t 1068\t [-1.2188532 -1.9971615  2.8536491] \t2\tfalse\n",
            "(2)\t 1069\t [-1.6106681 -1.8421592  3.0562828] \t2\ttrue\n",
            "(0)\t 1070\t [ 0.03334398  1.2525156  -1.6807688 ] \t1\tfalse\n",
            "(1)\t 1071\t [-2.6012607   0.75212836  1.5082427 ] \t2\tfalse\n",
            "(1)\t 1072\t [-1.9400955   2.0322988  -0.02939251] \t1\ttrue\n",
            "(2)\t 1073\t [-0.8873381 -1.910203   2.1774037] \t2\ttrue\n",
            "(0)\t 1074\t [-1.6861054 -1.7831435  3.0568924] \t2\tfalse\n",
            "(1)\t 1075\t [-2.5948455  1.411367   0.759296 ] \t1\ttrue\n",
            "(0)\t 1076\t [ 2.5840237 -1.2491452 -1.8186361] \t0\ttrue\n",
            "(1)\t 1077\t [-2.4250963  -0.54438055  2.5748954 ] \t2\tfalse\n",
            "(1)\t 1078\t [-1.0782607  2.5389657 -1.2837411] \t1\ttrue\n",
            "(1)\t 1079\t [-1.5862731 -1.3350394  2.5587184] \t2\tfalse\n",
            "(1)\t 1080\t [-1.4660934  2.6556032 -1.1773655] \t1\ttrue\n",
            "(1)\t 1081\t [-1.7754148   0.51513934  0.8653371 ] \t2\tfalse\n",
            "(1)\t 1082\t [ 0.2652252  1.5491421 -2.0606344] \t1\ttrue\n",
            "(1)\t 1083\t [ 0.7839509  0.7485378 -0.870413 ] \t0\tfalse\n",
            "(1)\t 1084\t [-1.9393656   2.0186095   0.09379733] \t1\ttrue\n",
            "(2)\t 1085\t [ 1.0534424  0.6022856 -1.9745363] \t0\tfalse\n",
            "(0)\t 1086\t [-1.5761    -1.8550547  2.979595 ] \t2\tfalse\n",
            "(1)\t 1087\t [-1.215892   2.5254064 -1.3058529] \t1\ttrue\n",
            "(0)\t 1088\t [ 2.7114184 -1.6361592 -1.5361314] \t0\ttrue\n",
            "(0)\t 1089\t [-1.3767915 -1.9876184  2.8255134] \t2\tfalse\n",
            "(0)\t 1090\t [-0.9633805 -2.109454   2.1991222] \t2\tfalse\n",
            "(2)\t 1091\t [ 1.1146274 -1.8045218  0.272614 ] \t0\tfalse\n",
            "(1)\t 1092\t [-2.208098  -1.1648202  2.8225093] \t2\tfalse\n",
            "(0)\t 1093\t [-1.6418104 -1.804934   2.9706805] \t2\tfalse\n",
            "(2)\t 1094\t [-2.0087388  -0.96980304  2.5094748 ] \t2\ttrue\n",
            "(0)\t 1095\t [ 0.58865124 -2.4329896   1.416741  ] \t2\tfalse\n",
            "(2)\t 1096\t [-1.6946633 -1.8200239  3.0241058] \t2\ttrue\n",
            "(1)\t 1097\t [-2.2968953   1.5576582   0.17583248] \t1\ttrue\n",
            "(1)\t 1098\t [-2.4899354 -0.3494406  2.4962752] \t2\tfalse\n",
            "(1)\t 1099\t [ 1.4552901  -1.841988    0.05786873] \t0\tfalse\n",
            "(2)\t 1100\t [ 0.9969261 -1.5564711  0.5393191] \t0\tfalse\n",
            "(0)\t 1101\t [-1.2093091 -2.109362   2.7484312] \t2\tfalse\n",
            "(0)\t 1102\t [ 1.1166794   0.22201638 -1.6245636 ] \t0\ttrue\n",
            "(2)\t 1103\t [-2.3481266 -1.0474924  2.7495084] \t2\ttrue\n",
            "(1)\t 1104\t [ 0.28921017 -1.641986    0.81418157] \t2\tfalse\n",
            "(0)\t 1105\t [ 1.391983   -1.8534484   0.11405221] \t0\ttrue\n",
            "(0)\t 1106\t [ 0.68604535 -2.3728774   1.1214825 ] \t2\tfalse\n",
            "(2)\t 1107\t [-1.1222879 -1.1985322  1.67409  ] \t2\ttrue\n",
            "(0)\t 1108\t [ 1.9201308 -1.6150761 -0.5879532] \t0\ttrue\n",
            "(1)\t 1109\t [ 1.6171917  -0.39357474 -1.560476  ] \t0\tfalse\n",
            "(2)\t 1110\t [-1.422726  -1.9005181  3.0018961] \t2\ttrue\n",
            "(0)\t 1111\t [ 0.93975294 -1.9468987   0.85833806] \t0\ttrue\n",
            "(0)\t 1112\t [-1.5245879 -1.9187717  2.9799197] \t2\tfalse\n",
            "(0)\t 1113\t [-1.4641018 -1.8608135  2.83218  ] \t2\tfalse\n",
            "(1)\t 1114\t [-2.2573264  -0.43102473  2.608265  ] \t2\tfalse\n",
            "(1)\t 1115\t [-1.7108126  1.0222641  1.364433 ] \t2\tfalse\n",
            "(1)\t 1116\t [-1.1772535  2.7266505 -1.2788543] \t1\ttrue\n",
            "(1)\t 1117\t [-1.3522416  2.3804095 -1.2066005] \t1\ttrue\n",
            "(0)\t 1118\t [-1.4912528 -1.7573103  2.8261383] \t2\tfalse\n",
            "(1)\t 1119\t [-2.630803   0.3522576  2.0848804] \t2\tfalse\n",
            "(1)\t 1120\t [-2.6817389   0.49493483  1.8871347 ] \t2\tfalse\n",
            "(1)\t 1121\t [-2.5463145   0.58903736  1.6439342 ] \t2\tfalse\n",
            "(2)\t 1122\t [-2.066136    0.04313248  1.6724164 ] \t2\ttrue\n",
            "(0)\t 1123\t [-0.7097738 -2.069638   2.458372 ] \t2\tfalse\n",
            "(2)\t 1124\t [-1.9232225 -1.4921825  3.066887 ] \t2\ttrue\n",
            "(1)\t 1125\t [-2.7503388  1.2546266  1.147654 ] \t1\ttrue\n",
            "(1)\t 1126\t [ 0.6967607  0.3893811 -1.6624731] \t0\tfalse\n",
            "(1)\t 1127\t [ 0.72165185 -0.45729834  0.3190341 ] \t0\tfalse\n",
            "(1)\t 1128\t [-2.4175527   1.4268165   0.42431256] \t1\ttrue\n",
            "(1)\t 1129\t [-1.2630333  2.7116287 -1.2286682] \t1\ttrue\n",
            "(0)\t 1130\t [-0.34377578 -2.1729965   2.10722   ] \t2\tfalse\n",
            "(2)\t 1131\t [-1.6609608 -1.8718103  2.917325 ] \t2\ttrue\n",
            "(0)\t 1132\t [ 0.6826243 -2.1387274  1.0818044] \t2\tfalse\n",
            "(1)\t 1133\t [-2.242429  -0.5148334  1.987664 ] \t2\tfalse\n",
            "(1)\t 1134\t [-2.1788354 -0.8194623  2.5248053] \t2\tfalse\n",
            "(1)\t 1135\t [-1.1263944  2.3790417 -1.5094687] \t1\ttrue\n",
            "(1)\t 1136\t [-0.91136193  2.5866942  -1.7970359 ] \t1\ttrue\n",
            "(2)\t 1137\t [-1.4603359 -1.8887115  2.94304  ] \t2\ttrue\n",
            "(2)\t 1138\t [-1.643205  -1.7982488  2.9729004] \t2\ttrue\n",
            "(0)\t 1139\t [-1.6048427 -1.7202482  2.8872194] \t2\tfalse\n",
            "(1)\t 1140\t [-1.718694    0.6428114   0.57668984] \t1\ttrue\n",
            "(1)\t 1141\t [ 0.72639674 -0.20652649 -0.9007251 ] \t0\tfalse\n",
            "(1)\t 1142\t [ 1.0516549   0.20826143 -0.45978448] \t0\tfalse\n",
            "(1)\t 1143\t [ 0.53348166 -0.27660707 -0.61571324] \t0\tfalse\n",
            "(0)\t 1144\t [-0.9003083 -0.7153492  1.1975332] \t2\tfalse\n",
            "(1)\t 1145\t [-2.5889623   0.20738527  2.1603034 ] \t2\tfalse\n",
            "(1)\t 1146\t [-2.7467268  1.1862432  1.1738002] \t1\ttrue\n",
            "(2)\t 1147\t [-1.8157575 -1.5675802  3.032949 ] \t2\ttrue\n",
            "(0)\t 1148\t [-1.0634192 -1.8969046  2.7014027] \t2\tfalse\n",
            "(1)\t 1149\t [-1.9088222   2.1925638  -0.21579865] \t1\ttrue\n",
            "(1)\t 1150\t [ 1.0077157   0.87793404 -1.9349787 ] \t0\tfalse\n",
            "(1)\t 1151\t [-1.1040096  2.7068882 -1.5541294] \t1\ttrue\n",
            "(1)\t 1152\t [-1.6647613  2.6212962 -1.0129596] \t1\ttrue\n",
            "(0)\t 1153\t [ 1.6984397 -0.636114  -1.4199357] \t0\ttrue\n",
            "(2)\t 1154\t [-1.4827167 -1.8183928  2.504487 ] \t2\ttrue\n",
            "(0)\t 1155\t [ 2.3480375 -1.5699816 -1.0394841] \t0\ttrue\n",
            "(0)\t 1156\t [-1.7014273 -1.6447893  2.9333508] \t2\tfalse\n",
            "(2)\t 1157\t [-2.238234  -0.6102173  2.7822642] \t2\ttrue\n",
            "(2)\t 1158\t [-1.7983966 -1.5344442  3.0768373] \t2\ttrue\n",
            "(0)\t 1159\t [ 1.5689701  -1.996073    0.04025135] \t0\ttrue\n",
            "(2)\t 1160\t [-2.1894195   1.8220286  -0.20120043] \t1\tfalse\n",
            "(0)\t 1161\t [-0.9511366 -2.0882044  2.7764792] \t2\tfalse\n",
            "(1)\t 1162\t [-0.4914213  2.3985848 -1.8994012] \t1\ttrue\n",
            "(2)\t 1163\t [-2.177548    0.46273792  0.9978523 ] \t2\ttrue\n",
            "(1)\t 1164\t [-1.4100914  1.5217125 -1.0082465] \t1\ttrue\n",
            "(1)\t 1165\t [-2.554248   1.4929348  0.8919392] \t1\ttrue\n",
            "(1)\t 1166\t [-2.4216008  -0.23511107  2.4500422 ] \t2\tfalse\n",
            "(1)\t 1167\t [-2.4951787  2.0343235  0.1947041] \t1\ttrue\n",
            "(1)\t 1168\t [-2.3965104   1.8709334   0.44513553] \t1\ttrue\n",
            "(1)\t 1169\t [-2.220124   -0.38526618  2.7088184 ] \t2\tfalse\n",
            "(0)\t 1170\t [-1.3592775 -2.070011   2.8287928] \t2\tfalse\n",
            "(1)\t 1171\t [-2.3719535   1.6708069   0.65547186] \t1\ttrue\n",
            "(1)\t 1172\t [-2.0223877 -1.393191   2.9607306] \t2\tfalse\n",
            "(1)\t 1173\t [-1.3040639   2.263331   -0.88372743] \t1\ttrue\n",
            "(0)\t 1174\t [-1.6333746 -1.809466   2.8615181] \t2\tfalse\n",
            "(2)\t 1175\t [-2.0904882   1.2158538   0.91793257] \t1\tfalse\n",
            "(0)\t 1176\t [-1.7397503 -1.2337321  2.348705 ] \t2\tfalse\n",
            "(2)\t 1177\t [-0.57942456 -1.1972735   1.3415812 ] \t2\ttrue\n",
            "(1)\t 1178\t [-1.7874044   2.1431868   0.05587039] \t1\ttrue\n",
            "(1)\t 1179\t [-1.1345022  2.7021077 -1.7432597] \t1\ttrue\n",
            "(1)\t 1180\t [-1.9360923 -0.7205394  1.982375 ] \t2\tfalse\n",
            "(1)\t 1181\t [-1.1419314 -1.8876361  2.1440504] \t2\tfalse\n",
            "(1)\t 1182\t [-2.3239517   2.073335    0.30905527] \t1\ttrue\n",
            "(1)\t 1183\t [ 0.26200628 -0.14878085 -0.6963609 ] \t0\tfalse\n",
            "(1)\t 1184\t [-1.1782099  2.6172855 -1.176352 ] \t1\ttrue\n",
            "(1)\t 1185\t [-0.7448743  2.2745893 -1.4704728] \t1\ttrue\n",
            "(1)\t 1186\t [-1.9839054 -1.4840986  2.9821703] \t2\tfalse\n",
            "(1)\t 1187\t [-2.1934853   0.40952852  1.2207649 ] \t2\tfalse\n",
            "(2)\t 1188\t [-1.1041585  1.4259648  0.4845378] \t1\tfalse\n",
            "(0)\t 1189\t [ 2.5235023 -1.8630692 -1.0783546] \t0\ttrue\n",
            "(2)\t 1190\t [ 1.7604865 -1.034722  -1.0835791] \t0\tfalse\n",
            "(1)\t 1191\t [ 1.7215797  -0.9264025  -0.93671757] \t0\tfalse\n",
            "(1)\t 1192\t [ 2.1100688 -1.3905789 -1.244134 ] \t0\tfalse\n",
            "(1)\t 1193\t [-2.08587     1.985797   -0.01777586] \t1\ttrue\n",
            "(2)\t 1194\t [-1.5297573 -1.938306   2.9663956] \t2\ttrue\n",
            "(0)\t 1195\t [-0.17931078 -2.289608    1.8730509 ] \t2\tfalse\n",
            "(1)\t 1196\t [-0.70075995  2.2128305  -1.1565995 ] \t1\ttrue\n",
            "(1)\t 1197\t [-2.1876504   1.835873    0.44282594] \t1\ttrue\n",
            "(0)\t 1198\t [-0.5768813 -2.1685424  2.2787864] \t2\tfalse\n",
            "(2)\t 1199\t [-2.0675373 -1.3444873  3.0176604] \t2\ttrue\n",
            "(2)\t 1200\t [-2.173779  -0.6907369  2.7102914] \t2\ttrue\n",
            "(0)\t 1201\t [ 2.113594  -1.0999775 -1.3527266] \t0\ttrue\n",
            "(1)\t 1202\t [-1.1950856  2.5416434 -1.4624248] \t1\ttrue\n",
            "(0)\t 1203\t [ 1.9887066  -2.0899632  -0.29472882] \t0\ttrue\n",
            "(1)\t 1204\t [-1.3725061  2.62887   -1.5190874] \t1\ttrue\n",
            "(0)\t 1205\t [ 1.1979951 -2.2268958  0.7081251] \t0\ttrue\n",
            "(2)\t 1206\t [-1.70395   -1.7598536  3.036676 ] \t2\ttrue\n",
            "(2)\t 1207\t [-1.84428  -1.707203  3.018943] \t2\ttrue\n",
            "(0)\t 1208\t [ 1.1720208  -0.19635518 -1.1040925 ] \t0\ttrue\n",
            "(1)\t 1209\t [-2.232112    1.8006427   0.30708018] \t1\ttrue\n",
            "(0)\t 1210\t [-1.5514598 -1.8828526  2.8096955] \t2\tfalse\n",
            "(2)\t 1211\t [-2.4583778   1.2494999   0.73652554] \t1\tfalse\n",
            "(0)\t 1212\t [-0.26820567 -2.3469365   2.0695288 ] \t2\tfalse\n",
            "(2)\t 1213\t [-1.931648  -1.234117   3.0987651] \t2\ttrue\n",
            "(0)\t 1214\t [ 2.6629877 -1.8688217 -1.3031485] \t0\ttrue\n",
            "(1)\t 1215\t [-2.1560502 -1.0474046  2.9849741] \t2\tfalse\n",
            "(0)\t 1216\t [-1.7012223 -1.7805731  3.087741 ] \t2\tfalse\n",
            "(1)\t 1217\t [-2.3178537  0.4357159  1.4513476] \t2\tfalse\n",
            "(1)\t 1218\t [-1.3776842  2.640158  -1.3669813] \t1\ttrue\n",
            "(0)\t 1219\t [-1.2907676 -1.8809003  2.9284716] \t2\tfalse\n",
            "(0)\t 1220\t [-1.641788  -1.5490094  2.9286861] \t2\tfalse\n",
            "(2)\t 1221\t [-2.1935465  -0.78155553  2.8372262 ] \t2\ttrue\n",
            "(1)\t 1222\t [-1.3923948  2.6654208 -1.0725143] \t1\ttrue\n",
            "(0)\t 1223\t [ 1.1711471  0.2831337 -1.7887145] \t0\ttrue\n",
            "(2)\t 1224\t [ 2.6513364 -1.4824536 -1.7872472] \t0\tfalse\n",
            "(1)\t 1225\t [-1.1320865  2.7103279 -1.560001 ] \t1\ttrue\n",
            "(1)\t 1226\t [-2.1588364 -0.9881743  2.903356 ] \t2\tfalse\n",
            "(1)\t 1227\t [ 1.6888982 -0.0909337 -2.1295836] \t0\tfalse\n",
            "(1)\t 1228\t [-0.43625906  2.40729    -2.024635  ] \t1\ttrue\n",
            "(1)\t 1229\t [-2.4360998  -0.33227068  2.5661116 ] \t2\tfalse\n",
            "(2)\t 1230\t [ 0.03162957 -0.09115081 -0.58025753] \t0\tfalse\n",
            "(2)\t 1231\t [ 0.5185207  -1.7828794   0.99486977] \t2\ttrue\n",
            "(2)\t 1232\t [-1.9007754 -1.6361167  3.1079626] \t2\ttrue\n",
            "(1)\t 1233\t [ 2.517932  -1.8622336 -1.0650021] \t0\tfalse\n",
            "(0)\t 1234\t [-1.0373627 -1.9660344  2.6464655] \t2\tfalse\n",
            "(0)\t 1235\t [ 1.1794773  -2.0857904   0.40980488] \t0\ttrue\n",
            "(0)\t 1236\t [ 2.2052681  -1.7923081  -0.81188637] \t0\ttrue\n",
            "(2)\t 1237\t [-1.4883921  2.3644001 -1.3200761] \t1\tfalse\n",
            "(1)\t 1238\t [-2.1360831 -1.1866935  2.905286 ] \t2\tfalse\n",
            "(0)\t 1239\t [-1.1854776 -2.0408056  2.8428383] \t2\tfalse\n",
            "(2)\t 1240\t [-1.4325016 -1.7245921  2.844706 ] \t2\ttrue\n",
            "(2)\t 1241\t [-2.3091476   1.7498777   0.18648316] \t1\tfalse\n",
            "(0)\t 1242\t [ 1.6586998  -1.652171   -0.54664814] \t0\ttrue\n",
            "(1)\t 1243\t [-1.2968323  2.7234612 -1.6582702] \t1\ttrue\n",
            "(1)\t 1244\t [-1.3568685  2.6650677 -1.3751743] \t1\ttrue\n",
            "(1)\t 1245\t [-1.8477058  2.5850143 -0.7795682] \t1\ttrue\n",
            "(1)\t 1246\t [-0.808242   2.5777524 -1.9441751] \t1\ttrue\n",
            "(1)\t 1247\t [-1.8309726 -1.6770074  2.9588146] \t2\tfalse\n",
            "(1)\t 1248\t [-1.4690186  2.353598  -1.0202223] \t1\ttrue\n",
            "(0)\t 1249\t [-1.4801496   0.9481379   0.02806896] \t1\tfalse\n",
            "(0)\t 1250\t [ 0.60526294  0.4167018  -1.1981583 ] \t0\ttrue\n",
            "(0)\t 1251\t [ 0.6053257  0.4259765 -1.2739515] \t0\ttrue\n",
            "(0)\t 1252\t [ 2.552841  -1.8739356 -1.0869666] \t0\ttrue\n",
            "(1)\t 1253\t [-1.5298879  2.7637491 -1.164714 ] \t1\ttrue\n",
            "(1)\t 1254\t [ 2.2176502  -0.40828794 -2.0636013 ] \t0\tfalse\n",
            "(1)\t 1255\t [-2.5250328   0.15726146  2.2906425 ] \t2\tfalse\n",
            "(2)\t 1256\t [-2.0397303  -0.49560273  2.2136352 ] \t2\ttrue\n",
            "(0)\t 1257\t [ 2.194589  -1.8963351 -0.6702138] \t0\ttrue\n",
            "(1)\t 1258\t [-2.0473604 -1.3918021  2.9225612] \t2\tfalse\n",
            "(2)\t 1259\t [-1.6875296 -1.849439   2.9913235] \t2\ttrue\n",
            "(0)\t 1260\t [ 1.8903407 -1.012027  -1.2955662] \t0\ttrue\n",
            "(0)\t 1261\t [ 2.5844195 -1.7763901 -1.2259302] \t0\ttrue\n",
            "(1)\t 1262\t [-2.484988   -0.17548881  2.4800713 ] \t2\tfalse\n",
            "(1)\t 1263\t [-2.1392946 -1.138144   2.6956508] \t2\tfalse\n",
            "(1)\t 1264\t [-2.0298834 -0.9236245  2.9100363] \t2\tfalse\n",
            "(1)\t 1265\t [-0.6818481   0.40390354  1.3424648 ] \t2\tfalse\n",
            "(1)\t 1266\t [-1.7998593  2.6744618 -0.7158579] \t1\ttrue\n",
            "(2)\t 1267\t [-2.1464024 -1.2524934  2.8569918] \t2\ttrue\n",
            "(1)\t 1268\t [-1.1263547  2.7426805 -1.3513619] \t1\ttrue\n",
            "(0)\t 1269\t [-2.0168612  -0.25772825  1.4944906 ] \t2\tfalse\n",
            "(0)\t 1270\t [-0.87778074 -1.8191692   2.1558444 ] \t2\tfalse\n",
            "(2)\t 1271\t [-1.7909007 -1.73683    2.9833555] \t2\ttrue\n",
            "(0)\t 1272\t [ 1.981653   -2.0918145  -0.33011928] \t0\ttrue\n",
            "(2)\t 1273\t [-1.5099262 -1.6365873  2.8206782] \t2\ttrue\n",
            "(0)\t 1274\t [ 2.292452  -1.7507774 -1.013299 ] \t0\ttrue\n",
            "(1)\t 1275\t [ 1.3651856  -0.10785029 -0.521027  ] \t0\tfalse\n",
            "(1)\t 1276\t [-2.4233055   1.3726264   0.98863393] \t1\ttrue\n",
            "(1)\t 1277\t [-1.4789873   2.4621642  -0.99272203] \t1\ttrue\n",
            "(1)\t 1278\t [-2.514862    0.00654058  2.2282584 ] \t2\tfalse\n",
            "(1)\t 1279\t [-2.237105    1.9864886   0.23969589] \t1\ttrue\n",
            "(0)\t 1280\t [ 1.4793063  -1.6553606  -0.22929075] \t0\ttrue\n",
            "(2)\t 1281\t [-2.0735772 -0.8683333  2.8124707] \t2\ttrue\n",
            "(1)\t 1282\t [-2.2392764   1.6608238   0.06560143] \t1\ttrue\n",
            "(0)\t 1283\t [ 0.12307911 -2.19125     1.7807851 ] \t2\tfalse\n",
            "(2)\t 1284\t [-1.3435137 -1.9452585  2.8876536] \t2\ttrue\n",
            "(0)\t 1285\t [ 1.5304908  -1.6407417  -0.20402136] \t0\ttrue\n",
            "(2)\t 1286\t [-1.7492343 -1.7350708  3.0765016] \t2\ttrue\n",
            "(1)\t 1287\t [-0.9961787  2.3609676 -1.7712266] \t1\ttrue\n",
            "(1)\t 1288\t [-0.82598686  2.6115072  -1.8961709 ] \t1\ttrue\n",
            "(1)\t 1289\t [-2.3298845  1.9385861  0.2496873] \t1\ttrue\n",
            "(1)\t 1290\t [-1.4270594  2.7648807 -1.3821338] \t1\ttrue\n",
            "(1)\t 1291\t [-0.9119253  2.5810876 -1.4553225] \t1\ttrue\n",
            "(0)\t 1292\t [ 1.9265385  -1.6476327  -0.65129256] \t0\ttrue\n",
            "(1)\t 1293\t [-1.7659127   2.255837   -0.59091914] \t1\ttrue\n",
            "(0)\t 1294\t [ 0.75924546 -2.185842    1.0904785 ] \t2\tfalse\n",
            "(2)\t 1295\t [-2.5598521  -0.07845802  2.1052988 ] \t2\ttrue\n",
            "(0)\t 1296\t [ 2.2846708 -1.5337253 -1.0745769] \t0\ttrue\n",
            "(2)\t 1297\t [-1.5033834 -1.8931204  2.8587308] \t2\ttrue\n",
            "(0)\t 1298\t [-0.92348415 -1.7620525   2.5494835 ] \t2\tfalse\n",
            "(0)\t 1299\t [-1.7313334 -1.6769148  2.9118164] \t2\tfalse\n",
            "(2)\t 1300\t [-1.9407535  -0.48802355  2.5215282 ] \t2\ttrue\n",
            "(2)\t 1301\t [ 0.8185273  -0.4493568  -0.79758906] \t0\tfalse\n",
            "(2)\t 1302\t [-1.6725987 -1.772846   2.8535714] \t2\ttrue\n",
            "(0)\t 1303\t [ 2.1826446 -2.188137  -0.3165443] \t0\ttrue\n",
            "(2)\t 1304\t [-0.4556511  -0.39098397  0.58801764] \t2\ttrue\n",
            "(2)\t 1305\t [ 1.470301  -0.5492152 -1.137776 ] \t0\tfalse\n",
            "(0)\t 1306\t [ 1.323427    0.02336843 -1.7603924 ] \t0\ttrue\n",
            "(2)\t 1307\t [ 0.11228084  0.66289127 -1.2985008 ] \t1\tfalse\n",
            "(0)\t 1308\t [-0.67027694 -2.1043086   2.5779984 ] \t2\tfalse\n",
            "(1)\t 1309\t [-1.0740101  2.5377207 -1.3152223] \t1\ttrue\n",
            "(0)\t 1310\t [-1.666518  -1.8589256  2.9775295] \t2\tfalse\n",
            "(0)\t 1311\t [ 1.9693025  -0.70720726 -1.7702408 ] \t0\ttrue\n",
            "(0)\t 1312\t [-0.4857827 -1.9895632  2.1454132] \t2\tfalse\n",
            "(2)\t 1313\t [-0.783667    0.75294214 -0.6596059 ] \t1\tfalse\n",
            "(2)\t 1314\t [ 2.1768968 -1.4058464 -1.2373998] \t0\tfalse\n",
            "(2)\t 1315\t [ 0.5418452  -1.1689392   0.40823004] \t0\tfalse\n",
            "(2)\t 1316\t [-2.0571342 -1.3379289  3.0195599] \t2\ttrue\n",
            "(0)\t 1317\t [ 1.0747925 -1.915051   0.3275884] \t0\ttrue\n",
            "(1)\t 1318\t [-2.3990302 -0.6336703  2.6483026] \t2\tfalse\n",
            "(0)\t 1319\t [ 2.7078009 -1.8584343 -1.2810391] \t0\ttrue\n",
            "(2)\t 1320\t [ 2.258413  -1.4541531 -1.2870634] \t0\tfalse\n",
            "(1)\t 1321\t [ 0.80711275  1.2027425  -2.1549065 ] \t1\ttrue\n",
            "(1)\t 1322\t [-2.3370004 -0.7852205  2.7258158] \t2\tfalse\n",
            "(1)\t 1323\t [ 0.8485948  0.8350306 -2.0617766] \t0\tfalse\n",
            "(1)\t 1324\t [ 0.43637565  1.3586373  -1.8252231 ] \t1\ttrue\n",
            "(1)\t 1325\t [ 0.8485948  0.8350306 -2.0617766] \t0\tfalse\n",
            "(2)\t 1326\t [-2.251116    0.40609902  1.3236237 ] \t2\ttrue\n",
            "(0)\t 1327\t [-0.06300224 -1.7224703   1.3732619 ] \t2\tfalse\n",
            "(1)\t 1328\t [-1.3897763  2.518232  -1.0282471] \t1\ttrue\n",
            "(0)\t 1329\t [-1.711682  -1.8176234  3.0123866] \t2\tfalse\n",
            "(0)\t 1330\t [ 1.3975376  -1.4741918  -0.33856392] \t0\ttrue\n",
            "(1)\t 1331\t [-1.0931584   2.11067    -0.88382804] \t1\ttrue\n",
            "(1)\t 1332\t [-1.5817008  2.1052067 -1.049633 ] \t1\ttrue\n",
            "(2)\t 1333\t [-2.5453293   0.41601005  1.7867125 ] \t2\ttrue\n",
            "(0)\t 1334\t [ 2.739748  -1.641267  -1.5382146] \t0\ttrue\n",
            "(2)\t 1335\t [-2.6099217   0.17910998  2.058902  ] \t2\ttrue\n",
            "(0)\t 1336\t [ 2.5470629 -1.779766  -1.1424583] \t0\ttrue\n",
            "(2)\t 1337\t [-2.3261988   0.09817376  1.5687212 ] \t2\ttrue\n",
            "(0)\t 1338\t [-1.1265353 -1.918321   2.340201 ] \t2\tfalse\n",
            "(0)\t 1339\t [ 1.2926481 -2.2049124  0.5872642] \t0\ttrue\n",
            "(2)\t 1340\t [-2.2644994  -0.85547966  2.78846   ] \t2\ttrue\n",
            "(2)\t 1341\t [-1.778629  -1.6266087  3.1022968] \t2\ttrue\n",
            "(0)\t 1342\t [-0.5237335 -1.9071007  1.9613525] \t2\tfalse\n",
            "(1)\t 1343\t [-1.8728974   0.91145355  0.22890279] \t1\ttrue\n",
            "(0)\t 1344\t [-1.4471178 -1.7112728  2.788326 ] \t2\tfalse\n",
            "(2)\t 1345\t [-2.4152858  -0.77769506  2.5441308 ] \t2\ttrue\n",
            "(0)\t 1346\t [-1.4204123 -1.5957948  2.6153054] \t2\tfalse\n",
            "(1)\t 1347\t [-2.712812   0.4570318  1.781516 ] \t2\tfalse\n",
            "(1)\t 1348\t [-2.1999161 -0.4940423  2.3290894] \t2\tfalse\n",
            "(2)\t 1349\t [-1.5735401 -1.860434   3.078607 ] \t2\ttrue\n",
            "(0)\t 1350\t [-1.5881677 -1.9849827  2.8675091] \t2\tfalse\n",
            "(0)\t 1351\t [ 2.7238424 -1.6263474 -1.625115 ] \t0\ttrue\n",
            "(1)\t 1352\t [-1.8668759  -0.51724917  1.9338205 ] \t2\tfalse\n",
            "(1)\t 1353\t [-1.500905   2.6203253 -1.047022 ] \t1\ttrue\n",
            "(1)\t 1354\t [-1.5165979 -1.184338   2.1039286] \t2\tfalse\n",
            "(1)\t 1355\t [-1.4528496 -1.3035786  2.1075275] \t2\tfalse\n",
            "(1)\t 1356\t [-1.6897228   2.3535368  -0.80506533] \t1\ttrue\n",
            "(1)\t 1357\t [-0.9287785  2.416567  -1.5874578] \t1\ttrue\n",
            "(1)\t 1358\t [-0.94380087  2.2120917  -1.6646942 ] \t1\ttrue\n",
            "(1)\t 1359\t [-2.6423326  1.6165146  0.5105559] \t1\ttrue\n",
            "(1)\t 1360\t [-1.3195665  2.760678  -1.3964689] \t1\ttrue\n",
            "(1)\t 1361\t [-1.6455669  2.6821783 -1.0007038] \t1\ttrue\n",
            "(1)\t 1362\t [ 1.3436099   0.24586001 -2.062366  ] \t0\tfalse\n",
            "(0)\t 1363\t [ 0.06245894 -1.7517465   1.4566542 ] \t2\tfalse\n",
            "(0)\t 1364\t [ 1.8490478  -1.9106398  -0.30066338] \t0\ttrue\n",
            "(1)\t 1365\t [-2.4295137  -0.44366884  2.6638093 ] \t2\tfalse\n",
            "(0)\t 1366\t [-1.5663916 -1.81722    2.748929 ] \t2\tfalse\n",
            "(2)\t 1367\t [-1.9302523 -1.1291374  2.883723 ] \t2\ttrue\n",
            "(0)\t 1368\t [-1.6588551 -1.5890713  2.6336608] \t2\tfalse\n",
            "(2)\t 1369\t [ 0.42356855 -0.04752782 -0.6559413 ] \t0\tfalse\n",
            "(0)\t 1370\t [-1.5859454 -1.559183   2.9839976] \t2\tfalse\n",
            "(1)\t 1371\t [-0.22413103  1.9188197  -1.8501912 ] \t1\ttrue\n",
            "(1)\t 1372\t [ 1.5896473  -0.19139102 -1.7460214 ] \t0\tfalse\n",
            "(0)\t 1373\t [-1.6202588 -1.6960192  2.7658775] \t2\tfalse\n",
            "(0)\t 1374\t [-1.8112519 -1.5642074  2.7233639] \t2\tfalse\n",
            "(1)\t 1375\t [-1.9479178   2.4669294  -0.48745307] \t1\ttrue\n",
            "(1)\t 1376\t [-1.4731724 -1.7616591  2.5796106] \t2\tfalse\n",
            "(0)\t 1377\t [ 1.9377093 -1.5556978 -0.7393359] \t0\ttrue\n",
            "(2)\t 1378\t [ 2.1424906  -0.90902495 -1.620874  ] \t0\tfalse\n",
            "(1)\t 1379\t [-1.4548947  2.65269   -1.1107863] \t1\ttrue\n",
            "(1)\t 1380\t [-1.582712   2.7396405 -1.1502334] \t1\ttrue\n",
            "(2)\t 1381\t [-2.1651309 -1.2776492  2.986264 ] \t2\ttrue\n",
            "(1)\t 1382\t [ 1.3161337  0.6124541 -1.8880116] \t0\tfalse\n",
            "(1)\t 1383\t [-2.6694295   0.54318374  1.8079455 ] \t2\tfalse\n",
            "(0)\t 1384\t [ 2.5834644 -1.6107967 -1.4650391] \t0\ttrue\n",
            "(1)\t 1385\t [-0.58373296  2.2353342  -1.9401212 ] \t1\ttrue\n",
            "(1)\t 1386\t [-0.59991175  2.041618   -1.7228683 ] \t1\ttrue\n",
            "(1)\t 1387\t [ 0.70835924  1.179653   -2.4176385 ] \t1\ttrue\n",
            "(1)\t 1388\t [ 0.75218326  0.9368809  -2.1056    ] \t1\ttrue\n",
            "(1)\t 1389\t [-2.150121  -1.2747508  2.974501 ] \t2\tfalse\n",
            "(1)\t 1390\t [-0.43888065  1.0140709  -1.173687  ] \t1\ttrue\n",
            "(1)\t 1391\t [-1.4198185   2.3371727  -0.66886777] \t1\ttrue\n",
            "(1)\t 1392\t [-1.291648   2.1842747 -1.0427705] \t1\ttrue\n",
            "(1)\t 1393\t [-0.6805058  1.9383236 -1.428726 ] \t1\ttrue\n",
            "(2)\t 1394\t [-0.9914911  2.251636  -1.4512384] \t1\tfalse\n",
            "(0)\t 1395\t [-1.4812245 -2.0223904  2.7420857] \t2\tfalse\n",
            "(2)\t 1396\t [-1.3133053 -1.9956769  2.9407752] \t2\ttrue\n",
            "(2)\t 1397\t [-1.681992  -1.5699207  2.6206384] \t2\ttrue\n",
            "(0)\t 1398\t [ 1.1025488 -2.2695658  0.7271684] \t0\ttrue\n",
            "(0)\t 1399\t [ 2.7827861 -1.717071  -1.645338 ] \t0\ttrue\n",
            "(1)\t 1400\t [-2.3994417  -0.40965673  2.1704688 ] \t2\tfalse\n",
            "Number of true predictions: 788\n",
            "Number of false predictions: 612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRMcHi1uLQdO",
        "colab_type": "code",
        "outputId": "44d91baa-357a-4dd1-f638-1960f5e56507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Accuracy:\",true_count/count_line*100,\"%\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 56.24553890078515 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgrPoBuDDz_d",
        "colab_type": "code",
        "outputId": "94684292-d6c4-4c49-d714-2f1b8e0c775f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "scores = [3.0, 1.0, 0.2]\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    predictions[i][j]=softmax(predictions[i][j])\n",
        "    print(predictions[i][j])\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00695945 0.01004818 0.98299235]\n",
            "[0.0223859  0.01546406 0.96215004]\n",
            "[0.12180378 0.8629621  0.01523409]\n",
            "[0.97537667 0.01395858 0.01066478]\n",
            "[0.01951366 0.9306396  0.04984669]\n",
            "[0.0081327  0.00785318 0.9840141 ]\n",
            "[0.01268791 0.89598167 0.09133045]\n",
            "[0.0154554  0.01461572 0.96992886]\n",
            "[0.22164492 0.33675963 0.44159544]\n",
            "[0.01234147 0.9670601  0.02059847]\n",
            "[0.00821598 0.00882732 0.98295677]\n",
            "[0.01305154 0.00824084 0.9787077 ]\n",
            "[0.0119886  0.91710347 0.07090793]\n",
            "[0.00783718 0.11954761 0.8726152 ]\n",
            "[0.01236934 0.00758957 0.9800411 ]\n",
            "[0.15178283 0.13332595 0.71489125]\n",
            "[0.00689588 0.05098267 0.94212145]\n",
            "[0.01223683 0.03330362 0.9544595 ]\n",
            "[0.01725937 0.93915504 0.04358555]\n",
            "[0.01387152 0.80064964 0.18547884]\n",
            "[0.01372934 0.65722    0.3290506 ]\n",
            "[0.01602755 0.09841242 0.88556004]\n",
            "[0.36705086 0.3975517  0.23539743]\n",
            "[0.01014522 0.03248816 0.9573666 ]\n",
            "[0.00668848 0.00827211 0.98503935]\n",
            "[0.00663589 0.00954827 0.98381585]\n",
            "[0.01188691 0.93921214 0.04890099]\n",
            "[0.01089407 0.7945122  0.19459368]\n",
            "[0.11161719 0.01232995 0.87605286]\n",
            "[0.00872025 0.00789951 0.9833802 ]\n",
            "[0.07485382 0.20087375 0.72427243]\n",
            "[0.01811901 0.01035112 0.9715299 ]\n",
            "[0.00979672 0.88427335 0.10592997]\n",
            "[0.8841976  0.07118724 0.04461509]\n",
            "[0.00738023 0.13199599 0.8606237 ]\n",
            "[0.00814848 0.17297876 0.81887275]\n",
            "[0.00707148 0.01135398 0.9815746 ]\n",
            "[0.01562843 0.00777317 0.9765984 ]\n",
            "[0.00982618 0.00734013 0.9828336 ]\n",
            "[0.01022118 0.00867146 0.98110735]\n",
            "[0.01371298 0.80277956 0.18350749]\n",
            "[0.01622895 0.9677958  0.01597533]\n",
            "[0.00981193 0.57772183 0.41246623]\n",
            "[0.01215112 0.6888401  0.29900873]\n",
            "[0.0105591  0.8794294  0.11001147]\n",
            "[0.01455019 0.0094536  0.9759962 ]\n",
            "[0.01783981 0.1732454  0.8089148 ]\n",
            "[0.01255587 0.01238408 0.97506   ]\n",
            "[0.00575158 0.01938366 0.9748648 ]\n",
            "[0.00895826 0.19263665 0.7984051 ]\n",
            "[0.00689735 0.05452489 0.9385777 ]\n",
            "[0.02673455 0.9098626  0.06340288]\n",
            "[0.00630881 0.0087789  0.9849123 ]\n",
            "[0.5928497  0.3778878  0.02926251]\n",
            "[0.43508762 0.02808645 0.53682595]\n",
            "[0.03254134 0.01023335 0.9572253 ]\n",
            "[0.01052906 0.00711137 0.9823596 ]\n",
            "[0.0098217  0.25410548 0.7360728 ]\n",
            "[0.00859736 0.70316654 0.28823617]\n",
            "[0.01878858 0.7671548  0.21405655]\n",
            "[0.00781095 0.2535556  0.73863345]\n",
            "[0.0086318  0.08718769 0.9041805 ]\n",
            "[0.00648335 0.01015145 0.98336524]\n",
            "[0.00689282 0.0117946  0.9813126 ]\n",
            "[0.00925734 0.00751247 0.9832302 ]\n",
            "[0.00621592 0.02658683 0.96719724]\n",
            "[0.49895987 0.29326192 0.20777822]\n",
            "[0.00713288 0.00856352 0.98430353]\n",
            "[0.01272434 0.70332235 0.28395325]\n",
            "[0.00610143 0.07695746 0.9169411 ]\n",
            "[0.01232999 0.8571866  0.13048336]\n",
            "[0.01088093 0.01399612 0.9751229 ]\n",
            "[0.00598061 0.02715359 0.96686584]\n",
            "[0.0129283  0.9594563  0.02761542]\n",
            "[0.00747403 0.00849081 0.98403513]\n",
            "[0.9595761  0.01252804 0.02789593]\n",
            "[0.00766985 0.06111281 0.9312174 ]\n",
            "[0.00568374 0.01582309 0.97849315]\n",
            "[0.07139469 0.01405515 0.9145502 ]\n",
            "[0.01302748 0.05701607 0.92995644]\n",
            "[0.01237536 0.48760375 0.50002086]\n",
            "[0.02188517 0.9521691  0.02594571]\n",
            "[0.00646854 0.00998915 0.9835423 ]\n",
            "[0.00665091 0.03571991 0.9576292 ]\n",
            "[0.01312096 0.00736582 0.9795132 ]\n",
            "[0.00595565 0.01463509 0.9794093 ]\n",
            "[0.26187855 0.46172872 0.2763928 ]\n",
            "[0.00917559 0.05044993 0.9403745 ]\n",
            "[0.9537631  0.01386427 0.03237266]\n",
            "[0.9150707  0.03878815 0.04614111]\n",
            "[0.1575131  0.7752627  0.06722412]\n",
            "[0.10326351 0.6865421  0.21019445]\n",
            "[0.00780867 0.00747019 0.9847211 ]\n",
            "[0.71934986 0.02607004 0.2545801 ]\n",
            "[0.8869632  0.02543766 0.08759917]\n",
            "[0.03514233 0.06171178 0.9031459 ]\n",
            "[0.01952277 0.00914649 0.9713307 ]\n",
            "[0.00821829 0.01255696 0.97922474]\n",
            "[0.14043391 0.02848642 0.83107966]\n",
            "[0.00642208 0.01653519 0.9770427 ]\n",
            "[0.05236677 0.02358042 0.92405283]\n",
            "[0.00669311 0.0102914  0.9830155 ]\n",
            "[0.6606748  0.27764466 0.06168049]\n",
            "[0.02118918 0.01150985 0.96730095]\n",
            "[0.00651675 0.00961147 0.9838718 ]\n",
            "[0.95222265 0.0150685  0.03270889]\n",
            "[0.00669136 0.00925631 0.9840523 ]\n",
            "[0.04330038 0.01768046 0.93901914]\n",
            "[0.9152649  0.03169663 0.05303845]\n",
            "[0.00607527 0.01163143 0.9822933 ]\n",
            "[0.01510075 0.00813383 0.97676545]\n",
            "[0.83450043 0.13752864 0.02797095]\n",
            "[0.17889062 0.13921176 0.68189764]\n",
            "[0.06223504 0.06261221 0.87515277]\n",
            "[0.83714825 0.0174241  0.14542766]\n",
            "[0.05674672 0.01708062 0.9261727 ]\n",
            "[0.00836071 0.08653754 0.9051018 ]\n",
            "[0.01823822 0.00768841 0.9740734 ]\n",
            "[0.47967577 0.05887813 0.46144602]\n",
            "[0.0252407  0.01307692 0.9616824 ]\n",
            "[0.03529743 0.01051449 0.95418805]\n",
            "[0.01245897 0.00763802 0.97990304]\n",
            "[0.00901657 0.0092425  0.9817409 ]\n",
            "[0.01233577 0.00932079 0.9783434 ]\n",
            "[0.01248668 0.60795623 0.37955704]\n",
            "[0.24845898 0.02848165 0.72305936]\n",
            "[0.5974407  0.05181545 0.3507438 ]\n",
            "[0.9012652  0.03632461 0.06241017]\n",
            "[0.28613213 0.12243281 0.5914351 ]\n",
            "[0.6115072  0.35606155 0.03243126]\n",
            "[0.7532902  0.18089254 0.06581721]\n",
            "[0.61045027 0.08645549 0.30309424]\n",
            "[0.02715842 0.01758762 0.955254  ]\n",
            "[0.03483592 0.01162034 0.9535438 ]\n",
            "[0.61937463 0.17914592 0.20147943]\n",
            "[0.20704184 0.08590177 0.7070564 ]\n",
            "[0.7173539 0.0976526 0.1849935]\n",
            "[0.38002342 0.11930411 0.50067246]\n",
            "[0.00609986 0.03634561 0.9575546 ]\n",
            "[0.02276095 0.01139869 0.9658403 ]\n",
            "[0.88102895 0.04998519 0.06898584]\n",
            "[0.00843581 0.00785269 0.98371154]\n",
            "[0.01034622 0.00740463 0.98224914]\n",
            "[0.00688532 0.11833221 0.87478244]\n",
            "[0.71846926 0.08220695 0.19932377]\n",
            "[0.00654966 0.01635848 0.97709185]\n",
            "[0.01142891 0.00836947 0.98020166]\n",
            "[0.00712302 0.00848569 0.9843912 ]\n",
            "[0.01087805 0.01034344 0.97877854]\n",
            "[0.00829511 0.16161752 0.83008736]\n",
            "[0.00582514 0.01628871 0.9778862 ]\n",
            "[0.0106646  0.00736055 0.9819749 ]\n",
            "[0.00613215 0.02123442 0.9726334 ]\n",
            "[0.00636165 0.04697597 0.94666237]\n",
            "[0.00634234 0.0126733  0.98098433]\n",
            "[0.00893652 0.0087485  0.98231494]\n",
            "[0.16953206 0.01336586 0.81710213]\n",
            "[0.00736018 0.01047626 0.98216355]\n",
            "[0.00685226 0.00803522 0.9851125 ]\n",
            "[0.01022004 0.81059575 0.17918423]\n",
            "[0.0063394  0.01312166 0.98053896]\n",
            "[0.90572345 0.01457815 0.07969832]\n",
            "[0.00766161 0.00763193 0.98470646]\n",
            "[0.01249996 0.00731921 0.9801808 ]\n",
            "[0.0097529 0.0080061 0.982241 ]\n",
            "[0.01030271 0.48506415 0.5046332 ]\n",
            "[0.0692516  0.91781783 0.01293057]\n",
            "[0.02284458 0.9669097  0.01024576]\n",
            "[0.01118147 0.9358725  0.05294608]\n",
            "[0.555534   0.38375205 0.06071397]\n",
            "[0.08278579 0.8236511  0.09356313]\n",
            "[0.01326049 0.01295327 0.9737863 ]\n",
            "[0.00973522 0.00919632 0.98106843]\n",
            "[0.01501142 0.9600507  0.02493788]\n",
            "[0.01538836 0.96756965 0.01704192]\n",
            "[0.921814   0.06043284 0.0177532 ]\n",
            "[0.02246064 0.90797925 0.06956006]\n",
            "[0.02602248 0.95185614 0.02212141]\n",
            "[0.00854858 0.03505105 0.9564004 ]\n",
            "[0.02601154 0.96151847 0.0124701 ]\n",
            "[0.00755321 0.03020807 0.9622388 ]\n",
            "[0.00567408 0.02892945 0.96539646]\n",
            "[0.00852106 0.92132175 0.07015721]\n",
            "[0.9306603  0.03538402 0.03395566]\n",
            "[0.00695964 0.01046946 0.98257095]\n",
            "[0.01309245 0.00857028 0.9783372 ]\n",
            "[0.96131104 0.0128518  0.02583709]\n",
            "[0.48299423 0.37591296 0.14109279]\n",
            "[0.54098666 0.4178943  0.04111909]\n",
            "[0.77074635 0.0738416  0.15541214]\n",
            "[0.37795514 0.02038858 0.6016563 ]\n",
            "[0.01251393 0.8755704  0.11191564]\n",
            "[0.30549085 0.03136872 0.6631405 ]\n",
            "[0.77233547 0.16434506 0.0633195 ]\n",
            "[0.0083785  0.0080315  0.98358995]\n",
            "[0.27587634 0.02068275 0.70344096]\n",
            "[0.01096913 0.9718858  0.01714495]\n",
            "[0.01347566 0.02206748 0.9644569 ]\n",
            "[0.8260493  0.0257021  0.14824854]\n",
            "[0.04112167 0.09572437 0.86315393]\n",
            "[0.95065004 0.01489669 0.03445325]\n",
            "[0.00718174 0.02399369 0.96882457]\n",
            "[0.00899188 0.04196283 0.94904536]\n",
            "[0.0113551  0.00733027 0.9813146 ]\n",
            "[0.00659238 0.008865   0.9845426 ]\n",
            "[0.95061886 0.01905914 0.030322  ]\n",
            "[0.01583502 0.8947428  0.08942226]\n",
            "[0.01603214 0.7875975  0.19637042]\n",
            "[0.01043393 0.75067455 0.23889144]\n",
            "[0.00581453 0.01792956 0.97625595]\n",
            "[0.11204308 0.06018908 0.8277679 ]\n",
            "[0.00705599 0.09189306 0.901051  ]\n",
            "[0.00612618 0.02919164 0.96468216]\n",
            "[0.32737407 0.01996647 0.65265954]\n",
            "[0.00662782 0.01335088 0.9800213 ]\n",
            "[0.01708838 0.96356577 0.01934582]\n",
            "[0.00576154 0.02050791 0.97373056]\n",
            "[0.00854834 0.00724876 0.98420286]\n",
            "[0.06026226 0.9270244  0.01271329]\n",
            "[0.00759654 0.06673148 0.925672  ]\n",
            "[0.01797391 0.9512857  0.03074033]\n",
            "[0.00728783 0.0117303  0.98098195]\n",
            "[0.0064579  0.00911067 0.98443145]\n",
            "[0.00573988 0.01367292 0.98058724]\n",
            "[0.7455036  0.02075644 0.23373994]\n",
            "[0.01078773 0.00887451 0.98033774]\n",
            "[0.00535209 0.02176285 0.9728851 ]\n",
            "[0.00785107 0.00909239 0.9830565 ]\n",
            "[0.01094981 0.00817972 0.9808704 ]\n",
            "[0.8624721  0.06748556 0.07004242]\n",
            "[0.00577869 0.01882487 0.9753964 ]\n",
            "[0.011154   0.9569133  0.03193273]\n",
            "[0.01124687 0.00859271 0.9801604 ]\n",
            "[0.006128   0.01051053 0.9833614 ]\n",
            "[0.7299767  0.12502313 0.14500017]\n",
            "[0.00602549 0.03197445 0.9620001 ]\n",
            "[0.00555451 0.020479   0.97396654]\n",
            "[0.9134733  0.02915132 0.05737539]\n",
            "[0.49565113 0.26744905 0.23689984]\n",
            "[0.00755485 0.00863587 0.98380923]\n",
            "[0.00845171 0.00833875 0.98320955]\n",
            "[0.01326711 0.27124408 0.71548885]\n",
            "[0.17273504 0.5187291  0.30853584]\n",
            "[0.00910232 0.00772449 0.98317325]\n",
            "[0.03275878 0.00818072 0.95906055]\n",
            "[0.0096401  0.00791489 0.98244506]\n",
            "[0.01152625 0.00682017 0.98165363]\n",
            "[0.04040275 0.9458078  0.01378948]\n",
            "[0.01469615 0.01334149 0.9719624 ]\n",
            "[0.05851768 0.0489133  0.892569  ]\n",
            "[0.00634364 0.02183215 0.9718242 ]\n",
            "[0.8753609  0.01676016 0.10787898]\n",
            "[0.05132173 0.00871334 0.93996495]\n",
            "[0.8870243  0.04493595 0.06803977]\n",
            "[0.00625287 0.05037214 0.94337493]\n",
            "[0.13290188 0.06214349 0.80495465]\n",
            "[0.9443215  0.02432205 0.03135644]\n",
            "[0.01404865 0.0086582  0.9772931 ]\n",
            "[0.03398814 0.9498503  0.01616161]\n",
            "[0.0171974  0.92013717 0.06266552]\n",
            "[0.00619241 0.00918874 0.98461884]\n",
            "[0.01940986 0.9625404  0.01804977]\n",
            "[0.01085382 0.96175647 0.02738971]\n",
            "[0.00761426 0.0088522  0.98353356]\n",
            "[0.00903917 0.19441299 0.79654783]\n",
            "[0.01650875 0.9193714  0.0641197 ]\n",
            "[0.00584381 0.01694683 0.9772093 ]\n",
            "[0.01560785 0.9653587  0.01903354]\n",
            "[0.06099944 0.9184406  0.02056001]\n",
            "[0.01969854 0.9665087  0.01379279]\n",
            "[0.21596229 0.76324135 0.02079633]\n",
            "[0.8538463  0.01759532 0.12855838]\n",
            "[0.00709424 0.11753391 0.8753719 ]\n",
            "[0.00678992 0.02794925 0.96526086]\n",
            "[0.01188556 0.00851626 0.9795982 ]\n",
            "[0.02182456 0.03314283 0.94503254]\n",
            "[0.96115905 0.01079254 0.0280484 ]\n",
            "[0.02132672 0.9488099  0.02986331]\n",
            "[0.01846319 0.17347915 0.80805767]\n",
            "[0.8181619  0.10230731 0.07953085]\n",
            "[0.01019692 0.00903597 0.98076713]\n",
            "[0.5506309  0.02533811 0.424031  ]\n",
            "[0.87567276 0.03059043 0.09373673]\n",
            "[0.35842022 0.25082818 0.3907516 ]\n",
            "[0.7690587  0.08041061 0.1505307 ]\n",
            "[0.9126524  0.0654577  0.02188985]\n",
            "[0.95835435 0.02097475 0.02067092]\n",
            "[0.01231456 0.9332793  0.05440622]\n",
            "[0.01609102 0.89182454 0.09208441]\n",
            "[0.00626001 0.02267121 0.9710688 ]\n",
            "[0.08525509 0.8551028  0.0596421 ]\n",
            "[0.696479   0.03732083 0.2662001 ]\n",
            "[0.04646581 0.37964398 0.5738902 ]\n",
            "[0.01224091 0.0076482  0.9801108 ]\n",
            "[0.3093511 0.1439719 0.546677 ]\n",
            "[0.03489803 0.46719182 0.4979102 ]\n",
            "[0.00840804 0.00735807 0.9842339 ]\n",
            "[0.01105196 0.00728614 0.98166186]\n",
            "[0.01359402 0.01294417 0.97346187]\n",
            "[0.00566616 0.01604054 0.9782933 ]\n",
            "[0.01037466 0.956818   0.03280732]\n",
            "[0.9466454  0.01110856 0.04224616]\n",
            "[0.14181432 0.05377781 0.80440784]\n",
            "[0.02476705 0.9575878  0.0176451 ]\n",
            "[0.03890473 0.9425266  0.01856877]\n",
            "[0.95943564 0.01993737 0.02062689]\n",
            "[0.03510623 0.01075356 0.9541402 ]\n",
            "[0.017263   0.02233077 0.96040624]\n",
            "[0.01673437 0.00885401 0.9744116 ]\n",
            "[0.88662875 0.01943813 0.09393314]\n",
            "[0.02103621 0.9618075  0.01715628]\n",
            "[0.01973538 0.95615053 0.02411404]\n",
            "[0.46376035 0.01761481 0.51862484]\n",
            "[0.02284795 0.9648515  0.01230046]\n",
            "[0.00695568 0.00981207 0.9832322 ]\n",
            "[0.00582119 0.02724168 0.9669371 ]\n",
            "[0.00702705 0.00825367 0.9847193 ]\n",
            "[0.40041497 0.01818917 0.58139586]\n",
            "[0.1124206  0.8509581  0.03662135]\n",
            "[0.03350616 0.807836   0.15865777]\n",
            "[0.02059763 0.00876134 0.970641  ]\n",
            "[0.00650133 0.13157123 0.86192745]\n",
            "[0.16638428 0.01317672 0.820439  ]\n",
            "[0.00570452 0.01499054 0.97930497]\n",
            "[0.02032482 0.00777027 0.971905  ]\n",
            "[0.00641413 0.01045258 0.98313326]\n",
            "[0.01018844 0.00729232 0.98251927]\n",
            "[0.01217499 0.00743684 0.98038816]\n",
            "[0.01156319 0.00720063 0.9812362 ]\n",
            "[0.021781   0.9012988  0.07692014]\n",
            "[0.06752444 0.90818685 0.02428864]\n",
            "[0.00670097 0.14507188 0.8482272 ]\n",
            "[0.00734987 0.01118331 0.9814668 ]\n",
            "[0.7019153  0.07144792 0.22663678]\n",
            "[0.01878263 0.88720995 0.09400736]\n",
            "[0.10768107 0.79911155 0.09320744]\n",
            "[0.00674197 0.01368931 0.9795687 ]\n",
            "[0.9661995  0.01757046 0.01622999]\n",
            "[0.01355028 0.43494385 0.55150586]\n",
            "[0.01486218 0.7082664  0.27687138]\n",
            "[0.0157367  0.91762847 0.06663483]\n",
            "[0.01033349 0.56377494 0.42589152]\n",
            "[0.05891132 0.01102739 0.9300613 ]\n",
            "[0.05128904 0.92878264 0.01992827]\n",
            "[0.02053177 0.01587158 0.96359664]\n",
            "[0.00592949 0.0455517  0.94851875]\n",
            "[0.06314967 0.8339223  0.10292804]\n",
            "[0.02923807 0.9568746  0.01388722]\n",
            "[0.00642469 0.01561366 0.97796166]\n",
            "[0.07332411 0.3995659  0.5271099 ]\n",
            "[0.0201168  0.00805024 0.97183293]\n",
            "[0.8057263  0.08597913 0.10829464]\n",
            "[0.6923424  0.08952508 0.21813253]\n",
            "[0.76531005 0.0964528  0.13823712]\n",
            "[0.9669736  0.01421331 0.01881307]\n",
            "[0.00885361 0.10793914 0.88320726]\n",
            "[0.03106886 0.0414074  0.92752373]\n",
            "[0.01541355 0.87063307 0.11395337]\n",
            "[0.59213394 0.26225767 0.14560844]\n",
            "[0.02183264 0.9517154  0.02645193]\n",
            "[0.00744718 0.11245656 0.8800963 ]\n",
            "[0.01346911 0.007102   0.97942895]\n",
            "[0.00983514 0.0182289  0.9719359 ]\n",
            "[0.55788    0.01686186 0.4252581 ]\n",
            "[0.03683763 0.00909519 0.9540672 ]\n",
            "[0.02977176 0.9572612  0.01296705]\n",
            "[0.00706574 0.00874921 0.9841851 ]\n",
            "[0.51392156 0.08708987 0.39898857]\n",
            "[0.00769861 0.01047811 0.9818233 ]\n",
            "[0.00865276 0.01423209 0.97711515]\n",
            "[0.01211363 0.00920369 0.97868264]\n",
            "[0.13041696 0.01984478 0.8497383 ]\n",
            "[0.00963533 0.00721668 0.983148  ]\n",
            "[0.43847293 0.0398656  0.5216615 ]\n",
            "[0.00706308 0.01036985 0.982567  ]\n",
            "[0.01258521 0.00904609 0.97836876]\n",
            "[0.26373762 0.02053973 0.71572274]\n",
            "[0.91929156 0.01806909 0.06263935]\n",
            "[0.82535785 0.07637923 0.09826291]\n",
            "[0.06023892 0.06078627 0.87897485]\n",
            "[0.03945931 0.01164463 0.9488961 ]\n",
            "[0.01394911 0.00831531 0.97773564]\n",
            "[0.64478284 0.02635369 0.3288635 ]\n",
            "[0.01988947 0.00878221 0.9713283 ]\n",
            "[0.00769548 0.01750423 0.9748003 ]\n",
            "[0.23134927 0.09590769 0.672743  ]\n",
            "[0.00717976 0.00837117 0.9844491 ]\n",
            "[0.08486878 0.21517475 0.69995654]\n",
            "[0.0065476  0.00916494 0.9842875 ]\n",
            "[0.04844877 0.03133661 0.9202146 ]\n",
            "[0.00779755 0.00841068 0.9837917 ]\n",
            "[0.9566982  0.01560797 0.02769388]\n",
            "[0.10325553 0.05259166 0.8441528 ]\n",
            "[0.06772739 0.07817881 0.8540938 ]\n",
            "[0.00697606 0.02436647 0.9686575 ]\n",
            "[0.00736611 0.01750226 0.97513163]\n",
            "[0.01404715 0.01203588 0.973917  ]\n",
            "[0.00810264 0.00810389 0.98379344]\n",
            "[0.01427987 0.0091934  0.97652674]\n",
            "[0.00867039 0.01032404 0.98100555]\n",
            "[0.70244664 0.07648277 0.22107062]\n",
            "[0.03906294 0.05578684 0.9051502 ]\n",
            "[0.21635287 0.09071657 0.6929306 ]\n",
            "[0.39455986 0.02098704 0.58445305]\n",
            "[0.02070807 0.015724   0.963568  ]\n",
            "[0.01822103 0.04724192 0.934537  ]\n",
            "[0.9484641  0.02834603 0.02318986]\n",
            "[0.00782895 0.00925953 0.98291147]\n",
            "[0.16408758 0.08206269 0.7538497 ]\n",
            "[0.00676891 0.00991786 0.98331326]\n",
            "[0.8680317  0.03130174 0.10066655]\n",
            "[0.00745408 0.01117882 0.98136705]\n",
            "[0.01279227 0.01426201 0.97294575]\n",
            "[0.01098617 0.0073588  0.981655  ]\n",
            "[0.00900852 0.00859219 0.9823992 ]\n",
            "[0.33514753 0.12868118 0.53617126]\n",
            "[0.1886863  0.01999569 0.791318  ]\n",
            "[0.09996371 0.01776703 0.88226926]\n",
            "[0.01773769 0.02411722 0.9581451 ]\n",
            "[0.01168741 0.01416729 0.97414535]\n",
            "[0.00939433 0.00750415 0.98310155]\n",
            "[0.01130841 0.00975253 0.97893906]\n",
            "[0.00970977 0.00782717 0.9824631 ]\n",
            "[0.01275211 0.00726186 0.9799861 ]\n",
            "[0.0136093  0.00701224 0.9793785 ]\n",
            "[0.0075789  0.01866432 0.9737568 ]\n",
            "[0.01200175 0.00945731 0.97854096]\n",
            "[0.00806707 0.01122565 0.9807072 ]\n",
            "[0.01427275 0.01195723 0.97377   ]\n",
            "[0.00730666 0.0094969  0.9831965 ]\n",
            "[0.00786972 0.00935288 0.9827775 ]\n",
            "[0.01165369 0.01379571 0.9745506 ]\n",
            "[0.03896369 0.0103404  0.95069593]\n",
            "[0.00998437 0.00786409 0.9821515 ]\n",
            "[0.03651542 0.00929938 0.95418525]\n",
            "[0.89332485 0.01875201 0.08792313]\n",
            "[0.01109739 0.00785216 0.98105043]\n",
            "[0.00765822 0.00801169 0.9843301 ]\n",
            "[0.01021479 0.00797191 0.9818133 ]\n",
            "[0.02020249 0.01447011 0.9653274 ]\n",
            "[0.15607709 0.01584995 0.828073  ]\n",
            "[0.00790207 0.00807556 0.9840224 ]\n",
            "[0.02006664 0.00723349 0.9726998 ]\n",
            "[0.00987395 0.01154321 0.97858286]\n",
            "[0.01120116 0.00889857 0.9799003 ]\n",
            "[0.7873391  0.09002405 0.1226369 ]\n",
            "[0.976819   0.01090749 0.01227353]\n",
            "[0.01242463 0.0077666  0.97980875]\n",
            "[0.05319171 0.01751112 0.9292972 ]\n",
            "[0.00963284 0.00896705 0.98140013]\n",
            "[0.00886718 0.00868208 0.9824508 ]\n",
            "[0.00686296 0.0090381  0.984099  ]\n",
            "[0.555534   0.38375205 0.06071397]\n",
            "[0.773562   0.09140441 0.13503361]\n",
            "[0.01126246 0.00894703 0.97979057]\n",
            "[0.01520997 0.00923492 0.97555506]\n",
            "[0.04034216 0.33206815 0.62758976]\n",
            "[0.91355515 0.0449258  0.04151896]\n",
            "[0.00700096 0.0408519  0.9521472 ]\n",
            "[0.01793705 0.00942575 0.97263724]\n",
            "[0.01167877 0.00749225 0.98082906]\n",
            "[0.00889326 0.01533407 0.9757726 ]\n",
            "[0.00596627 0.01316503 0.9808687 ]\n",
            "[0.01179723 0.00767095 0.9805319 ]\n",
            "[0.00911625 0.34802762 0.6428561 ]\n",
            "[0.01935362 0.9181267  0.0625197 ]\n",
            "[0.90772355 0.04008146 0.05219493]\n",
            "[0.0117879  0.00736566 0.98084646]\n",
            "[0.0122143  0.43145964 0.55632603]\n",
            "[0.00946631 0.00773611 0.9827976 ]\n",
            "[0.00648536 0.00973757 0.98377705]\n",
            "[0.9682893  0.01137481 0.02033586]\n",
            "[0.00761288 0.00886913 0.983518  ]\n",
            "[0.02216636 0.00748857 0.9703451 ]\n",
            "[0.8470149  0.01735643 0.13562866]\n",
            "[0.01618651 0.0069893  0.9768242 ]\n",
            "[0.28668174 0.04175661 0.67156166]\n",
            "[0.0074654  0.010651   0.98188365]\n",
            "[0.94223535 0.01512469 0.04264006]\n",
            "[0.0097298  0.00756458 0.9827056 ]\n",
            "[0.01005683 0.00785096 0.98209214]\n",
            "[0.01261029 0.00672704 0.98066264]\n",
            "[0.79691523 0.01792106 0.18516369]\n",
            "[0.01030441 0.01169578 0.97799975]\n",
            "[0.0106897  0.01216263 0.9771477 ]\n",
            "[0.01052851 0.00727428 0.9821973 ]\n",
            "[0.01282357 0.00928018 0.9778962 ]\n",
            "[0.7593275  0.01645198 0.22422059]\n",
            "[0.02196801 0.0706193  0.90741277]\n",
            "[0.09285752 0.647423   0.2597195 ]\n",
            "[0.00575866 0.02530555 0.9689358 ]\n",
            "[0.01156173 0.01610697 0.9723312 ]\n",
            "[0.00711567 0.0083281  0.9845562 ]\n",
            "[0.02787015 0.00795399 0.9641759 ]\n",
            "[0.00748449 0.00746798 0.9850476 ]\n",
            "[0.33776832 0.01680304 0.64542866]\n",
            "[0.9562457  0.01462771 0.02912656]\n",
            "[0.00716004 0.00917971 0.9836602 ]\n",
            "[0.00615087 0.01700668 0.9768424 ]\n",
            "[0.95019376 0.02318048 0.0266257 ]\n",
            "[0.06387988 0.67914826 0.25697184]\n",
            "[0.618715   0.01922045 0.36206454]\n",
            "[0.00605893 0.01900113 0.97494   ]\n",
            "[0.01618924 0.02314593 0.96066487]\n",
            "[0.01054152 0.01967133 0.9697871 ]\n",
            "[0.92497444 0.05107021 0.02395534]\n",
            "[0.03261046 0.00974989 0.95763963]\n",
            "[0.00639854 0.01649365 0.97710776]\n",
            "[0.03608306 0.02192187 0.941995  ]\n",
            "[0.6997741  0.03121368 0.26901227]\n",
            "[0.6987966  0.07197672 0.22922668]\n",
            "[0.00683859 0.00786259 0.98529875]\n",
            "[0.49491692 0.02278025 0.48230287]\n",
            "[0.01080494 0.08042356 0.9087715 ]\n",
            "[0.9155562  0.05697998 0.02746377]\n",
            "[0.10742078 0.0282599  0.8643193 ]\n",
            "[0.00598379 0.01265874 0.98135746]\n",
            "[0.00987272 0.007036   0.9830913 ]\n",
            "[0.04940033 0.00860285 0.9419968 ]\n",
            "[0.24748446 0.08040234 0.6721132 ]\n",
            "[0.00595692 0.02376256 0.9702805 ]\n",
            "[0.739951   0.01752309 0.24252592]\n",
            "[0.00539121 0.01952879 0.97507995]\n",
            "[0.04207055 0.25424096 0.7036885 ]\n",
            "[0.4579223  0.03506619 0.50701153]\n",
            "[0.01420277 0.00863416 0.9771631 ]\n",
            "[0.0058929  0.02593024 0.9681769 ]\n",
            "[0.00929208 0.00848991 0.98221797]\n",
            "[0.19333011 0.07924686 0.727423  ]\n",
            "[0.00952848 0.0076026  0.9828689 ]\n",
            "[0.96490246 0.01053978 0.02455776]\n",
            "[0.01650254 0.1028927  0.88060474]\n",
            "[0.00930706 0.19568443 0.79500854]\n",
            "[0.9396152  0.0415266  0.01885825]\n",
            "[0.96092486 0.01113352 0.02794154]\n",
            "[0.01209499 0.02573666 0.96216834]\n",
            "[0.8516586  0.04979693 0.09854455]\n",
            "[0.94876254 0.02433385 0.02690358]\n",
            "[0.01415764 0.2806867  0.7051557 ]\n",
            "[0.00857504 0.01158402 0.9798409 ]\n",
            "[0.13120149 0.024258   0.8445405 ]\n",
            "[0.01044044 0.01036571 0.97919387]\n",
            "[0.00872642 0.01045673 0.9808169 ]\n",
            "[0.02113456 0.66790897 0.31095642]\n",
            "[0.0094158  0.00848367 0.98210055]\n",
            "[0.02405012 0.12652163 0.8494282 ]\n",
            "[0.00526981 0.02458865 0.97014153]\n",
            "[0.01387944 0.0125609  0.9735597 ]\n",
            "[0.74495184 0.02030597 0.23474216]\n",
            "[0.01441576 0.02065662 0.9649276 ]\n",
            "[0.11277492 0.01348602 0.87373906]\n",
            "[0.01352988 0.00879588 0.9776742 ]\n",
            "[0.01100995 0.00833161 0.9806584 ]\n",
            "[0.03831124 0.32689762 0.6347912 ]\n",
            "[0.11774183 0.68871874 0.19353938]\n",
            "[0.00732966 0.00826808 0.9844022 ]\n",
            "[0.01015533 0.00791506 0.9819296 ]\n",
            "[0.13807811 0.01485533 0.8470665 ]\n",
            "[0.96231127 0.01080512 0.02688354]\n",
            "[0.02081153 0.01590782 0.9632806 ]\n",
            "[0.10992844 0.01635201 0.8737196 ]\n",
            "[0.42281118 0.05096743 0.52622133]\n",
            "[0.02646794 0.01937277 0.9541593 ]\n",
            "[0.02055209 0.01113438 0.9683136 ]\n",
            "[0.01278348 0.00852008 0.97869647]\n",
            "[0.02132546 0.02896366 0.94971085]\n",
            "[0.00910368 0.04926746 0.9416289 ]\n",
            "[0.43092367 0.0259225  0.5431538 ]\n",
            "[0.01134307 0.00698703 0.9816699 ]\n",
            "[0.04385059 0.01103667 0.94511276]\n",
            "[0.00695615 0.02458069 0.9684632 ]\n",
            "[0.01226682 0.08025431 0.9074789 ]\n",
            "[0.00576207 0.01569441 0.97854346]\n",
            "[0.00854214 0.08970827 0.90174955]\n",
            "[0.03114541 0.02928922 0.9395654 ]\n",
            "[0.01344701 0.00868686 0.9778661 ]\n",
            "[0.9413708  0.0130893  0.04553987]\n",
            "[0.01276451 0.00641531 0.9808202 ]\n",
            "[0.00620315 0.05499872 0.9387981 ]\n",
            "[0.9700366  0.01001507 0.01994831]\n",
            "[0.9522667  0.01326271 0.03447064]\n",
            "[0.00887983 0.01026141 0.98085874]\n",
            "[0.01314931 0.03176007 0.95509064]\n",
            "[0.01319205 0.00786661 0.9789413 ]\n",
            "[0.01410955 0.00696404 0.97892636]\n",
            "[0.00678943 0.01362892 0.9795816 ]\n",
            "[0.01320408 0.7174057  0.26939023]\n",
            "[0.048768   0.09547947 0.8557525 ]\n",
            "[0.9586806  0.01796299 0.0233564 ]\n",
            "[0.00765367 0.01082478 0.98152155]\n",
            "[0.01711827 0.0097882  0.9730935 ]\n",
            "[0.03869238 0.01376581 0.9475418 ]\n",
            "[0.0061557 0.0094413 0.984403 ]\n",
            "[0.94428915 0.03626515 0.01944564]\n",
            "[0.02007466 0.0096974  0.9702279 ]\n",
            "[0.0147841  0.00863733 0.9765786 ]\n",
            "[0.00826755 0.01121585 0.9805166 ]\n",
            "[0.3277755  0.07119687 0.6010276 ]\n",
            "[0.1746612  0.01445721 0.81088156]\n",
            "[0.01067075 0.00884467 0.98048455]\n",
            "[0.3698562  0.03720843 0.5929353 ]\n",
            "[0.02642362 0.01856223 0.9550141 ]\n",
            "[0.02676269 0.01041911 0.96281826]\n",
            "[0.00756981 0.0862195  0.9062107 ]\n",
            "[0.45399207 0.03511523 0.5108927 ]\n",
            "[0.00629592 0.00821231 0.9854917 ]\n",
            "[0.08926326 0.01309139 0.89764535]\n",
            "[0.00714449 0.00805129 0.9848043 ]\n",
            "[0.00940751 0.01190472 0.97868776]\n",
            "[0.01952743 0.01164169 0.96883094]\n",
            "[0.02702409 0.00955554 0.96342033]\n",
            "[0.01079583 0.00749047 0.9817137 ]\n",
            "[0.01073819 0.01108188 0.97817993]\n",
            "[0.01937166 0.0173331  0.9632952 ]\n",
            "[0.00769973 0.0096638  0.98263645]\n",
            "[0.01066163 0.32955867 0.6597797 ]\n",
            "[0.00742057 0.00985075 0.98272866]\n",
            "[0.01138041 0.0088477  0.9797719 ]\n",
            "[0.05592924 0.01046778 0.93360305]\n",
            "[0.00713272 0.01486603 0.97800124]\n",
            "[0.0068393  0.01580783 0.97735286]\n",
            "[0.02092404 0.00726717 0.9718088 ]\n",
            "[0.00705118 0.00858004 0.9843688 ]\n",
            "[0.9664541  0.0114011  0.02214484]\n",
            "[0.00763929 0.01001792 0.9823428 ]\n",
            "[0.05026041 0.0394931  0.9102465 ]\n",
            "[0.0065588  0.00871389 0.98472726]\n",
            "[0.01099038 0.00822788 0.9807817 ]\n",
            "[0.00738082 0.01837923 0.9742399 ]\n",
            "[0.01531182 0.0087428  0.9759454 ]\n",
            "[0.00742551 0.00814679 0.98442775]\n",
            "[0.01202341 0.00724913 0.98072743]\n",
            "[0.02452505 0.8037044  0.17177063]\n",
            "[0.49801865 0.0416156  0.46036574]\n",
            "[0.00739761 0.00884172 0.98376065]\n",
            "[0.04224532 0.03163296 0.9261218 ]\n",
            "[0.00666434 0.01227852 0.98105717]\n",
            "[0.01179196 0.01022132 0.97798675]\n",
            "[0.00739075 0.00912048 0.98348874]\n",
            "[0.0164884 0.0076845 0.9758271]\n",
            "[0.00861529 0.08471875 0.906666  ]\n",
            "[0.01401233 0.00837577 0.9776119 ]\n",
            "[0.9460841  0.02364244 0.03027342]\n",
            "[0.63341093 0.01822813 0.34836096]\n",
            "[0.08737879 0.01079435 0.9018269 ]\n",
            "[0.95597535 0.01209208 0.03193265]\n",
            "[0.01200427 0.00826466 0.979731  ]\n",
            "[0.01793931 0.00995988 0.97210085]\n",
            "[0.00905899 0.10593525 0.8850057 ]\n",
            "[0.00759372 0.00784368 0.9845626 ]\n",
            "[0.00796464 0.0264325  0.9656028 ]\n",
            "[0.00605505 0.01590941 0.97803557]\n",
            "[0.0150792  0.01154239 0.97337836]\n",
            "[0.07641027 0.04327085 0.8803189 ]\n",
            "[0.00683493 0.00986395 0.98330116]\n",
            "[0.00931585 0.01587762 0.97480655]\n",
            "[0.00597714 0.03226827 0.96175456]\n",
            "[0.00764129 0.08581243 0.90654624]\n",
            "[0.1268369  0.02278643 0.85037667]\n",
            "[0.00575856 0.01453659 0.97970486]\n",
            "[0.8314093  0.04564748 0.12294326]\n",
            "[0.01004877 0.00725798 0.9826933 ]\n",
            "[0.00871647 0.00797053 0.983313  ]\n",
            "[0.01146076 0.00734252 0.9811967 ]\n",
            "[0.00692024 0.03385383 0.9592259 ]\n",
            "[0.00827529 0.00746323 0.9842615 ]\n",
            "[0.97488755 0.01136023 0.01375221]\n",
            "[0.00688107 0.01034088 0.982778  ]\n",
            "[0.00994496 0.00791436 0.98214066]\n",
            "[0.00901108 0.00745497 0.9835339 ]\n",
            "[0.3090056  0.01733425 0.67366016]\n",
            "[0.10180626 0.85032064 0.04787305]\n",
            "[0.01339047 0.05486586 0.9317436 ]\n",
            "[0.00558624 0.01960895 0.9748048 ]\n",
            "[0.0065484 0.0257228 0.9677288]\n",
            "[0.03025207 0.02768703 0.94206095]\n",
            "[0.00618558 0.00890869 0.9849058 ]\n",
            "[0.01587406 0.01070633 0.9734196 ]\n",
            "[0.0076432  0.01206591 0.9802909 ]\n",
            "[0.01057137 0.0095328  0.97989583]\n",
            "[0.0078314  0.00898969 0.98317885]\n",
            "[0.00850341 0.00759748 0.9838991 ]\n",
            "[0.00790406 0.00868582 0.98341006]\n",
            "[0.6781476  0.01535007 0.30650225]\n",
            "[0.01551562 0.0106087  0.9738757 ]\n",
            "[0.02077537 0.00806803 0.9711566 ]\n",
            "[0.01190103 0.01046247 0.9776365 ]\n",
            "[0.00718863 0.00822552 0.9845858 ]\n",
            "[0.01354419 0.00854514 0.9779107 ]\n",
            "[0.01211204 0.00843942 0.9794485 ]\n",
            "[0.94745183 0.02741992 0.02512827]\n",
            "[0.00613796 0.01074983 0.98311216]\n",
            "[0.19776864 0.02096447 0.7812669 ]\n",
            "[0.00724426 0.01070717 0.9820486 ]\n",
            "[0.01167877 0.00749225 0.98082906]\n",
            "[0.00634021 0.00873504 0.98492473]\n",
            "[0.00999807 0.00707511 0.9829268 ]\n",
            "[0.87787545 0.04365804 0.07846656]\n",
            "[0.01044374 0.00737485 0.9821814 ]\n",
            "[0.7523574  0.02287334 0.22476926]\n",
            "[0.01896017 0.00700889 0.974031  ]\n",
            "[0.00729416 0.00764855 0.9850573 ]\n",
            "[0.72498715 0.02774479 0.247268  ]\n",
            "[0.06026912 0.01148926 0.92824167]\n",
            "[0.12568466 0.02375108 0.85056424]\n",
            "[0.01012929 0.00961416 0.98025656]\n",
            "[0.95896316 0.01688616 0.02415068]\n",
            "[0.00803765 0.01126975 0.98069257]\n",
            "[0.56503457 0.05013769 0.3848278 ]\n",
            "[0.04827556 0.01451469 0.9372097 ]\n",
            "[0.01108764 0.03161613 0.95729625]\n",
            "[0.01165991 0.00733824 0.9810019 ]\n",
            "[0.00564191 0.01424656 0.98011154]\n",
            "[0.00985868 0.09528293 0.89485836]\n",
            "[0.01603816 0.00831629 0.97564554]\n",
            "[0.00557388 0.01705126 0.97737485]\n",
            "[0.00753284 0.00817451 0.9842927 ]\n",
            "[0.01462534 0.00715305 0.9782216 ]\n",
            "[0.0097676  0.00974274 0.9804897 ]\n",
            "[0.006288  0.0305481 0.963164 ]\n",
            "[0.00658809 0.02059736 0.97281456]\n",
            "[0.05310425 0.00852748 0.93836826]\n",
            "[0.00903136 0.008248   0.9827207 ]\n",
            "[0.00633177 0.01456414 0.97910404]\n",
            "[0.15417404 0.02841969 0.81740624]\n",
            "[0.00650671 0.01000605 0.9834872 ]\n",
            "[0.00652564 0.01997247 0.97350186]\n",
            "[0.00663691 0.00893414 0.984429  ]\n",
            "[0.02167321 0.00971355 0.9686132 ]\n",
            "[0.00795385 0.02114021 0.97090596]\n",
            "[0.02411083 0.00878751 0.9671017 ]\n",
            "[0.00787907 0.00730423 0.98481673]\n",
            "[0.48120448 0.03577423 0.48302132]\n",
            "[0.00810313 0.00867459 0.9832223 ]\n",
            "[0.01513697 0.00911951 0.9757435 ]\n",
            "[0.00744671 0.02271172 0.9698416 ]\n",
            "[0.00793386 0.00897753 0.9830887 ]\n",
            "[0.0136157  0.96002716 0.02635723]\n",
            "[0.8875583  0.01844044 0.09400126]\n",
            "[0.00767282 0.01822766 0.9740995 ]\n",
            "[0.00731708 0.00966452 0.9830184 ]\n",
            "[0.03920265 0.00777805 0.95301926]\n",
            "[0.0079782  0.00830773 0.9837141 ]\n",
            "[0.01739958 0.00788007 0.97472036]\n",
            "[0.01323498 0.2196836  0.7670814 ]\n",
            "[0.0097205  0.00893727 0.98134226]\n",
            "[0.01192691 0.00779491 0.9802782 ]\n",
            "[0.00737924 0.00913076 0.98349   ]\n",
            "[0.01846656 0.00786409 0.9736693 ]\n",
            "[0.01053447 0.11937232 0.8700932 ]\n",
            "[0.00679982 0.01454254 0.97865766]\n",
            "[0.82836705 0.03322911 0.13840383]\n",
            "[0.3526177  0.02246877 0.6249135 ]\n",
            "[0.0079925  0.00914768 0.9828598 ]\n",
            "[0.01137426 0.01138364 0.9772421 ]\n",
            "[0.00834576 0.00921139 0.98244286]\n",
            "[0.00637    0.03866054 0.9549694 ]\n",
            "[0.02910543 0.01157634 0.9593183 ]\n",
            "[0.9528913  0.01388893 0.03321968]\n",
            "[0.00555951 0.01318967 0.98125076]\n",
            "[0.0066571  0.02015696 0.97318596]\n",
            "[0.9622976  0.01158996 0.02611245]\n",
            "[0.0103284  0.08700517 0.9026664 ]\n",
            "[0.00589377 0.03305968 0.9610465 ]\n",
            "[0.19375978 0.14367422 0.66256595]\n",
            "[0.00900629 0.00749058 0.9835031 ]\n",
            "[0.01112116 0.0608376  0.9280412 ]\n",
            "[0.9639091  0.01110095 0.02498999]\n",
            "[0.00840267 0.14306606 0.84853125]\n",
            "[0.00658578 0.00947989 0.98393434]\n",
            "[0.01177713 0.00788381 0.980339  ]\n",
            "[0.736378   0.01359418 0.2500278 ]\n",
            "[0.905595   0.04179427 0.05261079]\n",
            "[0.00837434 0.00815676 0.9834689 ]\n",
            "[0.01101959 0.06505903 0.92392135]\n",
            "[0.00878208 0.00794768 0.9832703 ]\n",
            "[0.8196749  0.09419128 0.08613379]\n",
            "[0.9310058  0.01179328 0.05720088]\n",
            "[0.07676913 0.01058172 0.9126491 ]\n",
            "[0.22783391 0.02548449 0.74668163]\n",
            "[0.00872831 0.07863261 0.9126391 ]\n",
            "[0.35037476 0.02047418 0.6291511 ]\n",
            "[0.7630074  0.0199228  0.21706979]\n",
            "[0.47515252 0.12349752 0.40134996]\n",
            "[0.01423022 0.00724003 0.97852975]\n",
            "[0.06876209 0.26347223 0.6677656 ]\n",
            "[0.00572264 0.01999933 0.97427803]\n",
            "[0.00745046 0.06986429 0.92268527]\n",
            "[0.08885153 0.05455492 0.85659355]\n",
            "[0.01644804 0.03188133 0.9516706 ]\n",
            "[0.00575583 0.01649533 0.9777489 ]\n",
            "[0.0057568  0.01589603 0.9783472 ]\n",
            "[0.01362698 0.01099145 0.97538155]\n",
            "[0.01332394 0.00696859 0.9797075 ]\n",
            "[0.01290844 0.01602563 0.9710659 ]\n",
            "[0.00679518 0.00907012 0.98413473]\n",
            "[0.0126312 0.0069488 0.98042  ]\n",
            "[0.26120833 0.02023138 0.7185603 ]\n",
            "[0.00679518 0.00907012 0.98413473]\n",
            "[0.00763818 0.00931918 0.9830427 ]\n",
            "[0.00762296 0.00980443 0.9825727 ]\n",
            "[0.01096496 0.00709235 0.9819427 ]\n",
            "[0.0067756  0.00967941 0.983545  ]\n",
            "[0.03584284 0.01116475 0.95299244]\n",
            "[0.05838639 0.01437092 0.9272427 ]\n",
            "[0.00720665 0.00944133 0.983352  ]\n",
            "[0.0182111 0.0085791 0.9732098]\n",
            "[0.00642984 0.01208246 0.98148775]\n",
            "[0.00677432 0.01767402 0.97555166]\n",
            "[0.02695701 0.00754241 0.9655006 ]\n",
            "[0.01855434 0.6847622  0.29668352]\n",
            "[0.01180776 0.00838942 0.9798028 ]\n",
            "[0.8904684  0.01500161 0.09452999]\n",
            "[0.06815141 0.06612997 0.86571866]\n",
            "[0.0066965  0.01183095 0.9814726 ]\n",
            "[0.00654821 0.01022516 0.9832266 ]\n",
            "[0.00795974 0.00887501 0.98316526]\n",
            "[0.09170187 0.01398849 0.8943096 ]\n",
            "[0.00874447 0.00854673 0.9827088 ]\n",
            "[0.00700669 0.01004721 0.98294616]\n",
            "[0.0867557 0.1196337 0.7936106]\n",
            "[0.01264399 0.01243068 0.9749254 ]\n",
            "[0.03880718 0.00867924 0.9525136 ]\n",
            "[0.01327784 0.03526364 0.9514585 ]\n",
            "[0.02421837 0.01057051 0.9652111 ]\n",
            "[0.01329457 0.03506429 0.95164114]\n",
            "[0.01067989 0.01029423 0.9790259 ]\n",
            "[0.00575014 0.0129758  0.98127407]\n",
            "[0.00760652 0.01325613 0.9791373 ]\n",
            "[0.3129969  0.06231675 0.62468636]\n",
            "[0.00747442 0.00930711 0.9832185 ]\n",
            "[0.01056786 0.00701937 0.9824127 ]\n",
            "[0.0071662  0.01013326 0.9827005 ]\n",
            "[0.00956323 0.00725682 0.9831799 ]\n",
            "[0.3060269  0.42149675 0.27247638]\n",
            "[0.0079717  0.02018244 0.97184587]\n",
            "[0.00866789 0.00789586 0.9834362 ]\n",
            "[0.01488495 0.00742096 0.97769403]\n",
            "[0.1754668  0.01996478 0.8045684 ]\n",
            "[0.01271768 0.05726553 0.93001676]\n",
            "[0.7747184  0.02440859 0.20087302]\n",
            "[0.01258903 0.00768316 0.9797278 ]\n",
            "[0.92904097 0.04547468 0.02548441]\n",
            "[0.02078184 0.00845013 0.970768  ]\n",
            "[0.14614744 0.14614907 0.7077035 ]\n",
            "[0.08906499 0.02620245 0.8847326 ]\n",
            "[0.01615496 0.01138061 0.9724645 ]\n",
            "[0.3460882 0.0646228 0.589289 ]\n",
            "[0.00861522 0.0084475  0.9829373 ]\n",
            "[0.73981816 0.12680367 0.1333782 ]\n",
            "[0.00719024 0.00879362 0.9840162 ]\n",
            "[0.00681927 0.01026565 0.98291504]\n",
            "[0.02187502 0.80008936 0.17803562]\n",
            "[0.08985113 0.0405802  0.86956865]\n",
            "[0.01589331 0.01219117 0.97191554]\n",
            "[0.0359115 0.5359639 0.4281246]\n",
            "[0.0157092  0.00896206 0.9753287 ]\n",
            "[0.9197535  0.02372468 0.05652182]\n",
            "[0.9442838  0.03362171 0.0220945 ]\n",
            "[0.00719081 0.01248753 0.9803217 ]\n",
            "[0.01175262 0.0076964  0.980551  ]\n",
            "[0.01766972 0.00728945 0.97504085]\n",
            "[0.00725487 0.00886118 0.9838839 ]\n",
            "[0.00729779 0.01329432 0.9794079 ]\n",
            "[0.42071134 0.02513    0.5541586 ]\n",
            "[0.00828184 0.00806763 0.9836505 ]\n",
            "[0.01470296 0.00769105 0.97760594]\n",
            "[0.01426373 0.00749478 0.97824156]\n",
            "[0.0108918  0.00894969 0.9801585 ]\n",
            "[0.01317099 0.00795361 0.9788754 ]\n",
            "[0.94096196 0.03852605 0.02051201]\n",
            "[0.00984227 0.0108802  0.97927755]\n",
            "[0.00671479 0.01358004 0.97970515]\n",
            "[0.45763084 0.01816036 0.5242088 ]\n",
            "[0.01401844 0.01243218 0.9735494 ]\n",
            "[0.00861815 0.00754949 0.98383236]\n",
            "[0.00798329 0.00793619 0.9840805 ]\n",
            "[0.00770894 0.00850772 0.9837833 ]\n",
            "[0.01403145 0.00689107 0.9790775 ]\n",
            "[0.81601703 0.04388511 0.1400979 ]\n",
            "[0.81412107 0.01981418 0.16606477]\n",
            "[0.13312602 0.02460395 0.8422701 ]\n",
            "[0.01488935 0.00727809 0.9778325 ]\n",
            "[0.00777547 0.0525008  0.9397237 ]\n",
            "[0.0365162  0.01314469 0.9503391 ]\n",
            "[0.01394242 0.01160545 0.9744521 ]\n",
            "[0.00552441 0.01544823 0.9790274 ]\n",
            "[0.01491234 0.6281109  0.35697672]\n",
            "[0.0098722  0.58632576 0.40380204]\n",
            "[0.01145401 0.95429075 0.03425527]\n",
            "[0.9293523  0.04986292 0.02078478]\n",
            "[0.00664196 0.00879911 0.9845589 ]\n",
            "[0.03134293 0.0376791  0.930978  ]\n",
            "[0.20872144 0.11655868 0.67471987]\n",
            "[0.00714766 0.0077316  0.98512065]\n",
            "[0.01160018 0.8799067  0.10849311]\n",
            "[0.01369329 0.87580544 0.11050124]\n",
            "[0.00635341 0.01030318 0.9833435 ]\n",
            "[0.00962328 0.28081933 0.70955735]\n",
            "[0.11585443 0.01871706 0.8654285 ]\n",
            "[0.01091919 0.01173694 0.97734386]\n",
            "[0.00830626 0.01470874 0.976985  ]\n",
            "[0.02351827 0.01522329 0.9612584 ]\n",
            "[0.00678531 0.03225088 0.96096385]\n",
            "[0.03222603 0.9331139  0.03466009]\n",
            "[0.02501514 0.9534047  0.02158005]\n",
            "[0.04601384 0.93860346 0.01538262]\n",
            "[0.00802846 0.00809814 0.9838734 ]\n",
            "[0.00633394 0.02116651 0.97249955]\n",
            "[0.00904393 0.00877939 0.98217666]\n",
            "[0.86916286 0.07640282 0.05443425]\n",
            "[0.8578322  0.05576567 0.08640211]\n",
            "[0.9684172  0.01382063 0.01776213]\n",
            "[0.01402335 0.9572545  0.02872217]\n",
            "[0.00623667 0.02742523 0.9663381 ]\n",
            "[0.04932252 0.9411165  0.00956087]\n",
            "[0.00694458 0.01180802 0.9812475 ]\n",
            "[0.00576122 0.05653632 0.9377024 ]\n",
            "[0.01144548 0.01531741 0.9732371 ]\n",
            "[0.02831408 0.02648262 0.94520336]\n",
            "[0.01471106 0.00866884 0.9766201 ]\n",
            "[0.9208002  0.02824812 0.05095167]\n",
            "[0.71075904 0.21321449 0.07602644]\n",
            "[0.01406743 0.00694817 0.9789844 ]\n",
            "[0.94360703 0.02038636 0.03600651]\n",
            "[0.00938939 0.13958219 0.85102844]\n",
            "[0.07527162 0.862137   0.06259134]\n",
            "[0.0086702  0.02925701 0.9620728 ]\n",
            "[0.01077293 0.08859588 0.90063125]\n",
            "[0.03558849 0.03610685 0.9283046 ]\n",
            "[0.6141126  0.15068437 0.235203  ]\n",
            "[0.03400065 0.0917704  0.87422895]\n",
            "[0.00953067 0.28310895 0.7073604 ]\n",
            "[0.00631558 0.02378476 0.96989965]\n",
            "[0.01165374 0.87173015 0.11661615]\n",
            "[0.00677809 0.01215847 0.98106337]\n",
            "[0.51986223 0.44469658 0.0354412 ]\n",
            "[0.9425096  0.01639509 0.04109528]\n",
            "[0.02457055 0.8534469  0.12198263]\n",
            "[0.00827352 0.00829916 0.9834273 ]\n",
            "[0.6395034  0.04010017 0.3203964 ]\n",
            "[0.01708426 0.0094224  0.9734934 ]\n",
            "[0.00585837 0.01367949 0.9804622 ]\n",
            "[0.0123908  0.35519388 0.6324153 ]\n",
            "[0.01469419 0.01950574 0.96580005]\n",
            "[0.00900579 0.14374992 0.84724426]\n",
            "[0.00952825 0.21901831 0.77145344]\n",
            "[0.00793302 0.0128489  0.9792181 ]\n",
            "[0.05124576 0.9120843  0.03666988]\n",
            "[0.00625748 0.04993827 0.94380426]\n",
            "[0.2584033  0.48267642 0.25892034]\n",
            "[0.00754126 0.0364359  0.95602286]\n",
            "[0.00858983 0.01038656 0.98102355]\n",
            "[0.00557173 0.02309907 0.9713292 ]\n",
            "[0.00959036 0.00694051 0.9834691 ]\n",
            "[0.01088897 0.00738265 0.9817284 ]\n",
            "[0.41672406 0.02565393 0.557622  ]\n",
            "[0.00819939 0.01403255 0.9777681 ]\n",
            "[0.01491629 0.07287418 0.9122096 ]\n",
            "[0.0087307  0.01268419 0.9785851 ]\n",
            "[0.09777524 0.01040442 0.8918203 ]\n",
            "[0.05118857 0.01742922 0.93138224]\n",
            "[0.96638805 0.01353723 0.02007468]\n",
            "[0.03923238 0.26968437 0.69108325]\n",
            "[0.0075751  0.00748224 0.9849427 ]\n",
            "[0.01047837 0.21662647 0.77289516]\n",
            "[0.03234523 0.03899377 0.92866105]\n",
            "[0.9655582  0.01164938 0.02279249]\n",
            "[0.00732983 0.06521869 0.92745155]\n",
            "[0.14612943 0.7520917  0.10177892]\n",
            "[0.06016584 0.9142789  0.02555521]\n",
            "[0.01384211 0.9181017  0.06805616]\n",
            "[0.8933746  0.01740365 0.08922175]\n",
            "[0.00705666 0.01566132 0.97728205]\n",
            "[0.00649867 0.01153879 0.9819626 ]\n",
            "[0.01595857 0.18677807 0.7972633 ]\n",
            "[0.01257561 0.11495733 0.8724671 ]\n",
            "[0.01233896 0.1215339  0.8661272 ]\n",
            "[0.94391197 0.04478994 0.01129807]\n",
            "[0.01958867 0.9614815  0.01892979]\n",
            "[0.01497278 0.9576721  0.02735515]\n",
            "[0.03567537 0.9478777  0.01644692]\n",
            "[0.01481718 0.84951705 0.13566579]\n",
            "[0.03716392 0.04124349 0.92159253]\n",
            "[0.01130841 0.00975253 0.97893906]\n",
            "[0.01414054 0.01252865 0.97333086]\n",
            "[0.08976468 0.01474424 0.8954911 ]\n",
            "[0.03074306 0.01574857 0.9535084 ]\n",
            "[0.00639866 0.0209342  0.9726671 ]\n",
            "[0.6283977  0.01497569 0.35662663]\n",
            "[0.9289248  0.02146671 0.0496085 ]\n",
            "[0.00590941 0.0226936  0.9713969 ]\n",
            "[0.00986028 0.00901788 0.9811218 ]\n",
            "[0.02275294 0.38180387 0.5954432 ]\n",
            "[0.01390532 0.0463018  0.9397929 ]\n",
            "[0.04323479 0.01103305 0.9457321 ]\n",
            "[0.07446301 0.9150225  0.0105145 ]\n",
            "[0.65223724 0.3180816  0.02968115]\n",
            "[0.03195398 0.01245908 0.9555869 ]\n",
            "[0.01956386 0.94975686 0.03067925]\n",
            "[0.04564801 0.9365986  0.01775335]\n",
            "[0.00984602 0.23044984 0.7597042 ]\n",
            "[0.01022995 0.9591849  0.03058518]\n",
            "[0.01136245 0.8124961  0.1761415 ]\n",
            "[0.60610855 0.01640945 0.377482  ]\n",
            "[0.01656545 0.00903817 0.9743964 ]\n",
            "[0.00927001 0.7362809  0.25444913]\n",
            "[0.00734671 0.0826864  0.9099669 ]\n",
            "[0.0403513  0.9419348  0.01771385]\n",
            "[0.00955484 0.26108107 0.7293641 ]\n",
            "[0.00829476 0.07507659 0.91662866]\n",
            "[0.0229639  0.9015189  0.07551724]\n",
            "[0.00914417 0.63793975 0.35291603]\n",
            "[0.01349397 0.97082216 0.01568389]\n",
            "[0.05953191 0.11268329 0.8277848 ]\n",
            "[0.00955001 0.9291763  0.06127362]\n",
            "[0.17703895 0.7725944  0.05036668]\n",
            "[0.56120855 0.40353736 0.03525408]\n",
            "[0.01217649 0.96654207 0.02128141]\n",
            "[0.03211332 0.02093409 0.9469526 ]\n",
            "[0.4167994  0.01751971 0.56568086]\n",
            "[0.07471707 0.01955529 0.90572757]\n",
            "[0.01084365 0.9579805  0.03117582]\n",
            "[0.00584973 0.04337628 0.950774  ]\n",
            "[0.00710513 0.00993283 0.9829621 ]\n",
            "[0.01879149 0.26157218 0.7196363 ]\n",
            "[0.04249515 0.9394549  0.01804994]\n",
            "[0.12445506 0.7336789  0.14186607]\n",
            "[0.00801631 0.01838133 0.9736024 ]\n",
            "[0.05306296 0.9246539  0.02228309]\n",
            "[0.97814935 0.01132695 0.01052368]\n",
            "[0.27214694 0.67308515 0.0547679 ]\n",
            "[0.43526036 0.01395629 0.55078334]\n",
            "[0.00710026 0.00840094 0.9844988 ]\n",
            "[0.00817049 0.2910232  0.7008063 ]\n",
            "[0.01984989 0.9684173  0.01173288]\n",
            "[0.00660424 0.0407851  0.9526106 ]\n",
            "[0.01508104 0.39980453 0.58511436]\n",
            "[0.01115666 0.00830808 0.9805353 ]\n",
            "[0.01136954 0.6446282  0.34400225]\n",
            "[0.02108618 0.01013319 0.9687807 ]\n",
            "[0.00705896 0.01205266 0.9808883 ]\n",
            "[0.02734893 0.01925697 0.9533941 ]\n",
            "[0.03039953 0.95835304 0.01124734]\n",
            "[0.04569134 0.94135624 0.01295253]\n",
            "[0.8955001  0.03197791 0.07252205]\n",
            "[0.95735776 0.02719538 0.01544682]\n",
            "[0.01228025 0.00910237 0.9786173 ]\n",
            "[0.5422803  0.3958965  0.06182322]\n",
            "[0.05192168 0.00994463 0.9381337 ]\n",
            "[0.00627652 0.0091704  0.9845531 ]\n",
            "[0.01126108 0.00838371 0.98035514]\n",
            "[0.01223279 0.28920287 0.69856435]\n",
            "[0.32844523 0.0225187  0.64903605]\n",
            "[0.76487964 0.03014818 0.20497218]\n",
            "[0.00788679 0.11971781 0.8723954 ]\n",
            "[0.00744025 0.05249518 0.9400646 ]\n",
            "[0.02451756 0.964007   0.01147539]\n",
            "[0.0104996  0.02583789 0.9636625 ]\n",
            "[0.1805079  0.3601378  0.45935425]\n",
            "[0.00873447 0.00713025 0.9841353 ]\n",
            "[0.01403666 0.00986555 0.9760978 ]\n",
            "[0.01102983 0.33215174 0.65681845]\n",
            "[0.9705573  0.00899342 0.02044933]\n",
            "[0.9183529  0.01279671 0.06885043]\n",
            "[0.9740952  0.01506755 0.01083724]\n",
            "[0.01386487 0.00776856 0.97836655]\n",
            "[0.01662155 0.00763232 0.9757461 ]\n",
            "[0.00924503 0.00733454 0.98342043]\n",
            "[0.21908174 0.74145645 0.03946177]\n",
            "[0.01104778 0.31596082 0.67299145]\n",
            "[0.01642862 0.8725494  0.11102195]\n",
            "[0.0438818  0.01577829 0.9403399 ]\n",
            "[0.00857006 0.00777751 0.9836525 ]\n",
            "[0.011826  0.6497017 0.3384723]\n",
            "[0.967225   0.02093164 0.01184341]\n",
            "[0.00641149 0.04204777 0.9515407 ]\n",
            "[0.02560924 0.9535383  0.02085248]\n",
            "[0.01528989 0.01965684 0.9650533 ]\n",
            "[0.01562537 0.963519   0.02085562]\n",
            "[0.04015394 0.39673746 0.56310856]\n",
            "[0.2123839  0.7668663  0.02074979]\n",
            "[0.4637315 0.4475967 0.0886718]\n",
            "[0.01639629 0.85836554 0.12523824]\n",
            "[0.5933646 0.3779086 0.0287268]\n",
            "[0.01031678 0.00780541 0.9818778 ]\n",
            "[0.0226929  0.95656663 0.02074056]\n",
            "[0.9734848  0.01259506 0.01392008]\n",
            "[0.01462349 0.00793912 0.9774374 ]\n",
            "[0.0400841  0.01274204 0.94717383]\n",
            "[0.67348146 0.03635426 0.29016426]\n",
            "[0.00637493 0.01809528 0.9755298 ]\n",
            "[0.00974809 0.00828086 0.98197097]\n",
            "[0.01047144 0.02959445 0.9599341 ]\n",
            "[0.2996108 0.0145974 0.6857918]\n",
            "[0.00877867 0.00774436 0.98347694]\n",
            "[0.01664939 0.7859765  0.19737417]\n",
            "[0.00641501 0.054551   0.93903404]\n",
            "[0.7786844  0.02879863 0.192517  ]\n",
            "[0.5845857  0.04549063 0.3699236 ]\n",
            "[0.01860622 0.00756433 0.97382945]\n",
            "[0.6787782 0.2774474 0.0437745]\n",
            "[0.00594155 0.02181516 0.97224325]\n",
            "[0.35268578 0.0511305  0.5961837 ]\n",
            "[0.75897586 0.02956344 0.2114607 ]\n",
            "[0.38571665 0.01810486 0.59617853]\n",
            "[0.05460966 0.05060075 0.89478964]\n",
            "[0.90043294 0.02625008 0.07331694]\n",
            "[0.8506521  0.11389042 0.03545753]\n",
            "[0.01175069 0.0072872  0.9809621 ]\n",
            "[0.50567013 0.02819749 0.46613234]\n",
            "[0.01085799 0.00732079 0.98182124]\n",
            "[0.01331579 0.00895524 0.977729  ]\n",
            "[0.00730148 0.04534858 0.9473499 ]\n",
            "[0.02629134 0.40436435 0.5693443 ]\n",
            "[0.01941782 0.96304035 0.01754187]\n",
            "[0.02275492 0.95092255 0.02632247]\n",
            "[0.01302777 0.00998442 0.97698784]\n",
            "[0.00755097 0.14911786 0.84333116]\n",
            "[0.00823708 0.19741715 0.7943458 ]\n",
            "[0.01110668 0.2554172  0.7334761 ]\n",
            "[0.01950105 0.1607317  0.8197673 ]\n",
            "[0.0399679  0.01025958 0.9497725 ]\n",
            "[0.00668935 0.01029395 0.98301667]\n",
            "[0.00950812 0.52170956 0.4687823 ]\n",
            "[0.5464887  0.4018722  0.05163914]\n",
            "[0.50602955 0.15565544 0.33831498]\n",
            "[0.0154138 0.7202746 0.2643116]\n",
            "[0.01809396 0.9631795  0.01872656]\n",
            "[0.07836727 0.01258098 0.9090518 ]\n",
            "[0.01008499 0.00816779 0.9817472 ]\n",
            "[0.39213726 0.02334213 0.5845206 ]\n",
            "[0.01327127 0.07467887 0.9120499 ]\n",
            "[0.0086774  0.03378763 0.957535  ]\n",
            "[0.02858963 0.95191896 0.01949133]\n",
            "[0.02901614 0.95901656 0.01196731]\n",
            "[0.01199359 0.00781462 0.9801918 ]\n",
            "[0.00971289 0.00831791 0.9819692 ]\n",
            "[0.01096534 0.00977017 0.9792645 ]\n",
            "[0.0464357  0.49253917 0.46102506]\n",
            "[0.62897176 0.24743879 0.12358936]\n",
            "[0.6057521  0.26062363 0.1336242 ]\n",
            "[0.5676302  0.25249246 0.17987734]\n",
            "[0.09660219 0.11622877 0.787169  ]\n",
            "[0.00752535 0.1233006  0.869174  ]\n",
            "[0.00975749 0.4982016  0.4920409 ]\n",
            "[0.00770078 0.00986999 0.98242927]\n",
            "[0.02242627 0.00974494 0.9678288 ]\n",
            "[0.01495665 0.9037406  0.08130276]\n",
            "[0.5178635  0.45483288 0.02730357]\n",
            "[0.02135449 0.96503085 0.01361459]\n",
            "[0.0132278  0.9613882  0.02538409]\n",
            "[0.8763607  0.08487877 0.03876053]\n",
            "[0.01797953 0.01285275 0.9691677 ]\n",
            "[0.9490612  0.01886775 0.03207098]\n",
            "[0.00951807 0.01007271 0.98040926]\n",
            "[0.00634596 0.03232482 0.9613292 ]\n",
            "[0.00750149 0.00976744 0.98273104]\n",
            "[0.8031425  0.02272554 0.17413197]\n",
            "[0.01574077 0.869312   0.11494721]\n",
            "[0.02330969 0.00747677 0.96921355]\n",
            "[0.0519803 0.9353034 0.0127163]\n",
            "[0.02567156 0.35984367 0.6144848 ]\n",
            "[0.04704548 0.8826412  0.0703132 ]\n",
            "[0.01115866 0.6386769  0.3501645 ]\n",
            "[0.00712052 0.06340045 0.92947906]\n",
            "[0.00922149 0.85494643 0.13583207]\n",
            "[0.01117531 0.79723567 0.191589  ]\n",
            "[0.00687297 0.04305395 0.950073  ]\n",
            "[0.0148397 0.0072905 0.9778698]\n",
            "[0.01271821 0.72472703 0.26255485]\n",
            "[0.00672021 0.01260781 0.98067194]\n",
            "[0.02635278 0.93352574 0.04012141]\n",
            "[0.01094127 0.0091747  0.979884  ]\n",
            "[0.02060134 0.5621104  0.4172882 ]\n",
            "[0.01604973 0.02662126 0.95732903]\n",
            "[0.11951822 0.06443261 0.8160491 ]\n",
            "[0.01716612 0.87439215 0.10844167]\n",
            "[0.02087158 0.9677737  0.01135469]\n",
            "[0.01828307 0.06165339 0.9200636 ]\n",
            "[0.03544891 0.01681696 0.9477341 ]\n",
            "[0.01040088 0.8448651  0.14473397]\n",
            "[0.48860407 0.3240071  0.18738876]\n",
            "[0.02150439 0.95695126 0.02154438]\n",
            "[0.04552835 0.9324343  0.0220373 ]\n",
            "[0.0068441  0.01128184 0.9818741 ]\n",
            "[0.02227245 0.3007755  0.67695206]\n",
            "[0.05419345 0.6804017  0.26540482]\n",
            "[0.96180075 0.01196799 0.02623122]\n",
            "[0.89342296 0.05459005 0.05198704]\n",
            "[0.87653077 0.06205305 0.06141625]\n",
            "[0.93886566 0.02833293 0.03280135]\n",
            "[0.01480069 0.86812973 0.11706955]\n",
            "[0.01094857 0.00727658 0.9817748 ]\n",
            "[0.11226533 0.01360678 0.8741279 ]\n",
            "[0.04985854 0.9185353  0.0316061 ]\n",
            "[0.01412867 0.78976005 0.19611126]\n",
            "[0.05379344 0.01095165 0.93525493]\n",
            "[0.00607266 0.01251397 0.98141336]\n",
            "[0.00726882 0.03202883 0.96070236]\n",
            "[0.93331945 0.03753133 0.02914919]\n",
            "[0.02286972 0.9596254  0.01750479]\n",
            "[0.8937641  0.0151314  0.09110444]\n",
            "[0.01768753 0.96703655 0.01527594]\n",
            "[0.6078071  0.01978584 0.37240708]\n",
            "[0.00858727 0.00812038 0.9832924 ]\n",
            "[0.0075995  0.00871599 0.98368454]\n",
            "[0.73680973 0.18753278 0.07565749]\n",
            "[0.01426827 0.80496067 0.18077098]\n",
            "[0.01248977 0.0089667  0.9785436 ]\n",
            "[0.01511145 0.6160512  0.36883736]\n",
            "[0.08708652 0.01089355 0.90201986]\n",
            "[0.00641005 0.01287643 0.98071355]\n",
            "[0.9711494  0.01045072 0.01839988]\n",
            "[0.00571687 0.01732355 0.9769596 ]\n",
            "[0.00818998 0.00756522 0.98424476]\n",
            "[0.01665445 0.2614511  0.72189444]\n",
            "[0.01736358 0.9650859  0.01755042]\n",
            "[0.01438104 0.00797074 0.97764826]\n",
            "[0.01013303 0.01111816 0.97874874]\n",
            "[0.0063229  0.02594992 0.96772724]\n",
            "[0.01660446 0.9605317  0.02286373]\n",
            "[0.6833876 0.2811951 0.0354173]\n",
            "[0.97291905 0.01558815 0.01149276]\n",
            "[0.0207083  0.9657926  0.01349906]\n",
            "[0.00616673 0.01988231 0.9739509 ]\n",
            "[0.8398932  0.14166184 0.01844499]\n",
            "[0.05440437 0.9344831  0.01111248]\n",
            "[0.00633155 0.05190288 0.94176555]\n",
            "[0.41206795 0.36445674 0.22347534]\n",
            "[0.36896238 0.03693999 0.5940977 ]\n",
            "[0.00657814 0.00857122 0.98485065]\n",
            "[0.9612452  0.01203795 0.02671688]\n",
            "[0.02427565 0.00959078 0.96613353]\n",
            "[0.6660666  0.02543489 0.30849856]\n",
            "[0.9369433  0.01720236 0.04585427]\n",
            "[0.02028078 0.95572066 0.02399845]\n",
            "[0.00631848 0.0163278  0.9773537 ]\n",
            "[0.01736371 0.00738207 0.9752542 ]\n",
            "[0.01355277 0.01011986 0.9763274 ]\n",
            "[0.01407515 0.815202   0.17072283]\n",
            "[0.8720703  0.03181696 0.09611275]\n",
            "[0.01741732 0.9704485  0.01213419]\n",
            "[0.01730375 0.96570635 0.01698988]\n",
            "[0.01135461 0.9556041  0.03304139]\n",
            "[0.0323955  0.95720154 0.01040292]\n",
            "[0.00816712 0.00952653 0.9823063 ]\n",
            "[0.02070817 0.94685405 0.03243781]\n",
            "[0.05931859 0.67264    0.26804137]\n",
            "[0.50178534 0.41555342 0.08266126]\n",
            "[0.50288796 0.4203208  0.07679121]\n",
            "[0.9631959  0.01151304 0.02529101]\n",
            "[0.01321473 0.9677459  0.01903932]\n",
            "[0.9206432  0.06662863 0.01272821]\n",
            "[0.00719172 0.10513287 0.8876754 ]\n",
            "[0.01315346 0.06160926 0.92523724]\n",
            "[0.9313432  0.01557557 0.05308132]\n",
            "[0.00680541 0.01310871 0.9800859 ]\n",
            "[0.00913267 0.0077675  0.9830998 ]\n",
            "[0.9122141  0.05007426 0.03771161]\n",
            "[0.9662691  0.01233737 0.02139362]\n",
            "[0.00647725 0.06522194 0.9283008 ]\n",
            "[0.00771884 0.02100614 0.97127503]\n",
            "[0.00695497 0.02102507 0.97202   ]\n",
            "[0.08671091 0.2568087  0.6564803 ]\n",
            "[0.01090613 0.95685005 0.03224384]\n",
            "[0.0065633  0.01604508 0.9773916 ]\n",
            "[0.02012288 0.9638088  0.01606834]\n",
            "[0.02481333 0.14410095 0.83108574]\n",
            "[0.0451213  0.01760118 0.93727756]\n",
            "[0.00830029 0.00876145 0.98293823]\n",
            "[0.89597404 0.01524794 0.08877802]\n",
            "[0.01284171 0.01131396 0.9758444 ]\n",
            "[0.9485755  0.01663871 0.03478584]\n",
            "[0.72417927 0.16600254 0.10981821]\n",
            "[0.01318501 0.58699274 0.39982224]\n",
            "[0.01848289 0.9514596  0.03005746]\n",
            "[0.00779801 0.09705433 0.8951477 ]\n",
            "[0.01231807 0.8410584  0.14662355]\n",
            "[0.8165705  0.03553245 0.14789702]\n",
            "[0.00731172 0.0244034  0.96828485]\n",
            "[0.01654797 0.81759244 0.1658596 ]\n",
            "[0.15757729 0.01557375 0.826849  ]\n",
            "[0.01421558 0.00778808 0.97799635]\n",
            "[0.8207228  0.03443085 0.14484632]\n",
            "[0.00789313 0.00800572 0.9841011 ]\n",
            "[0.03314789 0.95158154 0.01527062]\n",
            "[0.03081489 0.9586173  0.01056782]\n",
            "[0.01168172 0.83421904 0.1540993 ]\n",
            "[0.01466341 0.9699994  0.01533719]\n",
            "[0.0290144  0.9541349  0.01685074]\n",
            "[0.9058158  0.02539786 0.06878632]\n",
            "[0.01665646 0.9294079  0.05393565]\n",
            "[0.4089508  0.02150978 0.5695394 ]\n",
            "[0.00839352 0.10036906 0.8912374 ]\n",
            "[0.94632053 0.02078404 0.03289542]\n",
            "[0.0124844  0.00845487 0.9790607 ]\n",
            "[0.02970481 0.01284225 0.95745295]\n",
            "[0.00944047 0.00996844 0.9805911 ]\n",
            "[0.01087431 0.04648516 0.94264054]\n",
            "[0.67563224 0.19014081 0.13422704]\n",
            "[0.01060349 0.00959206 0.9798045 ]\n",
            "[0.9134147  0.0115468  0.07503849]\n",
            "[0.20381461 0.2174302  0.57875514]\n",
            "[0.8289154  0.11001336 0.06107124]\n",
            "[0.7585527  0.20671764 0.03472962]\n",
            "[0.3357661  0.58232296 0.08191099]\n",
            "[0.03705866 0.00883278 0.95410854]\n",
            "[0.02576273 0.9539961  0.02024113]\n",
            "[0.00945275 0.00779824 0.982749  ]\n",
            "[0.915275   0.06297355 0.02175147]\n",
            "[0.06616969 0.01470874 0.9191215 ]\n",
            "[0.14747337 0.68557423 0.1669524 ]\n",
            "[0.94277465 0.02620851 0.03101685]\n",
            "[0.48646396 0.0879157  0.42562032]\n",
            "[0.00612384 0.01257103 0.98130506]\n",
            "[0.65617466 0.03300251 0.3108228 ]\n",
            "[0.00615572 0.03597202 0.9578722 ]\n",
            "[0.9718945  0.01010482 0.01800064]\n",
            "[0.9494245  0.02318    0.02739552]\n",
            "[0.39416116 0.5854551  0.0203838 ]\n",
            "[0.00610669 0.02882275 0.9650706 ]\n",
            "[0.48995999 0.48335895 0.02668102]\n",
            "[0.2763075  0.6949057  0.02878677]\n",
            "[0.48995999 0.48335895 0.02668102]\n",
            "[0.01963022 0.27985886 0.7005109 ]\n",
            "[0.18535003 0.03526102 0.77938896]\n",
            "[0.01914418 0.95337385 0.02748191]\n",
            "[0.00873172 0.00785398 0.98341435]\n",
            "[0.81115705 0.04591227 0.14293075]\n",
            "[0.0372308  0.9168691  0.04590007]\n",
            "[0.02346116 0.93659747 0.03994142]\n",
            "[0.01037093 0.2004062  0.78922284]\n",
            "[0.97429466 0.01219101 0.01351434]\n",
            "[0.00807509 0.13134351 0.86058134]\n",
            "[0.9632117  0.01272342 0.02406484]\n",
            "[0.01627412 0.18381843 0.7999074 ]\n",
            "[0.02986406 0.01352947 0.95660645]\n",
            "[0.65608615 0.01986047 0.32405338]\n",
            "[0.00618901 0.02532506 0.96848595]\n",
            "[0.00746733 0.00869334 0.9838394 ]\n",
            "[0.07545527 0.01891912 0.9056256 ]\n",
            "[0.03941634 0.6381232  0.3224605 ]\n",
            "[0.01411229 0.01083619 0.9750515 ]\n",
            "[0.00672706 0.03459567 0.95867723]\n",
            "[0.01711665 0.0143632  0.96852016]\n",
            "[0.00874801 0.20823552 0.7830165 ]\n",
            "[0.01008344 0.05552135 0.93439525]\n",
            "[0.00938435 0.00704381 0.9835719 ]\n",
            "[0.01139122 0.00766012 0.9809487 ]\n",
            "[0.97482544 0.0125795  0.01259501]\n",
            "[0.02016604 0.07775999 0.902074  ]\n",
            "[0.01557404 0.959906   0.02451997]\n",
            "[0.02515639 0.03507089 0.9397727 ]\n",
            "[0.02678276 0.03109445 0.9421227 ]\n",
            "[0.01654697 0.9433737  0.04007931]\n",
            "[0.03345834 0.9492258  0.01731584]\n",
            "[0.04006362 0.94045275 0.01948365]\n",
            "[0.01051171 0.7434767  0.24601161]\n",
            "[0.01637039 0.968471   0.01515866]\n",
            "[0.01270987 0.96306854 0.02422154]\n",
            "[0.73163843 0.24408989 0.02427169]\n",
            "[0.19250405 0.03137187 0.77612406]\n",
            "[0.87734014 0.02043415 0.10222576]\n",
            "[0.00584059 0.04254987 0.9516096 ]\n",
            "[0.01305215 0.0101566  0.97679126]\n",
            "[0.00790836 0.01762001 0.97447157]\n",
            "[0.01329389 0.01425472 0.9724514 ]\n",
            "[0.50914437 0.3178677  0.17298794]\n",
            "[0.01014551 0.0104207  0.9794337 ]\n",
            "[0.10286736 0.87689835 0.02023432]\n",
            "[0.8305276  0.13991329 0.02955913]\n",
            "[0.0121571  0.01127009 0.9765728 ]\n",
            "[0.01047472 0.01341011 0.97611517]\n",
            "[0.01136658 0.9396666  0.04896681]\n",
            "[0.01686147 0.01263593 0.97050256]\n",
            "[0.909783   0.02765479 0.06256218]\n",
            "[0.93414927 0.0441733  0.02167743]\n",
            "[0.01582018 0.96186185 0.02231802]\n",
            "[0.01283585 0.96738315 0.01978098]\n",
            "[0.00567855 0.01379324 0.9805282 ]\n",
            "[0.65131515 0.3222456  0.02643921]\n",
            "[0.0087837 0.2182215 0.7729948]\n",
            "[0.9684946  0.01460672 0.01689875]\n",
            "[0.05549761 0.9302067  0.0142956 ]\n",
            "[0.06510427 0.9137162  0.0211795 ]\n",
            "[0.3779348  0.6054764  0.01658874]\n",
            "[0.44242886 0.5321776  0.02539358]\n",
            "[0.00583055 0.01399195 0.9801775 ]\n",
            "[0.17375246 0.74291617 0.08333138]\n",
            "[0.02176827 0.9321044  0.04612727]\n",
            "[0.0288932  0.9340489  0.03705798]\n",
            "[0.06582037 0.90303284 0.03114673]\n",
            "[0.0367038  0.9401198  0.02317636]\n",
            "[0.01431821 0.00833419 0.9773476 ]\n",
            "[0.0139087  0.00702969 0.97906166]\n",
            "[0.01315573 0.01471591 0.97212833]\n",
            "[0.5809411  0.01993615 0.39912271]\n",
            "[0.97747177 0.01086028 0.01166794]\n",
            "[0.00953749 0.06975681 0.92070574]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgpMTRW-jMtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.savetxt(\"/content/drive/My Drive/FYP/bert/glue/cola/task2hindi-results.txt\",predictions, fmt=\"%s\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PmWUtXdLW1I",
        "colab_type": "code",
        "outputId": "4e57907f-7d8b-40a3-d50b-19626b97e935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  \n",
        "\n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "                 \n",
        "  matthews_set.append(matthews)\n",
        "  \n",
        " # print(pred_labels_i)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb--na-oLbVM",
        "colab_type": "code",
        "outputId": "9db7592e-ab68-4234-f3a6-dd206139ce2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matthews_set\n",
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6aNsEuZMvjI",
        "colab_type": "code",
        "outputId": "d2d13d08-097b-401a-d1ba-1bf0b3c2e11b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/My Drive/FYP/bert/model-colab-task2hindi'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/My Drive/FYP/bert/model-colab-task2hindi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/FYP/bert/model-colab-task2hindi/vocab.txt',\n",
              " '/content/drive/My Drive/FYP/bert/model-colab-task2hindi/special_tokens_map.json',\n",
              " '/content/drive/My Drive/FYP/bert/model-colab-task2hindi/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}