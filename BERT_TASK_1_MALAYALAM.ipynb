{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-TASK 1-MALAYALAM",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69206e341634475a9454a057aa3023f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_526ac6a544dc4eea9c42cc5456f141f0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_372232e585cd4167b750fb9b80ab7cc9",
              "IPY_MODEL_68b3f5e310de4e219d6fdc9fde6db02a"
            ]
          }
        },
        "526ac6a544dc4eea9c42cc5456f141f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "372232e585cd4167b750fb9b80ab7cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da18d58bff254e1281a6fdf442672294",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e9e862e693b4ea389b1e282cc5cb9c1"
          }
        },
        "68b3f5e310de4e219d6fdc9fde6db02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c411c1730cc4e52a1588b48b5d5c9e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 996k/996k [00:00&lt;00:00, 19.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9de680c8a30342d2bf2fd70494be4925"
          }
        },
        "da18d58bff254e1281a6fdf442672294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e9e862e693b4ea389b1e282cc5cb9c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c411c1730cc4e52a1588b48b5d5c9e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9de680c8a30342d2bf2fd70494be4925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35df0b1367ba457d8791ffd8458bd5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b7438fb701f843cdab0a02528842028d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_764095436156407180fe9ad6b023d387",
              "IPY_MODEL_94856b01e57041d69d024b9b715c5f92"
            ]
          }
        },
        "b7438fb701f843cdab0a02528842028d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "764095436156407180fe9ad6b023d387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6f6e79a7b942422e9615335cd2888347",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 569,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 569,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12678455cd084be4a65e4f30747fea8a"
          }
        },
        "94856b01e57041d69d024b9b715c5f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e0332378a59432e9582716785cf177d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 569/569 [00:00&lt;00:00, 15.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_611968654f5740569586b8b5c03b103c"
          }
        },
        "6f6e79a7b942422e9615335cd2888347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12678455cd084be4a65e4f30747fea8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e0332378a59432e9582716785cf177d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "611968654f5740569586b8b5c03b103c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2300f51ddb4e4b1d8e09b140309ec5d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_628979814fb343428486ca2dc3fde399",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_497310035a6847cc9a5aac38692fdc96",
              "IPY_MODEL_cdecd492ea294ce88baf4b72b241b739"
            ]
          }
        },
        "628979814fb343428486ca2dc3fde399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "497310035a6847cc9a5aac38692fdc96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1cce8ab9ec42428697bb1cd1daf8a2c3",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9a71d5a59bd465f975ad23b0aba3c6c"
          }
        },
        "cdecd492ea294ce88baf4b72b241b739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5e57a7d641d4a5593025df31bccb200",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 714M/714M [00:10&lt;00:00, 68.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c06443188e744a99b83edf8471cf514"
          }
        },
        "1cce8ab9ec42428697bb1cd1daf8a2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9a71d5a59bd465f975ad23b0aba3c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5e57a7d641d4a5593025df31bccb200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c06443188e744a99b83edf8471cf514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakesh-SSN/FYP/blob/master/BERT_TASK_1_MALAYALAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN2gN6gr8nOJ",
        "colab_type": "code",
        "outputId": "d7dbbd3b-75f5-46a9-eff4-0a5ac1e4728f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "!pip install transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P4\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agL2oUFJO9BM",
        "colab_type": "code",
        "outputId": "e7b0359e-dce4-4ffd-f1d7-42ea61d1bb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roq3nEGz9wvH",
        "colab_type": "code",
        "outputId": "f04298f4-7102-4fb6-935b-d998d2ed345e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/malayalam/task1malayalam.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 2,500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2309</th>\n",
              "      <td>MAL2310</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>തൃശൂര്‍ നിയമസഭാ മണ്ഡലത്തിലെ തെരഞ്ഞെടുപ്പ് തോല...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2350</th>\n",
              "      <td>MAL2351</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>സാധാരണ കാര്‍ഗോ വിമാനങ്ങള്‍ക്ക് വഹിക്കാന്‍ പറ്റ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>MAL1014</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>അഫ്ഗാന്‍ ഉയര്‍ത്തിയ നൂറ്റി ഇരുപത്തി നാല്  റണ്‍...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>MAL0518</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ടോംസിന്റെ ഭൗതിക ശരീരം ഇന്ന് പൊതുദർശനത്തിനു വയ്...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>MAL1158</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>കാക്കനാട് ലാബില്‍ സൂക്ഷിച്ചിരുന്ന സാമ്പിളുകള്‍...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>MAL0793</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>പ്രഫഷനൽ ബോക്സിങ്ങിൽ അരങ്ങേറിയശേഷമുള്ള തുടർച്ചയ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1992</th>\n",
              "      <td>MAL1993</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ചിലയിടങ്ങളില്‍ ശക്തമായ ത്രികോണ മത്സരം നടന്നെങ്...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1768</th>\n",
              "      <td>MAL1769</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ഭാരത് മാതാ കീ ജയ് വിളിക്കാത്തവര്‍ക്ക് ഇന്ത്യയി...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>MAL1337</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ഇത്തരം ചിത്രങ്ങളിലാണോ മോഹന്‍ലാല്‍ അഭിനയിക്കേണ്...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1570</th>\n",
              "      <td>MAL1571</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>സുജോയ് ഘോഷ് സംവിധാനം നിര്‍വഹിക്കുന്ന കഹാനി രണ്...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "2309         MAL2310  ...  തൃശൂര്‍ നിയമസഭാ മണ്ഡലത്തിലെ തെരഞ്ഞെടുപ്പ് തോല...\n",
              "2350         MAL2351  ...  സാധാരണ കാര്‍ഗോ വിമാനങ്ങള്‍ക്ക് വഹിക്കാന്‍ പറ്റ...\n",
              "1013         MAL1014  ...  അഫ്ഗാന്‍ ഉയര്‍ത്തിയ നൂറ്റി ഇരുപത്തി നാല്  റണ്‍...\n",
              "517          MAL0518  ...  ടോംസിന്റെ ഭൗതിക ശരീരം ഇന്ന് പൊതുദർശനത്തിനു വയ്...\n",
              "1157         MAL1158  ...  കാക്കനാട് ലാബില്‍ സൂക്ഷിച്ചിരുന്ന സാമ്പിളുകള്‍...\n",
              "792          MAL0793  ...  പ്രഫഷനൽ ബോക്സിങ്ങിൽ അരങ്ങേറിയശേഷമുള്ള തുടർച്ചയ...\n",
              "1992         MAL1993  ...  ചിലയിടങ്ങളില്‍ ശക്തമായ ത്രികോണ മത്സരം നടന്നെങ്...\n",
              "1768         MAL1769  ...  ഭാരത് മാതാ കീ ജയ് വിളിക്കാത്തവര്‍ക്ക് ഇന്ത്യയി...\n",
              "1336         MAL1337  ...  ഇത്തരം ചിത്രങ്ങളിലാണോ മോഹന്‍ലാല്‍ അഭിനയിക്കേണ്...\n",
              "1570         MAL1571  ...  സുജോയ് ഘോഷ് സംവിധാനം നിര്‍വഹിക്കുന്ന കഹാനി രണ്...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK0Dm2839_fM",
        "colab_type": "code",
        "outputId": "b1449350-40d9-40b3-8362-78effbff010b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2274</th>\n",
              "      <td>അപ്രതീക്ഷിത തിരിച്ചടിയാണ്‌ തെരഞ്ഞെടുപ്പിലുണ്ടാ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1865</th>\n",
              "      <td>തെലങ്കാനയില്‍ വനിതയെ അപമാനിക്കാന്‍ ശ്രമിച്ച സി...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1808</th>\n",
              "      <td>കളിക്കാര്‍ പണത്തിനുവേണ്ടി മറ്റു വഴികള്‍ തേടിയത...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1058</th>\n",
              "      <td>ഇരുടീമുകളും അവരുടെ ബാറ്റിങ് നിരയെയാണ് ഈ മത്സരത...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1745</th>\n",
              "      <td>ടൂര്‍ണമെന്റിലുടനീളം വിജയങ്ങള്‍ നേടിയ വിന്‍ഡീസ്...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "2274  അപ്രതീക്ഷിത തിരിച്ചടിയാണ്‌ തെരഞ്ഞെടുപ്പിലുണ്ടാ...      0\n",
              "1865  തെലങ്കാനയില്‍ വനിതയെ അപമാനിക്കാന്‍ ശ്രമിച്ച സി...      0\n",
              "1808  കളിക്കാര്‍ പണത്തിനുവേണ്ടി മറ്റു വഴികള്‍ തേടിയത...      0\n",
              "1058  ഇരുടീമുകളും അവരുടെ ബാറ്റിങ് നിരയെയാണ് ഈ മത്സരത...      0\n",
              "1745  ടൂര്‍ണമെന്റിലുടനീളം വിജയങ്ങള്‍ നേടിയ വിന്‍ഡീസ്...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64AfSL-V-Ij5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60lFABu1-KAE",
        "colab_type": "code",
        "outputId": "964350e7-0f4a-4b1f-9beb-51a3b8d0cc61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "69206e341634475a9454a057aa3023f5",
            "526ac6a544dc4eea9c42cc5456f141f0",
            "372232e585cd4167b750fb9b80ab7cc9",
            "68b3f5e310de4e219d6fdc9fde6db02a",
            "da18d58bff254e1281a6fdf442672294",
            "4e9e862e693b4ea389b1e282cc5cb9c1",
            "0c411c1730cc4e52a1588b48b5d5c9e9",
            "9de680c8a30342d2bf2fd70494be4925"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69206e341634475a9454a057aa3023f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqawKMwS-o5b",
        "colab_type": "code",
        "outputId": "090fc60e-8551-49b4-e9e2-66a83e74948b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  റോയൽ ചലഞ്ചേഴ്സിനെ ആറു വിക്കറ്റിന് തകർത്ത് മുംബൈ വീണ്ടും വിജയവഴിയിൽ.<eol>ബാംഗ്ലൂര്‍ റോയൽ ചലഞ്ചേഴ്സിനെ മുംബൈ ആറ് വിക്കറ്റിന് തോല്‍പിച്ചു.\n",
            "Tokenized:  ['റ', '##േ', '##ായ', '##ൽ', 'ച', '##ല', '##ഞ', '##ച', '##േ', '##ഴ', '##സി', '##നെ', 'ആ', '##റ', 'വി', '##ക', '##ക', '##റ', '##റി', '##ന', 'ത', '##കർ', '##ത', '##ത', 'മ', '##ം', '##ബ', '##ൈ', 'വ', '##ീ', '##ണ', '##ടം', 'വി', '##ജ', '##യ', '##വ', '##ഴി', '##യിൽ', '.', '<', 'eo', '##l', '>', 'ബ', '##ാം', '##ഗ', '##ല', '##ര', 'റ', '##േ', '##ായ', '##ൽ', 'ച', '##ല', '##ഞ', '##ച', '##േ', '##ഴ', '##സി', '##നെ', 'മ', '##ം', '##ബ', '##ൈ', 'ആ', '##റ', 'വി', '##ക', '##ക', '##റ', '##റി', '##ന', 'ത', '##േ', '##ാല', '##പ', '##ി', '##ച', '##ച', '.']\n",
            "Token IDs:  [1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 94330, 20854, 20854, 1357, 14885, 111397, 59009, 1364, 60434, 36089, 53144, 80054, 111388, 18395, 36877, 90865, 17878, 119, 133, 13934, 10161, 135, 1355, 25406, 111383, 38847, 23290, 1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1357, 14885, 111397, 59009, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 29400, 79591, 111395, 15035, 111386, 111386, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKGzPxF1AUUM",
        "colab_type": "code",
        "outputId": "60aab84e-0e66-45f1-ccaa-ab286e1d9f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  റോയൽ ചലഞ്ചേഴ്സിനെ ആറു വിക്കറ്റിന് തകർത്ത് മുംബൈ വീണ്ടും വിജയവഴിയിൽ.<eol>ബാംഗ്ലൂര്‍ റോയൽ ചലഞ്ചേഴ്സിനെ മുംബൈ ആറ് വിക്കറ്റിന് തോല്‍പിച്ചു.\n",
            "Token IDs: [101, 1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 94330, 20854, 20854, 1357, 14885, 111397, 59009, 1364, 60434, 36089, 53144, 80054, 111388, 18395, 36877, 90865, 17878, 119, 133, 13934, 10161, 135, 1355, 25406, 111383, 38847, 23290, 1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1357, 14885, 111397, 59009, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 29400, 79591, 111395, 15035, 111386, 111386, 119, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv39u2kLAo9b",
        "colab_type": "code",
        "outputId": "ebb5bc90-b8cf-439f-9858-b02b70600543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH_GkPkFAsKR",
        "colab_type": "code",
        "outputId": "de4f7037-9eac-48be-c101-8c9572c38a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUKKZrYgAuTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfmeSm3zAxOP",
        "colab_type": "code",
        "outputId": "c09d1eb2-02ad-4241-d59e-600c5130a624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.2)\n",
        "print(train_inputs)\n",
        "print(train_labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.2)\n",
        "#print(train_masks)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   101   1357 111399 ...  23290  27215  21403]\n",
            " [   101   1357  25344 ...  75301  17896  71430]\n",
            " [   101   1325  20854 ...  20854  20854  23290]\n",
            " ...\n",
            " [   101  80054  36877 ... 111393  18395  47357]\n",
            " [   101   1321 111395 ...  60955  47025  93330]\n",
            " [   101   1321  36877 ...  42870  30585   1353]]\n",
            "[1 0 1 ... 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6BSzcZ-A8JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2ab-k8GgLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvYAxocaGzaO",
        "colab_type": "code",
        "outputId": "5794905e-73f4-4787-c431-240fa9769d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "35df0b1367ba457d8791ffd8458bd5c2",
            "b7438fb701f843cdab0a02528842028d",
            "764095436156407180fe9ad6b023d387",
            "94856b01e57041d69d024b9b715c5f92",
            "6f6e79a7b942422e9615335cd2888347",
            "12678455cd084be4a65e4f30747fea8a",
            "8e0332378a59432e9582716785cf177d",
            "611968654f5740569586b8b5c03b103c",
            "2300f51ddb4e4b1d8e09b140309ec5d7",
            "628979814fb343428486ca2dc3fde399",
            "497310035a6847cc9a5aac38692fdc96",
            "cdecd492ea294ce88baf4b72b241b739",
            "1cce8ab9ec42428697bb1cd1daf8a2c3",
            "b9a71d5a59bd465f975ad23b0aba3c6c",
            "f5e57a7d641d4a5593025df31bccb200",
            "3c06443188e744a99b83edf8471cf514"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35df0b1367ba457d8791ffd8458bd5c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2300f51ddb4e4b1d8e09b140309ec5d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xB1woJrHCZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "83a6f7c6-ac51-42de-d2e4-c4de5162c7bd"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NhjDCrtHGh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBK2E_PaHKQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOO83LgEHQYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2jmuLjzHUP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6dh8MSXHXCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "dc276557-e0a9-4763-d77d-1eda62e2c5cf"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     63.    Elapsed: 0:00:21.\n",
            "\n",
            "  Average training loss: 0.62\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     63.    Elapsed: 0:00:21.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     63.    Elapsed: 0:00:21.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     63.    Elapsed: 0:00:21.\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifs2QgT9HeUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "4d044c38-5d28-4f13-a273-258acc9a75fd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3sCgA3MK9B2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f869abaf-0f52-4474-a3bd-db071e786aff"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/testdata/task1malayalam-test.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 900\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHsFeNFSLIkL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d08921e7-7dbc-4af0-d3ee-55dc27ca2378"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "  # # print(predictions)\n",
        "  #print(true_labels)\n",
        "print('    DONE.')\n",
        "\n",
        "#print(true_labels)\n",
        "print(\"*************************\")\n",
        "\n",
        "print(len(predictions))\n",
        "#print(outputs)\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 900 test sentences...\n",
            "    DONE.\n",
            "*************************\n",
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgpMTRW-jMtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.savetxt(\"/content/drive/My Drive/FYP/bert/glue/cola/task-1-malayalam.txt\",predictions, fmt=\"%s\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCGGtb-jicKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db347724-6b33-45ce-e841-c4617832bb76"
      },
      "source": [
        "\n",
        "count_NP=0\n",
        "count_P=0\n",
        "count_line=1\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    print(count_line,end=\"\")\n",
        "    print(\"-  \",end=\"\")\n",
        "    if(predictions[i][j][0]>predictions[i][j][1]):\n",
        "      count_P+=1 \n",
        "      print(\" Paraphrase         \",end=\"\")\n",
        "      print(predictions[i][j][0])\n",
        "    else:\n",
        "      print(\" Not Paraphrase     \",end=\"\")\n",
        "      count_NP+=1      \n",
        "      print(predictions[i][j][1])\n",
        "    count_line+=1\n",
        "# print(true_labels)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-   Paraphrase         0.5437378\n",
            "2-   Paraphrase         0.3224047\n",
            "3-   Not Paraphrase     1.3639549\n",
            "4-   Not Paraphrase     1.2622488\n",
            "5-   Paraphrase         1.8946072\n",
            "6-   Not Paraphrase     1.2978162\n",
            "7-   Not Paraphrase     0.7690131\n",
            "8-   Paraphrase         1.7348007\n",
            "9-   Paraphrase         1.2521344\n",
            "10-   Not Paraphrase     1.5700879\n",
            "11-   Paraphrase         0.6325784\n",
            "12-   Paraphrase         1.7107123\n",
            "13-   Paraphrase         0.47937965\n",
            "14-   Paraphrase         1.7527692\n",
            "15-   Paraphrase         1.9732115\n",
            "16-   Paraphrase         0.9808496\n",
            "17-   Not Paraphrase     0.6382426\n",
            "18-   Paraphrase         1.286118\n",
            "19-   Paraphrase         0.29388484\n",
            "20-   Paraphrase         1.6981686\n",
            "21-   Paraphrase         1.8635151\n",
            "22-   Paraphrase         2.0162456\n",
            "23-   Paraphrase         0.42582875\n",
            "24-   Paraphrase         1.690171\n",
            "25-   Paraphrase         2.0104077\n",
            "26-   Paraphrase         1.921735\n",
            "27-   Paraphrase         1.9401757\n",
            "28-   Not Paraphrase     1.3763603\n",
            "29-   Not Paraphrase     0.46381068\n",
            "30-   Paraphrase         1.817701\n",
            "31-   Paraphrase         1.3904239\n",
            "32-   Paraphrase         1.4328827\n",
            "33-   Paraphrase         0.079009354\n",
            "34-   Paraphrase         1.2027357\n",
            "35-   Paraphrase         0.8952874\n",
            "36-   Paraphrase         1.0270984\n",
            "37-   Paraphrase         1.6671256\n",
            "38-   Not Paraphrase     1.5246875\n",
            "39-   Not Paraphrase     0.95139503\n",
            "40-   Paraphrase         0.2596474\n",
            "41-   Paraphrase         1.2405976\n",
            "42-   Not Paraphrase     0.96718085\n",
            "43-   Not Paraphrase     0.4598619\n",
            "44-   Paraphrase         1.3823904\n",
            "45-   Not Paraphrase     0.539796\n",
            "46-   Paraphrase         1.7167357\n",
            "47-   Paraphrase         0.5518666\n",
            "48-   Not Paraphrase     1.4685876\n",
            "49-   Paraphrase         1.8159249\n",
            "50-   Not Paraphrase     0.3108013\n",
            "51-   Paraphrase         1.3253322\n",
            "52-   Paraphrase         0.3031408\n",
            "53-   Not Paraphrase     0.34744114\n",
            "54-   Not Paraphrase     1.2227632\n",
            "55-   Not Paraphrase     0.26289263\n",
            "56-   Paraphrase         1.3388164\n",
            "57-   Paraphrase         1.6829265\n",
            "58-   Paraphrase         1.4041733\n",
            "59-   Paraphrase         1.8324419\n",
            "60-   Paraphrase         1.777881\n",
            "61-   Paraphrase         0.516597\n",
            "62-   Paraphrase         0.45198035\n",
            "63-   Paraphrase         1.8890144\n",
            "64-   Paraphrase         1.1898972\n",
            "65-   Paraphrase         1.8144162\n",
            "66-   Not Paraphrase     0.5574211\n",
            "67-   Paraphrase         1.5521297\n",
            "68-   Not Paraphrase     0.66754377\n",
            "69-   Paraphrase         1.7080592\n",
            "70-   Paraphrase         0.21730445\n",
            "71-   Paraphrase         1.8174363\n",
            "72-   Not Paraphrase     1.2926557\n",
            "73-   Paraphrase         1.1928896\n",
            "74-   Paraphrase         1.924512\n",
            "75-   Paraphrase         1.1957295\n",
            "76-   Paraphrase         1.5351508\n",
            "77-   Paraphrase         1.8916167\n",
            "78-   Paraphrase         1.8370646\n",
            "79-   Paraphrase         0.69726187\n",
            "80-   Not Paraphrase     0.18575129\n",
            "81-   Paraphrase         1.4998875\n",
            "82-   Paraphrase         1.0561869\n",
            "83-   Paraphrase         1.9128845\n",
            "84-   Not Paraphrase     0.7288235\n",
            "85-   Not Paraphrase     0.14586356\n",
            "86-   Paraphrase         0.43959108\n",
            "87-   Paraphrase         1.8056968\n",
            "88-   Paraphrase         1.1684998\n",
            "89-   Paraphrase         0.694465\n",
            "90-   Paraphrase         1.7073253\n",
            "91-   Paraphrase         1.639953\n",
            "92-   Paraphrase         1.5637351\n",
            "93-   Paraphrase         1.9713894\n",
            "94-   Not Paraphrase     0.5402243\n",
            "95-   Not Paraphrase     1.6706878\n",
            "96-   Not Paraphrase     0.5721448\n",
            "97-   Not Paraphrase     0.40227398\n",
            "98-   Not Paraphrase     0.09712444\n",
            "99-   Paraphrase         0.41686395\n",
            "100-   Paraphrase         1.5779704\n",
            "101-   Paraphrase         1.855174\n",
            "102-   Not Paraphrase     0.25487378\n",
            "103-   Paraphrase         0.772887\n",
            "104-   Paraphrase         0.09794509\n",
            "105-   Not Paraphrase     0.8089046\n",
            "106-   Not Paraphrase     1.2494029\n",
            "107-   Not Paraphrase     1.1370064\n",
            "108-   Not Paraphrase     0.7134078\n",
            "109-   Paraphrase         1.5029821\n",
            "110-   Paraphrase         1.3371296\n",
            "111-   Paraphrase         0.8251211\n",
            "112-   Paraphrase         1.0168649\n",
            "113-   Paraphrase         1.9137354\n",
            "114-   Not Paraphrase     0.83396786\n",
            "115-   Not Paraphrase     1.0222067\n",
            "116-   Paraphrase         0.09779542\n",
            "117-   Paraphrase         2.003092\n",
            "118-   Not Paraphrase     0.53785187\n",
            "119-   Paraphrase         1.660409\n",
            "120-   Paraphrase         1.7985492\n",
            "121-   Paraphrase         0.2603715\n",
            "122-   Paraphrase         0.2070888\n",
            "123-   Paraphrase         1.4381078\n",
            "124-   Paraphrase         0.42251542\n",
            "125-   Paraphrase         1.662531\n",
            "126-   Paraphrase         0.74320954\n",
            "127-   Paraphrase         1.9645659\n",
            "128-   Paraphrase         0.16671407\n",
            "129-   Paraphrase         0.70501035\n",
            "130-   Paraphrase         2.0275435\n",
            "131-   Paraphrase         1.9863102\n",
            "132-   Not Paraphrase     0.77076966\n",
            "133-   Paraphrase         1.6623096\n",
            "134-   Paraphrase         1.4336122\n",
            "135-   Paraphrase         1.3803945\n",
            "136-   Paraphrase         1.4449769\n",
            "137-   Paraphrase         1.1629795\n",
            "138-   Paraphrase         0.959791\n",
            "139-   Not Paraphrase     1.103096\n",
            "140-   Paraphrase         1.3423902\n",
            "141-   Paraphrase         1.9312998\n",
            "142-   Paraphrase         1.7413796\n",
            "143-   Paraphrase         1.2869452\n",
            "144-   Paraphrase         1.7787344\n",
            "145-   Not Paraphrase     0.6680414\n",
            "146-   Paraphrase         0.11529662\n",
            "147-   Paraphrase         1.8982686\n",
            "148-   Paraphrase         1.6920539\n",
            "149-   Paraphrase         0.85967064\n",
            "150-   Not Paraphrase     0.37767518\n",
            "151-   Paraphrase         0.5085783\n",
            "152-   Not Paraphrase     1.3107201\n",
            "153-   Paraphrase         1.5480281\n",
            "154-   Paraphrase         1.0510597\n",
            "155-   Not Paraphrase     0.21010503\n",
            "156-   Paraphrase         0.4312028\n",
            "157-   Paraphrase         0.79709715\n",
            "158-   Paraphrase         0.93005675\n",
            "159-   Paraphrase         1.5729529\n",
            "160-   Not Paraphrase     1.5489148\n",
            "161-   Paraphrase         0.6992919\n",
            "162-   Paraphrase         0.23921046\n",
            "163-   Paraphrase         1.854904\n",
            "164-   Not Paraphrase     0.7803608\n",
            "165-   Not Paraphrase     0.20805836\n",
            "166-   Paraphrase         1.8948511\n",
            "167-   Paraphrase         1.3620976\n",
            "168-   Paraphrase         1.7510622\n",
            "169-   Paraphrase         2.0052776\n",
            "170-   Paraphrase         0.8549425\n",
            "171-   Paraphrase         1.0050764\n",
            "172-   Paraphrase         0.14711201\n",
            "173-   Paraphrase         1.2525102\n",
            "174-   Paraphrase         1.8983737\n",
            "175-   Paraphrase         1.9749017\n",
            "176-   Not Paraphrase     1.4919643\n",
            "177-   Paraphrase         0.3615136\n",
            "178-   Not Paraphrase     0.1693268\n",
            "179-   Paraphrase         1.2534858\n",
            "180-   Paraphrase         0.13319355\n",
            "181-   Not Paraphrase     1.7569698\n",
            "182-   Paraphrase         1.2708585\n",
            "183-   Paraphrase         0.54631525\n",
            "184-   Not Paraphrase     0.8814414\n",
            "185-   Paraphrase         1.3950468\n",
            "186-   Paraphrase         1.1652135\n",
            "187-   Paraphrase         1.086815\n",
            "188-   Paraphrase         0.9403201\n",
            "189-   Paraphrase         1.1446937\n",
            "190-   Paraphrase         1.9469235\n",
            "191-   Paraphrase         1.6624113\n",
            "192-   Paraphrase         1.5804869\n",
            "193-   Paraphrase         1.8508439\n",
            "194-   Not Paraphrase     0.7729043\n",
            "195-   Paraphrase         0.17007785\n",
            "196-   Paraphrase         1.819996\n",
            "197-   Paraphrase         1.6074017\n",
            "198-   Not Paraphrase     0.38782766\n",
            "199-   Paraphrase         1.3847628\n",
            "200-   Not Paraphrase     1.0586312\n",
            "201-   Paraphrase         0.4365258\n",
            "202-   Paraphrase         1.4826087\n",
            "203-   Paraphrase         1.7137022\n",
            "204-   Paraphrase         0.7892615\n",
            "205-   Paraphrase         0.9044928\n",
            "206-   Paraphrase         1.9403119\n",
            "207-   Paraphrase         1.0508696\n",
            "208-   Paraphrase         1.8238373\n",
            "209-   Paraphrase         1.5974422\n",
            "210-   Paraphrase         1.8875732\n",
            "211-   Paraphrase         1.845533\n",
            "212-   Paraphrase         1.7471815\n",
            "213-   Not Paraphrase     1.7212476\n",
            "214-   Paraphrase         0.75510174\n",
            "215-   Paraphrase         1.963927\n",
            "216-   Not Paraphrase     0.59421784\n",
            "217-   Paraphrase         1.0309381\n",
            "218-   Paraphrase         1.6404717\n",
            "219-   Not Paraphrase     1.4499382\n",
            "220-   Paraphrase         1.8679094\n",
            "221-   Paraphrase         1.2830805\n",
            "222-   Paraphrase         0.25533095\n",
            "223-   Not Paraphrase     0.35232428\n",
            "224-   Paraphrase         1.6359675\n",
            "225-   Paraphrase         1.677916\n",
            "226-   Not Paraphrase     1.6758411\n",
            "227-   Paraphrase         1.4008012\n",
            "228-   Paraphrase         1.8031169\n",
            "229-   Paraphrase         0.9737329\n",
            "230-   Not Paraphrase     1.6921948\n",
            "231-   Paraphrase         1.5612271\n",
            "232-   Not Paraphrase     1.2891343\n",
            "233-   Paraphrase         1.0787925\n",
            "234-   Paraphrase         1.1412803\n",
            "235-   Not Paraphrase     0.7464826\n",
            "236-   Paraphrase         1.7262634\n",
            "237-   Not Paraphrase     1.5907797\n",
            "238-   Not Paraphrase     1.5100905\n",
            "239-   Paraphrase         0.5286689\n",
            "240-   Paraphrase         1.2142302\n",
            "241-   Paraphrase         0.8468822\n",
            "242-   Paraphrase         0.82881194\n",
            "243-   Paraphrase         0.2574537\n",
            "244-   Paraphrase         1.7127866\n",
            "245-   Paraphrase         1.8146065\n",
            "246-   Not Paraphrase     0.081483826\n",
            "247-   Not Paraphrase     1.6717718\n",
            "248-   Paraphrase         1.6662512\n",
            "249-   Paraphrase         1.4666826\n",
            "250-   Not Paraphrase     0.6060505\n",
            "251-   Not Paraphrase     1.7639383\n",
            "252-   Paraphrase         0.47126237\n",
            "253-   Not Paraphrase     1.6464916\n",
            "254-   Not Paraphrase     0.59574324\n",
            "255-   Paraphrase         0.62111944\n",
            "256-   Paraphrase         1.5183853\n",
            "257-   Not Paraphrase     0.96100754\n",
            "258-   Paraphrase         0.86530095\n",
            "259-   Not Paraphrase     0.34947166\n",
            "260-   Not Paraphrase     0.2585445\n",
            "261-   Not Paraphrase     1.5286888\n",
            "262-   Paraphrase         0.3239925\n",
            "263-   Paraphrase         1.2814301\n",
            "264-   Paraphrase         0.58868587\n",
            "265-   Not Paraphrase     0.5191185\n",
            "266-   Paraphrase         0.48780927\n",
            "267-   Paraphrase         1.3393265\n",
            "268-   Paraphrase         0.20565931\n",
            "269-   Not Paraphrase     0.6722968\n",
            "270-   Not Paraphrase     1.4787934\n",
            "271-   Paraphrase         1.6413652\n",
            "272-   Paraphrase         0.1483213\n",
            "273-   Paraphrase         0.13098902\n",
            "274-   Paraphrase         1.4981209\n",
            "275-   Not Paraphrase     1.077903\n",
            "276-   Paraphrase         1.275742\n",
            "277-   Not Paraphrase     1.2499348\n",
            "278-   Paraphrase         0.50092846\n",
            "279-   Not Paraphrase     1.7171798\n",
            "280-   Paraphrase         1.178319\n",
            "281-   Paraphrase         1.221263\n",
            "282-   Paraphrase         1.0416666\n",
            "283-   Paraphrase         0.90934134\n",
            "284-   Not Paraphrase     1.1776069\n",
            "285-   Not Paraphrase     1.7385563\n",
            "286-   Not Paraphrase     1.2042419\n",
            "287-   Not Paraphrase     1.1623019\n",
            "288-   Not Paraphrase     1.4405457\n",
            "289-   Not Paraphrase     0.98508376\n",
            "290-   Paraphrase         0.2590603\n",
            "291-   Paraphrase         1.4128883\n",
            "292-   Paraphrase         1.3314137\n",
            "293-   Not Paraphrase     0.97966605\n",
            "294-   Paraphrase         1.9875278\n",
            "295-   Not Paraphrase     0.9769847\n",
            "296-   Paraphrase         0.99118584\n",
            "297-   Paraphrase         0.6268477\n",
            "298-   Paraphrase         0.67267615\n",
            "299-   Paraphrase         1.3308877\n",
            "300-   Paraphrase         0.5621868\n",
            "301-   Paraphrase         0.82487726\n",
            "302-   Paraphrase         1.7932954\n",
            "303-   Paraphrase         1.8805209\n",
            "304-   Paraphrase         0.9126722\n",
            "305-   Paraphrase         1.7508398\n",
            "306-   Not Paraphrase     0.9576755\n",
            "307-   Paraphrase         1.8143595\n",
            "308-   Not Paraphrase     0.35898677\n",
            "309-   Not Paraphrase     0.42609015\n",
            "310-   Not Paraphrase     1.0118577\n",
            "311-   Paraphrase         1.9038607\n",
            "312-   Paraphrase         0.6675946\n",
            "313-   Paraphrase         1.0525128\n",
            "314-   Paraphrase         0.40352455\n",
            "315-   Not Paraphrase     0.35045195\n",
            "316-   Paraphrase         1.5452174\n",
            "317-   Paraphrase         1.813945\n",
            "318-   Not Paraphrase     0.34913218\n",
            "319-   Paraphrase         1.8533677\n",
            "320-   Paraphrase         1.0218712\n",
            "321-   Paraphrase         1.4918112\n",
            "322-   Not Paraphrase     0.31532305\n",
            "323-   Not Paraphrase     0.64820635\n",
            "324-   Paraphrase         1.6771916\n",
            "325-   Not Paraphrase     1.7708863\n",
            "326-   Paraphrase         1.4910775\n",
            "327-   Paraphrase         1.955184\n",
            "328-   Paraphrase         1.8075452\n",
            "329-   Paraphrase         1.2739688\n",
            "330-   Paraphrase         1.3278428\n",
            "331-   Not Paraphrase     1.1180485\n",
            "332-   Paraphrase         2.0330477\n",
            "333-   Paraphrase         1.638774\n",
            "334-   Not Paraphrase     1.7165397\n",
            "335-   Paraphrase         0.2267278\n",
            "336-   Not Paraphrase     1.7330836\n",
            "337-   Paraphrase         1.7098182\n",
            "338-   Paraphrase         0.6058335\n",
            "339-   Paraphrase         0.085768186\n",
            "340-   Not Paraphrase     0.89664483\n",
            "341-   Paraphrase         0.9804329\n",
            "342-   Paraphrase         0.33734912\n",
            "343-   Not Paraphrase     1.5765387\n",
            "344-   Paraphrase         0.5021113\n",
            "345-   Not Paraphrase     0.4784348\n",
            "346-   Not Paraphrase     1.1010572\n",
            "347-   Not Paraphrase     1.8032814\n",
            "348-   Not Paraphrase     1.1282574\n",
            "349-   Paraphrase         0.83470124\n",
            "350-   Paraphrase         1.4137702\n",
            "351-   Paraphrase         0.32372725\n",
            "352-   Paraphrase         1.1178073\n",
            "353-   Not Paraphrase     1.6512603\n",
            "354-   Not Paraphrase     0.72518104\n",
            "355-   Paraphrase         1.9057803\n",
            "356-   Not Paraphrase     1.3990628\n",
            "357-   Not Paraphrase     0.43690982\n",
            "358-   Not Paraphrase     1.3423072\n",
            "359-   Paraphrase         1.6979797\n",
            "360-   Paraphrase         1.2901698\n",
            "361-   Paraphrase         0.8603057\n",
            "362-   Not Paraphrase     0.27891803\n",
            "363-   Paraphrase         1.4985669\n",
            "364-   Paraphrase         1.0916235\n",
            "365-   Not Paraphrase     1.7499628\n",
            "366-   Not Paraphrase     1.1256734\n",
            "367-   Not Paraphrase     1.662104\n",
            "368-   Not Paraphrase     1.598849\n",
            "369-   Paraphrase         0.8371928\n",
            "370-   Not Paraphrase     1.7058183\n",
            "371-   Paraphrase         1.2935106\n",
            "372-   Paraphrase         1.9242617\n",
            "373-   Paraphrase         0.9865427\n",
            "374-   Not Paraphrase     0.37690264\n",
            "375-   Paraphrase         1.3467749\n",
            "376-   Paraphrase         1.1642004\n",
            "377-   Not Paraphrase     0.373049\n",
            "378-   Paraphrase         1.3570492\n",
            "379-   Not Paraphrase     1.4833648\n",
            "380-   Paraphrase         0.33206034\n",
            "381-   Not Paraphrase     0.7298227\n",
            "382-   Not Paraphrase     0.123515196\n",
            "383-   Paraphrase         1.804222\n",
            "384-   Paraphrase         0.4297852\n",
            "385-   Paraphrase         0.772312\n",
            "386-   Paraphrase         1.6592247\n",
            "387-   Paraphrase         1.9655164\n",
            "388-   Not Paraphrase     0.64168715\n",
            "389-   Not Paraphrase     0.91995865\n",
            "390-   Paraphrase         1.6666385\n",
            "391-   Not Paraphrase     0.86450773\n",
            "392-   Paraphrase         0.26210958\n",
            "393-   Not Paraphrase     1.0859107\n",
            "394-   Not Paraphrase     1.6868771\n",
            "395-   Paraphrase         0.14323933\n",
            "396-   Paraphrase         1.9431478\n",
            "397-   Not Paraphrase     1.6374501\n",
            "398-   Paraphrase         1.11243\n",
            "399-   Paraphrase         0.32966343\n",
            "400-   Paraphrase         0.35697845\n",
            "401-   Paraphrase         0.33251014\n",
            "402-   Not Paraphrase     0.2822848\n",
            "403-   Paraphrase         0.99956733\n",
            "404-   Not Paraphrase     0.19044417\n",
            "405-   Not Paraphrase     1.1559589\n",
            "406-   Not Paraphrase     1.51446\n",
            "407-   Paraphrase         1.8643674\n",
            "408-   Not Paraphrase     0.6464935\n",
            "409-   Not Paraphrase     0.7975197\n",
            "410-   Not Paraphrase     1.3535513\n",
            "411-   Not Paraphrase     1.7577437\n",
            "412-   Paraphrase         0.33042207\n",
            "413-   Not Paraphrase     1.7161882\n",
            "414-   Paraphrase         1.7600611\n",
            "415-   Paraphrase         1.2921524\n",
            "416-   Not Paraphrase     1.1646023\n",
            "417-   Paraphrase         1.3968414\n",
            "418-   Not Paraphrase     0.7037781\n",
            "419-   Paraphrase         0.5060087\n",
            "420-   Not Paraphrase     0.840982\n",
            "421-   Paraphrase         1.6008396\n",
            "422-   Paraphrase         1.2810863\n",
            "423-   Paraphrase         1.0096076\n",
            "424-   Not Paraphrase     0.4006168\n",
            "425-   Not Paraphrase     0.8222631\n",
            "426-   Paraphrase         0.57359403\n",
            "427-   Paraphrase         1.5472277\n",
            "428-   Not Paraphrase     0.98556334\n",
            "429-   Paraphrase         1.4280205\n",
            "430-   Paraphrase         1.8023514\n",
            "431-   Not Paraphrase     1.4686536\n",
            "432-   Not Paraphrase     1.356753\n",
            "433-   Paraphrase         0.25679198\n",
            "434-   Paraphrase         0.20655786\n",
            "435-   Paraphrase         1.5226568\n",
            "436-   Paraphrase         1.6569206\n",
            "437-   Paraphrase         1.402707\n",
            "438-   Not Paraphrase     0.4828806\n",
            "439-   Not Paraphrase     1.4242959\n",
            "440-   Not Paraphrase     0.47920877\n",
            "441-   Not Paraphrase     1.3566053\n",
            "442-   Paraphrase         1.1666449\n",
            "443-   Not Paraphrase     1.8009026\n",
            "444-   Paraphrase         1.0838662\n",
            "445-   Paraphrase         1.2849144\n",
            "446-   Paraphrase         1.8257903\n",
            "447-   Not Paraphrase     1.3524419\n",
            "448-   Paraphrase         1.341494\n",
            "449-   Paraphrase         1.6537606\n",
            "450-   Not Paraphrase     1.6513846\n",
            "451-   Paraphrase         0.9557231\n",
            "452-   Paraphrase         1.1078926\n",
            "453-   Not Paraphrase     0.35603765\n",
            "454-   Paraphrase         0.35752478\n",
            "455-   Paraphrase         1.0626255\n",
            "456-   Not Paraphrase     1.8198367\n",
            "457-   Paraphrase         1.8106688\n",
            "458-   Paraphrase         1.2384866\n",
            "459-   Not Paraphrase     1.2808168\n",
            "460-   Paraphrase         0.2778082\n",
            "461-   Not Paraphrase     1.587772\n",
            "462-   Not Paraphrase     1.3259946\n",
            "463-   Not Paraphrase     0.84747404\n",
            "464-   Paraphrase         0.1929123\n",
            "465-   Not Paraphrase     1.1435945\n",
            "466-   Not Paraphrase     0.16262177\n",
            "467-   Not Paraphrase     0.5185074\n",
            "468-   Not Paraphrase     0.41509256\n",
            "469-   Paraphrase         1.9414628\n",
            "470-   Paraphrase         1.8547382\n",
            "471-   Not Paraphrase     1.0980963\n",
            "472-   Paraphrase         0.2729257\n",
            "473-   Paraphrase         0.34677574\n",
            "474-   Paraphrase         0.40738395\n",
            "475-   Paraphrase         1.1970421\n",
            "476-   Not Paraphrase     0.2273346\n",
            "477-   Paraphrase         1.9175639\n",
            "478-   Not Paraphrase     1.7230027\n",
            "479-   Paraphrase         1.4550742\n",
            "480-   Paraphrase         1.5170748\n",
            "481-   Paraphrase         1.2021445\n",
            "482-   Not Paraphrase     1.3824126\n",
            "483-   Paraphrase         1.7359948\n",
            "484-   Not Paraphrase     0.52386415\n",
            "485-   Not Paraphrase     0.47167972\n",
            "486-   Paraphrase         1.4663767\n",
            "487-   Paraphrase         0.33910748\n",
            "488-   Paraphrase         1.9455125\n",
            "489-   Not Paraphrase     0.121991016\n",
            "490-   Paraphrase         1.2441782\n",
            "491-   Paraphrase         0.6909427\n",
            "492-   Not Paraphrase     0.5356242\n",
            "493-   Paraphrase         1.1266423\n",
            "494-   Not Paraphrase     0.45434663\n",
            "495-   Not Paraphrase     0.5700814\n",
            "496-   Paraphrase         1.6049193\n",
            "497-   Not Paraphrase     1.2283906\n",
            "498-   Paraphrase         1.7817476\n",
            "499-   Paraphrase         1.7772919\n",
            "500-   Paraphrase         0.45604\n",
            "501-   Not Paraphrase     1.401584\n",
            "502-   Not Paraphrase     1.0231962\n",
            "503-   Paraphrase         1.8421179\n",
            "504-   Not Paraphrase     0.546049\n",
            "505-   Paraphrase         1.9548719\n",
            "506-   Not Paraphrase     0.7778463\n",
            "507-   Paraphrase         1.8165919\n",
            "508-   Paraphrase         1.561401\n",
            "509-   Paraphrase         1.2814654\n",
            "510-   Not Paraphrase     1.0444862\n",
            "511-   Paraphrase         0.8877886\n",
            "512-   Paraphrase         1.9064972\n",
            "513-   Not Paraphrase     1.6313003\n",
            "514-   Not Paraphrase     0.72408336\n",
            "515-   Paraphrase         0.18802828\n",
            "516-   Not Paraphrase     0.27124155\n",
            "517-   Paraphrase         1.6688956\n",
            "518-   Paraphrase         1.0167671\n",
            "519-   Not Paraphrase     0.28967834\n",
            "520-   Paraphrase         0.5270622\n",
            "521-   Paraphrase         1.0457855\n",
            "522-   Not Paraphrase     1.6551963\n",
            "523-   Not Paraphrase     1.5226618\n",
            "524-   Paraphrase         1.5903622\n",
            "525-   Not Paraphrase     0.19020565\n",
            "526-   Not Paraphrase     0.3625898\n",
            "527-   Paraphrase         0.23647073\n",
            "528-   Paraphrase         1.1943337\n",
            "529-   Not Paraphrase     1.754455\n",
            "530-   Paraphrase         0.73582757\n",
            "531-   Not Paraphrase     0.69171077\n",
            "532-   Not Paraphrase     0.95085233\n",
            "533-   Not Paraphrase     1.2983108\n",
            "534-   Paraphrase         1.7224535\n",
            "535-   Paraphrase         1.0802332\n",
            "536-   Paraphrase         0.5582393\n",
            "537-   Paraphrase         1.8206378\n",
            "538-   Paraphrase         1.8201004\n",
            "539-   Paraphrase         1.8488415\n",
            "540-   Paraphrase         1.7266802\n",
            "541-   Paraphrase         1.6999573\n",
            "542-   Not Paraphrase     0.56884336\n",
            "543-   Paraphrase         0.5556463\n",
            "544-   Paraphrase         0.5491058\n",
            "545-   Paraphrase         1.5772842\n",
            "546-   Paraphrase         0.23435059\n",
            "547-   Paraphrase         0.7222947\n",
            "548-   Paraphrase         1.9489217\n",
            "549-   Paraphrase         0.30634624\n",
            "550-   Paraphrase         1.3430542\n",
            "551-   Not Paraphrase     1.1815803\n",
            "552-   Paraphrase         1.5707725\n",
            "553-   Not Paraphrase     1.1610494\n",
            "554-   Not Paraphrase     0.6870018\n",
            "555-   Paraphrase         1.9053534\n",
            "556-   Paraphrase         1.9612905\n",
            "557-   Paraphrase         1.7503966\n",
            "558-   Paraphrase         0.23115845\n",
            "559-   Not Paraphrase     1.1769173\n",
            "560-   Not Paraphrase     0.90881026\n",
            "561-   Paraphrase         1.7243026\n",
            "562-   Paraphrase         1.2319793\n",
            "563-   Not Paraphrase     0.36513153\n",
            "564-   Paraphrase         1.8557996\n",
            "565-   Not Paraphrase     0.14320083\n",
            "566-   Paraphrase         1.8028938\n",
            "567-   Paraphrase         0.5581077\n",
            "568-   Paraphrase         0.49516353\n",
            "569-   Paraphrase         1.178081\n",
            "570-   Paraphrase         1.5290371\n",
            "571-   Paraphrase         1.5373718\n",
            "572-   Not Paraphrase     0.3914536\n",
            "573-   Paraphrase         1.6205142\n",
            "574-   Paraphrase         1.4551243\n",
            "575-   Not Paraphrase     0.7231247\n",
            "576-   Not Paraphrase     0.7243845\n",
            "577-   Not Paraphrase     1.1782994\n",
            "578-   Paraphrase         1.6503953\n",
            "579-   Not Paraphrase     0.2993142\n",
            "580-   Paraphrase         1.2378491\n",
            "581-   Paraphrase         0.49245712\n",
            "582-   Paraphrase         0.98217726\n",
            "583-   Paraphrase         0.7280268\n",
            "584-   Paraphrase         0.256676\n",
            "585-   Paraphrase         1.3846306\n",
            "586-   Paraphrase         1.7201998\n",
            "587-   Paraphrase         1.3496851\n",
            "588-   Paraphrase         1.5182867\n",
            "589-   Not Paraphrase     0.74325085\n",
            "590-   Paraphrase         1.4039243\n",
            "591-   Not Paraphrase     1.2438987\n",
            "592-   Paraphrase         1.6887187\n",
            "593-   Paraphrase         0.8653723\n",
            "594-   Paraphrase         1.5700315\n",
            "595-   Not Paraphrase     1.7706488\n",
            "596-   Not Paraphrase     1.1056882\n",
            "597-   Not Paraphrase     0.31962755\n",
            "598-   Paraphrase         1.6143461\n",
            "599-   Paraphrase         0.47529897\n",
            "600-   Not Paraphrase     1.1168798\n",
            "601-   Paraphrase         1.1312414\n",
            "602-   Not Paraphrase     0.07625586\n",
            "603-   Paraphrase         1.2011666\n",
            "604-   Paraphrase         0.97255737\n",
            "605-   Paraphrase         0.44542757\n",
            "606-   Not Paraphrase     1.020837\n",
            "607-   Paraphrase         1.9982086\n",
            "608-   Not Paraphrase     0.42967075\n",
            "609-   Paraphrase         1.8919688\n",
            "610-   Not Paraphrase     1.7749599\n",
            "611-   Not Paraphrase     0.15474491\n",
            "612-   Not Paraphrase     0.6994674\n",
            "613-   Not Paraphrase     1.7391464\n",
            "614-   Paraphrase         1.6820037\n",
            "615-   Not Paraphrase     0.9350997\n",
            "616-   Not Paraphrase     0.70763004\n",
            "617-   Not Paraphrase     1.4581836\n",
            "618-   Paraphrase         1.2994324\n",
            "619-   Paraphrase         0.68745434\n",
            "620-   Not Paraphrase     1.1052688\n",
            "621-   Not Paraphrase     0.67136234\n",
            "622-   Paraphrase         1.8586581\n",
            "623-   Paraphrase         0.71981543\n",
            "624-   Paraphrase         0.63442606\n",
            "625-   Paraphrase         0.5642903\n",
            "626-   Not Paraphrase     1.1966826\n",
            "627-   Not Paraphrase     0.9648722\n",
            "628-   Paraphrase         1.9006923\n",
            "629-   Not Paraphrase     1.1560475\n",
            "630-   Paraphrase         0.094038114\n",
            "631-   Paraphrase         0.6391272\n",
            "632-   Paraphrase         1.917141\n",
            "633-   Not Paraphrase     1.6825408\n",
            "634-   Not Paraphrase     0.35397077\n",
            "635-   Not Paraphrase     0.72126436\n",
            "636-   Not Paraphrase     0.25140703\n",
            "637-   Paraphrase         1.0582658\n",
            "638-   Not Paraphrase     0.085734814\n",
            "639-   Paraphrase         1.4470702\n",
            "640-   Paraphrase         1.0642072\n",
            "641-   Not Paraphrase     0.50088304\n",
            "642-   Paraphrase         0.5706913\n",
            "643-   Paraphrase         1.5509965\n",
            "644-   Paraphrase         0.86188006\n",
            "645-   Not Paraphrase     0.4901578\n",
            "646-   Paraphrase         1.8332871\n",
            "647-   Paraphrase         1.8382453\n",
            "648-   Not Paraphrase     1.0986984\n",
            "649-   Paraphrase         1.8955008\n",
            "650-   Paraphrase         0.65797454\n",
            "651-   Paraphrase         1.2468759\n",
            "652-   Not Paraphrase     1.2009585\n",
            "653-   Paraphrase         0.8830555\n",
            "654-   Paraphrase         1.0699723\n",
            "655-   Not Paraphrase     1.2492286\n",
            "656-   Paraphrase         1.7803923\n",
            "657-   Not Paraphrase     0.23805377\n",
            "658-   Paraphrase         1.3137059\n",
            "659-   Paraphrase         1.7580659\n",
            "660-   Paraphrase         0.48184803\n",
            "661-   Not Paraphrase     1.2882184\n",
            "662-   Paraphrase         1.9945701\n",
            "663-   Paraphrase         0.72390133\n",
            "664-   Paraphrase         1.789031\n",
            "665-   Paraphrase         1.7062863\n",
            "666-   Paraphrase         1.7991922\n",
            "667-   Paraphrase         1.9737325\n",
            "668-   Not Paraphrase     0.72400624\n",
            "669-   Paraphrase         1.3915284\n",
            "670-   Paraphrase         1.6294413\n",
            "671-   Paraphrase         1.8163668\n",
            "672-   Paraphrase         1.9364547\n",
            "673-   Paraphrase         1.466105\n",
            "674-   Paraphrase         1.2318326\n",
            "675-   Not Paraphrase     0.745454\n",
            "676-   Not Paraphrase     1.7144097\n",
            "677-   Not Paraphrase     1.3983299\n",
            "678-   Not Paraphrase     0.6011149\n",
            "679-   Not Paraphrase     0.21977963\n",
            "680-   Paraphrase         0.84633577\n",
            "681-   Paraphrase         0.29120082\n",
            "682-   Paraphrase         0.92555326\n",
            "683-   Paraphrase         1.9562095\n",
            "684-   Not Paraphrase     0.5334099\n",
            "685-   Not Paraphrase     0.71997595\n",
            "686-   Not Paraphrase     1.0015788\n",
            "687-   Paraphrase         0.35990414\n",
            "688-   Not Paraphrase     0.41495004\n",
            "689-   Not Paraphrase     1.055193\n",
            "690-   Not Paraphrase     0.42810458\n",
            "691-   Not Paraphrase     0.7005445\n",
            "692-   Not Paraphrase     0.9661921\n",
            "693-   Paraphrase         1.7355303\n",
            "694-   Not Paraphrase     0.46346715\n",
            "695-   Not Paraphrase     0.15880553\n",
            "696-   Paraphrase         0.6645228\n",
            "697-   Paraphrase         1.0798415\n",
            "698-   Not Paraphrase     0.4348589\n",
            "699-   Paraphrase         1.1778251\n",
            "700-   Paraphrase         1.9372004\n",
            "701-   Not Paraphrase     0.3752241\n",
            "702-   Paraphrase         1.3703243\n",
            "703-   Paraphrase         1.3860414\n",
            "704-   Not Paraphrase     1.5590947\n",
            "705-   Paraphrase         1.6956872\n",
            "706-   Paraphrase         1.8070351\n",
            "707-   Paraphrase         1.1782572\n",
            "708-   Paraphrase         1.5456791\n",
            "709-   Not Paraphrase     0.7568135\n",
            "710-   Not Paraphrase     1.363306\n",
            "711-   Paraphrase         1.4801644\n",
            "712-   Paraphrase         1.8502965\n",
            "713-   Paraphrase         0.65861446\n",
            "714-   Not Paraphrase     1.6588591\n",
            "715-   Paraphrase         1.3238469\n",
            "716-   Paraphrase         0.69379246\n",
            "717-   Not Paraphrase     1.7283846\n",
            "718-   Not Paraphrase     0.40765503\n",
            "719-   Paraphrase         1.8562793\n",
            "720-   Not Paraphrase     1.2766103\n",
            "721-   Not Paraphrase     0.9084266\n",
            "722-   Paraphrase         0.6732587\n",
            "723-   Not Paraphrase     0.15579538\n",
            "724-   Paraphrase         0.8468669\n",
            "725-   Paraphrase         0.3352622\n",
            "726-   Paraphrase         0.31029928\n",
            "727-   Paraphrase         1.2936615\n",
            "728-   Paraphrase         1.3238912\n",
            "729-   Paraphrase         2.0185976\n",
            "730-   Not Paraphrase     0.859814\n",
            "731-   Paraphrase         1.5292696\n",
            "732-   Paraphrase         1.3268172\n",
            "733-   Paraphrase         0.4937178\n",
            "734-   Paraphrase         1.6478238\n",
            "735-   Not Paraphrase     1.0039295\n",
            "736-   Paraphrase         1.4448737\n",
            "737-   Paraphrase         1.4957968\n",
            "738-   Paraphrase         1.8274127\n",
            "739-   Paraphrase         0.5131501\n",
            "740-   Paraphrase         1.3406818\n",
            "741-   Paraphrase         1.075693\n",
            "742-   Paraphrase         1.5500789\n",
            "743-   Not Paraphrase     1.705218\n",
            "744-   Paraphrase         1.606712\n",
            "745-   Paraphrase         1.3111624\n",
            "746-   Paraphrase         0.8262996\n",
            "747-   Not Paraphrase     0.7597204\n",
            "748-   Not Paraphrase     1.7276336\n",
            "749-   Paraphrase         1.2351507\n",
            "750-   Paraphrase         1.6293181\n",
            "751-   Paraphrase         1.0076874\n",
            "752-   Not Paraphrase     1.5364621\n",
            "753-   Paraphrase         1.3608705\n",
            "754-   Paraphrase         1.9855777\n",
            "755-   Paraphrase         1.6788831\n",
            "756-   Paraphrase         1.512514\n",
            "757-   Paraphrase         1.7555517\n",
            "758-   Paraphrase         1.7683822\n",
            "759-   Paraphrase         2.0039415\n",
            "760-   Paraphrase         1.3293742\n",
            "761-   Paraphrase         1.4265292\n",
            "762-   Paraphrase         1.8973309\n",
            "763-   Not Paraphrase     1.7357253\n",
            "764-   Paraphrase         1.0734951\n",
            "765-   Paraphrase         1.7570249\n",
            "766-   Paraphrase         0.3445473\n",
            "767-   Not Paraphrase     0.12448824\n",
            "768-   Paraphrase         1.0372463\n",
            "769-   Not Paraphrase     0.7956681\n",
            "770-   Not Paraphrase     1.4582939\n",
            "771-   Paraphrase         2.0508475\n",
            "772-   Paraphrase         1.8972796\n",
            "773-   Paraphrase         1.1938366\n",
            "774-   Not Paraphrase     0.9613825\n",
            "775-   Not Paraphrase     1.5373611\n",
            "776-   Not Paraphrase     1.0623823\n",
            "777-   Not Paraphrase     0.8942142\n",
            "778-   Not Paraphrase     1.4009234\n",
            "779-   Paraphrase         1.8834256\n",
            "780-   Not Paraphrase     0.51129526\n",
            "781-   Paraphrase         0.50019306\n",
            "782-   Paraphrase         1.3850623\n",
            "783-   Not Paraphrase     0.5842426\n",
            "784-   Not Paraphrase     0.110064335\n",
            "785-   Paraphrase         1.7725395\n",
            "786-   Paraphrase         1.7611104\n",
            "787-   Paraphrase         1.0699447\n",
            "788-   Paraphrase         1.8439287\n",
            "789-   Paraphrase         0.19991618\n",
            "790-   Paraphrase         1.525693\n",
            "791-   Paraphrase         1.9446627\n",
            "792-   Paraphrase         1.7143399\n",
            "793-   Not Paraphrase     1.5670334\n",
            "794-   Paraphrase         1.6387964\n",
            "795-   Paraphrase         1.8158\n",
            "796-   Paraphrase         1.445923\n",
            "797-   Paraphrase         1.7094649\n",
            "798-   Paraphrase         1.838796\n",
            "799-   Not Paraphrase     0.30427638\n",
            "800-   Paraphrase         1.6405398\n",
            "801-   Paraphrase         1.7379956\n",
            "802-   Not Paraphrase     1.4230126\n",
            "803-   Paraphrase         1.8396944\n",
            "804-   Paraphrase         0.76104826\n",
            "805-   Not Paraphrase     0.6498079\n",
            "806-   Paraphrase         1.2570106\n",
            "807-   Not Paraphrase     0.28158757\n",
            "808-   Paraphrase         1.5148424\n",
            "809-   Not Paraphrase     1.4077677\n",
            "810-   Paraphrase         0.26898015\n",
            "811-   Paraphrase         1.1168379\n",
            "812-   Not Paraphrase     1.6930043\n",
            "813-   Not Paraphrase     1.3046423\n",
            "814-   Paraphrase         0.4591174\n",
            "815-   Not Paraphrase     0.19038098\n",
            "816-   Paraphrase         0.52415997\n",
            "817-   Not Paraphrase     1.5860738\n",
            "818-   Not Paraphrase     1.4249798\n",
            "819-   Paraphrase         0.9775535\n",
            "820-   Paraphrase         0.9893565\n",
            "821-   Paraphrase         0.8129103\n",
            "822-   Not Paraphrase     1.801286\n",
            "823-   Not Paraphrase     0.37747929\n",
            "824-   Paraphrase         1.083651\n",
            "825-   Paraphrase         1.748329\n",
            "826-   Paraphrase         1.7793727\n",
            "827-   Not Paraphrase     1.1921314\n",
            "828-   Paraphrase         1.3649281\n",
            "829-   Not Paraphrase     1.6393309\n",
            "830-   Paraphrase         1.8632017\n",
            "831-   Not Paraphrase     1.7227708\n",
            "832-   Paraphrase         0.57578325\n",
            "833-   Paraphrase         1.4177762\n",
            "834-   Not Paraphrase     0.60479194\n",
            "835-   Not Paraphrase     0.8012654\n",
            "836-   Paraphrase         1.112245\n",
            "837-   Paraphrase         0.88817483\n",
            "838-   Paraphrase         0.38859323\n",
            "839-   Paraphrase         0.98759764\n",
            "840-   Paraphrase         1.6729347\n",
            "841-   Not Paraphrase     1.6345217\n",
            "842-   Paraphrase         1.5393277\n",
            "843-   Not Paraphrase     1.687126\n",
            "844-   Paraphrase         1.7230669\n",
            "845-   Paraphrase         1.918203\n",
            "846-   Paraphrase         1.546373\n",
            "847-   Paraphrase         1.634025\n",
            "848-   Paraphrase         1.9625431\n",
            "849-   Paraphrase         1.5210215\n",
            "850-   Paraphrase         0.68488324\n",
            "851-   Paraphrase         0.5601511\n",
            "852-   Paraphrase         1.856586\n",
            "853-   Paraphrase         1.3751448\n",
            "854-   Not Paraphrase     1.8007069\n",
            "855-   Paraphrase         0.5296742\n",
            "856-   Paraphrase         0.58642596\n",
            "857-   Not Paraphrase     0.21816842\n",
            "858-   Not Paraphrase     1.087771\n",
            "859-   Paraphrase         1.4766834\n",
            "860-   Paraphrase         1.4215084\n",
            "861-   Paraphrase         0.89060074\n",
            "862-   Paraphrase         1.1468378\n",
            "863-   Paraphrase         1.7663006\n",
            "864-   Not Paraphrase     1.6987377\n",
            "865-   Not Paraphrase     1.330066\n",
            "866-   Paraphrase         1.199319\n",
            "867-   Not Paraphrase     1.0923246\n",
            "868-   Paraphrase         1.7705764\n",
            "869-   Paraphrase         1.264527\n",
            "870-   Not Paraphrase     1.0733904\n",
            "871-   Paraphrase         1.629496\n",
            "872-   Not Paraphrase     0.7673779\n",
            "873-   Paraphrase         0.58467823\n",
            "874-   Not Paraphrase     0.02317558\n",
            "875-   Paraphrase         0.40954542\n",
            "876-   Paraphrase         1.0183588\n",
            "877-   Paraphrase         1.3917023\n",
            "878-   Not Paraphrase     0.5392788\n",
            "879-   Paraphrase         0.31193885\n",
            "880-   Paraphrase         0.95228446\n",
            "881-   Paraphrase         1.408693\n",
            "882-   Not Paraphrase     1.1060547\n",
            "883-   Paraphrase         1.332373\n",
            "884-   Paraphrase         1.292732\n",
            "885-   Paraphrase         1.9979151\n",
            "886-   Paraphrase         1.0562298\n",
            "887-   Paraphrase         1.3525407\n",
            "888-   Paraphrase         1.2131296\n",
            "889-   Not Paraphrase     0.31561667\n",
            "890-   Not Paraphrase     0.53186476\n",
            "891-   Paraphrase         1.6986347\n",
            "892-   Paraphrase         0.6055101\n",
            "893-   Paraphrase         1.431889\n",
            "894-   Paraphrase         1.4470309\n",
            "895-   Paraphrase         1.7635945\n",
            "896-   Paraphrase         1.776484\n",
            "897-   Paraphrase         1.3666382\n",
            "898-   Not Paraphrase     0.9836727\n",
            "899-   Not Paraphrase     0.7220844\n",
            "900-   Paraphrase         1.6733702\n",
            "[array([1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 1, 1, 0, 1, 1]), array([1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
            "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0]), array([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
            "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
            "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1]), array([0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
            "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0]), array([0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
            "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0]), array([0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
            "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0]), array([0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
            "       1, 1, 0, 0, 0, 1, 1, 1, 0, 1]), array([1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
            "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1]), array([1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
            "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
            "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1]), array([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
            "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1]), array([0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
            "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0]), array([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
            "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
            "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
            "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1]), array([0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
            "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0]), array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
            "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1]), array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
            "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
            "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0]), array([0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
            "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0]), array([0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1]), array([1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
            "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0]), array([0, 1, 1, 1])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNC2ARoXOfyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "## left -P\n",
        "#right - NP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRMcHi1uLQdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5780d777-160a-480d-d31d-63e235227367"
      },
      "source": [
        "print('Paraphrase samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Paraphrase samples: 400 of 900 (44.44%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PmWUtXdLW1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "e2110de8-93f3-49eb-8806-58157ffe09dd"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  \n",
        "\n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)\n",
        "  \n",
        "  # print(pred_labels_i)\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "[0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
            "[0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0]\n",
            "[0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1]\n",
            "[1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1]\n",
            "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
            "[0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0]\n",
            "[0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 0 0]\n",
            "[1 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1]\n",
            "[1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 0]\n",
            "[0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 0]\n",
            "[0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1]\n",
            "[0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0]\n",
            "[0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0]\n",
            "[0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0]\n",
            "[1 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0]\n",
            "[0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1]\n",
            "[1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 1]\n",
            "[0 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0]\n",
            "[1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1]\n",
            "[0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
            "[0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
            "[1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
            "[0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0]\n",
            "[0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1]\n",
            "[1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
            "[0 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb--na-oLbVM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dec97469-50bc-4d9f-9fee-f2605262720e"
      },
      "source": [
        "matthews_set\n",
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6aNsEuZMvjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6114f66d-b49f-4edd-ea5f-aaa397c85bca"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/My Drive/FYP/bert/model-colab/malayalam'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/My Drive/FYP/bert/model-colab/malayalam\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/FYP/bert/model-colab/malayalam/vocab.txt',\n",
              " '/content/drive/My Drive/FYP/bert/model-colab/malayalam/special_tokens_map.json',\n",
              " '/content/drive/My Drive/FYP/bert/model-colab/malayalam/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1pCMRfZM2YG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c1a1e9c6-54a4-4c09-fdea-dc8d86505334"
      },
      "source": [
        "!ls -l --block-size=K \"/content/drive/My Drive/FYP/bert/model-colab\""
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 983K\n",
            "-rw------- 1 root root   2K Feb 16 13:28 config.json\n",
            "drwx------ 2 root root   4K Feb 16 15:46 malayalam\n",
            "drwx------ 2 root root   4K Feb 16 08:55 model-colab\n",
            "-rw------- 1 root root   0K Feb 16 13:28 pytorch_model.bin\n",
            "-rw------- 1 root root   1K Feb 16 12:44 special_tokens_map.json\n",
            "-rw------- 1 root root   1K Feb 16 12:44 tokenizer_config.json\n",
            "-rw------- 1 root root 973K Feb 16 12:44 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQeGwIIMM5Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!cp -r \"/content/drive/My Drive/FYP/bert/model-colab\" \"/content/drive/My Drive/FYP/bert/model-daw\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}