{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d43cfaa89c74d5aab79461b4969762a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0c8b25cd7da4c6087caa75a8e2761d8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4bb1bd433ea34495847b98e6cf877ea5",
              "IPY_MODEL_1e9ac47afeb74043a29c06eae6db9048"
            ]
          }
        },
        "e0c8b25cd7da4c6087caa75a8e2761d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bb1bd433ea34495847b98e6cf877ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6788928ebca8476a8955780dd777a36b",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4a90c19ac894baea1e8c43a499eef14"
          }
        },
        "1e9ac47afeb74043a29c06eae6db9048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1bbbfcaf7fe745f08e61815107a99b75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 996k/996k [00:00&lt;00:00, 5.68MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d75b000a77d84d67a4e75e3e9f748beb"
          }
        },
        "6788928ebca8476a8955780dd777a36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4a90c19ac894baea1e8c43a499eef14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bbbfcaf7fe745f08e61815107a99b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d75b000a77d84d67a4e75e3e9f748beb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9288c3431f024e3d8c39ecc80f7bb71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2cfa8a5945ae41319ea436135eabde8d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_66b4bafc437a4641bb58d4e8445feb61",
              "IPY_MODEL_f16faf9e725047b8a128ad90acfaf9de"
            ]
          }
        },
        "2cfa8a5945ae41319ea436135eabde8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66b4bafc437a4641bb58d4e8445feb61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a4f28342d4d642d497d659ce4aac1987",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 569,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 569,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92c3969bfed14f1c89be61a20be46a71"
          }
        },
        "f16faf9e725047b8a128ad90acfaf9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d9ba6986edd45b2ae8912bd68c9ba82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 569/569 [00:00&lt;00:00, 24.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18f7b3b149d34ae4a81b930a50adbc09"
          }
        },
        "a4f28342d4d642d497d659ce4aac1987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92c3969bfed14f1c89be61a20be46a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d9ba6986edd45b2ae8912bd68c9ba82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18f7b3b149d34ae4a81b930a50adbc09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d4f046f657840d999d8510a3aa46131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4740fbff47ac4667ae4cba3b8fee6e90",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91e889a2ed19440491244da8c9c2ebb3",
              "IPY_MODEL_d038637a30fc49e2a8e57aa2785b531e"
            ]
          }
        },
        "4740fbff47ac4667ae4cba3b8fee6e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91e889a2ed19440491244da8c9c2ebb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f7a1b213536e4d2798d244c1d861a662",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_49507cb950334a3089d71c630de1e0b8"
          }
        },
        "d038637a30fc49e2a8e57aa2785b531e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b2cd167ee6d488bb750824c7c037218",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 714M/714M [00:10&lt;00:00, 68.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8900a76ca96f46408610a58082f7fcaa"
          }
        },
        "f7a1b213536e4d2798d244c1d861a662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "49507cb950334a3089d71c630de1e0b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b2cd167ee6d488bb750824c7c037218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8900a76ca96f46408610a58082f7fcaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakesh-SSN/FYP/blob/master/BERT%20TAMIL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN2gN6gr8nOJ",
        "colab_type": "code",
        "outputId": "02fc7c5f-3f29-4ad6-ff89-73ba3612b702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agL2oUFJO9BM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "791c143e-a65d-4798-a17a-31a1620b09ad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roq3nEGz9wvH",
        "colab_type": "code",
        "outputId": "6d81a860-3ad6-4b1d-eee5-a056556a7a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/tamil/task1tamil.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 2,500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2469</th>\n",
              "      <td>TAM2470</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>இந்தியாவிலும், பாகிஸ்தானிலும் உள்ள அணுசக்தி நி...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1614</th>\n",
              "      <td>TAM1615</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>இணையங்களை நடத்துபவர்கள் இணையதள முகவரியில் எழுத...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2217</th>\n",
              "      <td>TAM2218</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>அணுசக்தி விநியோக நாடுகள் அமைப்பில் (என்.எஸ்.ஜி...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1357</th>\n",
              "      <td>TAM1358</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>பின்னர் 8-வதாக 42 வயது நிரம்பிய ஒருவருடன் பவித...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>900</th>\n",
              "      <td>TAM0901</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>புதுச்சேரி துணை ஆளுநராக பொறுப்பேற்கும் கிரண் ப...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1484</th>\n",
              "      <td>TAM1485</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>சிதம்பரத்தில் சாலையோரம் விநாயகர் சிலையை கடத்தல...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>TAM0365</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ஆந்திராவில் 2 நாட்களுக்கு அனல் காற்று வீசும் எ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1489</th>\n",
              "      <td>TAM1490</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>இந்த விநாயகர் சிலை 16-ம் நூற்றாண்டை சேர்ந்ததாக...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1342</th>\n",
              "      <td>TAM1343</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>அப்போது சிலர் போலீசார் மீதும், பஸ்கள் மீதும் க...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>TAM0148</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>பிரிட்டிஷ் - மணிப்பூர் போர் நினைவிடத்தில் நாளை...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "2469         TAM2470  ...  இந்தியாவிலும், பாகிஸ்தானிலும் உள்ள அணுசக்தி நி...\n",
              "1614         TAM1615  ...  இணையங்களை நடத்துபவர்கள் இணையதள முகவரியில் எழுத...\n",
              "2217         TAM2218  ...  அணுசக்தி விநியோக நாடுகள் அமைப்பில் (என்.எஸ்.ஜி...\n",
              "1357         TAM1358  ...  பின்னர் 8-வதாக 42 வயது நிரம்பிய ஒருவருடன் பவித...\n",
              "900          TAM0901  ...  புதுச்சேரி துணை ஆளுநராக பொறுப்பேற்கும் கிரண் ப...\n",
              "1484         TAM1485  ...  சிதம்பரத்தில் சாலையோரம் விநாயகர் சிலையை கடத்தல...\n",
              "364          TAM0365  ...  ஆந்திராவில் 2 நாட்களுக்கு அனல் காற்று வீசும் எ...\n",
              "1489         TAM1490  ...  இந்த விநாயகர் சிலை 16-ம் நூற்றாண்டை சேர்ந்ததாக...\n",
              "1342         TAM1343  ...  அப்போது சிலர் போலீசார் மீதும், பஸ்கள் மீதும் க...\n",
              "147          TAM0148  ...  பிரிட்டிஷ் - மணிப்பூர் போர் நினைவிடத்தில் நாளை...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK0Dm2839_fM",
        "colab_type": "code",
        "outputId": "8955370f-e872-48bf-c255-93ff5bfe037e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2265</th>\n",
              "      <td>என்.எல்.சி., உள்ளிட்ட மத்திய மின்நிலையங்களில்,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>ஆர்.கே.நகர் தொகுதியில் முதல்-அமைச்சரின் தனிப்ப...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1412</th>\n",
              "      <td>ஹரியானா மாநிலத்தில் பள்ளி ஆசிரியர்கள் ஜீன்ஸ் அ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>இந்தியா, இங்கிலாந்து விஞ்ஞானிகள் இணைந்து வங்க ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2469</th>\n",
              "      <td>இந்தியாவிலும், பாகிஸ்தானிலும் உள்ள அணுசக்தி நி...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "2265  என்.எல்.சி., உள்ளிட்ட மத்திய மின்நிலையங்களில்,...      0\n",
              "1235  ஆர்.கே.நகர் தொகுதியில் முதல்-அமைச்சரின் தனிப்ப...      0\n",
              "1412  ஹரியானா மாநிலத்தில் பள்ளி ஆசிரியர்கள் ஜீன்ஸ் அ...      0\n",
              "1395  இந்தியா, இங்கிலாந்து விஞ்ஞானிகள் இணைந்து வங்க ...      0\n",
              "2469  இந்தியாவிலும், பாகிஸ்தானிலும் உள்ள அணுசக்தி நி...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64AfSL-V-Ij5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60lFABu1-KAE",
        "colab_type": "code",
        "outputId": "abdbf14f-6278-4880-818f-0b6a2269ec83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "4d43cfaa89c74d5aab79461b4969762a",
            "e0c8b25cd7da4c6087caa75a8e2761d8",
            "4bb1bd433ea34495847b98e6cf877ea5",
            "1e9ac47afeb74043a29c06eae6db9048",
            "6788928ebca8476a8955780dd777a36b",
            "b4a90c19ac894baea1e8c43a499eef14",
            "1bbbfcaf7fe745f08e61815107a99b75",
            "d75b000a77d84d67a4e75e3e9f748beb"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d43cfaa89c74d5aab79461b4969762a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqawKMwS-o5b",
        "colab_type": "code",
        "outputId": "3fa7e51d-961e-4c59-e1b3-a47b7e66155f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  சங்கராபுரம் தொகுதியில் போட்டியிடும் ஸ்டாலின் நடைபயணமாக சென்று பிரசாரம் செய்தார்.<eol>தி.மு.க., வேட்பாளர் ஸ்டாலின் போட்டியிடும் சங்கராபுரம் தொகுதியில் சின்ன சேலம் பகுதியில் நடைபயணமாக சென்று ஓட்டு சேகரித்தார்.\n",
            "Tokenized:  ['ச', '##ங', '##க', '##ரா', '##பு', '##ர', '##ம', 'த', '##ெ', '##ாக', '##ு', '##திய', '##ில', 'ப', '##ே', '##ா', '##ட', '##டி', '##ய', '##ி', '##டு', '##ம', 'ஸ', '##ட', '##ால', '##ி', '##ன', 'ந', '##டை', '##ப', '##ய', '##ண', '##மாக', 'ச', '##ெ', '##ன', '##று', 'பி', '##ர', '##ச', '##ார', '##ம', 'ச', '##ெ', '##ய', '##தா', '##ர', '.', '<', 'eo', '##l', '>', 'தி', '.', 'மு', '.', 'க', '.', ',', 'வ', '##ே', '##ட', '##பா', '##ள', '##ர', 'ஸ', '##ட', '##ால', '##ி', '##ன', 'ப', '##ே', '##ா', '##ட', '##டி', '##ய', '##ி', '##டு', '##ம', 'ச', '##ங', '##க', '##ரா', '##பு', '##ர', '##ம', 'த', '##ெ', '##ாக', '##ு', '##திய', '##ில', 'சி', '##ன', '##ன', 'ச', '##ே', '##ல', '##ம', 'பகுதி', '##ய', '##ில', 'ந', '##டை', '##ப', '##ய', '##ண', '##மாக', 'ச', '##ெ', '##ன', '##று', 'ஓ', '##ட', '##டு', 'ச', '##ே', '##க', '##ரி', '##த', '##தா', '##ர', '.']\n",
            "Token IDs:  [1154, 111305, 19894, 74405, 29972, 21060, 39123, 1159, 111312, 24515, 18660, 85056, 94978, 1162, 18827, 15472, 35186, 24171, 15220, 20242, 35667, 39123, 1172, 35186, 71071, 20242, 17506, 1160, 51177, 46168, 15220, 40397, 22093, 1154, 111312, 17506, 21800, 37076, 21060, 59245, 81773, 39123, 1154, 111312, 15220, 99099, 21060, 119, 133, 13934, 10161, 135, 55993, 119, 95512, 119, 1152, 119, 117, 1170, 18827, 35186, 88626, 55186, 21060, 1172, 35186, 71071, 20242, 17506, 1162, 18827, 15472, 35186, 24171, 15220, 20242, 35667, 39123, 1154, 111305, 19894, 74405, 29972, 21060, 39123, 1159, 111312, 24515, 18660, 85056, 94978, 86625, 17506, 17506, 1154, 18827, 27885, 39123, 81512, 15220, 94978, 1160, 51177, 46168, 15220, 40397, 22093, 1154, 111312, 17506, 21800, 1150, 35186, 35667, 1154, 18827, 19894, 21426, 31484, 99099, 21060, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKGzPxF1AUUM",
        "colab_type": "code",
        "outputId": "aff7f467-a05c-4e97-dc5d-a4945e7b1522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  சங்கராபுரம் தொகுதியில் போட்டியிடும் ஸ்டாலின் நடைபயணமாக சென்று பிரசாரம் செய்தார்.<eol>தி.மு.க., வேட்பாளர் ஸ்டாலின் போட்டியிடும் சங்கராபுரம் தொகுதியில் சின்ன சேலம் பகுதியில் நடைபயணமாக சென்று ஓட்டு சேகரித்தார்.\n",
            "Token IDs: [101, 1154, 111305, 19894, 74405, 29972, 21060, 39123, 1159, 111312, 24515, 18660, 85056, 94978, 1162, 18827, 15472, 35186, 24171, 15220, 20242, 35667, 39123, 1172, 35186, 71071, 20242, 17506, 1160, 51177, 46168, 15220, 40397, 22093, 1154, 111312, 17506, 21800, 37076, 21060, 59245, 81773, 39123, 1154, 111312, 15220, 99099, 21060, 119, 133, 13934, 10161, 135, 55993, 119, 95512, 119, 1152, 119, 117, 1170, 18827, 35186, 88626, 55186, 21060, 1172, 35186, 71071, 20242, 17506, 1162, 18827, 15472, 35186, 24171, 15220, 20242, 35667, 39123, 1154, 111305, 19894, 74405, 29972, 21060, 39123, 1159, 111312, 24515, 18660, 85056, 94978, 86625, 17506, 17506, 1154, 18827, 27885, 39123, 81512, 15220, 94978, 1160, 51177, 46168, 15220, 40397, 22093, 1154, 111312, 17506, 21800, 1150, 35186, 35667, 1154, 18827, 19894, 21426, 31484, 99099, 21060, 119, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv39u2kLAo9b",
        "colab_type": "code",
        "outputId": "2f09238f-d4d3-49bb-858e-47eed4dbaf58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH_GkPkFAsKR",
        "colab_type": "code",
        "outputId": "4c432ec5-3ff9-4171-94a4-f8346153d1c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUKKZrYgAuTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfmeSm3zAxOP",
        "colab_type": "code",
        "outputId": "1b59b576-3a23-42d4-f4cb-1fb444db9fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.2)\n",
        "print(train_inputs)\n",
        "print(train_labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.2)\n",
        "#print(train_masks)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   101   1142 111308 ...  21060  39123  46168]\n",
            " [   101   1155  19187 ...   1155  19187  50047]\n",
            " [   101   1160  15472 ...  94978   1162 111312]\n",
            " ...\n",
            " [   101   1147  39123 ...  86728    119  86625]\n",
            " [   101  37076    119 ...  39123    119    133]\n",
            " [   101   1150  59245 ...  14124    119    133]]\n",
            "[0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1\n",
            " 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1\n",
            " 0 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1\n",
            " 0 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1\n",
            " 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0\n",
            " 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0\n",
            " 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0\n",
            " 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 1\n",
            " 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1\n",
            " 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0\n",
            " 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
            " 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1\n",
            " 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
            " 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 0\n",
            " 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1\n",
            " 0 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 0 1\n",
            " 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1\n",
            " 0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6BSzcZ-A8JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2ab-k8GgLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvYAxocaGzaO",
        "colab_type": "code",
        "outputId": "9190e514-4589-4920-cddf-58aa9b1cc4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9288c3431f024e3d8c39ecc80f7bb71c",
            "2cfa8a5945ae41319ea436135eabde8d",
            "66b4bafc437a4641bb58d4e8445feb61",
            "f16faf9e725047b8a128ad90acfaf9de",
            "a4f28342d4d642d497d659ce4aac1987",
            "92c3969bfed14f1c89be61a20be46a71",
            "2d9ba6986edd45b2ae8912bd68c9ba82",
            "18f7b3b149d34ae4a81b930a50adbc09",
            "2d4f046f657840d999d8510a3aa46131",
            "4740fbff47ac4667ae4cba3b8fee6e90",
            "91e889a2ed19440491244da8c9c2ebb3",
            "d038637a30fc49e2a8e57aa2785b531e",
            "f7a1b213536e4d2798d244c1d861a662",
            "49507cb950334a3089d71c630de1e0b8",
            "1b2cd167ee6d488bb750824c7c037218",
            "8900a76ca96f46408610a58082f7fcaa"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9288c3431f024e3d8c39ecc80f7bb71c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d4f046f657840d999d8510a3aa46131",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xB1woJrHCZ0",
        "colab_type": "code",
        "outputId": "b5f786b0-8eb7-4eb8-d93c-e193890783aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NhjDCrtHGh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBK2E_PaHKQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOO83LgEHQYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2jmuLjzHUP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6dh8MSXHXCv",
        "colab_type": "code",
        "outputId": "161ceadc-b555-490a-e417-3a15997f2dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     63.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     63.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     63.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     63.    Elapsed: 0:00:17.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epcoh took: 0:00:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifs2QgT9HeUe",
        "colab_type": "code",
        "outputId": "01e0e940-160a-446e-be02-d1b9fa6336e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZH/D03d+vI4zDljAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3sCgA3MK9B2",
        "colab_type": "code",
        "outputId": "b5abcef6-536f-45bf-a7d1-cbd4b3f815a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/testdata/task1tamil-test.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 900\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHsFeNFSLIkL",
        "colab_type": "code",
        "outputId": "8b943b3c-353f-434d-cb76-594a73ac368b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "  # # print(predictions)\n",
        "  #print(true_labels)\n",
        "print('    DONE.')\n",
        "\n",
        "#print(true_labels)\n",
        "print(\"*************************\")\n",
        "\n",
        "print(len(predictions))\n",
        "#print(outputs)\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 900 test sentences...\n",
            "    DONE.\n",
            "*************************\n",
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgpMTRW-jMtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.savetxt(\"/content/drive/My Drive/FYP/bert/glue/cola/results.txt\",predictions, fmt=\"%s\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCGGtb-jicKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "268a7e9c-a041-4c87-d0d4-c636be3c141d"
      },
      "source": [
        "\n",
        "count_NP=0\n",
        "count_P=0\n",
        "count_line=1\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    print(count_line,end=\"\")\n",
        "    print(\"-  \",end=\"\")\n",
        "    if(predictions[i][j][0]>predictions[i][j][1]):\n",
        "      count_P+=1 \n",
        "      print(\" Paraphrase         \",end=\"\")\n",
        "      print(predictions[i][j][0])\n",
        "    else:\n",
        "      print(\" Not Paraphrase     \",end=\"\")\n",
        "      count_NP+=1      \n",
        "      print(predictions[i][j][1])\n",
        "    count_line+=1\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-   Paraphrase         1.5582528\n",
            "2-   Paraphrase         1.3060418\n",
            "3-   Paraphrase         0.29689583\n",
            "4-   Paraphrase         2.2002861\n",
            "5-   Paraphrase         2.3668046\n",
            "6-   Paraphrase         1.9061013\n",
            "7-   Paraphrase         1.1737014\n",
            "8-   Paraphrase         0.74190253\n",
            "9-   Paraphrase         2.3001027\n",
            "10-   Paraphrase         2.0273864\n",
            "11-   Paraphrase         1.6414293\n",
            "12-   Paraphrase         2.121935\n",
            "13-   Paraphrase         1.214591\n",
            "14-   Paraphrase         2.3119462\n",
            "15-   Paraphrase         1.1950719\n",
            "16-   Paraphrase         1.5448562\n",
            "17-   Paraphrase         2.2991593\n",
            "18-   Not Paraphrase     1.370861\n",
            "19-   Paraphrase         0.76718074\n",
            "20-   Paraphrase         1.8206081\n",
            "21-   Paraphrase         1.5114232\n",
            "22-   Not Paraphrase     1.2291605\n",
            "23-   Paraphrase         1.9347223\n",
            "24-   Not Paraphrase     0.61245245\n",
            "25-   Paraphrase         1.9774365\n",
            "26-   Paraphrase         1.8703246\n",
            "27-   Paraphrase         2.2033086\n",
            "28-   Not Paraphrase     0.8612726\n",
            "29-   Paraphrase         2.0998974\n",
            "30-   Paraphrase         0.1333279\n",
            "31-   Not Paraphrase     1.2577564\n",
            "32-   Paraphrase         0.71220326\n",
            "33-   Paraphrase         1.8625273\n",
            "34-   Paraphrase         2.1894674\n",
            "35-   Paraphrase         2.1894674\n",
            "36-   Paraphrase         2.0258257\n",
            "37-   Not Paraphrase     0.7863948\n",
            "38-   Paraphrase         1.7737833\n",
            "39-   Paraphrase         1.7227968\n",
            "40-   Paraphrase         1.1905707\n",
            "41-   Paraphrase         0.9900783\n",
            "42-   Paraphrase         0.7718654\n",
            "43-   Not Paraphrase     0.9229827\n",
            "44-   Paraphrase         1.7250885\n",
            "45-   Paraphrase         1.7250885\n",
            "46-   Paraphrase         2.118173\n",
            "47-   Paraphrase         2.1583838\n",
            "48-   Paraphrase         1.6034058\n",
            "49-   Not Paraphrase     1.1140281\n",
            "50-   Paraphrase         1.8167374\n",
            "51-   Paraphrase         0.4500905\n",
            "52-   Paraphrase         1.2576205\n",
            "53-   Paraphrase         2.3738482\n",
            "54-   Paraphrase         2.0301774\n",
            "55-   Paraphrase         2.3278694\n",
            "56-   Paraphrase         0.6467049\n",
            "57-   Not Paraphrase     1.7103633\n",
            "58-   Paraphrase         1.9043419\n",
            "59-   Paraphrase         2.2160673\n",
            "60-   Paraphrase         1.5889049\n",
            "61-   Paraphrase         1.3940283\n",
            "62-   Paraphrase         1.3280004\n",
            "63-   Not Paraphrase     1.7768341\n",
            "64-   Paraphrase         0.7682086\n",
            "65-   Paraphrase         0.7682086\n",
            "66-   Paraphrase         1.2232066\n",
            "67-   Paraphrase         1.4539655\n",
            "68-   Paraphrase         1.8899494\n",
            "69-   Paraphrase         2.0446205\n",
            "70-   Paraphrase         2.1086018\n",
            "71-   Paraphrase         1.5885013\n",
            "72-   Not Paraphrase     1.694576\n",
            "73-   Not Paraphrase     1.694576\n",
            "74-   Not Paraphrase     1.3892281\n",
            "75-   Not Paraphrase     1.3892281\n",
            "76-   Paraphrase         2.0429726\n",
            "77-   Paraphrase         2.0429726\n",
            "78-   Not Paraphrase     1.5830908\n",
            "79-   Paraphrase         2.1608055\n",
            "80-   Paraphrase         1.2524279\n",
            "81-   Paraphrase         2.2837179\n",
            "82-   Not Paraphrase     1.7763232\n",
            "83-   Paraphrase         2.2394812\n",
            "84-   Paraphrase         2.1787217\n",
            "85-   Paraphrase         2.0773652\n",
            "86-   Paraphrase         1.4449251\n",
            "87-   Paraphrase         1.7322962\n",
            "88-   Paraphrase         2.1628323\n",
            "89-   Not Paraphrase     0.40613073\n",
            "90-   Not Paraphrase     1.527278\n",
            "91-   Not Paraphrase     1.2825251\n",
            "92-   Not Paraphrase     1.791105\n",
            "93-   Paraphrase         1.9081795\n",
            "94-   Paraphrase         1.126904\n",
            "95-   Paraphrase         2.1320992\n",
            "96-   Paraphrase         1.498601\n",
            "97-   Paraphrase         1.9805539\n",
            "98-   Paraphrase         2.3554974\n",
            "99-   Paraphrase         2.2520018\n",
            "100-   Paraphrase         2.242978\n",
            "101-   Not Paraphrase     1.5816795\n",
            "102-   Paraphrase         2.3524551\n",
            "103-   Paraphrase         2.1780498\n",
            "104-   Paraphrase         1.5384775\n",
            "105-   Paraphrase         1.4158387\n",
            "106-   Paraphrase         0.3156559\n",
            "107-   Paraphrase         1.9588233\n",
            "108-   Paraphrase         1.9434325\n",
            "109-   Paraphrase         2.3556378\n",
            "110-   Paraphrase         1.952318\n",
            "111-   Paraphrase         1.3201572\n",
            "112-   Paraphrase         0.4737672\n",
            "113-   Paraphrase         1.0827516\n",
            "114-   Paraphrase         2.078018\n",
            "115-   Paraphrase         2.145244\n",
            "116-   Paraphrase         2.1635635\n",
            "117-   Paraphrase         0.40113127\n",
            "118-   Paraphrase         1.0620915\n",
            "119-   Paraphrase         2.386317\n",
            "120-   Paraphrase         2.2180934\n",
            "121-   Paraphrase         1.6908543\n",
            "122-   Paraphrase         2.2099655\n",
            "123-   Not Paraphrase     1.1792446\n",
            "124-   Paraphrase         2.2739317\n",
            "125-   Paraphrase         2.2730613\n",
            "126-   Paraphrase         2.2270117\n",
            "127-   Paraphrase         2.0919607\n",
            "128-   Paraphrase         2.0919607\n",
            "129-   Paraphrase         2.1661599\n",
            "130-   Paraphrase         2.249974\n",
            "131-   Paraphrase         2.2463002\n",
            "132-   Paraphrase         2.219499\n",
            "133-   Paraphrase         2.2118342\n",
            "134-   Paraphrase         1.8464648\n",
            "135-   Paraphrase         2.332263\n",
            "136-   Paraphrase         1.3299453\n",
            "137-   Paraphrase         1.4272348\n",
            "138-   Paraphrase         2.1831136\n",
            "139-   Paraphrase         2.3997822\n",
            "140-   Paraphrase         2.1528285\n",
            "141-   Paraphrase         2.3214936\n",
            "142-   Paraphrase         1.3213081\n",
            "143-   Paraphrase         2.33974\n",
            "144-   Paraphrase         0.653193\n",
            "145-   Paraphrase         1.5765841\n",
            "146-   Paraphrase         2.3195744\n",
            "147-   Not Paraphrase     0.8842307\n",
            "148-   Paraphrase         2.132394\n",
            "149-   Paraphrase         2.132394\n",
            "150-   Paraphrase         2.3007789\n",
            "151-   Paraphrase         2.3007789\n",
            "152-   Paraphrase         1.5048512\n",
            "153-   Paraphrase         1.5048512\n",
            "154-   Paraphrase         2.2775984\n",
            "155-   Paraphrase         0.8433189\n",
            "156-   Paraphrase         0.8433189\n",
            "157-   Paraphrase         2.4043615\n",
            "158-   Paraphrase         2.1327841\n",
            "159-   Paraphrase         2.2540596\n",
            "160-   Paraphrase         1.264462\n",
            "161-   Paraphrase         1.5277792\n",
            "162-   Not Paraphrase     0.604758\n",
            "163-   Paraphrase         2.1845872\n",
            "164-   Not Paraphrase     0.59773725\n",
            "165-   Paraphrase         1.9516275\n",
            "166-   Not Paraphrase     0.31887236\n",
            "167-   Paraphrase         2.1664112\n",
            "168-   Paraphrase         1.6332095\n",
            "169-   Paraphrase         2.198545\n",
            "170-   Paraphrase         2.198545\n",
            "171-   Not Paraphrase     0.6195448\n",
            "172-   Paraphrase         1.0112236\n",
            "173-   Paraphrase         1.3532476\n",
            "174-   Paraphrase         2.2685773\n",
            "175-   Not Paraphrase     1.8153789\n",
            "176-   Paraphrase         1.8947695\n",
            "177-   Paraphrase         2.0501359\n",
            "178-   Paraphrase         2.2779493\n",
            "179-   Paraphrase         2.2048366\n",
            "180-   Paraphrase         2.1874466\n",
            "181-   Paraphrase         1.9653769\n",
            "182-   Paraphrase         1.945629\n",
            "183-   Paraphrase         1.4059321\n",
            "184-   Paraphrase         1.3224753\n",
            "185-   Paraphrase         2.1420372\n",
            "186-   Paraphrase         1.7810003\n",
            "187-   Paraphrase         0.7643985\n",
            "188-   Not Paraphrase     1.6232592\n",
            "189-   Paraphrase         1.395356\n",
            "190-   Paraphrase         1.2662588\n",
            "191-   Paraphrase         2.3698392\n",
            "192-   Paraphrase         1.8756236\n",
            "193-   Paraphrase         0.76827127\n",
            "194-   Paraphrase         1.4161316\n",
            "195-   Paraphrase         0.49774668\n",
            "196-   Not Paraphrase     0.96432906\n",
            "197-   Paraphrase         1.429039\n",
            "198-   Paraphrase         0.8637816\n",
            "199-   Paraphrase         1.2649319\n",
            "200-   Paraphrase         1.2649319\n",
            "201-   Paraphrase         2.1872282\n",
            "202-   Paraphrase         0.4489726\n",
            "203-   Paraphrase         1.804699\n",
            "204-   Paraphrase         1.804699\n",
            "205-   Paraphrase         1.3384782\n",
            "206-   Paraphrase         1.7333174\n",
            "207-   Paraphrase         1.4554949\n",
            "208-   Paraphrase         0.8948686\n",
            "209-   Paraphrase         1.7803091\n",
            "210-   Paraphrase         2.2200923\n",
            "211-   Paraphrase         0.88526976\n",
            "212-   Paraphrase         1.9120773\n",
            "213-   Paraphrase         2.1882458\n",
            "214-   Paraphrase         2.273148\n",
            "215-   Paraphrase         2.2848601\n",
            "216-   Paraphrase         1.7391714\n",
            "217-   Paraphrase         1.3112319\n",
            "218-   Paraphrase         0.98377055\n",
            "219-   Not Paraphrase     1.2799246\n",
            "220-   Paraphrase         0.18733785\n",
            "221-   Paraphrase         2.2736204\n",
            "222-   Paraphrase         2.2736204\n",
            "223-   Not Paraphrase     1.0956748\n",
            "224-   Not Paraphrase     0.560793\n",
            "225-   Paraphrase         1.1836923\n",
            "226-   Not Paraphrase     1.5745335\n",
            "227-   Paraphrase         1.9558309\n",
            "228-   Paraphrase         1.9558309\n",
            "229-   Paraphrase         1.154345\n",
            "230-   Paraphrase         2.3195398\n",
            "231-   Paraphrase         1.1787963\n",
            "232-   Paraphrase         1.1787963\n",
            "233-   Paraphrase         1.4916146\n",
            "234-   Paraphrase         1.4824425\n",
            "235-   Paraphrase         1.4261737\n",
            "236-   Paraphrase         2.2174206\n",
            "237-   Not Paraphrase     1.8530008\n",
            "238-   Paraphrase         2.1266265\n",
            "239-   Paraphrase         1.9213113\n",
            "240-   Paraphrase         0.8374452\n",
            "241-   Paraphrase         0.6561015\n",
            "242-   Paraphrase         1.332419\n",
            "243-   Paraphrase         0.7850601\n",
            "244-   Paraphrase         1.727548\n",
            "245-   Paraphrase         2.0803063\n",
            "246-   Paraphrase         2.2211277\n",
            "247-   Paraphrase         2.2211277\n",
            "248-   Paraphrase         1.5738572\n",
            "249-   Not Paraphrase     0.5412497\n",
            "250-   Not Paraphrase     0.5412497\n",
            "251-   Paraphrase         1.3436714\n",
            "252-   Paraphrase         2.1752713\n",
            "253-   Paraphrase         2.1039546\n",
            "254-   Paraphrase         1.8169818\n",
            "255-   Paraphrase         1.5599554\n",
            "256-   Paraphrase         0.88532186\n",
            "257-   Paraphrase         0.41833088\n",
            "258-   Paraphrase         0.74790287\n",
            "259-   Paraphrase         2.2742767\n",
            "260-   Paraphrase         2.036105\n",
            "261-   Paraphrase         2.3074722\n",
            "262-   Paraphrase         1.7946804\n",
            "263-   Paraphrase         2.0778513\n",
            "264-   Paraphrase         1.5004202\n",
            "265-   Paraphrase         2.0324497\n",
            "266-   Paraphrase         2.1376157\n",
            "267-   Paraphrase         2.1405623\n",
            "268-   Not Paraphrase     1.7826836\n",
            "269-   Paraphrase         0.34273413\n",
            "270-   Paraphrase         0.82026035\n",
            "271-   Paraphrase         2.1168427\n",
            "272-   Paraphrase         0.88172925\n",
            "273-   Paraphrase         1.8100994\n",
            "274-   Paraphrase         0.29514804\n",
            "275-   Paraphrase         1.555146\n",
            "276-   Not Paraphrase     0.44580013\n",
            "277-   Paraphrase         2.1909623\n",
            "278-   Paraphrase         2.324213\n",
            "279-   Not Paraphrase     0.7420743\n",
            "280-   Paraphrase         2.2958388\n",
            "281-   Not Paraphrase     1.278604\n",
            "282-   Paraphrase         0.3682067\n",
            "283-   Not Paraphrase     0.18202677\n",
            "284-   Paraphrase         0.6974184\n",
            "285-   Paraphrase         1.6670691\n",
            "286-   Paraphrase         1.6670691\n",
            "287-   Paraphrase         1.3552204\n",
            "288-   Paraphrase         1.1541519\n",
            "289-   Paraphrase         1.64138\n",
            "290-   Paraphrase         1.1954352\n",
            "291-   Paraphrase         0.25714964\n",
            "292-   Paraphrase         0.6413633\n",
            "293-   Paraphrase         1.9650126\n",
            "294-   Paraphrase         1.8274378\n",
            "295-   Paraphrase         1.9162627\n",
            "296-   Paraphrase         2.06464\n",
            "297-   Not Paraphrase     0.8584017\n",
            "298-   Paraphrase         1.9152161\n",
            "299-   Not Paraphrase     0.29378247\n",
            "300-   Paraphrase         2.143148\n",
            "301-   Not Paraphrase     0.4842835\n",
            "302-   Paraphrase         2.352194\n",
            "303-   Paraphrase         2.352194\n",
            "304-   Not Paraphrase     1.7126077\n",
            "305-   Not Paraphrase     0.37272924\n",
            "306-   Paraphrase         0.37115136\n",
            "307-   Paraphrase         2.224807\n",
            "308-   Paraphrase         1.7709653\n",
            "309-   Paraphrase         2.1896412\n",
            "310-   Paraphrase         2.0447934\n",
            "311-   Not Paraphrase     0.32273284\n",
            "312-   Paraphrase         1.7159957\n",
            "313-   Paraphrase         2.037396\n",
            "314-   Paraphrase         2.161922\n",
            "315-   Paraphrase         1.9816134\n",
            "316-   Paraphrase         1.8237556\n",
            "317-   Paraphrase         2.2348685\n",
            "318-   Not Paraphrase     1.603607\n",
            "319-   Paraphrase         1.8751996\n",
            "320-   Paraphrase         2.3429897\n",
            "321-   Paraphrase         2.2004478\n",
            "322-   Paraphrase         1.7797037\n",
            "323-   Paraphrase         2.2207024\n",
            "324-   Paraphrase         1.888127\n",
            "325-   Paraphrase         1.948912\n",
            "326-   Paraphrase         1.6811136\n",
            "327-   Paraphrase         0.69282174\n",
            "328-   Paraphrase         1.9500812\n",
            "329-   Not Paraphrase     1.3975868\n",
            "330-   Not Paraphrase     1.6611826\n",
            "331-   Not Paraphrase     0.30931187\n",
            "332-   Not Paraphrase     1.3050022\n",
            "333-   Not Paraphrase     0.47681183\n",
            "334-   Paraphrase         1.5837239\n",
            "335-   Not Paraphrase     1.7041343\n",
            "336-   Paraphrase         2.067987\n",
            "337-   Paraphrase         2.1326528\n",
            "338-   Paraphrase         1.2920761\n",
            "339-   Paraphrase         0.3166084\n",
            "340-   Not Paraphrase     1.7129351\n",
            "341-   Not Paraphrase     0.82337123\n",
            "342-   Not Paraphrase     0.94168407\n",
            "343-   Paraphrase         1.2240387\n",
            "344-   Paraphrase         0.5128968\n",
            "345-   Paraphrase         1.1261641\n",
            "346-   Paraphrase         1.9745597\n",
            "347-   Paraphrase         2.097519\n",
            "348-   Paraphrase         0.67725295\n",
            "349-   Paraphrase         0.9180785\n",
            "350-   Paraphrase         1.23256\n",
            "351-   Not Paraphrase     1.4210161\n",
            "352-   Paraphrase         2.2582443\n",
            "353-   Not Paraphrase     1.0228895\n",
            "354-   Paraphrase         2.0814757\n",
            "355-   Paraphrase         1.0571377\n",
            "356-   Paraphrase         2.3142934\n",
            "357-   Paraphrase         2.1078691\n",
            "358-   Paraphrase         2.247884\n",
            "359-   Paraphrase         2.4105108\n",
            "360-   Paraphrase         2.1272252\n",
            "361-   Paraphrase         1.7690779\n",
            "362-   Paraphrase         1.7287933\n",
            "363-   Paraphrase         1.6512175\n",
            "364-   Paraphrase         0.9759718\n",
            "365-   Paraphrase         0.41911843\n",
            "366-   Paraphrase         2.2774055\n",
            "367-   Paraphrase         0.89070785\n",
            "368-   Paraphrase         2.2027097\n",
            "369-   Paraphrase         2.018169\n",
            "370-   Paraphrase         0.45540926\n",
            "371-   Paraphrase         1.5030035\n",
            "372-   Not Paraphrase     1.7470492\n",
            "373-   Paraphrase         1.4337944\n",
            "374-   Not Paraphrase     0.77690417\n",
            "375-   Paraphrase         2.3198822\n",
            "376-   Paraphrase         2.3668394\n",
            "377-   Paraphrase         2.2820823\n",
            "378-   Paraphrase         0.45799378\n",
            "379-   Not Paraphrase     0.5606378\n",
            "380-   Paraphrase         0.6315362\n",
            "381-   Not Paraphrase     1.3576444\n",
            "382-   Paraphrase         1.9702827\n",
            "383-   Paraphrase         2.0844834\n",
            "384-   Paraphrase         0.60015106\n",
            "385-   Paraphrase         1.7913743\n",
            "386-   Paraphrase         1.6954733\n",
            "387-   Paraphrase         2.1534874\n",
            "388-   Not Paraphrase     1.2835425\n",
            "389-   Paraphrase         2.3387764\n",
            "390-   Paraphrase         2.2493582\n",
            "391-   Paraphrase         2.290151\n",
            "392-   Paraphrase         2.1738875\n",
            "393-   Not Paraphrase     1.3149903\n",
            "394-   Paraphrase         0.87392306\n",
            "395-   Paraphrase         1.9390476\n",
            "396-   Not Paraphrase     0.40980527\n",
            "397-   Paraphrase         1.792252\n",
            "398-   Not Paraphrase     1.0560337\n",
            "399-   Paraphrase         2.247713\n",
            "400-   Paraphrase         2.3001356\n",
            "401-   Paraphrase         1.9764838\n",
            "402-   Paraphrase         0.8221411\n",
            "403-   Paraphrase         1.6104454\n",
            "404-   Paraphrase         0.23463513\n",
            "405-   Paraphrase         0.6361744\n",
            "406-   Paraphrase         2.0224988\n",
            "407-   Paraphrase         0.20089328\n",
            "408-   Paraphrase         1.039127\n",
            "409-   Paraphrase         2.1374993\n",
            "410-   Paraphrase         0.5824315\n",
            "411-   Paraphrase         1.744346\n",
            "412-   Paraphrase         2.1339483\n",
            "413-   Paraphrase         0.9203577\n",
            "414-   Not Paraphrase     1.5525942\n",
            "415-   Paraphrase         2.176654\n",
            "416-   Paraphrase         1.4421357\n",
            "417-   Paraphrase         2.3737745\n",
            "418-   Paraphrase         0.87274176\n",
            "419-   Paraphrase         2.2932975\n",
            "420-   Not Paraphrase     1.2700939\n",
            "421-   Paraphrase         2.1080468\n",
            "422-   Paraphrase         1.6306977\n",
            "423-   Paraphrase         2.1916466\n",
            "424-   Paraphrase         1.9568003\n",
            "425-   Paraphrase         1.2882198\n",
            "426-   Not Paraphrase     1.3227615\n",
            "427-   Paraphrase         1.9968724\n",
            "428-   Paraphrase         1.6037242\n",
            "429-   Paraphrase         1.435183\n",
            "430-   Paraphrase         2.2071455\n",
            "431-   Not Paraphrase     0.7455862\n",
            "432-   Paraphrase         2.090126\n",
            "433-   Paraphrase         2.090126\n",
            "434-   Paraphrase         0.5372819\n",
            "435-   Paraphrase         1.9721822\n",
            "436-   Paraphrase         1.9721822\n",
            "437-   Paraphrase         2.1826892\n",
            "438-   Not Paraphrase     0.8328914\n",
            "439-   Not Paraphrase     1.0382004\n",
            "440-   Paraphrase         1.8484788\n",
            "441-   Paraphrase         1.1179446\n",
            "442-   Paraphrase         1.5394346\n",
            "443-   Paraphrase         1.9955823\n",
            "444-   Paraphrase         2.2726042\n",
            "445-   Paraphrase         2.0120702\n",
            "446-   Paraphrase         1.9968632\n",
            "447-   Paraphrase         2.294244\n",
            "448-   Paraphrase         1.7727977\n",
            "449-   Paraphrase         1.4705704\n",
            "450-   Paraphrase         2.0397916\n",
            "451-   Paraphrase         2.0397916\n",
            "452-   Paraphrase         2.2871063\n",
            "453-   Paraphrase         1.8197378\n",
            "454-   Paraphrase         1.7764783\n",
            "455-   Paraphrase         1.7765607\n",
            "456-   Not Paraphrase     1.3724059\n",
            "457-   Paraphrase         0.6495581\n",
            "458-   Paraphrase         1.5490807\n",
            "459-   Paraphrase         0.4012808\n",
            "460-   Paraphrase         2.2714298\n",
            "461-   Paraphrase         2.2714298\n",
            "462-   Paraphrase         1.5208703\n",
            "463-   Paraphrase         2.077957\n",
            "464-   Paraphrase         1.6474891\n",
            "465-   Paraphrase         1.976963\n",
            "466-   Not Paraphrase     1.50479\n",
            "467-   Paraphrase         2.0279722\n",
            "468-   Paraphrase         1.8517326\n",
            "469-   Not Paraphrase     0.27938768\n",
            "470-   Paraphrase         0.30678517\n",
            "471-   Paraphrase         1.7844985\n",
            "472-   Paraphrase         1.7844985\n",
            "473-   Paraphrase         0.8049204\n",
            "474-   Paraphrase         0.41293728\n",
            "475-   Paraphrase         2.201002\n",
            "476-   Paraphrase         2.3654547\n",
            "477-   Paraphrase         2.331116\n",
            "478-   Paraphrase         2.293493\n",
            "479-   Paraphrase         0.89309233\n",
            "480-   Paraphrase         1.7787212\n",
            "481-   Paraphrase         1.2324115\n",
            "482-   Paraphrase         1.9244978\n",
            "483-   Paraphrase         1.9459411\n",
            "484-   Paraphrase         0.48140952\n",
            "485-   Paraphrase         2.2984602\n",
            "486-   Paraphrase         2.047056\n",
            "487-   Paraphrase         1.1942483\n",
            "488-   Paraphrase         1.6587629\n",
            "489-   Paraphrase         1.8615636\n",
            "490-   Paraphrase         2.1946888\n",
            "491-   Paraphrase         1.769991\n",
            "492-   Paraphrase         2.2535272\n",
            "493-   Paraphrase         2.2535272\n",
            "494-   Paraphrase         1.7331823\n",
            "495-   Paraphrase         1.8595427\n",
            "496-   Paraphrase         1.0378808\n",
            "497-   Not Paraphrase     0.40519893\n",
            "498-   Paraphrase         1.5749139\n",
            "499-   Paraphrase         2.180609\n",
            "500-   Paraphrase         0.51709294\n",
            "501-   Paraphrase         2.0379689\n",
            "502-   Paraphrase         2.0379689\n",
            "503-   Paraphrase         1.2991306\n",
            "504-   Paraphrase         2.1943636\n",
            "505-   Paraphrase         0.9156518\n",
            "506-   Paraphrase         0.8372577\n",
            "507-   Not Paraphrase     1.6687769\n",
            "508-   Not Paraphrase     1.5929564\n",
            "509-   Not Paraphrase     1.5146294\n",
            "510-   Paraphrase         0.9919094\n",
            "511-   Not Paraphrase     1.6882682\n",
            "512-   Paraphrase         1.5280918\n",
            "513-   Paraphrase         1.4162362\n",
            "514-   Paraphrase         0.69796205\n",
            "515-   Not Paraphrase     1.9458408\n",
            "516-   Paraphrase         2.2045796\n",
            "517-   Paraphrase         1.1143245\n",
            "518-   Paraphrase         1.5056015\n",
            "519-   Paraphrase         0.83794075\n",
            "520-   Paraphrase         2.357204\n",
            "521-   Paraphrase         0.8906752\n",
            "522-   Paraphrase         1.0182234\n",
            "523-   Not Paraphrase     0.73857915\n",
            "524-   Not Paraphrase     0.3257758\n",
            "525-   Paraphrase         2.177101\n",
            "526-   Not Paraphrase     1.1763813\n",
            "527-   Not Paraphrase     1.6407952\n",
            "528-   Paraphrase         2.110257\n",
            "529-   Not Paraphrase     0.5721932\n",
            "530-   Not Paraphrase     0.5721932\n",
            "531-   Paraphrase         1.1467103\n",
            "532-   Not Paraphrase     1.5886927\n",
            "533-   Paraphrase         2.3011498\n",
            "534-   Paraphrase         2.3011498\n",
            "535-   Paraphrase         0.79113597\n",
            "536-   Paraphrase         0.79113597\n",
            "537-   Paraphrase         2.1912925\n",
            "538-   Not Paraphrase     1.3764617\n",
            "539-   Not Paraphrase     1.3764617\n",
            "540-   Not Paraphrase     1.6806537\n",
            "541-   Not Paraphrase     1.6806537\n",
            "542-   Paraphrase         0.74898297\n",
            "543-   Paraphrase         2.1557937\n",
            "544-   Paraphrase         2.1557937\n",
            "545-   Paraphrase         2.2791572\n",
            "546-   Paraphrase         1.5922235\n",
            "547-   Not Paraphrase     0.7194281\n",
            "548-   Paraphrase         2.2327034\n",
            "549-   Paraphrase         2.2327034\n",
            "550-   Paraphrase         2.3658445\n",
            "551-   Paraphrase         2.0019202\n",
            "552-   Paraphrase         1.499486\n",
            "553-   Not Paraphrase     0.207376\n",
            "554-   Paraphrase         1.7154098\n",
            "555-   Paraphrase         2.074214\n",
            "556-   Not Paraphrase     1.5092868\n",
            "557-   Not Paraphrase     1.827047\n",
            "558-   Paraphrase         2.0557976\n",
            "559-   Paraphrase         0.2049272\n",
            "560-   Not Paraphrase     1.6851697\n",
            "561-   Not Paraphrase     1.5036668\n",
            "562-   Paraphrase         1.6017687\n",
            "563-   Paraphrase         1.6017687\n",
            "564-   Paraphrase         1.9634655\n",
            "565-   Paraphrase         1.369202\n",
            "566-   Paraphrase         1.0163275\n",
            "567-   Paraphrase         1.0163275\n",
            "568-   Not Paraphrase     1.114549\n",
            "569-   Paraphrase         1.7879407\n",
            "570-   Paraphrase         2.1004765\n",
            "571-   Paraphrase         1.9886711\n",
            "572-   Not Paraphrase     0.40633568\n",
            "573-   Paraphrase         0.99858177\n",
            "574-   Paraphrase         1.975136\n",
            "575-   Paraphrase         1.1672506\n",
            "576-   Paraphrase         2.0068147\n",
            "577-   Paraphrase         0.32001683\n",
            "578-   Paraphrase         2.3245327\n",
            "579-   Paraphrase         0.29364237\n",
            "580-   Paraphrase         2.2723184\n",
            "581-   Paraphrase         1.0344228\n",
            "582-   Paraphrase         1.0156075\n",
            "583-   Paraphrase         1.0156075\n",
            "584-   Paraphrase         2.1740859\n",
            "585-   Paraphrase         2.0813081\n",
            "586-   Paraphrase         2.335646\n",
            "587-   Paraphrase         1.9248563\n",
            "588-   Paraphrase         1.9874426\n",
            "589-   Not Paraphrase     0.5199488\n",
            "590-   Paraphrase         2.00459\n",
            "591-   Paraphrase         1.7770437\n",
            "592-   Paraphrase         1.9918538\n",
            "593-   Paraphrase         2.0034783\n",
            "594-   Paraphrase         2.0034783\n",
            "595-   Paraphrase         1.8214732\n",
            "596-   Paraphrase         2.1011362\n",
            "597-   Not Paraphrase     0.82998914\n",
            "598-   Paraphrase         1.1204704\n",
            "599-   Not Paraphrase     0.99422413\n",
            "600-   Not Paraphrase     1.4601754\n",
            "601-   Paraphrase         0.6856335\n",
            "602-   Not Paraphrase     0.2905194\n",
            "603-   Paraphrase         1.2506636\n",
            "604-   Paraphrase         1.8458003\n",
            "605-   Paraphrase         1.8458003\n",
            "606-   Paraphrase         2.0790167\n",
            "607-   Paraphrase         0.9401159\n",
            "608-   Paraphrase         2.1064851\n",
            "609-   Not Paraphrase     0.25919732\n",
            "610-   Not Paraphrase     0.25919732\n",
            "611-   Paraphrase         1.4456683\n",
            "612-   Paraphrase         1.3024781\n",
            "613-   Paraphrase         1.9816064\n",
            "614-   Paraphrase         1.9754374\n",
            "615-   Paraphrase         1.4946373\n",
            "616-   Paraphrase         1.1233364\n",
            "617-   Paraphrase         1.449871\n",
            "618-   Paraphrase         1.3191024\n",
            "619-   Paraphrase         1.0508472\n",
            "620-   Paraphrase         1.8225847\n",
            "621-   Paraphrase         1.7560133\n",
            "622-   Paraphrase         1.7560133\n",
            "623-   Paraphrase         0.7900064\n",
            "624-   Paraphrase         1.8812134\n",
            "625-   Paraphrase         1.0481561\n",
            "626-   Paraphrase         1.7962977\n",
            "627-   Paraphrase         2.287591\n",
            "628-   Not Paraphrase     1.7568716\n",
            "629-   Paraphrase         1.8557968\n",
            "630-   Not Paraphrase     0.71294886\n",
            "631-   Paraphrase         1.2145237\n",
            "632-   Paraphrase         2.2855911\n",
            "633-   Paraphrase         1.7201558\n",
            "634-   Paraphrase         1.2818891\n",
            "635-   Paraphrase         1.1970626\n",
            "636-   Paraphrase         1.981842\n",
            "637-   Paraphrase         1.9681244\n",
            "638-   Not Paraphrase     0.868316\n",
            "639-   Paraphrase         1.3981129\n",
            "640-   Not Paraphrase     1.828974\n",
            "641-   Paraphrase         1.7172748\n",
            "642-   Paraphrase         2.2058191\n",
            "643-   Paraphrase         1.6753954\n",
            "644-   Paraphrase         0.3950958\n",
            "645-   Not Paraphrase     0.48008296\n",
            "646-   Not Paraphrase     1.2753928\n",
            "647-   Not Paraphrase     0.7926062\n",
            "648-   Paraphrase         2.085854\n",
            "649-   Not Paraphrase     1.708776\n",
            "650-   Not Paraphrase     1.764654\n",
            "651-   Paraphrase         2.2162683\n",
            "652-   Not Paraphrase     1.5188522\n",
            "653-   Paraphrase         1.7144563\n",
            "654-   Not Paraphrase     1.4781563\n",
            "655-   Paraphrase         1.9940488\n",
            "656-   Paraphrase         1.036965\n",
            "657-   Paraphrase         2.0715716\n",
            "658-   Paraphrase         2.0073156\n",
            "659-   Paraphrase         1.9757789\n",
            "660-   Paraphrase         2.3501794\n",
            "661-   Paraphrase         2.19198\n",
            "662-   Paraphrase         0.6191652\n",
            "663-   Paraphrase         0.5898599\n",
            "664-   Paraphrase         0.5898599\n",
            "665-   Paraphrase         2.3397238\n",
            "666-   Paraphrase         1.8718716\n",
            "667-   Paraphrase         2.3439262\n",
            "668-   Not Paraphrase     0.9387099\n",
            "669-   Paraphrase         1.955738\n",
            "670-   Paraphrase         2.2569208\n",
            "671-   Paraphrase         2.2967129\n",
            "672-   Paraphrase         1.959389\n",
            "673-   Paraphrase         1.2824844\n",
            "674-   Paraphrase         1.9988507\n",
            "675-   Paraphrase         1.9988507\n",
            "676-   Paraphrase         1.4685531\n",
            "677-   Paraphrase         1.2152652\n",
            "678-   Not Paraphrase     1.4225845\n",
            "679-   Not Paraphrase     1.494216\n",
            "680-   Not Paraphrase     1.34784\n",
            "681-   Paraphrase         2.2387881\n",
            "682-   Paraphrase         2.062328\n",
            "683-   Paraphrase         0.5437164\n",
            "684-   Not Paraphrase     1.7910649\n",
            "685-   Not Paraphrase     0.9260277\n",
            "686-   Paraphrase         2.0576339\n",
            "687-   Paraphrase         2.0239344\n",
            "688-   Paraphrase         1.984363\n",
            "689-   Paraphrase         2.109368\n",
            "690-   Paraphrase         1.2840568\n",
            "691-   Not Paraphrase     0.69103265\n",
            "692-   Paraphrase         2.2961214\n",
            "693-   Paraphrase         1.2282084\n",
            "694-   Paraphrase         2.1596634\n",
            "695-   Paraphrase         1.9391598\n",
            "696-   Paraphrase         2.2913811\n",
            "697-   Paraphrase         1.0571249\n",
            "698-   Paraphrase         1.7333516\n",
            "699-   Not Paraphrase     0.3801429\n",
            "700-   Paraphrase         2.1812286\n",
            "701-   Paraphrase         1.5655793\n",
            "702-   Paraphrase         1.929529\n",
            "703-   Paraphrase         2.172652\n",
            "704-   Paraphrase         0.3782976\n",
            "705-   Paraphrase         1.3869561\n",
            "706-   Paraphrase         0.28058034\n",
            "707-   Paraphrase         2.413204\n",
            "708-   Paraphrase         1.765156\n",
            "709-   Not Paraphrase     1.389372\n",
            "710-   Paraphrase         1.9520259\n",
            "711-   Paraphrase         2.088179\n",
            "712-   Not Paraphrase     1.4109449\n",
            "713-   Paraphrase         0.6393967\n",
            "714-   Paraphrase         0.9101384\n",
            "715-   Paraphrase         0.7806859\n",
            "716-   Paraphrase         2.0697653\n",
            "717-   Paraphrase         2.0256703\n",
            "718-   Paraphrase         1.1770674\n",
            "719-   Paraphrase         2.2993197\n",
            "720-   Paraphrase         2.3424757\n",
            "721-   Paraphrase         1.2669338\n",
            "722-   Not Paraphrase     1.4863187\n",
            "723-   Paraphrase         0.9711644\n",
            "724-   Paraphrase         1.6232765\n",
            "725-   Paraphrase         2.1079452\n",
            "726-   Paraphrase         2.2493038\n",
            "727-   Paraphrase         1.885672\n",
            "728-   Not Paraphrase     1.8470218\n",
            "729-   Paraphrase         0.6765518\n",
            "730-   Not Paraphrase     1.4009094\n",
            "731-   Paraphrase         2.0933073\n",
            "732-   Paraphrase         2.0933073\n",
            "733-   Paraphrase         2.29289\n",
            "734-   Paraphrase         2.1566784\n",
            "735-   Paraphrase         0.8401002\n",
            "736-   Paraphrase         1.8182913\n",
            "737-   Paraphrase         2.1984596\n",
            "738-   Paraphrase         2.3281248\n",
            "739-   Paraphrase         2.3281248\n",
            "740-   Paraphrase         1.0764219\n",
            "741-   Paraphrase         1.0124029\n",
            "742-   Paraphrase         1.0124029\n",
            "743-   Paraphrase         1.3740964\n",
            "744-   Paraphrase         0.76379377\n",
            "745-   Paraphrase         1.0925845\n",
            "746-   Paraphrase         2.0987618\n",
            "747-   Paraphrase         2.12102\n",
            "748-   Paraphrase         2.3290403\n",
            "749-   Paraphrase         2.1404958\n",
            "750-   Paraphrase         1.3292962\n",
            "751-   Not Paraphrase     1.3633045\n",
            "752-   Paraphrase         2.266036\n",
            "753-   Paraphrase         2.1395855\n",
            "754-   Paraphrase         2.2452712\n",
            "755-   Paraphrase         1.9810898\n",
            "756-   Paraphrase         1.9520032\n",
            "757-   Not Paraphrase     0.07256894\n",
            "758-   Not Paraphrase     1.6346648\n",
            "759-   Paraphrase         1.7951171\n",
            "760-   Paraphrase         1.3329018\n",
            "761-   Paraphrase         2.2557156\n",
            "762-   Paraphrase         1.808771\n",
            "763-   Paraphrase         0.7638776\n",
            "764-   Not Paraphrase     0.3610338\n",
            "765-   Not Paraphrase     1.8982635\n",
            "766-   Paraphrase         2.2439206\n",
            "767-   Paraphrase         1.905297\n",
            "768-   Paraphrase         2.1214974\n",
            "769-   Paraphrase         1.1397238\n",
            "770-   Paraphrase         2.2804513\n",
            "771-   Paraphrase         2.3071942\n",
            "772-   Paraphrase         2.3071942\n",
            "773-   Paraphrase         1.208072\n",
            "774-   Paraphrase         1.208072\n",
            "775-   Paraphrase         2.028297\n",
            "776-   Paraphrase         2.028297\n",
            "777-   Paraphrase         0.83655137\n",
            "778-   Paraphrase         1.378194\n",
            "779-   Not Paraphrase     0.29628772\n",
            "780-   Not Paraphrase     0.65756476\n",
            "781-   Paraphrase         2.1725762\n",
            "782-   Paraphrase         1.6552368\n",
            "783-   Not Paraphrase     0.64010894\n",
            "784-   Not Paraphrase     0.74741066\n",
            "785-   Paraphrase         0.5392467\n",
            "786-   Paraphrase         1.8878452\n",
            "787-   Not Paraphrase     1.1226089\n",
            "788-   Paraphrase         2.209156\n",
            "789-   Paraphrase         1.2363745\n",
            "790-   Paraphrase         0.5022551\n",
            "791-   Paraphrase         0.30164894\n",
            "792-   Paraphrase         2.2308135\n",
            "793-   Not Paraphrase     1.7333249\n",
            "794-   Not Paraphrase     0.35546425\n",
            "795-   Paraphrase         1.4978851\n",
            "796-   Paraphrase         2.2748446\n",
            "797-   Paraphrase         2.209994\n",
            "798-   Not Paraphrase     1.5226848\n",
            "799-   Not Paraphrase     0.8851313\n",
            "800-   Paraphrase         1.5796275\n",
            "801-   Paraphrase         1.7519624\n",
            "802-   Paraphrase         1.7519624\n",
            "803-   Paraphrase         1.5557953\n",
            "804-   Not Paraphrase     1.6334418\n",
            "805-   Not Paraphrase     1.6929797\n",
            "806-   Paraphrase         1.7411373\n",
            "807-   Paraphrase         1.0477662\n",
            "808-   Paraphrase         1.8948613\n",
            "809-   Not Paraphrase     0.6675634\n",
            "810-   Not Paraphrase     0.6675634\n",
            "811-   Paraphrase         1.1521924\n",
            "812-   Paraphrase         2.0708475\n",
            "813-   Paraphrase         1.2477757\n",
            "814-   Paraphrase         1.2477757\n",
            "815-   Not Paraphrase     1.8180877\n",
            "816-   Not Paraphrase     0.2746125\n",
            "817-   Paraphrase         1.2530428\n",
            "818-   Not Paraphrase     0.18444592\n",
            "819-   Paraphrase         1.2805346\n",
            "820-   Paraphrase         2.012952\n",
            "821-   Paraphrase         2.203187\n",
            "822-   Paraphrase         1.8328264\n",
            "823-   Paraphrase         0.7148485\n",
            "824-   Paraphrase         1.6029658\n",
            "825-   Paraphrase         1.119751\n",
            "826-   Paraphrase         0.53509635\n",
            "827-   Not Paraphrase     1.3338517\n",
            "828-   Paraphrase         1.9883838\n",
            "829-   Paraphrase         0.8027814\n",
            "830-   Paraphrase         1.9747294\n",
            "831-   Paraphrase         1.8204234\n",
            "832-   Paraphrase         1.4713415\n",
            "833-   Paraphrase         2.1997025\n",
            "834-   Paraphrase         1.3674604\n",
            "835-   Paraphrase         0.55497086\n",
            "836-   Paraphrase         0.8301916\n",
            "837-   Paraphrase         1.0664206\n",
            "838-   Paraphrase         1.38529\n",
            "839-   Paraphrase         2.3158596\n",
            "840-   Paraphrase         1.8570449\n",
            "841-   Not Paraphrase     0.80030847\n",
            "842-   Paraphrase         1.663258\n",
            "843-   Paraphrase         2.2976024\n",
            "844-   Not Paraphrase     0.3030532\n",
            "845-   Not Paraphrase     1.1678094\n",
            "846-   Paraphrase         0.998898\n",
            "847-   Paraphrase         1.9679518\n",
            "848-   Paraphrase         1.9679518\n",
            "849-   Not Paraphrase     0.7535493\n",
            "850-   Paraphrase         0.77918935\n",
            "851-   Paraphrase         0.91433984\n",
            "852-   Paraphrase         2.0479376\n",
            "853-   Paraphrase         0.77485675\n",
            "854-   Paraphrase         1.231199\n",
            "855-   Not Paraphrase     1.5530919\n",
            "856-   Not Paraphrase     1.2690234\n",
            "857-   Paraphrase         2.0478423\n",
            "858-   Paraphrase         2.1965852\n",
            "859-   Not Paraphrase     1.5660825\n",
            "860-   Paraphrase         0.9153982\n",
            "861-   Not Paraphrase     0.7349835\n",
            "862-   Paraphrase         2.0860872\n",
            "863-   Paraphrase         2.0860872\n",
            "864-   Not Paraphrase     0.5565925\n",
            "865-   Paraphrase         0.6349023\n",
            "866-   Paraphrase         0.8809558\n",
            "867-   Paraphrase         2.2047446\n",
            "868-   Not Paraphrase     1.3380325\n",
            "869-   Not Paraphrase     0.66707397\n",
            "870-   Paraphrase         2.2179847\n",
            "871-   Paraphrase         1.5654286\n",
            "872-   Paraphrase         1.7899138\n",
            "873-   Paraphrase         1.13688\n",
            "874-   Paraphrase         1.66246\n",
            "875-   Paraphrase         0.6580738\n",
            "876-   Paraphrase         1.2748641\n",
            "877-   Paraphrase         2.1951435\n",
            "878-   Paraphrase         1.4747163\n",
            "879-   Paraphrase         0.842191\n",
            "880-   Paraphrase         2.2898552\n",
            "881-   Not Paraphrase     0.6358387\n",
            "882-   Paraphrase         0.57111996\n",
            "883-   Paraphrase         1.2627165\n",
            "884-   Paraphrase         1.2384362\n",
            "885-   Not Paraphrase     1.764089\n",
            "886-   Paraphrase         2.350389\n",
            "887-   Not Paraphrase     0.7128015\n",
            "888-   Not Paraphrase     0.7567721\n",
            "889-   Paraphrase         2.0641046\n",
            "890-   Paraphrase         1.9649096\n",
            "891-   Paraphrase         1.368387\n",
            "892-   Paraphrase         1.9482199\n",
            "893-   Paraphrase         1.9896618\n",
            "894-   Paraphrase         1.9154016\n",
            "895-   Paraphrase         1.5642027\n",
            "896-   Not Paraphrase     0.5565712\n",
            "897-   Paraphrase         0.9773475\n",
            "898-   Paraphrase         1.5579294\n",
            "899-   Not Paraphrase     0.18961824\n",
            "900-   Paraphrase         1.3267769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNC2ARoXOfyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "## left -P\n",
        "#right - NP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRMcHi1uLQdO",
        "colab_type": "code",
        "outputId": "79d21c97-aa0c-4e27-e47e-093fa64006d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Paraphrase samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Paraphrase samples: 400 of 900 (44.44%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PmWUtXdLW1I",
        "colab_type": "code",
        "outputId": "025ad86d-dcf4-47a7-eb63-1fbf8bda5e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  \n",
        "\n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)\n",
        "  \n",
        "  print(pred_labels_i)\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]\n",
            "[0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1]\n",
            "[0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            "[0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0]\n",
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0]\n",
            "[0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "[0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0]\n",
            "[0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0]\n",
            "[0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1]\n",
            "[0 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "[0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0]\n",
            "[0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1]\n",
            "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1]\n",
            "[0 0 1 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb--na-oLbVM",
        "colab_type": "code",
        "outputId": "ec1a38d7-042a-4f76-df7b-804f0a6a6537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matthews_set\n",
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6aNsEuZMvjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/My Drive/FYP/bert/model-colab'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1pCMRfZM2YG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l --block-size=K \"/content/drive/My Drive/FYP/bert/model-colab\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQeGwIIMM5Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!cp -r \"/content/drive/My Drive/FYP/bert/model-colab\" \"/content/drive/My Drive/FYP/bert/model-daw\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}