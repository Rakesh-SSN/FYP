{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_TASK_2_MALAYALAM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "065ed7bc1b1d411ab9e1d5c727578610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b6ca50843e5d47a7a77da7abdf0086e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b1c7dd2c9ae148eead135073f9fac544",
              "IPY_MODEL_5c80daaf644f4677a541975009b08401"
            ]
          }
        },
        "b6ca50843e5d47a7a77da7abdf0086e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1c7dd2c9ae148eead135073f9fac544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ac923caf5164b89a24f54434d69bdf6",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20af1916c46343979f27010142b87ce1"
          }
        },
        "5c80daaf644f4677a541975009b08401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ada6ee6f5ad9439090a4a65f9a4c6c29",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 996k/996k [00:01&lt;00:00, 915kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03e07b3d1b664a0ca2211e788de51989"
          }
        },
        "9ac923caf5164b89a24f54434d69bdf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20af1916c46343979f27010142b87ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ada6ee6f5ad9439090a4a65f9a4c6c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03e07b3d1b664a0ca2211e788de51989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "781e76d646574591bb2f820dd4ae7561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_590b96f0fca2470d92e3f52245805354",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b1fa2ed2304c41f69df3c0d26e8d8e8d",
              "IPY_MODEL_7cebbf029e9a446d8e256f4f15e066a5"
            ]
          }
        },
        "590b96f0fca2470d92e3f52245805354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1fa2ed2304c41f69df3c0d26e8d8e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70fcf1de715949a29f0fcee800a86f2d",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 569,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 569,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd5142e7bfe841a9b93d67c1023eeb0b"
          }
        },
        "7cebbf029e9a446d8e256f4f15e066a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_103aac47ebf94a228524f208beba1f9d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 569/569 [00:00&lt;00:00, 18.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2230ad01284455684a08b3eafd6a566"
          }
        },
        "70fcf1de715949a29f0fcee800a86f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd5142e7bfe841a9b93d67c1023eeb0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "103aac47ebf94a228524f208beba1f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2230ad01284455684a08b3eafd6a566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a257bc4150e4d79a012368ac2937388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_543842d3009447f4bd24ebde03c4a705",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ce8929819ce4ac8adc76e9b3406fe05",
              "IPY_MODEL_6cd4506d80a546d5a4c1f6d2bbb8b819"
            ]
          }
        },
        "543842d3009447f4bd24ebde03c4a705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ce8929819ce4ac8adc76e9b3406fe05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa45824e6c1c447592d866a02b53488b",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42578d3fa8614d888346d8f9edfb12ba"
          }
        },
        "6cd4506d80a546d5a4c1f6d2bbb8b819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7598ebd072504b03a971fd526401985e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 714M/714M [00:50&lt;00:00, 14.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc9f8ebf186945c8914b4ed285ea3c60"
          }
        },
        "aa45824e6c1c447592d866a02b53488b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42578d3fa8614d888346d8f9edfb12ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7598ebd072504b03a971fd526401985e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc9f8ebf186945c8914b4ed285ea3c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakesh-SSN/FYP/blob/master/BERT_TASK_2_MALAYALAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN2gN6gr8nOJ",
        "colab_type": "code",
        "outputId": "7ff19efb-d48f-4a27-e2ef-e1348c5fe0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "!pip install transformers"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agL2oUFJO9BM",
        "colab_type": "code",
        "outputId": "d4f808af-4f16-4a18-d3b1-072c9ad23d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roq3nEGz9wvH",
        "colab_type": "code",
        "outputId": "ec74b947-94a0-4c39-dbd7-da87b8b0e957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/malayalam/task2malayalam.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 3,500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2121</th>\n",
              "      <td>MAL2122</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ഇപ്പോള്‍ പുള്ളും ഹുക്കും ഉള്‍പ്പെടെയുള്ള ക്രോ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2896</th>\n",
              "      <td>MAL2897</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>സാമ്പത്തികപ്രതിസന്ധി ഐഎസ് നേതൃത്വത്തില്‍ പ്രകട...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>MAL0512</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>സരിതയെന്നു കേട്ടാൽ ഉമ്മൻചാണ്ടി മൌനിയാകുന്നുവെന...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>MAL0208</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>മഹാരാഷ്ട്രയിൽ ശുദ്ധജലക്ഷാമം രൂക്ഷമായ താനെ, നവി...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2618</th>\n",
              "      <td>MAL2619</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ഫ്രഞ്ച് തലസ്ഥാനമായ പാരീസിലെ പാര്‍പ്പിട മേഖലയില...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3231</th>\n",
              "      <td>MAL3232</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>യൂറോപ്പി ലീഗ് കിരീടം സ്പാനിഷ് ക്ലബ് സെവിയക്ക്....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>MAL0879</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>മണിയുടെ സുഹൃത്തുക്കളായ മൂന്ന് പേർ ചേർന്ന് തെളി...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1286</th>\n",
              "      <td>MAL1287</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "      <td>മോഷ്ടിച്ച രണ്ടു ബൈക്കുകളുമായി മൂന്നംഗ കുട്ടിക...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3465</th>\n",
              "      <td>MAL3466</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ഇന്ന് ജയിക്കുന്ന ടീമിന് ടൂര്‍ണമെന്റിന്റെ ഫൈനലി...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2890</th>\n",
              "      <td>MAL2891</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>കൂടിക്കാഴ്ചയ്ക്ക് മുന്നോടിയായി ഇന്ത്യന്‍ പ്രധാ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "2121         MAL2122  ...  ഇപ്പോള്‍ പുള്ളും ഹുക്കും ഉള്‍പ്പെടെയുള്ള ക്രോ...\n",
              "2896         MAL2897  ...  സാമ്പത്തികപ്രതിസന്ധി ഐഎസ് നേതൃത്വത്തില്‍ പ്രകട...\n",
              "511          MAL0512  ...  സരിതയെന്നു കേട്ടാൽ ഉമ്മൻചാണ്ടി മൌനിയാകുന്നുവെന...\n",
              "207          MAL0208  ...  മഹാരാഷ്ട്രയിൽ ശുദ്ധജലക്ഷാമം രൂക്ഷമായ താനെ, നവി...\n",
              "2618         MAL2619  ...  ഫ്രഞ്ച് തലസ്ഥാനമായ പാരീസിലെ പാര്‍പ്പിട മേഖലയില...\n",
              "3231         MAL3232  ...  യൂറോപ്പി ലീഗ് കിരീടം സ്പാനിഷ് ക്ലബ് സെവിയക്ക്....\n",
              "878          MAL0879  ...  മണിയുടെ സുഹൃത്തുക്കളായ മൂന്ന് പേർ ചേർന്ന് തെളി...\n",
              "1286         MAL1287  ...  മോഷ്ടിച്ച രണ്ടു ബൈക്കുകളുമായി മൂന്നംഗ കുട്ടിക...\n",
              "3465         MAL3466  ...  ഇന്ന് ജയിക്കുന്ന ടീമിന് ടൂര്‍ണമെന്റിന്റെ ഫൈനലി...\n",
              "2890         MAL2891  ...  കൂടിക്കാഴ്ചയ്ക്ക് മുന്നോടിയായി ഇന്ത്യന്‍ പ്രധാ...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 3,500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1650</th>\n",
              "      <td>MAL1651</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "      <td>എം.എസ്.പി ക്യാമ്പിലെ സര്‍ക്കാര്‍ ആശുപത്രിയില്‍...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2456</th>\n",
              "      <td>MAL2457</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ധോണി എത്തിയതോടെ കോഹ്‌ലി യഥാർഥ കോഹ്‌ലിയായി. &lt;eo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2232</th>\n",
              "      <td>MAL2233</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ശേഖരനോട് പ്രതികാരം ചെയ്യാന്‍ കിട്ടിയൊരവസരത്തില...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1945</th>\n",
              "      <td>MAL1946</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "      <td>ജാഗ്രതാനിര്‍ദേശം ഫലം കണ്ടതോടെ ജില്ലയില്‍ പകര്...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>MAL0310</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ഭീകര സംഘടനയായ ഐ.എസ്സിലേക്ക് ഇന്ത്യയില്‍നിന്ന് ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2341</th>\n",
              "      <td>MAL2342</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>രാഘവനെകൊണ്ട് ജീവിതം എഴുതിപ്പിക്കാന്‍ ആവതെല്ലാം...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1666</th>\n",
              "      <td>MAL1667</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "      <td>സാമ്പത്തിക വര്‍ഷത്തെ ലാന്‍ഡ് റവന്യൂ, റവന്യൂ റി...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>MAL1682</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "      <td>സ്ത്രീ വോട്ടര്‍മാരുടെ എണ്ണത്തിലുള്ള കുറവ് പരി...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>MAL1188</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "      <td>അങ്കണവാടികളില്‍ കുട്ടികള്‍ സുരക്ഷിതരല്ലെന്ന് റ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>MAL0326</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ലോകത്തിലെ ഏറ്റവും വിനാശകരമായ ആണവനിലയ അപകടമായ ച...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "1650         MAL1651  ...  എം.എസ്.പി ക്യാമ്പിലെ സര്‍ക്കാര്‍ ആശുപത്രിയില്‍...\n",
              "2456         MAL2457  ...  ധോണി എത്തിയതോടെ കോഹ്‌ലി യഥാർഥ കോഹ്‌ലിയായി. <eo...\n",
              "2232         MAL2233  ...  ശേഖരനോട് പ്രതികാരം ചെയ്യാന്‍ കിട്ടിയൊരവസരത്തില...\n",
              "1945         MAL1946  ...  ജാഗ്രതാനിര്‍ദേശം ഫലം കണ്ടതോടെ ജില്ലയില്‍ പകര്...\n",
              "309          MAL0310  ...  ഭീകര സംഘടനയായ ഐ.എസ്സിലേക്ക് ഇന്ത്യയില്‍നിന്ന് ...\n",
              "2341         MAL2342  ...  രാഘവനെകൊണ്ട് ജീവിതം എഴുതിപ്പിക്കാന്‍ ആവതെല്ലാം...\n",
              "1666         MAL1667  ...  സാമ്പത്തിക വര്‍ഷത്തെ ലാന്‍ഡ് റവന്യൂ, റവന്യൂ റി...\n",
              "1681         MAL1682  ...  സ്ത്രീ വോട്ടര്‍മാരുടെ എണ്ണത്തിലുള്ള കുറവ് പരി...\n",
              "1187         MAL1188  ...  അങ്കണവാടികളില്‍ കുട്ടികള്‍ സുരക്ഷിതരല്ലെന്ന് റ...\n",
              "325          MAL0326  ...  ലോകത്തിലെ ഏറ്റവും വിനാശകരമായ ആണവനിലയ അപകടമായ ച...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK0Dm2839_fM",
        "colab_type": "code",
        "outputId": "b1bef137-5704-4e6d-d4c9-2676e0ca0b98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]\n",
        "print(df.label)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "3495    0\n",
            "3496    0\n",
            "3497    0\n",
            "3498    0\n",
            "3499    0\n",
            "Name: label, Length: 3500, dtype: int64\n",
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "3495    0\n",
            "3496    0\n",
            "3497    0\n",
            "3498    0\n",
            "3499    0\n",
            "Name: label, Length: 3500, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64AfSL-V-Ij5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60lFABu1-KAE",
        "colab_type": "code",
        "outputId": "dc86fb11-b5de-4c84-9b5f-dddff3476b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "065ed7bc1b1d411ab9e1d5c727578610",
            "b6ca50843e5d47a7a77da7abdf0086e6",
            "b1c7dd2c9ae148eead135073f9fac544",
            "5c80daaf644f4677a541975009b08401",
            "9ac923caf5164b89a24f54434d69bdf6",
            "20af1916c46343979f27010142b87ce1",
            "ada6ee6f5ad9439090a4a65f9a4c6c29",
            "03e07b3d1b664a0ca2211e788de51989"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "065ed7bc1b1d411ab9e1d5c727578610",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqawKMwS-o5b",
        "colab_type": "code",
        "outputId": "6ff1ad30-a880-42de-c41e-f201dfea7626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  റോയൽ ചലഞ്ചേഴ്സിനെ ആറു വിക്കറ്റിന് തകർത്ത് മുംബൈ വീണ്ടും വിജയവഴിയിൽ.<eol>ബാംഗ്ലൂര്‍ റോയൽ ചലഞ്ചേഴ്സിനെ മുംബൈ ആറ് വിക്കറ്റിന് തോല്‍പിച്ചു.\n",
            "Tokenized:  ['റ', '##േ', '##ായ', '##ൽ', 'ച', '##ല', '##ഞ', '##ച', '##േ', '##ഴ', '##സി', '##നെ', 'ആ', '##റ', 'വി', '##ക', '##ക', '##റ', '##റി', '##ന', 'ത', '##കർ', '##ത', '##ത', 'മ', '##ം', '##ബ', '##ൈ', 'വ', '##ീ', '##ണ', '##ടം', 'വി', '##ജ', '##യ', '##വ', '##ഴി', '##യിൽ', '.', '<', 'eo', '##l', '>', 'ബ', '##ാം', '##ഗ', '##ല', '##ര', 'റ', '##േ', '##ായ', '##ൽ', 'ച', '##ല', '##ഞ', '##ച', '##േ', '##ഴ', '##സി', '##നെ', 'മ', '##ം', '##ബ', '##ൈ', 'ആ', '##റ', 'വി', '##ക', '##ക', '##റ', '##റി', '##ന', 'ത', '##േ', '##ാല', '##പ', '##ി', '##ച', '##ച', '.']\n",
            "Token IDs:  [1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 94330, 20854, 20854, 1357, 14885, 111397, 59009, 1364, 60434, 36089, 53144, 80054, 111388, 18395, 36877, 90865, 17878, 119, 133, 13934, 10161, 135, 1355, 25406, 111383, 38847, 23290, 1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1357, 14885, 111397, 59009, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 29400, 79591, 111395, 15035, 111386, 111386, 119]\n",
            " Original:  റോയൽ ചലഞ്ചേഴ്സിനെ ആറു വിക്കറ്റിന് തകർത്ത് മുംബൈ വീണ്ടും വിജയവഴിയിൽ.<eol>ബാംഗ്ലൂര്‍ റോയൽ ചലഞ്ചേഴ്സിനെ മുംബൈ ആറ് വിക്കറ്റിന് തോല്‍പിച്ചു.\n",
            "Tokenized:  ['റ', '##േ', '##ായ', '##ൽ', 'ച', '##ല', '##ഞ', '##ച', '##േ', '##ഴ', '##സി', '##നെ', 'ആ', '##റ', 'വി', '##ക', '##ക', '##റ', '##റി', '##ന', 'ത', '##കർ', '##ത', '##ത', 'മ', '##ം', '##ബ', '##ൈ', 'വ', '##ീ', '##ണ', '##ടം', 'വി', '##ജ', '##യ', '##വ', '##ഴി', '##യിൽ', '.', '<', 'eo', '##l', '>', 'ബ', '##ാം', '##ഗ', '##ല', '##ര', 'റ', '##േ', '##ായ', '##ൽ', 'ച', '##ല', '##ഞ', '##ച', '##േ', '##ഴ', '##സി', '##നെ', 'മ', '##ം', '##ബ', '##ൈ', 'ആ', '##റ', 'വി', '##ക', '##ക', '##റ', '##റി', '##ന', 'ത', '##േ', '##ാല', '##പ', '##ി', '##ച', '##ച', '.']\n",
            "Token IDs:  [1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 94330, 20854, 20854, 1357, 14885, 111397, 59009, 1364, 60434, 36089, 53144, 80054, 111388, 18395, 36877, 90865, 17878, 119, 133, 13934, 10161, 135, 1355, 25406, 111383, 38847, 23290, 1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1357, 14885, 111397, 59009, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 29400, 79591, 111395, 15035, 111386, 111386, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKGzPxF1AUUM",
        "colab_type": "code",
        "outputId": "3be4aafe-899a-4166-ab9b-655bbbf252cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  റോയൽ ചലഞ്ചേഴ്സിനെ ആറു വിക്കറ്റിന് തകർത്ത് മുംബൈ വീണ്ടും വിജയവഴിയിൽ.<eol>ബാംഗ്ലൂര്‍ റോയൽ ചലഞ്ചേഴ്സിനെ മുംബൈ ആറ് വിക്കറ്റിന് തോല്‍പിച്ചു.\n",
            "Token IDs: [101, 1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 94330, 20854, 20854, 1357, 14885, 111397, 59009, 1364, 60434, 36089, 53144, 80054, 111388, 18395, 36877, 90865, 17878, 119, 133, 13934, 10161, 135, 1355, 25406, 111383, 38847, 23290, 1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1357, 14885, 111397, 59009, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 29400, 79591, 111395, 15035, 111386, 111386, 119, 102]\n",
            "Original:  റോയൽ ചലഞ്ചേഴ്സിനെ ആറു വിക്കറ്റിന് തകർത്ത് മുംബൈ വീണ്ടും വിജയവഴിയിൽ.<eol>ബാംഗ്ലൂര്‍ റോയൽ ചലഞ്ചേഴ്സിനെ മുംബൈ ആറ് വിക്കറ്റിന് തോല്‍പിച്ചു.\n",
            "Token IDs: [101, 1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 94330, 20854, 20854, 1357, 14885, 111397, 59009, 1364, 60434, 36089, 53144, 80054, 111388, 18395, 36877, 90865, 17878, 119, 133, 13934, 10161, 135, 1355, 25406, 111383, 38847, 23290, 1360, 29400, 40542, 15080, 1339, 38847, 111389, 111386, 29400, 111399, 108628, 47639, 1357, 14885, 111397, 59009, 1322, 75301, 80054, 17896, 17896, 75301, 37054, 25344, 1348, 29400, 79591, 111395, 15035, 111386, 111386, 119, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv39u2kLAo9b",
        "colab_type": "code",
        "outputId": "d4544b74-bef0-4f52-b15b-28a0f34d57d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  277\n",
            "Max sentence length:  277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH_GkPkFAsKR",
        "colab_type": "code",
        "outputId": "8ce9ea68-5092-43c5-bb44-544e86230969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUKKZrYgAuTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfmeSm3zAxOP",
        "colab_type": "code",
        "outputId": "93291ae0-5241-49a3-8afa-39c766618c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 20% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.2)\n",
        "# print(train_inputs)\n",
        "# print(train_labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.2)\n",
        "\n",
        "print(labels)\n",
        "#print(train_masks)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 0 0 0]\n",
            "[1 1 1 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6BSzcZ-A8JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2ab-k8GgLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvYAxocaGzaO",
        "colab_type": "code",
        "outputId": "7c485814-5b60-495a-ec40-3f59a2353cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "781e76d646574591bb2f820dd4ae7561",
            "590b96f0fca2470d92e3f52245805354",
            "b1fa2ed2304c41f69df3c0d26e8d8e8d",
            "7cebbf029e9a446d8e256f4f15e066a5",
            "70fcf1de715949a29f0fcee800a86f2d",
            "dd5142e7bfe841a9b93d67c1023eeb0b",
            "103aac47ebf94a228524f208beba1f9d",
            "b2230ad01284455684a08b3eafd6a566",
            "6a257bc4150e4d79a012368ac2937388",
            "543842d3009447f4bd24ebde03c4a705",
            "2ce8929819ce4ac8adc76e9b3406fe05",
            "6cd4506d80a546d5a4c1f6d2bbb8b819",
            "aa45824e6c1c447592d866a02b53488b",
            "42578d3fa8614d888346d8f9edfb12ba",
            "7598ebd072504b03a971fd526401985e",
            "dc9f8ebf186945c8914b4ed285ea3c60"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "781e76d646574591bb2f820dd4ae7561",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a257bc4150e4d79a012368ac2937388",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xB1woJrHCZ0",
        "colab_type": "code",
        "outputId": "ea87d4d3-90f7-4579-beb2-cc6bd4b660ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n",
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NhjDCrtHGh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBK2E_PaHKQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOO83LgEHQYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2jmuLjzHUP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6dh8MSXHXCv",
        "colab_type": "code",
        "outputId": "b0d0d77b-7595-4738-9458-28d728cd1276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     88.    Elapsed: 0:00:09.\n",
            "  Batch    80  of     88.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 1.03\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     88.    Elapsed: 0:00:09.\n",
            "  Batch    80  of     88.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.85\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     88.    Elapsed: 0:00:09.\n",
            "  Batch    80  of     88.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     88.    Elapsed: 0:00:09.\n",
            "  Batch    80  of     88.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     88.    Elapsed: 0:00:09.\n",
            "  Batch    80  of     88.    Elapsed: 0:00:18.\n",
            "\n",
            "  Average training loss: 1.05\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3sCgA3MK9B2",
        "colab_type": "code",
        "outputId": "5deebdbf-7bf4-4c78-a73d-4699b2919f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/testdata/task2malayalam-test.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "#print(len(labels))\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "#print(len(prediction_labels))\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 1,400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHsFeNFSLIkL",
        "colab_type": "code",
        "outputId": "935d8cde-76b0-4b53-cc2e-b659e50a0cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  #print(outputs)\n",
        "  # print(logits)\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "  # # print(predictions)\n",
        "  #print(true_labels)\n",
        "print('    DONE.')\n",
        "\n",
        "#print(true_labels)\n",
        "print(\"*************************\")\n",
        "\n",
        "print(len(predictions))\n",
        "#print(outputs)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,400 test sentences...\n",
            "    DONE.\n",
            "*************************\n",
            "44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgpMTRW-jMtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.savetxt(\"/content/drive/My Drive/FYP/bert/glue/cola/task2malayalam-results.txt\",predictions, fmt=\"%s\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCGGtb-jicKL",
        "colab_type": "code",
        "outputId": "d50eceef-b9a2-45b7-fd55-35f52ccd72ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "count_NP=0\n",
        "count_P=0\n",
        "count_line=1\n",
        "x=-1\n",
        "true_count,false_count=0,0\n",
        "print(\"label \\t sno\\tlogit\\t\\t\\t\\t\\tindex\")\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    print(\"(\",end=\"\")\n",
        "    print(true_labels[i][j],end=\"\")\n",
        "    print(\")\",end=\"\")\n",
        "    print(\"\\t\",count_line,end=\"\")\n",
        "    # print(\"-  \",end=\"\")\n",
        "    if(predictions[i][j][0]>predictions[i][j][1] and predictions[i][j][0]>predictions[i][j][2]):\n",
        "      #count_P+=1 \n",
        "      #print(\" Non Paraphrase         \",end=\"\")\n",
        "      print(\"\\t\",predictions[i][j],\"\\t0\\t\",end=\"\")\n",
        "      x=0\n",
        "    elif(predictions[i][j][1]>predictions[i][j][0] and predictions[i][j][1]>predictions[i][j][2]):\n",
        "      #print(\" Paraphrase     \",end=\"\")\n",
        "     # count_NP+=1      \n",
        "      print(\"\\t\",predictions[i][j],\"\\t1\\t\",end=\"\")\n",
        "      x=1\n",
        "    elif(predictions[i][j][2]>predictions[i][j][0] and predictions[i][j][2]>predictions[i][j][1]):\n",
        "      #print(\" Semi Paraphrase     \",end=\"\")\n",
        "      #count_NP+=1      \n",
        "      print(\"\\t\",predictions[i][j],\"\\t2\\t\",end=\"\")\n",
        "      x=2\n",
        "    count_line+=1\n",
        "    #print(\"\\t\",predictions[i][j],\"\\t2\\t\",end=\"\")\n",
        "\n",
        "    if(true_labels[i][j]==x):\n",
        "      true_count+=1\n",
        "      print(\"true\")\n",
        "    else:\n",
        "      print(\"false\")\n",
        "      false_count+=1\n",
        "\n",
        "print(\"Number of true predictions:\",true_count)\n",
        "print(\"Number of false predictions:\",false_count)\n",
        "  \n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label \t sno\tlogit\t\t\t\t\tindex\n",
            "(2)\t 1\t [ 1.1117982   0.86303955 -1.9602993 ] \t0\tfalse\n",
            "(0)\t 2\t [ 0.05068202  1.4664345  -1.5741664 ] \t1\tfalse\n",
            "(0)\t 3\t [ 0.0757511  -0.3535634  -0.19134599] \t0\ttrue\n",
            "(1)\t 4\t [-0.4576137   1.1731212  -0.37339535] \t1\ttrue\n",
            "(1)\t 5\t [ 1.9412161 -0.5197002 -1.8190007] \t0\tfalse\n",
            "(2)\t 6\t [-1.2702378  -0.57358193  2.3466568 ] \t2\ttrue\n",
            "(1)\t 7\t [-1.427555   1.1138266  0.3494515] \t1\ttrue\n",
            "(0)\t 8\t [-0.85053045 -0.7435745   1.8622766 ] \t2\tfalse\n",
            "(0)\t 9\t [ 1.10989     0.50118345 -1.6479114 ] \t0\ttrue\n",
            "(0)\t 10\t [ 0.43578535 -0.52451855 -0.12191161] \t0\ttrue\n",
            "(0)\t 11\t [ 1.9994067  -0.31818616 -1.9117076 ] \t0\ttrue\n",
            "(0)\t 12\t [ 1.1754711  -0.30944848 -1.0693581 ] \t0\ttrue\n",
            "(2)\t 13\t [-0.09065587 -0.3672627   0.1964344 ] \t2\ttrue\n",
            "(2)\t 14\t [-1.0144725 -1.158925   2.3244402] \t2\ttrue\n",
            "(1)\t 15\t [-0.21068586  0.619348   -0.38728026] \t1\ttrue\n",
            "(1)\t 16\t [-0.83228225  0.11907452  0.9108224 ] \t2\tfalse\n",
            "(0)\t 17\t [ 2.1721647 -0.9050744 -1.3434175] \t0\ttrue\n",
            "(0)\t 18\t [ 1.0269433   0.49019858 -1.6403806 ] \t0\ttrue\n",
            "(0)\t 19\t [ 0.97881216 -0.35828683 -1.2362614 ] \t0\ttrue\n",
            "(0)\t 20\t [ 2.2871044  -0.59340715 -1.8744454 ] \t0\ttrue\n",
            "(1)\t 21\t [ 2.3764637 -0.5879372 -1.8632375] \t0\tfalse\n",
            "(2)\t 22\t [ 1.5451934  -0.82487637 -0.88102555] \t0\tfalse\n",
            "(2)\t 23\t [ 0.7955447  0.668524  -1.757853 ] \t0\tfalse\n",
            "(0)\t 24\t [ 2.2503726 -0.565134  -1.9235725] \t0\ttrue\n",
            "(1)\t 25\t [ 1.1523921   0.45439735 -1.6491154 ] \t0\tfalse\n",
            "(0)\t 26\t [ 2.1674325 -0.3337795 -2.0094535] \t0\ttrue\n",
            "(0)\t 27\t [ 0.3583926  0.9148373 -1.4334354] \t1\tfalse\n",
            "(0)\t 28\t [ 0.8663632   0.56010777 -1.7165135 ] \t0\ttrue\n",
            "(0)\t 29\t [-0.05255813 -1.3655326   1.5204213 ] \t2\tfalse\n",
            "(0)\t 30\t [-0.19212352  0.31986088 -0.20170176] \t1\tfalse\n",
            "(0)\t 31\t [ 2.2602577 -1.0371456 -1.4340475] \t0\ttrue\n",
            "(2)\t 32\t [-0.7591527   0.53729534  0.42935404] \t1\tfalse\n",
            "(2)\t 33\t [-0.77858275 -1.2322627   2.2793744 ] \t2\ttrue\n",
            "(1)\t 34\t [ 1.8619117  0.1088656 -2.0665236] \t0\tfalse\n",
            "(0)\t 35\t [ 2.2981677 -0.7891969 -1.7153025] \t0\ttrue\n",
            "(0)\t 36\t [ 1.8955104  -0.83559936 -1.233638  ] \t0\ttrue\n",
            "(2)\t 37\t [ 0.65671724 -1.4952714   0.2892671 ] \t0\tfalse\n",
            "(0)\t 38\t [ 1.9701363 -0.9374437 -1.308667 ] \t0\ttrue\n",
            "(1)\t 39\t [ 1.6208014   0.47511476 -2.0200467 ] \t0\tfalse\n",
            "(1)\t 40\t [ 1.85643    -0.29737398 -1.6838933 ] \t0\tfalse\n",
            "(2)\t 41\t [ 0.95053655 -0.6256308  -0.6554473 ] \t0\tfalse\n",
            "(0)\t 42\t [ 2.290411  -0.6650833 -1.750148 ] \t0\ttrue\n",
            "(0)\t 43\t [ 1.7893792  -0.12570441 -1.7581666 ] \t0\ttrue\n",
            "(0)\t 44\t [ 2.3488874  -0.49310955 -1.8597699 ] \t0\ttrue\n",
            "(0)\t 45\t [ 2.1274188  -0.24801043 -2.0573087 ] \t0\ttrue\n",
            "(0)\t 46\t [ 1.3216194 -0.8046345 -1.1485127] \t0\ttrue\n",
            "(0)\t 47\t [ 2.2482097 -1.0347465 -1.401201 ] \t0\ttrue\n",
            "(2)\t 48\t [ 1.306346   -0.37547782 -1.5891321 ] \t0\tfalse\n",
            "(0)\t 49\t [ 2.0469441  -0.31060052 -1.8938792 ] \t0\ttrue\n",
            "(2)\t 50\t [-0.20970248 -1.3969419   1.756732  ] \t2\ttrue\n",
            "(1)\t 51\t [ 2.1367905  -0.11482846 -2.083786  ] \t0\tfalse\n",
            "(1)\t 52\t [ 1.9986922  -0.44716954 -1.8845228 ] \t0\tfalse\n",
            "(1)\t 53\t [ 1.979291  -0.2838321 -1.7714005] \t0\tfalse\n",
            "(1)\t 54\t [-0.16167791  1.5648187  -1.46362   ] \t1\ttrue\n",
            "(1)\t 55\t [-1.722155    0.9041658   0.54644704] \t1\ttrue\n",
            "(0)\t 56\t [ 0.5766228   0.09943119 -0.8105806 ] \t0\ttrue\n",
            "(0)\t 57\t [ 1.8701798  -0.04167523 -1.9992675 ] \t0\ttrue\n",
            "(0)\t 58\t [-0.50875556  0.26924124  0.3407679 ] \t2\tfalse\n",
            "(2)\t 59\t [-1.2677709 -1.021913   2.4505439] \t2\ttrue\n",
            "(2)\t 60\t [ 1.6517733 -1.0696087 -0.91372  ] \t0\tfalse\n",
            "(0)\t 61\t [ 0.16195452  1.2345152  -1.6289824 ] \t1\tfalse\n",
            "(0)\t 62\t [ 1.2804525  0.7653491 -2.1099553] \t0\ttrue\n",
            "(0)\t 63\t [ 2.3275073 -0.50759   -1.8682913] \t0\ttrue\n",
            "(2)\t 64\t [ 0.3853439  1.2575352 -1.6237067] \t1\tfalse\n",
            "(1)\t 65\t [ 0.44931775  1.3770697  -1.6527138 ] \t1\ttrue\n",
            "(1)\t 66\t [ 0.06567556  1.0549572  -1.3510319 ] \t1\ttrue\n",
            "(0)\t 67\t [ 2.0792863 -0.9812755 -1.3802073] \t0\ttrue\n",
            "(2)\t 68\t [-0.46780047 -0.63978577  1.2461538 ] \t2\ttrue\n",
            "(0)\t 69\t [-0.58350974 -0.6645322   1.5447769 ] \t2\tfalse\n",
            "(2)\t 70\t [ 0.08753662  0.6444748  -0.90684927] \t1\tfalse\n",
            "(1)\t 71\t [ 2.0715644  -0.24328353 -2.0398111 ] \t0\tfalse\n",
            "(0)\t 72\t [ 2.2904994  -0.72777325 -1.6751907 ] \t0\ttrue\n",
            "(0)\t 73\t [ 1.5789405   0.20680614 -2.0159216 ] \t0\ttrue\n",
            "(1)\t 74\t [ 1.3291467 -1.0051916 -0.8997976] \t0\tfalse\n",
            "(2)\t 75\t [ 0.27178702  0.8138935  -1.5237215 ] \t1\tfalse\n",
            "(1)\t 76\t [ 1.8536209   0.03576519 -2.1584878 ] \t0\tfalse\n",
            "(0)\t 77\t [-0.3850944  -0.12741864  0.56269574] \t2\tfalse\n",
            "(2)\t 78\t [ 0.32012674  1.4083056  -1.7711556 ] \t1\tfalse\n",
            "(0)\t 79\t [ 1.8647898 -0.4206725 -1.7385836] \t0\ttrue\n",
            "(0)\t 80\t [ 2.2761848  -0.62883747 -1.825527  ] \t0\ttrue\n",
            "(0)\t 81\t [-0.5759995  -0.22110428  0.8421067 ] \t2\tfalse\n",
            "(0)\t 82\t [ 0.8066043   0.83424205 -1.9642882 ] \t1\tfalse\n",
            "(1)\t 83\t [ 1.505239    0.31678113 -1.9984341 ] \t0\tfalse\n",
            "(0)\t 84\t [ 1.8913301  -0.40020862 -1.8200555 ] \t0\ttrue\n",
            "(1)\t 85\t [ 0.60465795  1.1867597  -2.0172734 ] \t1\ttrue\n",
            "(2)\t 86\t [-1.3934472  -0.34726086  2.066862  ] \t2\ttrue\n",
            "(0)\t 87\t [ 2.2576993 -0.8868591 -1.5515286] \t0\ttrue\n",
            "(1)\t 88\t [ 1.4355217   0.59272176 -2.084907  ] \t0\tfalse\n",
            "(1)\t 89\t [ 1.4096204   0.67909217 -2.207478  ] \t0\tfalse\n",
            "(2)\t 90\t [ 1.6685306  -0.16021521 -1.7563448 ] \t0\tfalse\n",
            "(0)\t 91\t [ 1.0787354   0.29585198 -1.4553694 ] \t0\ttrue\n",
            "(1)\t 92\t [ 1.782891  -1.2787101 -0.9331235] \t0\tfalse\n",
            "(0)\t 93\t [-0.578093    0.32800525  0.2458193 ] \t1\tfalse\n",
            "(0)\t 94\t [ 2.2756965  -0.67535925 -1.7225864 ] \t0\ttrue\n",
            "(0)\t 95\t [ 1.411723    0.43212757 -2.0271297 ] \t0\ttrue\n",
            "(0)\t 96\t [ 1.6852682   0.19252537 -2.2036097 ] \t0\ttrue\n",
            "(0)\t 97\t [ 1.7932152   0.13007559 -2.084292  ] \t0\ttrue\n",
            "(0)\t 98\t [ 1.8543609  -0.12405025 -1.9177971 ] \t0\ttrue\n",
            "(0)\t 99\t [-0.20341918 -1.0792739   1.229398  ] \t2\tfalse\n",
            "(0)\t 100\t [ 0.13604641  1.4983652  -1.7114027 ] \t1\tfalse\n",
            "(0)\t 101\t [ 2.334317  -0.6455756 -1.8110089] \t0\ttrue\n",
            "(0)\t 102\t [ 0.63008624  1.0117651  -1.5779594 ] \t1\tfalse\n",
            "(0)\t 103\t [ 0.4922967  1.0779119 -1.5544602] \t1\tfalse\n",
            "(2)\t 104\t [-0.61250716 -1.2768859   1.9944185 ] \t2\ttrue\n",
            "(0)\t 105\t [-0.87593156  0.56250757  0.44000688] \t1\tfalse\n",
            "(1)\t 106\t [-1.347362    1.4996774   0.02498417] \t1\ttrue\n",
            "(1)\t 107\t [-0.8757116  0.6308666  0.7296891] \t2\tfalse\n",
            "(1)\t 108\t [-0.46099848  1.3816748  -0.6663091 ] \t1\ttrue\n",
            "(2)\t 109\t [ 0.0270712 -1.2510843  1.1055121] \t2\ttrue\n",
            "(1)\t 110\t [-0.9538466 -1.1690822  2.302887 ] \t2\tfalse\n",
            "(1)\t 111\t [-0.71692353 -1.3428123   2.1322272 ] \t2\tfalse\n",
            "(2)\t 112\t [-0.2310724   0.5186544  -0.15111282] \t1\tfalse\n",
            "(0)\t 113\t [ 2.3052657 -0.7642179 -1.7242379] \t0\ttrue\n",
            "(2)\t 114\t [-1.0019786 -1.1303576  2.3218708] \t2\ttrue\n",
            "(0)\t 115\t [-0.47093523 -1.0961711   1.6770722 ] \t2\tfalse\n",
            "(2)\t 116\t [ 1.0564158  0.7825084 -1.842144 ] \t0\tfalse\n",
            "(1)\t 117\t [ 2.3588345 -0.6751576 -1.7421556] \t0\tfalse\n",
            "(2)\t 118\t [-1.332438   -0.19432855  1.8014481 ] \t2\ttrue\n",
            "(2)\t 119\t [-0.38726813  1.530024   -1.2483773 ] \t1\tfalse\n",
            "(1)\t 120\t [ 0.61006147  0.3439662  -1.2242043 ] \t0\tfalse\n",
            "(0)\t 121\t [ 1.8082484 -0.7140868 -1.4125347] \t0\ttrue\n",
            "(0)\t 122\t [-0.4235504 -1.2950839  1.9359455] \t2\tfalse\n",
            "(2)\t 123\t [-0.52068454 -0.9048572   1.6463497 ] \t2\ttrue\n",
            "(0)\t 124\t [-0.45319977  1.0162725  -0.18902352] \t1\tfalse\n",
            "(2)\t 125\t [-0.68772644 -1.0009971   1.8726007 ] \t2\ttrue\n",
            "(2)\t 126\t [-0.7907763 -1.0541807  2.2546244] \t2\ttrue\n",
            "(0)\t 127\t [ 0.7399321  -1.4120786   0.20445216] \t0\ttrue\n",
            "(1)\t 128\t [ 2.2518382 -0.4131249 -1.9438472] \t0\tfalse\n",
            "(0)\t 129\t [ 2.3801415  -0.84700334 -1.617168  ] \t0\ttrue\n",
            "(2)\t 130\t [-0.23734681 -1.39867     1.3376472 ] \t2\ttrue\n",
            "(0)\t 131\t [ 2.0894568  -0.10627229 -2.1398249 ] \t0\ttrue\n",
            "(2)\t 132\t [-1.5959752  1.1069648  0.6068213] \t1\tfalse\n",
            "(0)\t 133\t [ 2.1951544 -0.3435387 -2.0597897] \t0\ttrue\n",
            "(0)\t 134\t [ 2.1473112  -0.13412553 -2.088546  ] \t0\ttrue\n",
            "(1)\t 135\t [ 1.427457   0.5103493 -2.160336 ] \t0\tfalse\n",
            "(0)\t 136\t [ 2.3230689 -0.6573354 -1.8151773] \t0\ttrue\n",
            "(0)\t 137\t [-0.77982104  0.9801029  -0.10717989] \t1\tfalse\n",
            "(0)\t 138\t [-0.27258158  1.1253579  -0.8925785 ] \t1\tfalse\n",
            "(0)\t 139\t [ 0.25666314  1.0523009  -1.4687604 ] \t1\tfalse\n",
            "(0)\t 140\t [ 2.1616619 -0.1436428 -2.036087 ] \t0\ttrue\n",
            "(1)\t 141\t [-0.24390155  1.2017076  -1.0319726 ] \t1\ttrue\n",
            "(0)\t 142\t [ 0.77676773  0.9056131  -2.0794187 ] \t1\tfalse\n",
            "(2)\t 143\t [ 1.1312407  0.8909129 -2.0000648] \t0\tfalse\n",
            "(2)\t 144\t [-0.11918664 -1.0546911   1.0932586 ] \t2\ttrue\n",
            "(1)\t 145\t [ 1.5591923  0.5660529 -2.1314983] \t0\tfalse\n",
            "(0)\t 146\t [-0.0461144  -0.2338102  -0.18380624] \t0\ttrue\n",
            "(0)\t 147\t [ 0.06893807  0.8395017  -1.083698  ] \t1\tfalse\n",
            "(1)\t 148\t [ 0.06721271  0.37199673 -0.20738319] \t1\ttrue\n",
            "(2)\t 149\t [ 0.73261577  1.1145273  -1.8677697 ] \t1\tfalse\n",
            "(1)\t 150\t [ 1.941575   -0.64670354 -1.6125426 ] \t0\tfalse\n",
            "(0)\t 151\t [ 1.0562239 -0.5625672 -1.0227572] \t0\ttrue\n",
            "(0)\t 152\t [ 1.7811503 -0.7147775 -1.4589896] \t0\ttrue\n",
            "(0)\t 153\t [ 2.2768753 -0.6568687 -1.8413677] \t0\ttrue\n",
            "(0)\t 154\t [ 2.1973593  -0.68067527 -1.8213344 ] \t0\ttrue\n",
            "(1)\t 155\t [ 2.3632183 -0.6748286 -1.7631128] \t0\tfalse\n",
            "(2)\t 156\t [ 0.6840847   0.23833032 -1.1211495 ] \t0\tfalse\n",
            "(0)\t 157\t [ 0.17623411  0.94197947 -1.3019867 ] \t1\tfalse\n",
            "(2)\t 158\t [-0.01120207  0.6080261  -0.792021  ] \t1\tfalse\n",
            "(2)\t 159\t [-0.61881936 -0.3898082   1.3295338 ] \t2\ttrue\n",
            "(0)\t 160\t [ 0.404835   -0.38728693 -0.38380733] \t0\ttrue\n",
            "(1)\t 161\t [ 2.2321413 -0.5122585 -1.9012969] \t0\tfalse\n",
            "(2)\t 162\t [ 0.34039333 -0.29486805 -0.18442002] \t0\tfalse\n",
            "(0)\t 163\t [ 2.251641  -0.6475984 -1.8057998] \t0\ttrue\n",
            "(1)\t 164\t [-0.8223371   1.617737   -0.83138967] \t1\ttrue\n",
            "(0)\t 165\t [ 2.3580077  -0.93098944 -1.4882534 ] \t0\ttrue\n",
            "(0)\t 166\t [ 2.2581139 -0.7300902 -1.7444154] \t0\ttrue\n",
            "(1)\t 167\t [ 0.57783854  0.8849286  -1.7223309 ] \t1\ttrue\n",
            "(1)\t 168\t [ 0.11976584  1.1868018  -1.5433202 ] \t1\ttrue\n",
            "(0)\t 169\t [ 2.3250353 -0.760047  -1.7022389] \t0\ttrue\n",
            "(1)\t 170\t [ 0.7408076  1.1054586 -1.8312185] \t1\ttrue\n",
            "(1)\t 171\t [ 0.19668816  0.3176244  -1.1141515 ] \t1\ttrue\n",
            "(1)\t 172\t [ 1.9207017 -0.0190578 -1.7060995] \t0\tfalse\n",
            "(0)\t 173\t [ 2.3966022  -0.90854114 -1.5480425 ] \t0\ttrue\n",
            "(2)\t 174\t [ 1.1026398   0.36390707 -1.6109731 ] \t0\tfalse\n",
            "(1)\t 175\t [ 0.08430173  1.3590984  -1.53881   ] \t1\ttrue\n",
            "(1)\t 176\t [ 0.31986558  1.0865817  -1.515636  ] \t1\ttrue\n",
            "(1)\t 177\t [ 1.4673539  0.5142757 -2.005351 ] \t0\tfalse\n",
            "(2)\t 178\t [ 0.6330871  -0.58863866 -0.4383756 ] \t0\tfalse\n",
            "(0)\t 179\t [-0.6147228 -1.3201923  2.1181874] \t2\tfalse\n",
            "(2)\t 180\t [-0.7378368 -1.0788972  2.1445417] \t2\ttrue\n",
            "(0)\t 181\t [ 0.9630019  -1.4146446   0.24276417] \t0\ttrue\n",
            "(0)\t 182\t [-0.07502922  0.86426663 -0.8937485 ] \t1\tfalse\n",
            "(1)\t 183\t [ 0.68779236  0.50714976 -1.1713398 ] \t0\tfalse\n",
            "(0)\t 184\t [ 1.7388908   0.09582887 -2.1034846 ] \t0\ttrue\n",
            "(0)\t 185\t [ 1.9037186  -0.15768929 -1.7593505 ] \t0\ttrue\n",
            "(2)\t 186\t [-0.67947537 -0.09122908  0.8484095 ] \t2\ttrue\n",
            "(1)\t 187\t [ 0.14454344  1.3049476  -1.2586207 ] \t1\ttrue\n",
            "(2)\t 188\t [-0.48264635  1.1719005  -0.7602281 ] \t1\tfalse\n",
            "(0)\t 189\t [ 1.6767088  -0.15597108 -1.4525611 ] \t0\ttrue\n",
            "(1)\t 190\t [-1.3529263   0.97701645  0.4568846 ] \t1\ttrue\n",
            "(2)\t 191\t [-0.45030764  1.4615153  -1.0031011 ] \t1\tfalse\n",
            "(2)\t 192\t [ 0.46785477  0.27470288 -1.0518979 ] \t0\tfalse\n",
            "(2)\t 193\t [-0.73162216 -1.1482406   2.033939  ] \t2\ttrue\n",
            "(0)\t 194\t [ 1.9752122  0.0149843 -2.0447278] \t0\ttrue\n",
            "(1)\t 195\t [ 1.4351122  0.578651  -1.8655679] \t0\tfalse\n",
            "(1)\t 196\t [ 1.751581    0.21497141 -2.0362298 ] \t0\tfalse\n",
            "(0)\t 197\t [-0.62128633  0.6416725  -0.13001916] \t1\tfalse\n",
            "(2)\t 198\t [-0.22473489 -0.15442772  0.30948043] \t2\ttrue\n",
            "(0)\t 199\t [ 2.1192396  -0.60511416 -1.7205372 ] \t0\ttrue\n",
            "(0)\t 200\t [ 2.2274845 -0.766519  -1.6814423] \t0\ttrue\n",
            "(0)\t 201\t [ 1.4570806  -0.55492336 -1.0863616 ] \t0\ttrue\n",
            "(1)\t 202\t [-0.78118926  0.23052612  0.6908754 ] \t2\tfalse\n",
            "(1)\t 203\t [ 0.20718116  0.8690486  -1.0276415 ] \t1\ttrue\n",
            "(1)\t 204\t [ 2.0699003 -1.0271829 -1.4492877] \t0\tfalse\n",
            "(0)\t 205\t [ 0.15022728  0.2641007  -0.19248962] \t1\tfalse\n",
            "(0)\t 206\t [ 2.2818005 -0.7151881 -1.7810303] \t0\ttrue\n",
            "(1)\t 207\t [ 2.3898146 -0.7868898 -1.6900337] \t0\tfalse\n",
            "(0)\t 208\t [-1.0625461  -0.48363325  1.9040786 ] \t2\tfalse\n",
            "(2)\t 209\t [-0.5368458  1.6099763 -0.9746661] \t1\tfalse\n",
            "(0)\t 210\t [ 0.9684867  0.7480801 -1.8699241] \t0\ttrue\n",
            "(1)\t 211\t [-0.23176856  1.6226857  -1.2850498 ] \t1\ttrue\n",
            "(2)\t 212\t [-0.67642033 -0.9945883   1.7108626 ] \t2\ttrue\n",
            "(2)\t 213\t [-1.6472816   0.62529427  1.2204578 ] \t2\ttrue\n",
            "(1)\t 214\t [-0.91041386 -1.1515663   2.3601894 ] \t2\tfalse\n",
            "(0)\t 215\t [ 2.2512014  -0.52182525 -1.9219842 ] \t0\ttrue\n",
            "(2)\t 216\t [-0.86890996 -1.0680543   2.4312184 ] \t2\ttrue\n",
            "(0)\t 217\t [ 1.6985489   0.28347504 -1.9620483 ] \t0\ttrue\n",
            "(1)\t 218\t [ 1.4523212 -0.9726071 -0.9402122] \t0\tfalse\n",
            "(0)\t 219\t [ 2.3457482 -0.7133007 -1.7957882] \t0\ttrue\n",
            "(2)\t 220\t [-1.0135266 -1.0599427  2.4586558] \t2\ttrue\n",
            "(2)\t 221\t [-0.9605287 -1.1020738  2.2328153] \t2\ttrue\n",
            "(0)\t 222\t [-0.32125977 -1.0316063   1.3175857 ] \t2\tfalse\n",
            "(0)\t 223\t [ 1.5565852 -0.7509518 -1.1360545] \t0\ttrue\n",
            "(1)\t 224\t [-0.82812876  0.43447477  0.32257608] \t1\ttrue\n",
            "(1)\t 225\t [-1.654824   -0.46782494  2.1576262 ] \t2\tfalse\n",
            "(1)\t 226\t [-1.3389386e+00  1.5705079e+00 -5.3435174e-04] \t1\ttrue\n",
            "(0)\t 227\t [ 2.0824974  -0.52537686 -1.7939832 ] \t0\ttrue\n",
            "(2)\t 228\t [-0.6825744 -1.2181665  2.2398868] \t2\ttrue\n",
            "(2)\t 229\t [-0.715581   1.7309484 -0.8646976] \t1\tfalse\n",
            "(2)\t 230\t [-0.07225599 -1.2649893   1.1368651 ] \t2\ttrue\n",
            "(2)\t 231\t [-0.60837567 -1.2535765   2.1567497 ] \t2\ttrue\n",
            "(0)\t 232\t [ 2.1735432 -0.6427736 -1.7452226] \t0\ttrue\n",
            "(2)\t 233\t [ 0.19774693  0.24089088 -0.26000133] \t1\tfalse\n",
            "(2)\t 234\t [ 0.17689723 -1.4084696   1.1338569 ] \t2\ttrue\n",
            "(1)\t 235\t [ 2.2386794  -0.70827407 -1.6714258 ] \t0\tfalse\n",
            "(2)\t 236\t [ 0.46507025 -0.36553878  0.05976178] \t0\tfalse\n",
            "(0)\t 237\t [-0.6429286  1.426328  -0.4496477] \t1\tfalse\n",
            "(2)\t 238\t [-0.996301  -1.0848122  2.308178 ] \t2\ttrue\n",
            "(0)\t 239\t [ 1.4596235   0.48364136 -2.0658522 ] \t0\ttrue\n",
            "(0)\t 240\t [ 1.9183358 -1.253953  -1.092246 ] \t0\ttrue\n",
            "(2)\t 241\t [-0.7874637 -1.1434757  2.1394331] \t2\ttrue\n",
            "(1)\t 242\t [ 1.7521647 -0.2921238 -1.8286762] \t0\tfalse\n",
            "(1)\t 243\t [-0.7344852  -0.04215572  0.9170537 ] \t2\tfalse\n",
            "(2)\t 244\t [ 0.39521483 -1.4770697   0.8759387 ] \t2\ttrue\n",
            "(1)\t 245\t [ 1.9111544  -0.22503912 -1.7996491 ] \t0\tfalse\n",
            "(0)\t 246\t [ 2.0764074 -1.2068517 -1.0435195] \t0\ttrue\n",
            "(2)\t 247\t [ 1.3448972 -1.2173775 -0.8594924] \t0\tfalse\n",
            "(2)\t 248\t [ 0.01294396  0.24784763 -0.49083325] \t1\tfalse\n",
            "(0)\t 249\t [ 2.0117428 -0.9763598 -1.3097519] \t0\ttrue\n",
            "(2)\t 250\t [ 0.19946094 -1.493814    1.0349905 ] \t2\ttrue\n",
            "(0)\t 251\t [-0.9021885 -0.8496999  2.1023126] \t2\tfalse\n",
            "(0)\t 252\t [ 2.1989827 -0.969159  -1.439952 ] \t0\ttrue\n",
            "(2)\t 253\t [-0.5041077 -1.3626502  2.0769963] \t2\ttrue\n",
            "(2)\t 254\t [ 0.5644193   0.82173663 -1.5653806 ] \t1\tfalse\n",
            "(2)\t 255\t [ 1.0893078  0.7459837 -1.8302763] \t0\tfalse\n",
            "(2)\t 256\t [-0.84237295 -1.1203525   2.2937517 ] \t2\ttrue\n",
            "(2)\t 257\t [ 0.7286719  -1.4888175   0.51101375] \t0\tfalse\n",
            "(1)\t 258\t [ 0.65415865  0.57203716 -1.6504526 ] \t0\tfalse\n",
            "(1)\t 259\t [ 1.8851904   0.08189069 -2.0570486 ] \t0\tfalse\n",
            "(2)\t 260\t [ 1.6478976  -1.3826873  -0.69733363] \t0\tfalse\n",
            "(2)\t 261\t [ 1.6017784 -0.8902388 -1.1160576] \t0\tfalse\n",
            "(1)\t 262\t [-1.680977    0.64323515  1.3539808 ] \t2\tfalse\n",
            "(2)\t 263\t [ 0.2693853   0.12835617 -0.53553593] \t0\tfalse\n",
            "(1)\t 264\t [ 1.4937552 -0.0636274 -1.5064347] \t0\tfalse\n",
            "(2)\t 265\t [-0.23637941  0.96488327 -0.8287592 ] \t1\tfalse\n",
            "(1)\t 266\t [ 1.8345534  -0.94274336 -1.2308381 ] \t0\tfalse\n",
            "(1)\t 267\t [ 1.1263331  0.7238907 -1.831101 ] \t0\tfalse\n",
            "(2)\t 268\t [-1.733528   0.5188179  1.4785092] \t2\ttrue\n",
            "(1)\t 269\t [ 1.0550655  -1.2355739  -0.67227805] \t0\tfalse\n",
            "(0)\t 270\t [-0.64700776 -0.65384096  1.4912809 ] \t2\tfalse\n",
            "(2)\t 271\t [-0.9516135 -1.107507   2.4241748] \t2\ttrue\n",
            "(2)\t 272\t [ 0.19528043 -0.8666976   0.37911323] \t2\ttrue\n",
            "(2)\t 273\t [ 1.7169036   0.04869051 -1.5016636 ] \t0\tfalse\n",
            "(2)\t 274\t [ 0.9245097   0.50870806 -1.5644681 ] \t0\tfalse\n",
            "(1)\t 275\t [-0.46103275 -1.2564101   1.9189751 ] \t2\tfalse\n",
            "(1)\t 276\t [-0.3302038   1.2941955  -0.53871936] \t1\ttrue\n",
            "(0)\t 277\t [-0.79873407 -1.2366424   1.5384938 ] \t2\tfalse\n",
            "(2)\t 278\t [-1.331412   -0.55042714  2.4321237 ] \t2\ttrue\n",
            "(0)\t 279\t [-1.0552428 -1.1498946  2.3631349] \t2\tfalse\n",
            "(1)\t 280\t [ 2.0578606  -0.68055105 -1.6015084 ] \t0\tfalse\n",
            "(0)\t 281\t [-0.37176728  1.5257139  -1.0659077 ] \t1\tfalse\n",
            "(1)\t 282\t [ 1.0153657   0.88347024 -2.0243278 ] \t0\tfalse\n",
            "(1)\t 283\t [-0.54874176 -0.69483817  1.0799713 ] \t2\tfalse\n",
            "(1)\t 284\t [-1.0393656  0.9719679  0.3463159] \t1\ttrue\n",
            "(1)\t 285\t [ 0.08479086 -0.8328287   0.6243961 ] \t2\tfalse\n",
            "(1)\t 286\t [-0.9962624 -1.081886   2.3966408] \t2\tfalse\n",
            "(1)\t 287\t [-1.3965427  1.3688052  0.2399217] \t1\ttrue\n",
            "(0)\t 288\t [ 0.49247915  0.48554513 -0.78527474] \t0\ttrue\n",
            "(0)\t 289\t [ 2.3557098  -0.86710864 -1.558523  ] \t0\ttrue\n",
            "(0)\t 290\t [-0.4781524   1.3354863  -0.92191064] \t1\tfalse\n",
            "(0)\t 291\t [-0.64804536 -0.6772645   1.4605293 ] \t2\tfalse\n",
            "(1)\t 292\t [ 2.0399475  -0.27923378 -2.0616965 ] \t0\tfalse\n",
            "(1)\t 293\t [-0.32886365  1.3866065  -1.1469862 ] \t1\ttrue\n",
            "(2)\t 294\t [-0.12819403 -1.3199713   1.1131529 ] \t2\ttrue\n",
            "(2)\t 295\t [-0.8709708 -0.7390099  1.946941 ] \t2\ttrue\n",
            "(0)\t 296\t [ 0.8333889  -1.4304768   0.13496697] \t0\ttrue\n",
            "(1)\t 297\t [ 1.8741854 -0.5201096 -1.5432088] \t0\tfalse\n",
            "(2)\t 298\t [ 0.23336399  0.485481   -0.9465023 ] \t1\tfalse\n",
            "(2)\t 299\t [-0.16867001  1.3539169  -1.1820323 ] \t1\tfalse\n",
            "(2)\t 300\t [-0.3518665  1.7756547 -1.2763107] \t1\tfalse\n",
            "(0)\t 301\t [ 0.3566093   0.49256456 -0.85453767] \t1\tfalse\n",
            "(2)\t 302\t [-0.98254424 -1.1199974   2.3565173 ] \t2\ttrue\n",
            "(2)\t 303\t [-1.4001018 -0.6282289  2.375381 ] \t2\ttrue\n",
            "(1)\t 304\t [ 0.00960896  0.5127872  -0.66248643] \t1\ttrue\n",
            "(0)\t 305\t [ 0.27791846 -0.88257444  0.51783806] \t2\tfalse\n",
            "(0)\t 306\t [-0.12888853 -0.85856014  0.7659229 ] \t2\tfalse\n",
            "(0)\t 307\t [ 0.5118423  1.0750407 -1.7667607] \t1\tfalse\n",
            "(0)\t 308\t [ 1.8433851  -0.87294275 -1.194107  ] \t0\ttrue\n",
            "(2)\t 309\t [-1.1552761 -0.8062441  2.3743124] \t2\ttrue\n",
            "(2)\t 310\t [-0.74314505 -1.3821024   2.2564359 ] \t2\ttrue\n",
            "(0)\t 311\t [ 1.5514573   0.38511547 -2.1846495 ] \t0\ttrue\n",
            "(2)\t 312\t [-0.7212153 -1.0886327  2.1711555] \t2\ttrue\n",
            "(0)\t 313\t [ 0.19427583  1.1127279  -1.4027402 ] \t1\tfalse\n",
            "(0)\t 314\t [-0.59346086 -1.2654834   2.0484054 ] \t2\tfalse\n",
            "(0)\t 315\t [ 2.0882602 -0.2302697 -2.0846114] \t0\ttrue\n",
            "(2)\t 316\t [ 0.42041337  0.09843755 -0.791868  ] \t0\tfalse\n",
            "(2)\t 317\t [-1.230979  -0.9084928  2.4276557] \t2\ttrue\n",
            "(2)\t 318\t [-1.3562839  -0.63682824  2.3012505 ] \t2\ttrue\n",
            "(2)\t 319\t [-1.7329696  -0.19623348  1.7484037 ] \t2\ttrue\n",
            "(0)\t 320\t [ 2.0475593  -0.93776023 -1.3705475 ] \t0\ttrue\n",
            "(2)\t 321\t [ 0.47921026  1.1517121  -1.7442371 ] \t1\tfalse\n",
            "(2)\t 322\t [-1.6452792  -0.17024451  1.9490504 ] \t2\ttrue\n",
            "(0)\t 323\t [ 1.4816693  -1.5303389  -0.21831647] \t0\ttrue\n",
            "(2)\t 324\t [-1.1771692 -0.9288998  2.4468699] \t2\ttrue\n",
            "(1)\t 325\t [ 0.7766022  -1.6226838   0.37306982] \t0\tfalse\n",
            "(2)\t 326\t [ 0.5490314  -1.3656542   0.40511507] \t0\tfalse\n",
            "(1)\t 327\t [ 1.594812  -0.0263436 -1.7396873] \t0\tfalse\n",
            "(1)\t 328\t [-1.6007777  0.5249676  1.0508506] \t2\tfalse\n",
            "(2)\t 329\t [-1.0187305 -1.078655   2.3468165] \t2\ttrue\n",
            "(1)\t 330\t [-1.338623    1.1761925   0.30074152] \t1\ttrue\n",
            "(1)\t 331\t [ 0.6329867   0.89243037 -1.7481155 ] \t1\ttrue\n",
            "(2)\t 332\t [ 0.7388368  -1.483526    0.43392336] \t0\tfalse\n",
            "(2)\t 333\t [-0.5728896 -1.4148009  2.1228952] \t2\ttrue\n",
            "(2)\t 334\t [-1.1853021 -0.61758    1.9290993] \t2\ttrue\n",
            "(1)\t 335\t [-0.42291722 -1.0359813   1.5218768 ] \t2\tfalse\n",
            "(2)\t 336\t [-0.05656749 -1.3701526   1.4876132 ] \t2\ttrue\n",
            "(2)\t 337\t [-1.070083  -0.9303063  2.2155352] \t2\ttrue\n",
            "(0)\t 338\t [-0.655935  -0.8954487  1.9547759] \t2\tfalse\n",
            "(2)\t 339\t [-1.576044   -0.31793502  2.2322173 ] \t2\ttrue\n",
            "(2)\t 340\t [ 1.1197414   0.50328845 -1.8138207 ] \t0\tfalse\n",
            "(0)\t 341\t [ 1.3646883 -1.1621974 -0.5787111] \t0\ttrue\n",
            "(2)\t 342\t [-0.8543938 -1.2037108  2.2617605] \t2\ttrue\n",
            "(2)\t 343\t [-0.6444511 -1.3013039  2.0668151] \t2\ttrue\n",
            "(1)\t 344\t [-1.1400806   0.90567917  0.26486948] \t1\ttrue\n",
            "(2)\t 345\t [ 0.14409277 -0.98741287  0.7993187 ] \t2\ttrue\n",
            "(2)\t 346\t [-0.8314135 -1.2162831  2.2931356] \t2\ttrue\n",
            "(0)\t 347\t [-1.271901    0.9637385   0.42631918] \t1\tfalse\n",
            "(2)\t 348\t [-0.6795588 -0.7439151  1.8442898] \t2\ttrue\n",
            "(2)\t 349\t [-0.6121065 -1.0756934  2.066609 ] \t2\ttrue\n",
            "(2)\t 350\t [-1.3397746   1.3258218   0.19993323] \t1\tfalse\n",
            "(0)\t 351\t [ 0.8274699   0.27997366 -1.4151335 ] \t0\ttrue\n",
            "(2)\t 352\t [-1.5053557   0.92589825  0.91397053] \t1\tfalse\n",
            "(2)\t 353\t [-1.0379287 -1.0127218  2.3064828] \t2\ttrue\n",
            "(2)\t 354\t [-0.19025365  1.1451612  -0.87706864] \t1\tfalse\n",
            "(0)\t 355\t [-0.07103255  0.97447675 -0.902586  ] \t1\tfalse\n",
            "(2)\t 356\t [-0.6534757 -1.1153144  1.9832776] \t2\ttrue\n",
            "(2)\t 357\t [-0.86566865  0.5604196   0.47884995] \t1\tfalse\n",
            "(2)\t 358\t [ 0.28766692  0.23507173 -0.4917474 ] \t0\tfalse\n",
            "(2)\t 359\t [-0.6618308 -0.7924013  1.542165 ] \t2\ttrue\n",
            "(2)\t 360\t [-1.009585   -0.99214387  2.1101198 ] \t2\ttrue\n",
            "(2)\t 361\t [-1.0306929 -1.0821009  2.4590302] \t2\ttrue\n",
            "(2)\t 362\t [-0.68460387  0.8518234  -0.07888871] \t1\tfalse\n",
            "(2)\t 363\t [-1.3169316  -0.76661223  2.4481382 ] \t2\ttrue\n",
            "(2)\t 364\t [-0.96021265 -1.0979216   2.4735508 ] \t2\ttrue\n",
            "(2)\t 365\t [-1.2204515   0.97536564  0.29052827] \t1\tfalse\n",
            "(1)\t 366\t [ 0.46964735  0.5894884  -1.165101  ] \t1\ttrue\n",
            "(0)\t 367\t [ 1.8932582 -1.1409571 -1.188331 ] \t0\ttrue\n",
            "(0)\t 368\t [ 2.0426278e+00 -2.5629153e-04 -2.0375638e+00] \t0\ttrue\n",
            "(0)\t 369\t [-0.13108674 -1.1251231   1.2218952 ] \t2\tfalse\n",
            "(2)\t 370\t [-0.40693808 -0.75996196  1.2959142 ] \t2\ttrue\n",
            "(0)\t 371\t [ 1.0990877 -0.3788807 -1.3641825] \t0\ttrue\n",
            "(2)\t 372\t [-0.32148823 -0.90781945  1.3668013 ] \t2\ttrue\n",
            "(1)\t 373\t [ 0.23010796  1.2382909  -1.4420311 ] \t1\ttrue\n",
            "(0)\t 374\t [ 2.1411731  -0.26388818 -2.020555  ] \t0\ttrue\n",
            "(0)\t 375\t [ 0.41531068  1.1755301  -1.4332818 ] \t1\tfalse\n",
            "(0)\t 376\t [-0.2372409   1.2012336  -0.80070126] \t1\tfalse\n",
            "(2)\t 377\t [ 0.44650853  0.7097743  -1.3464603 ] \t1\tfalse\n",
            "(1)\t 378\t [-0.250441   1.32198   -0.7264272] \t1\ttrue\n",
            "(1)\t 379\t [ 1.9805467  -0.03219321 -2.0282598 ] \t0\tfalse\n",
            "(2)\t 380\t [-0.87052494 -0.47816277  1.7300593 ] \t2\ttrue\n",
            "(0)\t 381\t [ 2.0246327 -0.1989655 -2.067884 ] \t0\ttrue\n",
            "(0)\t 382\t [-0.8536537  1.383717  -0.6353888] \t1\tfalse\n",
            "(0)\t 383\t [ 0.55725247 -0.13779138 -0.7920792 ] \t0\ttrue\n",
            "(2)\t 384\t [ 0.15700549  1.035733   -1.2599249 ] \t1\tfalse\n",
            "(1)\t 385\t [-1.4135437  1.4149743  0.3153881] \t1\ttrue\n",
            "(2)\t 386\t [-0.2307014  1.0770116 -0.8770945] \t1\tfalse\n",
            "(1)\t 387\t [ 1.3539277   0.41688105 -1.8041029 ] \t0\tfalse\n",
            "(0)\t 388\t [ 0.7828786  -1.2386672  -0.01271433] \t0\ttrue\n",
            "(2)\t 389\t [-1.0316987  -0.78333014  1.9261832 ] \t2\ttrue\n",
            "(2)\t 390\t [-0.610048   -0.66502297  1.3786027 ] \t2\ttrue\n",
            "(1)\t 391\t [-1.3846864  1.0334167  0.6221392] \t1\ttrue\n",
            "(1)\t 392\t [ 1.4459653   0.38849333 -1.8339131 ] \t0\tfalse\n",
            "(1)\t 393\t [-0.1529799  1.5307062 -1.1975927] \t1\ttrue\n",
            "(0)\t 394\t [-0.37332392  1.4216335  -1.1311569 ] \t1\tfalse\n",
            "(1)\t 395\t [-0.7528022   1.7348262  -0.66046804] \t1\ttrue\n",
            "(0)\t 396\t [ 0.40505466  0.80388486 -1.1686268 ] \t1\tfalse\n",
            "(0)\t 397\t [-0.16022858 -0.00263503  0.11536038] \t2\tfalse\n",
            "(2)\t 398\t [-1.2797225   1.2442117   0.48060402] \t1\tfalse\n",
            "(0)\t 399\t [ 0.6472004 -1.1111187  0.1549917] \t0\ttrue\n",
            "(2)\t 400\t [-0.22717234 -0.35503015  0.64093745] \t2\ttrue\n",
            "(2)\t 401\t [-0.55988044 -0.06831808  0.9672196 ] \t2\ttrue\n",
            "(0)\t 402\t [ 1.7255071  -1.5397317  -0.45211303] \t0\ttrue\n",
            "(1)\t 403\t [-0.16946107  1.3976543  -1.2371838 ] \t1\ttrue\n",
            "(1)\t 404\t [ 0.30721337  1.3208426  -1.7605745 ] \t1\ttrue\n",
            "(0)\t 405\t [ 0.5827188  -0.9108856   0.24361171] \t0\ttrue\n",
            "(2)\t 406\t [-1.5302117  1.014349   0.7836002] \t1\tfalse\n",
            "(2)\t 407\t [-0.7783606 -1.2676699  2.1141605] \t2\ttrue\n",
            "(0)\t 408\t [ 0.61968577  0.1451769  -0.7221141 ] \t0\ttrue\n",
            "(2)\t 409\t [-1.2710443   0.9532177   0.62468624] \t1\tfalse\n",
            "(0)\t 410\t [ 0.13101575  1.1765817  -1.2200022 ] \t1\tfalse\n",
            "(1)\t 411\t [-0.87439483  1.6810882  -0.7187659 ] \t1\ttrue\n",
            "(0)\t 412\t [ 2.2601473  -0.44223058 -1.9409316 ] \t0\ttrue\n",
            "(2)\t 413\t [-0.44115573 -1.3905666   1.8931689 ] \t2\ttrue\n",
            "(2)\t 414\t [-0.88134164 -1.2571551   2.3331327 ] \t2\ttrue\n",
            "(2)\t 415\t [-1.4564363  -0.24507047  2.0223665 ] \t2\ttrue\n",
            "(2)\t 416\t [-0.9297388 -0.8108788  2.2398002] \t2\ttrue\n",
            "(0)\t 417\t [ 0.7166699  -0.03884829 -1.0469207 ] \t0\ttrue\n",
            "(2)\t 418\t [-0.43310457 -0.5607972   1.173409  ] \t2\ttrue\n",
            "(0)\t 419\t [ 0.64968103  0.9062466  -1.5271401 ] \t1\tfalse\n",
            "(0)\t 420\t [ 0.76299477 -0.6602191  -0.51781523] \t0\ttrue\n",
            "(2)\t 421\t [ 0.17020524 -1.3472724   0.9750042 ] \t2\ttrue\n",
            "(1)\t 422\t [ 0.75936776  0.38034657 -1.2433815 ] \t0\tfalse\n",
            "(0)\t 423\t [ 0.8070446   0.16081478 -1.1426394 ] \t0\ttrue\n",
            "(0)\t 424\t [ 1.824771  -0.3707218 -1.6414185] \t0\ttrue\n",
            "(0)\t 425\t [ 1.5686074 -0.6183377 -1.4614319] \t0\ttrue\n",
            "(0)\t 426\t [ 1.8022727   0.17177838 -2.0050619 ] \t0\ttrue\n",
            "(2)\t 427\t [-0.6977536 -0.9463205  1.9290082] \t2\ttrue\n",
            "(2)\t 428\t [-0.10928159 -1.5227578   1.5821277 ] \t2\ttrue\n",
            "(2)\t 429\t [-0.5231115  -0.36413118  1.503691  ] \t2\ttrue\n",
            "(0)\t 430\t [ 2.3295856  -0.93496937 -1.4860721 ] \t0\ttrue\n",
            "(0)\t 431\t [-0.8679971 -1.0654753  2.2198772] \t2\tfalse\n",
            "(2)\t 432\t [-1.7313071  -0.07535065  1.9401761 ] \t2\ttrue\n",
            "(2)\t 433\t [-0.9070043 -1.1459297  2.36794  ] \t2\ttrue\n",
            "(2)\t 434\t [-1.504836   0.7219436  1.1511341] \t2\ttrue\n",
            "(0)\t 435\t [ 0.27784994 -1.2580414   0.91006184] \t2\tfalse\n",
            "(0)\t 436\t [-0.8282371 -1.3240048  2.1126409] \t2\tfalse\n",
            "(2)\t 437\t [-1.3646563  -0.61843437  2.3315268 ] \t2\ttrue\n",
            "(1)\t 438\t [ 1.9197081 -1.028165  -1.3953567] \t0\tfalse\n",
            "(1)\t 439\t [ 0.56338894  0.9797438  -1.5895363 ] \t1\ttrue\n",
            "(1)\t 440\t [-0.7666344  -0.74167573  1.9498258 ] \t2\tfalse\n",
            "(1)\t 441\t [ 2.3475258 -0.5281092 -1.9094079] \t0\tfalse\n",
            "(1)\t 442\t [-0.57230234  0.5294357   0.2948326 ] \t1\ttrue\n",
            "(2)\t 443\t [-1.6679924 -0.4038914  2.1309404] \t2\ttrue\n",
            "(1)\t 444\t [-0.6302943 -0.6629128  1.8465402] \t2\tfalse\n",
            "(2)\t 445\t [-0.9629916 -0.500005   1.6440631] \t2\ttrue\n",
            "(1)\t 446\t [ 0.93800795 -1.6775825   0.2571983 ] \t0\tfalse\n",
            "(1)\t 447\t [-0.352473   1.040635  -0.6996703] \t1\ttrue\n",
            "(2)\t 448\t [-0.5476685   1.1920085  -0.51344764] \t1\tfalse\n",
            "(0)\t 449\t [ 1.6876236   0.17690484 -2.0998073 ] \t0\ttrue\n",
            "(0)\t 450\t [-1.1419737e-03  1.3104117e+00 -9.6202672e-01] \t1\tfalse\n",
            "(1)\t 451\t [ 0.03757477 -0.9813228   0.52379   ] \t2\tfalse\n",
            "(2)\t 452\t [ 0.08711424  1.0906416  -1.2423472 ] \t1\tfalse\n",
            "(1)\t 453\t [ 1.1641577   0.49623567 -1.7059488 ] \t0\tfalse\n",
            "(2)\t 454\t [-1.1582739 -0.8536193  2.409401 ] \t2\ttrue\n",
            "(2)\t 455\t [-1.1391388 -0.9213369  2.4055877] \t2\ttrue\n",
            "(2)\t 456\t [-0.47943705 -0.94617814  1.4965653 ] \t2\ttrue\n",
            "(0)\t 457\t [ 1.8742906  -0.59897155 -1.2437742 ] \t0\ttrue\n",
            "(0)\t 458\t [ 0.6200268   0.22548723 -1.231586  ] \t0\ttrue\n",
            "(2)\t 459\t [-0.77840096 -0.991913    2.0345292 ] \t2\ttrue\n",
            "(0)\t 460\t [ 1.589395    0.39445797 -1.9072716 ] \t0\ttrue\n",
            "(1)\t 461\t [-0.19760227  1.2218925  -1.1022645 ] \t1\ttrue\n",
            "(2)\t 462\t [-0.25764364 -0.5769884   1.2584131 ] \t2\ttrue\n",
            "(0)\t 463\t [ 2.341873  -0.6509802 -1.7480638] \t0\ttrue\n",
            "(2)\t 464\t [-0.20232348  0.4545655  -0.5298836 ] \t1\tfalse\n",
            "(2)\t 465\t [-0.68942577 -1.2000895   1.9444654 ] \t2\ttrue\n",
            "(2)\t 466\t [ 1.111472   -1.3825347  -0.07945064] \t0\tfalse\n",
            "(0)\t 467\t [ 0.14597586  0.94379383 -1.2527411 ] \t1\tfalse\n",
            "(2)\t 468\t [-0.19525632 -1.242578    1.4152317 ] \t2\ttrue\n",
            "(1)\t 469\t [-1.5315803   1.2341394   0.26571444] \t1\ttrue\n",
            "(2)\t 470\t [-0.5775464 -0.7136957  1.6081309] \t2\ttrue\n",
            "(1)\t 471\t [ 1.4103066  -1.1264788  -0.77030647] \t0\tfalse\n",
            "(0)\t 472\t [ 2.2778993  -0.66554075 -1.9054904 ] \t0\ttrue\n",
            "(0)\t 473\t [ 1.4911467  -0.74852175 -0.9846307 ] \t0\ttrue\n",
            "(1)\t 474\t [-1.334454    0.82731634  0.8757312 ] \t2\tfalse\n",
            "(0)\t 475\t [ 2.3177812 -0.7525909 -1.7140803] \t0\ttrue\n",
            "(2)\t 476\t [-1.0587612 -0.978574   2.4953952] \t2\ttrue\n",
            "(2)\t 477\t [-0.83293486 -1.1787928   2.2967653 ] \t2\ttrue\n",
            "(2)\t 478\t [-0.12442616 -0.45022744  0.95114243] \t2\ttrue\n",
            "(1)\t 479\t [-0.9023587  1.7862074 -0.7927942] \t1\ttrue\n",
            "(2)\t 480\t [-0.26675013  0.37438872 -0.07525866] \t1\tfalse\n",
            "(0)\t 481\t [ 2.237157   -0.70778364 -1.6785948 ] \t0\ttrue\n",
            "(2)\t 482\t [-0.7879142 -1.035358   2.3917372] \t2\ttrue\n",
            "(2)\t 483\t [ 1.1509215  -1.0611796  -0.57259357] \t0\tfalse\n",
            "(0)\t 484\t [ 0.61336166  1.2594209  -1.8368295 ] \t1\tfalse\n",
            "(1)\t 485\t [ 1.6990902 -0.2581417 -1.5827973] \t0\tfalse\n",
            "(0)\t 486\t [ 1.1962856  -1.4124135  -0.03269424] \t0\ttrue\n",
            "(0)\t 487\t [ 1.1078614 -0.5068212 -0.9179779] \t0\ttrue\n",
            "(0)\t 488\t [ 0.2733949  -0.00579436 -0.1907648 ] \t0\ttrue\n",
            "(1)\t 489\t [-1.2082574  0.9972621  0.6364862] \t1\ttrue\n",
            "(2)\t 490\t [-0.78399265 -0.8850182   2.1282654 ] \t2\ttrue\n",
            "(0)\t 491\t [ 2.0241468  -0.41765618 -1.7291726 ] \t0\ttrue\n",
            "(0)\t 492\t [ 0.11357425 -1.4652436   0.9055519 ] \t2\tfalse\n",
            "(1)\t 493\t [ 1.7848059  -0.06329127 -2.0328927 ] \t0\tfalse\n",
            "(0)\t 494\t [ 0.46840605 -1.3347144   0.53632957] \t2\tfalse\n",
            "(1)\t 495\t [ 0.26372978  1.1988969  -1.5675831 ] \t1\ttrue\n",
            "(2)\t 496\t [-0.61436313 -0.80908686  1.5496691 ] \t2\ttrue\n",
            "(2)\t 497\t [ 1.8989503   0.07065598 -1.9865777 ] \t0\tfalse\n",
            "(0)\t 498\t [-0.21082827  0.0863198   0.14404878] \t2\tfalse\n",
            "(2)\t 499\t [ 0.65333277 -0.567995   -0.42128435] \t0\tfalse\n",
            "(2)\t 500\t [ 0.65333277 -0.567995   -0.42128435] \t0\tfalse\n",
            "(2)\t 501\t [-0.4130194  -0.82182366  1.5720694 ] \t2\ttrue\n",
            "(2)\t 502\t [ 0.0436307  -0.4669545   0.05240956] \t2\ttrue\n",
            "(1)\t 503\t [-0.2944248  1.0681219 -0.879585 ] \t1\ttrue\n",
            "(1)\t 504\t [-1.2549256   1.5220833  -0.31875458] \t1\ttrue\n",
            "(1)\t 505\t [ 0.04218696 -1.0968282   0.8917885 ] \t2\tfalse\n",
            "(1)\t 506\t [-1.3085114   1.466142   -0.07246111] \t1\ttrue\n",
            "(2)\t 507\t [-0.9805605 -0.8976728  2.22819  ] \t2\ttrue\n",
            "(2)\t 508\t [-0.9568588 -1.0528355  2.2718282] \t2\ttrue\n",
            "(2)\t 509\t [-1.0218726 -1.156537   2.3758774] \t2\ttrue\n",
            "(2)\t 510\t [-0.8592059 -1.0497558  2.1711507] \t2\ttrue\n",
            "(2)\t 511\t [-0.93973917 -1.012079    2.4689164 ] \t2\ttrue\n",
            "(2)\t 512\t [-1.1083997 -1.0119929  2.471625 ] \t2\ttrue\n",
            "(2)\t 513\t [ 0.9519771  -1.4409223   0.21182595] \t0\tfalse\n",
            "(2)\t 514\t [-0.8574287 -1.0539293  2.4347262] \t2\ttrue\n",
            "(2)\t 515\t [-1.100088  -1.0808942  2.451087 ] \t2\ttrue\n",
            "(2)\t 516\t [-1.0214556 -1.0333384  2.475327 ] \t2\ttrue\n",
            "(2)\t 517\t [-0.75387436 -1.418168    2.0176775 ] \t2\ttrue\n",
            "(2)\t 518\t [-1.173102  -0.7869208  2.2775302] \t2\ttrue\n",
            "(0)\t 519\t [-1.1414534   1.2266521  -0.06770226] \t1\tfalse\n",
            "(2)\t 520\t [-1.3063573   1.4271606   0.15434083] \t1\tfalse\n",
            "(2)\t 521\t [-1.2066516  1.4666598 -0.2980827] \t1\tfalse\n",
            "(1)\t 522\t [-1.7399379  0.9363139  0.727381 ] \t1\ttrue\n",
            "(2)\t 523\t [-0.19287914  0.6364192  -0.55821145] \t1\tfalse\n",
            "(2)\t 524\t [-0.5608301  1.7764316 -1.1529346] \t1\tfalse\n",
            "(2)\t 525\t [ 0.40384835 -1.4060423   0.64609313] \t2\ttrue\n",
            "(1)\t 526\t [-0.67803913 -1.0028343   1.9381323 ] \t2\tfalse\n",
            "(0)\t 527\t [ 2.0137513  -0.92983943 -1.3931329 ] \t0\ttrue\n",
            "(0)\t 528\t [ 1.9671288  -0.11780104 -1.8198513 ] \t0\ttrue\n",
            "(0)\t 529\t [ 2.151674   -0.30773416 -1.9758081 ] \t0\ttrue\n",
            "(0)\t 530\t [ 2.0278904  -0.20323947 -1.9251187 ] \t0\ttrue\n",
            "(1)\t 531\t [ 0.17393005  0.6958895  -0.9432221 ] \t1\ttrue\n",
            "(0)\t 532\t [ 2.3520792  -0.82951057 -1.695086  ] \t0\ttrue\n",
            "(1)\t 533\t [ 1.0596975   0.81077224 -1.7905294 ] \t0\tfalse\n",
            "(1)\t 534\t [-0.5669313 -1.1090887  2.016698 ] \t2\tfalse\n",
            "(0)\t 535\t [ 1.161764  -0.5334843 -0.8737639] \t0\ttrue\n",
            "(1)\t 536\t [ 2.0791535  -0.30307215 -2.065445  ] \t0\tfalse\n",
            "(1)\t 537\t [ 1.9667636   0.06270085 -2.0829406 ] \t0\tfalse\n",
            "(0)\t 538\t [ 2.3831313 -0.7613568 -1.6885107] \t0\ttrue\n",
            "(1)\t 539\t [ 0.00647467  1.2208546  -1.0135874 ] \t1\ttrue\n",
            "(1)\t 540\t [ 0.34394747  1.0600215  -1.3977454 ] \t1\ttrue\n",
            "(1)\t 541\t [-1.5067956 -0.3715264  2.214168 ] \t2\tfalse\n",
            "(1)\t 542\t [-0.2166009  1.6890993 -1.2690682] \t1\ttrue\n",
            "(1)\t 543\t [ 0.22530478  1.364022   -1.4802778 ] \t1\ttrue\n",
            "(1)\t 544\t [ 2.081463  -0.5988479 -1.6927267] \t0\tfalse\n",
            "(1)\t 545\t [ 0.76985484  0.9413845  -1.8860756 ] \t1\ttrue\n",
            "(1)\t 546\t [-0.00465665  0.7101639  -0.5888799 ] \t1\ttrue\n",
            "(1)\t 547\t [ 2.3501358  -0.82703775 -1.6774577 ] \t0\tfalse\n",
            "(1)\t 548\t [ 1.6994252   0.16777572 -2.011983  ] \t0\tfalse\n",
            "(1)\t 549\t [ 1.2455277 -1.1338184 -0.5512459] \t0\tfalse\n",
            "(1)\t 550\t [ 1.7980056  -0.10245854 -1.971372  ] \t0\tfalse\n",
            "(2)\t 551\t [-0.5792853 -0.8108773  1.5399979] \t2\ttrue\n",
            "(1)\t 552\t [ 0.9310231   0.65450543 -1.818644  ] \t0\tfalse\n",
            "(0)\t 553\t [ 0.80547434  0.40022162 -1.3978703 ] \t0\ttrue\n",
            "(2)\t 554\t [ 0.08388791  0.51960474 -0.68107736] \t1\tfalse\n",
            "(1)\t 555\t [-1.4147216   1.0200028   0.45256117] \t1\ttrue\n",
            "(1)\t 556\t [-0.7207393  1.6161499 -0.7694111] \t1\ttrue\n",
            "(0)\t 557\t [ 1.4716667 -1.2725928 -0.7007731] \t0\ttrue\n",
            "(1)\t 558\t [-0.5130419 -0.9973344  1.4160665] \t2\tfalse\n",
            "(2)\t 559\t [ 0.53137165  0.36505115 -1.2593714 ] \t0\tfalse\n",
            "(2)\t 560\t [-0.13528468 -0.37025326  0.30407026] \t2\ttrue\n",
            "(1)\t 561\t [ 0.0072103 -1.32085    1.2517866] \t2\tfalse\n",
            "(2)\t 562\t [-0.5256168 -1.2284477  1.9629514] \t2\ttrue\n",
            "(2)\t 563\t [ 1.2158235  -1.0226841  -0.54425246] \t0\tfalse\n",
            "(2)\t 564\t [-0.87481827 -1.0066836   2.4674997 ] \t2\ttrue\n",
            "(1)\t 565\t [-0.5470693   0.16902825  0.42462137] \t2\tfalse\n",
            "(0)\t 566\t [-0.5470693   0.16902825  0.42462137] \t2\tfalse\n",
            "(0)\t 567\t [ 0.9669005  0.723139  -1.5924315] \t0\ttrue\n",
            "(1)\t 568\t [-0.05254842  1.6072524  -1.5350505 ] \t1\ttrue\n",
            "(2)\t 569\t [ 0.86370903  0.72176915 -1.6062444 ] \t0\tfalse\n",
            "(0)\t 570\t [ 2.0883143  -0.23064823 -2.0184362 ] \t0\ttrue\n",
            "(1)\t 571\t [ 0.66278416 -0.48989072 -0.65022355] \t0\tfalse\n",
            "(0)\t 572\t [ 1.550408   0.4385013 -2.0690117] \t0\ttrue\n",
            "(0)\t 573\t [ 1.002041    0.51560456 -1.7374825 ] \t0\ttrue\n",
            "(1)\t 574\t [-0.53593713  1.4627047  -0.62735975] \t1\ttrue\n",
            "(1)\t 575\t [-0.83560437 -0.9053857   2.1751566 ] \t2\tfalse\n",
            "(2)\t 576\t [-0.23600884  1.3142303  -0.9687202 ] \t1\tfalse\n",
            "(2)\t 577\t [-0.14087375  1.1372573  -1.0473207 ] \t1\tfalse\n",
            "(2)\t 578\t [-1.1016982 -1.1684445  2.429234 ] \t2\ttrue\n",
            "(0)\t 579\t [ 1.1954857  0.3248761 -1.688287 ] \t0\ttrue\n",
            "(2)\t 580\t [-0.7240521  -0.07604778  0.9203412 ] \t2\ttrue\n",
            "(0)\t 581\t [ 0.5895981  -0.91945475  0.28007975] \t0\ttrue\n",
            "(0)\t 582\t [ 0.12766807 -1.3483367   1.3570261 ] \t2\tfalse\n",
            "(1)\t 583\t [-0.48560908  0.95242184 -0.13822466] \t1\ttrue\n",
            "(2)\t 584\t [ 2.2210617 -0.9382499 -1.4941691] \t0\tfalse\n",
            "(0)\t 585\t [ 1.7789067  -0.34365597 -1.7934625 ] \t0\ttrue\n",
            "(2)\t 586\t [-0.97599804 -0.95454735  2.423001  ] \t2\ttrue\n",
            "(2)\t 587\t [-1.1791571  -0.98485404  2.391404  ] \t2\ttrue\n",
            "(1)\t 588\t [ 0.7253952  -0.02435081 -0.6760458 ] \t0\tfalse\n",
            "(0)\t 589\t [ 1.5971811 -0.801753  -1.2710772] \t0\ttrue\n",
            "(2)\t 590\t [-1.6041402   0.34190518  1.436029  ] \t2\ttrue\n",
            "(0)\t 591\t [ 2.210336   -0.50525725 -1.8886247 ] \t0\ttrue\n",
            "(1)\t 592\t [ 0.5374956  1.092828  -1.6826869] \t1\ttrue\n",
            "(1)\t 593\t [-0.37501776  1.4160397  -0.7354568 ] \t1\ttrue\n",
            "(1)\t 594\t [-0.5535193 -1.0326025  1.7114832] \t2\tfalse\n",
            "(1)\t 595\t [-0.1156868 -0.9297278  1.2113414] \t2\tfalse\n",
            "(2)\t 596\t [ 0.08621987  0.06196192 -0.22060075] \t0\tfalse\n",
            "(1)\t 597\t [ 0.60784006 -1.1314678   0.37217847] \t0\tfalse\n",
            "(0)\t 598\t [ 0.39734945  0.6332393  -1.1596019 ] \t1\tfalse\n",
            "(1)\t 599\t [-1.128605  -1.0832989  2.3582828] \t2\tfalse\n",
            "(2)\t 600\t [-0.4074306 -1.3604597  1.958616 ] \t2\ttrue\n",
            "(2)\t 601\t [ 1.8093473   0.04441822 -1.7637864 ] \t0\tfalse\n",
            "(2)\t 602\t [-1.7679914  0.5288855  1.4032257] \t2\ttrue\n",
            "(1)\t 603\t [ 1.680397    0.15670668 -1.745795  ] \t0\tfalse\n",
            "(1)\t 604\t [-1.4096087   0.13643207  1.5942137 ] \t2\tfalse\n",
            "(0)\t 605\t [ 2.3827808 -0.6426774 -1.7457367] \t0\ttrue\n",
            "(0)\t 606\t [ 0.253161   -0.8878703   0.30106753] \t2\tfalse\n",
            "(1)\t 607\t [ 1.8915908  -0.46258903 -1.6407734 ] \t0\tfalse\n",
            "(1)\t 608\t [-0.695203   1.212235  -0.3507538] \t1\ttrue\n",
            "(1)\t 609\t [-1.5395554   1.3307034   0.40511385] \t1\ttrue\n",
            "(0)\t 610\t [-0.59327567 -1.0648453   2.0878727 ] \t2\tfalse\n",
            "(1)\t 611\t [ 1.3207326  -0.10392423 -1.2526828 ] \t0\tfalse\n",
            "(2)\t 612\t [-0.6605782 -1.279001   2.2189178] \t2\ttrue\n",
            "(1)\t 613\t [-0.90329707  0.97408414  0.2680845 ] \t1\ttrue\n",
            "(0)\t 614\t [ 1.6618148   0.41865194 -2.2438388 ] \t0\ttrue\n",
            "(1)\t 615\t [ 1.1307023   0.74200684 -1.6981511 ] \t0\tfalse\n",
            "(0)\t 616\t [ 2.321249   -0.80828464 -1.6892998 ] \t0\ttrue\n",
            "(0)\t 617\t [ 2.1848629 -0.8426456 -1.6161395] \t0\ttrue\n",
            "(2)\t 618\t [-1.1366801  -0.63270766  2.169232  ] \t2\ttrue\n",
            "(0)\t 619\t [ 2.0408483  -0.26176128 -1.7053851 ] \t0\ttrue\n",
            "(1)\t 620\t [-1.0809425 -0.6385907  1.9924564] \t2\tfalse\n",
            "(2)\t 621\t [-0.9259266 -0.9450206  2.1350765] \t2\ttrue\n",
            "(1)\t 622\t [-0.7156091 -1.1955564  2.2195535] \t2\tfalse\n",
            "(0)\t 623\t [ 1.7653518   0.16025247 -2.0045097 ] \t0\ttrue\n",
            "(2)\t 624\t [-0.60798025 -0.8760929   1.4223298 ] \t2\ttrue\n",
            "(2)\t 625\t [-0.753347  -1.2815734  2.1583736] \t2\ttrue\n",
            "(0)\t 626\t [ 2.306471  -0.8224789 -1.661806 ] \t0\ttrue\n",
            "(0)\t 627\t [ 1.6264423   0.28318888 -1.915076  ] \t0\ttrue\n",
            "(2)\t 628\t [-1.0579627 -1.0443274  2.4444022] \t2\ttrue\n",
            "(0)\t 629\t [-0.5838104 -0.6548354  1.4680141] \t2\tfalse\n",
            "(1)\t 630\t [-0.5838104 -0.6548354  1.4680141] \t2\tfalse\n",
            "(0)\t 631\t [ 0.22738498  0.8318956  -0.8532802 ] \t1\tfalse\n",
            "(0)\t 632\t [ 0.02916806  1.3869278  -1.4132211 ] \t1\tfalse\n",
            "(1)\t 633\t [ 0.64658123 -1.6682596   0.44364157] \t0\tfalse\n",
            "(0)\t 634\t [-0.4649979   1.2044791  -0.60694087] \t1\tfalse\n",
            "(1)\t 635\t [ 1.2049361  -1.4580846  -0.21272251] \t0\tfalse\n",
            "(1)\t 636\t [-1.4288508 -0.4702182  2.3431964] \t2\tfalse\n",
            "(0)\t 637\t [ 2.1173475  -0.64200824 -1.7435768 ] \t0\ttrue\n",
            "(2)\t 638\t [-0.18798405 -1.2622479   1.5192592 ] \t2\ttrue\n",
            "(2)\t 639\t [-0.33023196 -1.2292719   1.5368098 ] \t2\ttrue\n",
            "(0)\t 640\t [ 1.2289304   0.26166263 -1.6441514 ] \t0\ttrue\n",
            "(0)\t 641\t [ 1.8271264   0.04985312 -2.212427  ] \t0\ttrue\n",
            "(1)\t 642\t [ 2.2787907 -1.0554161 -1.3937476] \t0\tfalse\n",
            "(1)\t 643\t [ 1.6421167 -0.1996062 -1.6597744] \t0\tfalse\n",
            "(0)\t 644\t [ 0.13095373  0.5673408  -0.69116616] \t1\tfalse\n",
            "(0)\t 645\t [ 1.769651  -0.9545446 -1.1835699] \t0\ttrue\n",
            "(1)\t 646\t [-0.7512966  -0.33304903  1.338331  ] \t2\tfalse\n",
            "(0)\t 647\t [ 0.94774675  1.0312462  -2.0957713 ] \t1\tfalse\n",
            "(1)\t 648\t [-0.25297725 -0.8796548   0.81837964] \t2\tfalse\n",
            "(0)\t 649\t [-1.132598    1.6931986  -0.26399377] \t1\tfalse\n",
            "(1)\t 650\t [ 1.8027059   0.22748773 -2.057972  ] \t0\tfalse\n",
            "(0)\t 651\t [ 2.1932676  -0.37804544 -1.9508542 ] \t0\ttrue\n",
            "(0)\t 652\t [ 1.467552  -0.5886374 -1.0965755] \t0\ttrue\n",
            "(0)\t 653\t [ 2.3952553  -0.67969394 -1.7753217 ] \t0\ttrue\n",
            "(0)\t 654\t [ 1.829467  -1.1105216 -1.1836746] \t0\ttrue\n",
            "(2)\t 655\t [ 2.0780878  -0.60010785 -1.5463817 ] \t0\tfalse\n",
            "(1)\t 656\t [ 0.22284973  0.79938304 -1.3755126 ] \t1\ttrue\n",
            "(1)\t 657\t [ 1.3445309  0.6809804 -1.9578204] \t0\tfalse\n",
            "(1)\t 658\t [ 1.7278754   0.16567013 -1.8109024 ] \t0\tfalse\n",
            "(2)\t 659\t [-1.6772629   0.06097874  1.7886403 ] \t2\ttrue\n",
            "(2)\t 660\t [-0.8676591   1.0520991  -0.02206093] \t1\tfalse\n",
            "(2)\t 661\t [-0.53028786 -0.87353235  1.5387512 ] \t2\ttrue\n",
            "(1)\t 662\t [-0.31825966 -1.2648495   1.595533  ] \t2\tfalse\n",
            "(0)\t 663\t [ 1.4422214  -1.106652   -0.53274405] \t0\ttrue\n",
            "(2)\t 664\t [-0.77554196 -1.047738    2.2384284 ] \t2\ttrue\n",
            "(1)\t 665\t [-0.21256614 -0.16286297  0.3999174 ] \t2\tfalse\n",
            "(0)\t 666\t [ 2.348001   -0.97775257 -1.5032797 ] \t0\ttrue\n",
            "(0)\t 667\t [ 0.41409683  1.0268474  -1.4900365 ] \t1\tfalse\n",
            "(1)\t 668\t [ 0.23263118  1.2341123  -1.0780355 ] \t1\ttrue\n",
            "(1)\t 669\t [-0.92089367 -0.89014393  1.9091365 ] \t2\tfalse\n",
            "(2)\t 670\t [-0.633486  -1.1577963  2.2776468] \t2\ttrue\n",
            "(2)\t 671\t [-0.9532025 -1.2263     2.2481327] \t2\ttrue\n",
            "(2)\t 672\t [-0.48866433 -1.3987391   2.0238504 ] \t2\ttrue\n",
            "(2)\t 673\t [-0.9584237 -1.1176426  2.4723544] \t2\ttrue\n",
            "(2)\t 674\t [-0.8982474 -1.0593257  2.4624135] \t2\ttrue\n",
            "(2)\t 675\t [-0.8228855 -1.1148094  2.3822546] \t2\ttrue\n",
            "(2)\t 676\t [-1.5357798 -0.5726669  2.2176542] \t2\ttrue\n",
            "(2)\t 677\t [-1.2040135 -1.0189266  2.495478 ] \t2\ttrue\n",
            "(2)\t 678\t [-0.96427387 -1.1411626   2.4453301 ] \t2\ttrue\n",
            "(2)\t 679\t [-1.0691293 -1.1445744  2.4290597] \t2\ttrue\n",
            "(1)\t 680\t [-1.6296967  -0.50955373  2.2246912 ] \t2\tfalse\n",
            "(1)\t 681\t [ 1.8305945   0.04694813 -2.0447717 ] \t0\tfalse\n",
            "(1)\t 682\t [ 2.0403283 -1.2605611 -1.1619103] \t0\tfalse\n",
            "(2)\t 683\t [-0.53339285 -1.3587403   2.0053468 ] \t2\ttrue\n",
            "(0)\t 684\t [ 2.2371898  -0.34285337 -2.0678048 ] \t0\ttrue\n",
            "(1)\t 685\t [ 1.493234   0.2828726 -1.9890205] \t0\tfalse\n",
            "(0)\t 686\t [ 2.316028  -1.0318973 -1.4722553] \t0\ttrue\n",
            "(0)\t 687\t [ 2.3319035  -0.66683006 -1.8267851 ] \t0\ttrue\n",
            "(0)\t 688\t [ 2.155297  -1.0598335 -1.3763468] \t0\ttrue\n",
            "(1)\t 689\t [-1.717945    0.31252334  1.4957168 ] \t2\tfalse\n",
            "(0)\t 690\t [ 0.14633894  0.1293452  -0.429181  ] \t0\ttrue\n",
            "(0)\t 691\t [ 0.2349586  1.0990903 -1.367523 ] \t1\tfalse\n",
            "(0)\t 692\t [ 2.068178   -0.77394396 -1.4278669 ] \t0\ttrue\n",
            "(2)\t 693\t [ 1.6818601 -0.7526364 -1.3243568] \t0\tfalse\n",
            "(1)\t 694\t [-0.843347   -0.92641836  1.9193637 ] \t2\tfalse\n",
            "(1)\t 695\t [-0.63002485 -0.8223222   1.4267241 ] \t2\tfalse\n",
            "(2)\t 696\t [-1.0348758 -1.0546888  2.365622 ] \t2\ttrue\n",
            "(2)\t 697\t [-1.0632077 -0.94919    2.433998 ] \t2\ttrue\n",
            "(2)\t 698\t [-1.041778  -0.8947928  2.4144852] \t2\ttrue\n",
            "(2)\t 699\t [-1.2150702  -0.47842944  2.0058703 ] \t2\ttrue\n",
            "(0)\t 700\t [ 2.164027  -0.66313   -1.5869483] \t0\ttrue\n",
            "(1)\t 701\t [ 2.2632248 -0.3825966 -1.9114459] \t0\tfalse\n",
            "(1)\t 702\t [ 2.18      -0.6806038 -1.7907298] \t0\tfalse\n",
            "(1)\t 703\t [ 2.1259348  -0.36142436 -1.8997476 ] \t0\tfalse\n",
            "(2)\t 704\t [ 1.6134315  -0.35199896 -1.4504063 ] \t0\tfalse\n",
            "(1)\t 705\t [-1.3117107   1.1594552   0.36852744] \t1\ttrue\n",
            "(0)\t 706\t [ 2.1054752  -0.43363866 -1.9293163 ] \t0\ttrue\n",
            "(0)\t 707\t [-0.30085972  0.57265586 -0.22611809] \t1\tfalse\n",
            "(2)\t 708\t [-1.5215     0.9947207  0.9033071] \t1\tfalse\n",
            "(2)\t 709\t [ 0.43754196  0.16489805 -0.64852524] \t0\tfalse\n",
            "(0)\t 710\t [ 2.284179  -0.8660449 -1.6128571] \t0\ttrue\n",
            "(2)\t 711\t [-0.66548616  0.4016757   0.5747805 ] \t2\ttrue\n",
            "(2)\t 712\t [ 0.3348932  1.1213125 -1.5417434] \t1\tfalse\n",
            "(2)\t 713\t [-0.09039278  1.3294213  -1.2410305 ] \t1\tfalse\n",
            "(0)\t 714\t [-0.6847183 -0.2502052  0.8201914] \t2\tfalse\n",
            "(0)\t 715\t [ 0.32188797  0.43037745 -0.83828014] \t1\tfalse\n",
            "(1)\t 716\t [ 0.32188797  0.43037745 -0.83828014] \t1\ttrue\n",
            "(1)\t 717\t [-0.9122786   1.3056688   0.18910721] \t1\ttrue\n",
            "(0)\t 718\t [-0.74007124 -0.08009204  1.0311387 ] \t2\tfalse\n",
            "(0)\t 719\t [ 0.847762    0.61265284 -1.4292531 ] \t0\ttrue\n",
            "(0)\t 720\t [ 0.9550721  -0.7728233  -0.26073846] \t0\ttrue\n",
            "(1)\t 721\t [ 0.25060475  0.8898235  -1.1601329 ] \t1\ttrue\n",
            "(0)\t 722\t [-0.61348623 -0.9753157   1.8297881 ] \t2\tfalse\n",
            "(1)\t 723\t [-0.7080478 -0.9600477  2.1433048] \t2\tfalse\n",
            "(2)\t 724\t [-0.42642742 -0.93732244  1.7331628 ] \t2\ttrue\n",
            "(0)\t 725\t [ 1.5454844 -0.1243654 -1.3902681] \t0\ttrue\n",
            "(1)\t 726\t [ 1.5454844 -0.1243654 -1.3902681] \t0\tfalse\n",
            "(1)\t 727\t [-0.25201932  1.063991   -0.53330904] \t1\ttrue\n",
            "(2)\t 728\t [-0.07290773 -1.5593247   1.5239084 ] \t2\ttrue\n",
            "(2)\t 729\t [ 0.07137711 -0.5968531   0.44691664] \t2\ttrue\n",
            "(2)\t 730\t [-0.687679   -0.86413515  1.8555894 ] \t2\ttrue\n",
            "(0)\t 731\t [ 0.38428384 -0.7621036   0.19214126] \t0\ttrue\n",
            "(2)\t 732\t [ 0.6561931  -1.2782354   0.27654508] \t0\tfalse\n",
            "(1)\t 733\t [ 1.0684654  0.4642631 -1.5399883] \t0\tfalse\n",
            "(1)\t 734\t [-0.00816047  0.97063094 -0.9279244 ] \t1\ttrue\n",
            "(0)\t 735\t [ 1.698151   -0.48191455 -1.5246968 ] \t0\ttrue\n",
            "(1)\t 736\t [ 1.2248378   0.76738673 -1.8978543 ] \t0\tfalse\n",
            "(2)\t 737\t [-0.9256927 -1.1161091  2.3194695] \t2\ttrue\n",
            "(0)\t 738\t [-0.4652459 -0.3766894  1.1481872] \t2\tfalse\n",
            "(1)\t 739\t [ 2.3076303 -0.9008517 -1.5743966] \t0\tfalse\n",
            "(0)\t 740\t [ 2.167912  -1.1485083 -1.2738242] \t0\ttrue\n",
            "(0)\t 741\t [ 2.3046029  -0.85888517 -1.6441762 ] \t0\ttrue\n",
            "(2)\t 742\t [ 0.07306723 -0.85959053  0.4294972 ] \t2\ttrue\n",
            "(2)\t 743\t [-0.94506425 -1.1636171   2.3593554 ] \t2\ttrue\n",
            "(1)\t 744\t [ 1.3376023 -0.9218307 -0.755592 ] \t0\tfalse\n",
            "(0)\t 745\t [ 2.180517   -0.78188556 -1.6042676 ] \t0\ttrue\n",
            "(0)\t 746\t [ 2.2105622  -0.11715305 -2.035726  ] \t0\ttrue\n",
            "(2)\t 747\t [-0.69964355 -0.9150329   1.724406  ] \t2\ttrue\n",
            "(0)\t 748\t [ 1.8097875  -0.56964153 -1.3195024 ] \t0\ttrue\n",
            "(2)\t 749\t [-0.04090003 -0.78614885  0.84520245] \t2\ttrue\n",
            "(2)\t 750\t [-1.213976   0.8914719  0.8744416] \t1\tfalse\n",
            "(2)\t 751\t [-1.017696  -1.0524964  2.4951644] \t2\ttrue\n",
            "(2)\t 752\t [-1.0435368  -0.21754637  1.0667727 ] \t2\ttrue\n",
            "(0)\t 753\t [ 1.7041596   0.16373862 -2.0312517 ] \t0\ttrue\n",
            "(1)\t 754\t [-0.439609   1.5098009 -0.8704421] \t1\ttrue\n",
            "(0)\t 755\t [ 0.46991178 -0.8836768   0.04846636] \t0\ttrue\n",
            "(0)\t 756\t [ 2.1411018 -0.4150147 -1.787883 ] \t0\ttrue\n",
            "(2)\t 757\t [-1.2250971  -0.84717464  2.4116755 ] \t2\ttrue\n",
            "(2)\t 758\t [-0.7856775   0.49863014  0.24133301] \t1\tfalse\n",
            "(0)\t 759\t [ 0.86432153 -1.6575979   0.3125355 ] \t0\ttrue\n",
            "(2)\t 760\t [-1.0667211   0.8359849   0.42058447] \t1\tfalse\n",
            "(2)\t 761\t [-0.9238743  -0.46251628  1.7204096 ] \t2\ttrue\n",
            "(0)\t 762\t [-0.50093687 -0.5146769   1.0235643 ] \t2\tfalse\n",
            "(0)\t 763\t [ 0.9788471   0.16565946 -1.4849563 ] \t0\ttrue\n",
            "(0)\t 764\t [ 0.84981704 -0.61851084 -0.36361283] \t0\ttrue\n",
            "(2)\t 765\t [-0.95420486 -1.1203535   2.3868792 ] \t2\ttrue\n",
            "(2)\t 766\t [-0.08166511 -1.3849483   1.3210424 ] \t2\ttrue\n",
            "(0)\t 767\t [-0.50724274 -1.2898424   1.9871695 ] \t2\tfalse\n",
            "(1)\t 768\t [ 0.37642556  1.3658231  -1.8052227 ] \t1\ttrue\n",
            "(1)\t 769\t [ 1.7922988 -1.2178875 -1.0397974] \t0\tfalse\n",
            "(2)\t 770\t [-0.6076396 -0.6600784  1.6785483] \t2\ttrue\n",
            "(2)\t 771\t [ 1.0939386   0.01783486 -1.2033119 ] \t0\tfalse\n",
            "(2)\t 772\t [ 0.58216316 -0.7181632  -0.10974216] \t0\tfalse\n",
            "(1)\t 773\t [ 2.1795547  -0.57831633 -1.8603305 ] \t0\tfalse\n",
            "(2)\t 774\t [-1.4678634  -0.13405429  1.865751  ] \t2\ttrue\n",
            "(2)\t 775\t [-0.6273198  1.4474208 -0.7640433] \t1\tfalse\n",
            "(1)\t 776\t [-0.99964195  0.46320102  0.45230845] \t1\ttrue\n",
            "(2)\t 777\t [ 0.062878    0.15490375 -0.62130105] \t1\tfalse\n",
            "(1)\t 778\t [ 1.8133013  -0.23102663 -1.5552247 ] \t0\tfalse\n",
            "(1)\t 779\t [-1.2651398 -0.7201244  2.0130215] \t2\tfalse\n",
            "(0)\t 780\t [ 0.65077525 -1.6318066   0.6936002 ] \t2\tfalse\n",
            "(2)\t 781\t [-0.440272   -0.05571574  0.714564  ] \t2\ttrue\n",
            "(2)\t 782\t [-0.84232414 -1.1778017   2.3133311 ] \t2\ttrue\n",
            "(1)\t 783\t [ 0.04254666 -1.1982237   1.2863609 ] \t2\tfalse\n",
            "(2)\t 784\t [-1.2992272 -0.7349129  2.3553271] \t2\ttrue\n",
            "(2)\t 785\t [-0.87238675 -1.189362    2.2900028 ] \t2\ttrue\n",
            "(0)\t 786\t [ 2.0732992  -0.15366268 -1.9740587 ] \t0\ttrue\n",
            "(2)\t 787\t [-1.3343332 -0.6675361  2.387123 ] \t2\ttrue\n",
            "(1)\t 788\t [-1.0717512 -1.0045552  2.3358173] \t2\tfalse\n",
            "(2)\t 789\t [ 2.3098643  -0.60061646 -1.8259066 ] \t0\tfalse\n",
            "(1)\t 790\t [ 0.3645762   0.64688367 -1.1924354 ] \t1\ttrue\n",
            "(1)\t 791\t [ 1.7098304  -0.51929873 -1.6473017 ] \t0\tfalse\n",
            "(1)\t 792\t [ 1.705452    0.13327186 -1.9417785 ] \t0\tfalse\n",
            "(0)\t 793\t [ 0.06023002 -1.2718598   1.132618  ] \t2\tfalse\n",
            "(2)\t 794\t [ 0.9262454  0.5915529 -1.6773891] \t0\tfalse\n",
            "(1)\t 795\t [-0.705523    1.731163   -0.80814075] \t1\ttrue\n",
            "(2)\t 796\t [-0.67387646 -0.4437714   1.3075006 ] \t2\ttrue\n",
            "(0)\t 797\t [ 2.3744786  -0.80405337 -1.6386772 ] \t0\ttrue\n",
            "(2)\t 798\t [-0.4095065   0.35907707  0.21721953] \t1\tfalse\n",
            "(0)\t 799\t [ 2.0683959  -0.68561244 -1.6235723 ] \t0\ttrue\n",
            "(0)\t 800\t [-0.9601287   0.9611525  -0.03759634] \t1\tfalse\n",
            "(0)\t 801\t [-0.5136431 -1.2367857  1.8796524] \t2\tfalse\n",
            "(1)\t 802\t [-0.62832445  1.0066189  -0.42110994] \t1\ttrue\n",
            "(2)\t 803\t [-0.844464    0.11730693  0.72148526] \t2\ttrue\n",
            "(2)\t 804\t [-0.9813122 -1.1309087  2.4698658] \t2\ttrue\n",
            "(1)\t 805\t [ 2.2822506 -0.6285296 -1.8913951] \t0\tfalse\n",
            "(2)\t 806\t [ 0.87105405  1.0128145  -1.9162009 ] \t1\tfalse\n",
            "(0)\t 807\t [ 1.688481  -1.4216496 -0.6731049] \t0\ttrue\n",
            "(1)\t 808\t [-0.03591728  0.6975476  -0.60747236] \t1\ttrue\n",
            "(0)\t 809\t [ 2.3036385  -0.80779666 -1.5786241 ] \t0\ttrue\n",
            "(1)\t 810\t [ 1.6932802 -0.8003823 -1.1104803] \t0\tfalse\n",
            "(0)\t 811\t [ 2.2185824 -0.8419462 -1.5786372] \t0\ttrue\n",
            "(1)\t 812\t [ 2.1720881 -0.2542181 -2.0238295] \t0\tfalse\n",
            "(2)\t 813\t [-1.2185156  -0.69765925  2.4243245 ] \t2\ttrue\n",
            "(2)\t 814\t [-1.0268596   0.39477792  0.957451  ] \t2\ttrue\n",
            "(2)\t 815\t [-0.03163488  0.9298833  -0.7855967 ] \t1\tfalse\n",
            "(2)\t 816\t [-0.19819713 -0.88225436  1.3267903 ] \t2\ttrue\n",
            "(2)\t 817\t [-1.0026412 -1.0487411  2.429544 ] \t2\ttrue\n",
            "(2)\t 818\t [ 0.14613897 -0.8436546   0.5476112 ] \t2\ttrue\n",
            "(2)\t 819\t [ 0.5097137   0.33475193 -1.06663   ] \t0\tfalse\n",
            "(1)\t 820\t [-0.70979947 -0.00844604  0.98464775] \t2\tfalse\n",
            "(0)\t 821\t [ 2.245644  -0.8096828 -1.7754864] \t0\ttrue\n",
            "(0)\t 822\t [ 2.2801647  -0.48009974 -1.9551618 ] \t0\ttrue\n",
            "(2)\t 823\t [-1.4323055 -0.5189436  2.3741665] \t2\ttrue\n",
            "(1)\t 824\t [ 2.08597   -0.7496596 -1.6030091] \t0\tfalse\n",
            "(0)\t 825\t [ 2.209256  -0.8470541 -1.6685748] \t0\ttrue\n",
            "(2)\t 826\t [-0.66839415 -1.2788044   2.0064943 ] \t2\ttrue\n",
            "(2)\t 827\t [-0.679125   -0.51055753  1.3854883 ] \t2\ttrue\n",
            "(1)\t 828\t [ 0.27963293  0.74253094 -1.2825183 ] \t1\ttrue\n",
            "(0)\t 829\t [ 0.2701208   0.58381635 -0.93252325] \t1\tfalse\n",
            "(0)\t 830\t [ 2.2002213  -0.76650053 -1.6560764 ] \t0\ttrue\n",
            "(1)\t 831\t [ 1.5210084  0.5036021 -1.9910821] \t0\tfalse\n",
            "(1)\t 832\t [ 1.414621   0.7120264 -2.1746845] \t0\tfalse\n",
            "(2)\t 833\t [-0.71308404 -1.3113567   2.1379485 ] \t2\ttrue\n",
            "(2)\t 834\t [-0.689903   -0.94630814  1.8231387 ] \t2\ttrue\n",
            "(0)\t 835\t [-0.3282134 -1.2611966  1.6557112] \t2\tfalse\n",
            "(0)\t 836\t [-0.7725844  1.6804559 -0.6983706] \t1\tfalse\n",
            "(0)\t 837\t [ 2.0970976 -1.0825955 -1.3249106] \t0\ttrue\n",
            "(0)\t 838\t [ 1.9557136  -0.01590623 -2.1086056 ] \t0\ttrue\n",
            "(0)\t 839\t [ 2.1228917 -0.3364719 -1.9951665] \t0\ttrue\n",
            "(0)\t 840\t [ 0.9657237  -1.2133503  -0.21052581] \t0\ttrue\n",
            "(0)\t 841\t [ 0.52302235 -0.23659311 -0.52523494] \t0\ttrue\n",
            "(0)\t 842\t [-0.32942837  1.0708435  -0.5831487 ] \t1\tfalse\n",
            "(0)\t 843\t [ 0.18896782 -1.0463808   0.5959101 ] \t2\tfalse\n",
            "(2)\t 844\t [-1.0227123 -1.1638343  2.332734 ] \t2\ttrue\n",
            "(1)\t 845\t [ 1.8625169   0.27412412 -2.209649  ] \t0\tfalse\n",
            "(1)\t 846\t [ 2.1289232  -0.45953545 -1.9664023 ] \t0\tfalse\n",
            "(1)\t 847\t [ 0.8852777  0.6456074 -1.6122491] \t0\tfalse\n",
            "(0)\t 848\t [ 1.1368285 -1.2866442 -0.3667474] \t0\ttrue\n",
            "(1)\t 849\t [ 1.72899     0.29308066 -2.059485  ] \t0\tfalse\n",
            "(0)\t 850\t [ 2.080905   -0.22332262 -1.9720496 ] \t0\ttrue\n",
            "(1)\t 851\t [-1.5854123   0.8441672   0.33826295] \t1\ttrue\n",
            "(0)\t 852\t [-0.6284277 -0.2895958  1.3457255] \t2\tfalse\n",
            "(1)\t 853\t [-0.4556057  1.6644343 -1.1355062] \t1\ttrue\n",
            "(2)\t 854\t [-0.5414944 -0.9422955  1.7583421] \t2\ttrue\n",
            "(2)\t 855\t [-0.616685  -1.0669624  2.0365343] \t2\ttrue\n",
            "(1)\t 856\t [ 1.484306   -0.63687867 -1.2063626 ] \t0\tfalse\n",
            "(0)\t 857\t [-0.6881116 -0.7770451  1.8508586] \t2\tfalse\n",
            "(1)\t 858\t [ 2.1619203  -0.74196774 -1.5990195 ] \t0\tfalse\n",
            "(1)\t 859\t [ 2.3396766 -0.7728124 -1.7569008] \t0\tfalse\n",
            "(2)\t 860\t [-0.82371396 -1.079855    2.2384186 ] \t2\ttrue\n",
            "(2)\t 861\t [-0.9215298  -0.95562726  2.2950368 ] \t2\ttrue\n",
            "(1)\t 862\t [-1.6977876  0.7436339  1.282799 ] \t2\tfalse\n",
            "(1)\t 863\t [ 0.91949064  0.8059953  -1.7664251 ] \t0\tfalse\n",
            "(0)\t 864\t [ 0.09161656  1.2794381  -1.1854151 ] \t1\tfalse\n",
            "(0)\t 865\t [ 0.2240192  1.2566442 -1.5401539] \t1\tfalse\n",
            "(1)\t 866\t [ 0.87536114  1.0389582  -1.7796235 ] \t1\ttrue\n",
            "(1)\t 867\t [-0.98877877 -0.66202253  1.6486433 ] \t2\tfalse\n",
            "(0)\t 868\t [ 1.7107302  -0.13486274 -1.8149656 ] \t0\ttrue\n",
            "(2)\t 869\t [-0.81579375  1.7151723  -0.7039129 ] \t1\tfalse\n",
            "(0)\t 870\t [ 1.2482136 -0.2315661 -1.243418 ] \t0\ttrue\n",
            "(0)\t 871\t [ 2.2414153 -0.2521255 -2.0343997] \t0\ttrue\n",
            "(1)\t 872\t [ 1.1773013  -1.1262524  -0.51094127] \t0\tfalse\n",
            "(0)\t 873\t [ 1.1595708   0.07042257 -1.3112288 ] \t0\ttrue\n",
            "(0)\t 874\t [-0.5482227   0.27649644  0.62665963] \t2\tfalse\n",
            "(2)\t 875\t [ 0.16437444 -0.9243436   0.28595003] \t2\ttrue\n",
            "(0)\t 876\t [-0.48756167  0.675008   -0.10002945] \t1\tfalse\n",
            "(0)\t 877\t [ 0.78881496  0.7107123  -1.4227186 ] \t0\ttrue\n",
            "(0)\t 878\t [ 0.92752564  0.9268433  -1.9480283 ] \t0\ttrue\n",
            "(2)\t 879\t [-1.6133713 -0.1344964  2.1312215] \t2\ttrue\n",
            "(0)\t 880\t [ 1.3169993 -0.9186028 -0.6167089] \t0\ttrue\n",
            "(0)\t 881\t [ 1.7065684 -1.1668266 -0.9125304] \t0\ttrue\n",
            "(0)\t 882\t [ 2.3394196  -0.57894725 -1.8338532 ] \t0\ttrue\n",
            "(0)\t 883\t [ 2.2538154 -0.5785187 -1.828994 ] \t0\ttrue\n",
            "(2)\t 884\t [-1.3139563 -0.905543   2.463901 ] \t2\ttrue\n",
            "(2)\t 885\t [-1.0332221  -0.96235543  2.4505053 ] \t2\ttrue\n",
            "(2)\t 886\t [ 0.1637085  -0.77836573  0.2420505 ] \t2\ttrue\n",
            "(1)\t 887\t [ 1.9848462  -0.86882937 -1.4385529 ] \t0\tfalse\n",
            "(2)\t 888\t [ 0.64660025 -0.37370965 -0.53522485] \t0\tfalse\n",
            "(2)\t 889\t [ 1.7621263  -0.28084674 -1.5509171 ] \t0\tfalse\n",
            "(2)\t 890\t [-0.84758955 -1.2355901   2.2561173 ] \t2\ttrue\n",
            "(2)\t 891\t [-0.66651744 -1.2896994   2.1223164 ] \t2\ttrue\n",
            "(2)\t 892\t [-0.32378584 -1.216296    1.4914813 ] \t2\ttrue\n",
            "(2)\t 893\t [ 0.47547662 -0.45222738 -0.47520915] \t0\tfalse\n",
            "(1)\t 894\t [-0.6157604 -0.6956747  1.8369981] \t2\tfalse\n",
            "(2)\t 895\t [-0.5491492  1.1630944 -0.6773554] \t1\tfalse\n",
            "(1)\t 896\t [ 1.6543819 -0.7636893 -1.303067 ] \t0\tfalse\n",
            "(2)\t 897\t [-0.6142272  0.8585642 -0.0896182] \t1\tfalse\n",
            "(1)\t 898\t [-0.63839644 -1.1413983   2.2267694 ] \t2\tfalse\n",
            "(0)\t 899\t [ 0.83217126  0.5314606  -1.211128  ] \t0\ttrue\n",
            "(0)\t 900\t [ 2.0286632  -0.28002155 -1.9148353 ] \t0\ttrue\n",
            "(2)\t 901\t [ 1.8342452 -1.0150797 -1.3545882] \t0\tfalse\n",
            "(0)\t 902\t [ 1.2666489  0.6006846 -1.9329307] \t0\ttrue\n",
            "(2)\t 903\t [-0.77867156 -0.9148352   1.9865679 ] \t2\ttrue\n",
            "(0)\t 904\t [ 1.0685374  -1.4954941   0.08713141] \t0\ttrue\n",
            "(2)\t 905\t [-0.99914986 -1.0338893   2.3402252 ] \t2\ttrue\n",
            "(2)\t 906\t [ 0.05783017 -0.51104265  0.769717  ] \t2\ttrue\n",
            "(2)\t 907\t [-0.6014577  -0.85037017  1.7915156 ] \t2\ttrue\n",
            "(0)\t 908\t [ 0.08567723 -1.2555163   0.93550026] \t2\tfalse\n",
            "(1)\t 909\t [-0.5709928  0.8437385 -0.3649038] \t1\ttrue\n",
            "(1)\t 910\t [ 0.7325584  0.3801621 -1.1825292] \t0\tfalse\n",
            "(0)\t 911\t [-0.15625465  1.6520407  -1.3591884 ] \t1\tfalse\n",
            "(0)\t 912\t [ 2.3130991 -0.7756684 -1.7177644] \t0\ttrue\n",
            "(1)\t 913\t [ 0.6140583  0.9538999 -1.6240144] \t1\ttrue\n",
            "(1)\t 914\t [ 2.1902466  -0.66778034 -1.7293773 ] \t0\tfalse\n",
            "(0)\t 915\t [ 1.7816778 -0.5422696 -1.4110439] \t0\ttrue\n",
            "(0)\t 916\t [ 1.3565842  -1.4112816  -0.19110265] \t0\ttrue\n",
            "(0)\t 917\t [ 1.3649243  -1.2813729  -0.50870794] \t0\ttrue\n",
            "(0)\t 918\t [-0.54805976 -0.53104025  1.155213  ] \t2\tfalse\n",
            "(1)\t 919\t [ 2.2265155  -0.60171723 -1.6929495 ] \t0\tfalse\n",
            "(0)\t 920\t [ 0.8147529  1.0899711 -2.0179431] \t1\tfalse\n",
            "(1)\t 921\t [ 2.3583524 -0.7316619 -1.6951141] \t0\tfalse\n",
            "(0)\t 922\t [ 2.0289927  -0.12832536 -2.0911453 ] \t0\ttrue\n",
            "(1)\t 923\t [ 0.96173185  0.67305917 -1.9342318 ] \t0\tfalse\n",
            "(2)\t 924\t [-0.7037627 -1.3698101  2.0721288] \t2\ttrue\n",
            "(1)\t 925\t [ 1.4728739  0.4787505 -2.0615225] \t0\tfalse\n",
            "(2)\t 926\t [-0.39756012 -0.03175778  0.71696573] \t2\ttrue\n",
            "(1)\t 927\t [ 0.9074982   0.76928145 -1.6098537 ] \t0\tfalse\n",
            "(2)\t 928\t [ 2.0358434 -0.5202724 -1.6425599] \t0\tfalse\n",
            "(0)\t 929\t [ 0.8829656  0.7700526 -1.6315845] \t0\ttrue\n",
            "(1)\t 930\t [ 1.5059327   0.41431603 -2.1226137 ] \t0\tfalse\n",
            "(1)\t 931\t [ 0.6079331  1.1482748 -1.7905959] \t1\ttrue\n",
            "(0)\t 932\t [ 0.39078844  0.9454893  -1.4002988 ] \t1\tfalse\n",
            "(2)\t 933\t [-1.1773986 -0.9784649  2.3122125] \t2\ttrue\n",
            "(2)\t 934\t [-1.7093291  -0.12758742  2.0701458 ] \t2\ttrue\n",
            "(2)\t 935\t [-1.0226088 -1.0178609  2.526482 ] \t2\ttrue\n",
            "(1)\t 936\t [ 1.9945441  -0.11773235 -2.0357685 ] \t0\tfalse\n",
            "(1)\t 937\t [ 0.46330857  1.1104773  -1.6923918 ] \t1\ttrue\n",
            "(1)\t 938\t [-0.20241225 -0.7507463   0.34710947] \t2\tfalse\n",
            "(2)\t 939\t [ 0.23143905  1.1138579  -1.4956632 ] \t1\tfalse\n",
            "(0)\t 940\t [-1.0341461  -0.42961547  1.7693238 ] \t2\tfalse\n",
            "(0)\t 941\t [ 0.36101687  0.802934   -1.3816278 ] \t1\tfalse\n",
            "(0)\t 942\t [ 0.75637335 -1.6440015   0.35055566] \t0\ttrue\n",
            "(2)\t 943\t [-0.93694735 -1.112458    2.0494153 ] \t2\ttrue\n",
            "(1)\t 944\t [ 1.6382371 -1.002734  -0.6546459] \t0\tfalse\n",
            "(0)\t 945\t [ 1.043331   -1.2702715  -0.05935799] \t0\ttrue\n",
            "(0)\t 946\t [ 1.0463849   0.43342206 -1.6833098 ] \t0\ttrue\n",
            "(0)\t 947\t [ 1.3700002  -0.77592385 -0.7319057 ] \t0\ttrue\n",
            "(2)\t 948\t [-0.86805815 -0.8304406   1.8978326 ] \t2\ttrue\n",
            "(1)\t 949\t [-1.1789726   1.5258923  -0.28911364] \t1\ttrue\n",
            "(2)\t 950\t [-1.0518779  -0.17913385  1.5910268 ] \t2\ttrue\n",
            "(0)\t 951\t [ 2.232824  -0.6776398 -1.8340302] \t0\ttrue\n",
            "(0)\t 952\t [ 2.047804   -0.21304265 -1.872581  ] \t0\ttrue\n",
            "(1)\t 953\t [-0.3433149  1.1343715 -1.0146742] \t1\ttrue\n",
            "(1)\t 954\t [-0.9254939 -0.8222739  2.1074357] \t2\tfalse\n",
            "(2)\t 955\t [-0.9745658  -0.99186367  2.4457803 ] \t2\ttrue\n",
            "(0)\t 956\t [ 2.3452542 -0.6099203 -1.8361552] \t0\ttrue\n",
            "(1)\t 957\t [ 1.7614533   0.01979973 -1.7925097 ] \t0\tfalse\n",
            "(0)\t 958\t [ 2.10091   -0.1104053 -2.130807 ] \t0\ttrue\n",
            "(1)\t 959\t [ 2.1820543 -0.4335622 -1.9393871] \t0\tfalse\n",
            "(0)\t 960\t [-0.11751189  1.2827038  -1.1593875 ] \t1\tfalse\n",
            "(0)\t 961\t [-0.63780564  0.10015473  0.7886248 ] \t2\tfalse\n",
            "(0)\t 962\t [ 1.8421866   0.20333023 -2.043385  ] \t0\ttrue\n",
            "(2)\t 963\t [-0.93038553  1.0718546   0.299309  ] \t1\tfalse\n",
            "(2)\t 964\t [-0.845127  -1.3147712  2.3237731] \t2\ttrue\n",
            "(2)\t 965\t [-0.21238452 -1.1239414   1.4352882 ] \t2\ttrue\n",
            "(1)\t 966\t [ 2.1332822 -0.2966793 -2.0444624] \t0\tfalse\n",
            "(0)\t 967\t [ 2.3118777 -0.7501735 -1.6386105] \t0\ttrue\n",
            "(0)\t 968\t [ 0.40982208  1.3527331  -1.6214783 ] \t1\tfalse\n",
            "(2)\t 969\t [ 0.21075176  1.4385525  -1.8240328 ] \t1\tfalse\n",
            "(2)\t 970\t [-0.62542766 -0.19664223  0.7672786 ] \t2\ttrue\n",
            "(2)\t 971\t [-0.17301448 -0.5968618   0.99649346] \t2\ttrue\n",
            "(2)\t 972\t [-1.3544133  0.2809949  1.4037547] \t2\ttrue\n",
            "(0)\t 973\t [ 2.1706998 -0.944027  -1.6202528] \t0\ttrue\n",
            "(1)\t 974\t [ 1.1916949   0.09094938 -1.3173702 ] \t0\tfalse\n",
            "(0)\t 975\t [ 1.8362368 -1.0934256 -1.3124193] \t0\ttrue\n",
            "(1)\t 976\t [ 1.8440595   0.18286933 -2.0317974 ] \t0\tfalse\n",
            "(2)\t 977\t [-0.9069865 -1.1996577  2.3535652] \t2\ttrue\n",
            "(2)\t 978\t [ 0.366916   0.5429188 -1.165297 ] \t1\tfalse\n",
            "(0)\t 979\t [ 2.3232696 -0.78476   -1.7337873] \t0\ttrue\n",
            "(2)\t 980\t [-1.543722    0.01323021  1.9571258 ] \t2\ttrue\n",
            "(2)\t 981\t [-0.835751    0.71368295  0.41991526] \t1\tfalse\n",
            "(2)\t 982\t [-0.98918515 -0.81036144  2.2028298 ] \t2\ttrue\n",
            "(1)\t 983\t [-1.3887354  1.3957577  0.0387308] \t1\ttrue\n",
            "(2)\t 984\t [-0.38674238  0.5905812  -0.25022718] \t1\tfalse\n",
            "(2)\t 985\t [-0.8811261 -0.8014919  2.156707 ] \t2\ttrue\n",
            "(1)\t 986\t [ 0.19743636  0.80656546 -1.1937013 ] \t1\ttrue\n",
            "(0)\t 987\t [ 0.12047706  1.2083457  -1.4555857 ] \t1\tfalse\n",
            "(1)\t 988\t [ 0.3209767  1.0248381 -1.427757 ] \t1\ttrue\n",
            "(1)\t 989\t [ 0.20418043  1.2037406  -1.3094598 ] \t1\ttrue\n",
            "(1)\t 990\t [ 2.277527   -0.32967314 -1.9068666 ] \t0\tfalse\n",
            "(2)\t 991\t [-0.67584974 -1.0466596   2.1265626 ] \t2\ttrue\n",
            "(2)\t 992\t [ 0.6115449 -0.7330044 -0.0638529] \t0\tfalse\n",
            "(0)\t 993\t [ 0.74628514  0.9001516  -1.7575479 ] \t1\tfalse\n",
            "(2)\t 994\t [-0.3781517  -0.98603195  1.1258147 ] \t2\ttrue\n",
            "(0)\t 995\t [ 1.9688531   0.04593817 -2.0416174 ] \t0\ttrue\n",
            "(2)\t 996\t [-1.3520207  1.2374647  0.5156926] \t1\tfalse\n",
            "(0)\t 997\t [ 1.9978124 -0.9869018 -1.4087355] \t0\ttrue\n",
            "(2)\t 998\t [-0.63700116 -0.00367297  0.7999543 ] \t2\ttrue\n",
            "(2)\t 999\t [-0.13453397 -1.4646571   1.6659074 ] \t2\ttrue\n",
            "(1)\t 1000\t [ 2.3445365 -0.711387  -1.70409  ] \t0\tfalse\n",
            "(0)\t 1001\t [-0.03391608 -0.8114639   0.52673924] \t2\tfalse\n",
            "(2)\t 1002\t [-0.22924653 -0.69335777  1.1485127 ] \t2\ttrue\n",
            "(0)\t 1003\t [ 1.382273   -1.3427125  -0.59914017] \t0\ttrue\n",
            "(2)\t 1004\t [-1.2080357   0.47453582  1.163537  ] \t2\ttrue\n",
            "(1)\t 1005\t [ 1.9974355  -0.37230185 -1.8219638 ] \t0\tfalse\n",
            "(0)\t 1006\t [ 0.43336555  1.3546214  -1.8430126 ] \t1\tfalse\n",
            "(2)\t 1007\t [-1.3399048  -0.54367244  2.403646  ] \t2\ttrue\n",
            "(2)\t 1008\t [-1.0266063 -1.1340634  2.3256922] \t2\ttrue\n",
            "(2)\t 1009\t [-0.99241394  0.9754821   0.4489041 ] \t1\tfalse\n",
            "(2)\t 1010\t [-0.9943094 -1.0141644  2.4773958] \t2\ttrue\n",
            "(2)\t 1011\t [-1.4035215  -0.67998815  2.2488258 ] \t2\ttrue\n",
            "(2)\t 1012\t [-0.37746555  0.62070113 -0.28104606] \t1\tfalse\n",
            "(0)\t 1013\t [ 1.443384  -0.6278203 -0.9399217] \t0\ttrue\n",
            "(1)\t 1014\t [ 0.08917315  1.1871864  -1.1592835 ] \t1\ttrue\n",
            "(0)\t 1015\t [ 1.984139  -0.9976405 -1.503359 ] \t0\ttrue\n",
            "(1)\t 1016\t [ 0.13753648  0.48430786 -0.37183073] \t1\ttrue\n",
            "(0)\t 1017\t [ 1.5295249  -1.2604035  -0.80408764] \t0\ttrue\n",
            "(0)\t 1018\t [ 0.9796093   0.78924257 -1.7688918 ] \t0\ttrue\n",
            "(2)\t 1019\t [-0.06547491 -1.4899092   1.2562118 ] \t2\ttrue\n",
            "(1)\t 1020\t [ 1.2168242  -0.04469667 -1.2186182 ] \t0\tfalse\n",
            "(2)\t 1021\t [-1.1240879 -1.0435855  2.4207592] \t2\ttrue\n",
            "(1)\t 1022\t [ 2.342378  -0.6231041 -1.8586984] \t0\tfalse\n",
            "(0)\t 1023\t [ 1.1567417  -0.67862695 -0.8337594 ] \t0\ttrue\n",
            "(2)\t 1024\t [-0.25864053 -1.0429535   1.3103592 ] \t2\ttrue\n",
            "(2)\t 1025\t [-0.24103191 -1.0646378   1.4970653 ] \t2\ttrue\n",
            "(2)\t 1026\t [-0.9153666 -1.1319635  2.3099012] \t2\ttrue\n",
            "(0)\t 1027\t [ 2.415212  -0.7620558 -1.6531943] \t0\ttrue\n",
            "(1)\t 1028\t [ 1.9586691 -0.8072871 -1.6460936] \t0\tfalse\n",
            "(2)\t 1029\t [-0.7735396 -0.5874233  1.4766455] \t2\ttrue\n",
            "(2)\t 1030\t [-0.30726066  0.40111184 -0.37055957] \t1\tfalse\n",
            "(0)\t 1031\t [ 2.0034506 -0.691007  -1.4655964] \t0\ttrue\n",
            "(0)\t 1032\t [ 2.1377075  -0.12740164 -2.1231189 ] \t0\ttrue\n",
            "(0)\t 1033\t [ 2.1485927 -0.4310216 -1.8592172] \t0\ttrue\n",
            "(2)\t 1034\t [ 0.3415063 -1.6853344  1.2928622] \t2\ttrue\n",
            "(2)\t 1035\t [ 1.6912291 -1.0914327 -1.1007196] \t0\tfalse\n",
            "(2)\t 1036\t [ 0.0029402 -1.2670133  1.2173723] \t2\ttrue\n",
            "(1)\t 1037\t [ 2.03294   -0.1612974 -1.9175386] \t0\tfalse\n",
            "(0)\t 1038\t [ 2.1304717 -1.0263093 -1.4418931] \t0\ttrue\n",
            "(0)\t 1039\t [-0.6342112  -0.40940905  1.0941315 ] \t2\tfalse\n",
            "(1)\t 1040\t [-0.11477412 -1.0370837   0.8615968 ] \t2\tfalse\n",
            "(2)\t 1041\t [-0.7208277 -1.2482975  2.2813215] \t2\ttrue\n",
            "(0)\t 1042\t [-0.77083606 -0.15223615  1.1271545 ] \t2\tfalse\n",
            "(0)\t 1043\t [ 2.3312793 -0.6011809 -1.8380811] \t0\ttrue\n",
            "(0)\t 1044\t [ 1.1825969 -0.7869269 -0.8318999] \t0\ttrue\n",
            "(0)\t 1045\t [ 1.7460843 -1.2451006 -0.9194763] \t0\ttrue\n",
            "(1)\t 1046\t [-0.8013679   1.1285093  -0.25975844] \t1\ttrue\n",
            "(0)\t 1047\t [ 1.3613111   0.69522893 -2.2483003 ] \t0\ttrue\n",
            "(2)\t 1048\t [-0.08332144  0.49615756 -0.28405705] \t1\tfalse\n",
            "(0)\t 1049\t [ 1.2005333   0.07034281 -1.6421696 ] \t0\ttrue\n",
            "(2)\t 1050\t [-0.14647016  0.5823812  -0.5401662 ] \t1\tfalse\n",
            "(0)\t 1051\t [-0.3301409   0.23529056  0.11063461] \t1\tfalse\n",
            "(2)\t 1052\t [-0.7369381 -1.2256705  2.260093 ] \t2\ttrue\n",
            "(2)\t 1053\t [-0.96037614 -1.0513687   2.3194675 ] \t2\ttrue\n",
            "(2)\t 1054\t [-0.6601569 -1.121511   2.1204607] \t2\ttrue\n",
            "(1)\t 1055\t [-0.31513038  0.7777659  -0.520597  ] \t1\ttrue\n",
            "(2)\t 1056\t [ 0.6623182  1.1082549 -1.9100113] \t1\tfalse\n",
            "(0)\t 1057\t [ 0.00646793  1.2950425  -1.4525211 ] \t1\tfalse\n",
            "(2)\t 1058\t [ 0.07561062  1.1571951  -1.2672747 ] \t1\tfalse\n",
            "(0)\t 1059\t [-0.61436254 -0.286439    1.1569276 ] \t2\tfalse\n",
            "(1)\t 1060\t [-0.29053974  0.16010877  0.06472494] \t1\ttrue\n",
            "(0)\t 1061\t [ 2.1069088 -0.650116  -1.7043219] \t0\ttrue\n",
            "(2)\t 1062\t [-0.54043895 -1.2810339   2.099603  ] \t2\ttrue\n",
            "(2)\t 1063\t [-1.0169667 -1.1290901  2.4129152] \t2\ttrue\n",
            "(1)\t 1064\t [ 2.1672473 -0.9543331 -1.3623607] \t0\tfalse\n",
            "(2)\t 1065\t [-0.5608613  -0.69299996  1.1213305 ] \t2\ttrue\n",
            "(1)\t 1066\t [-0.5044581 -1.2462034  2.089937 ] \t2\tfalse\n",
            "(2)\t 1067\t [-0.61597914 -0.7505464   1.7692287 ] \t2\ttrue\n",
            "(2)\t 1068\t [ 2.1850183  -0.31875739 -1.9443853 ] \t0\tfalse\n",
            "(1)\t 1069\t [-0.8453486  1.2503844 -0.5124159] \t1\ttrue\n",
            "(2)\t 1070\t [-0.94119525 -1.0868535   2.2865274 ] \t2\ttrue\n",
            "(0)\t 1071\t [ 1.8104992  -0.35820857 -1.920095  ] \t0\ttrue\n",
            "(2)\t 1072\t [-1.0862672 -1.0941674  2.364511 ] \t2\ttrue\n",
            "(2)\t 1073\t [ 0.71055996 -0.07097261 -0.8373271 ] \t0\tfalse\n",
            "(2)\t 1074\t [-0.7915052  -0.85177904  1.8410275 ] \t2\ttrue\n",
            "(0)\t 1075\t [-0.49913883  0.36287594  0.06678662] \t1\tfalse\n",
            "(0)\t 1076\t [ 0.97328687  0.28570813 -1.4136447 ] \t0\ttrue\n",
            "(0)\t 1077\t [ 1.2609464  0.5736415 -1.8248203] \t0\ttrue\n",
            "(2)\t 1078\t [-0.5728855 -0.9190166  1.9060926] \t2\ttrue\n",
            "(1)\t 1079\t [-1.2473611  -0.30292597  1.9763696 ] \t2\tfalse\n",
            "(2)\t 1080\t [-0.995826  -0.9663127  2.3444974] \t2\ttrue\n",
            "(2)\t 1081\t [-0.95366067 -1.1743503   2.310121  ] \t2\ttrue\n",
            "(2)\t 1082\t [-0.77305573 -0.6270984   1.5512967 ] \t2\ttrue\n",
            "(1)\t 1083\t [ 1.5221235  0.2843144 -1.7875822] \t0\tfalse\n",
            "(1)\t 1084\t [ 2.3615658 -0.7523593 -1.5766156] \t0\tfalse\n",
            "(1)\t 1085\t [ 0.22009052  1.2183726  -1.4884194 ] \t1\ttrue\n",
            "(2)\t 1086\t [-0.720432  -1.1662331  2.143034 ] \t2\ttrue\n",
            "(1)\t 1087\t [-0.90237516  0.46557957  0.68075657] \t2\tfalse\n",
            "(2)\t 1088\t [-0.8763142  -0.29171517  1.1417115 ] \t2\ttrue\n",
            "(0)\t 1089\t [ 2.0741208 -0.9341292 -1.393578 ] \t0\ttrue\n",
            "(2)\t 1090\t [-0.49807748  0.736326   -0.32685158] \t1\tfalse\n",
            "(0)\t 1091\t [ 1.3771445  0.6053019 -1.8972747] \t0\ttrue\n",
            "(0)\t 1092\t [ 2.421662   -0.74990016 -1.7423965 ] \t0\ttrue\n",
            "(2)\t 1093\t [-0.6948253  -0.62941676  1.5164375 ] \t2\ttrue\n",
            "(0)\t 1094\t [ 2.1682093  -0.40382165 -2.0447297 ] \t0\ttrue\n",
            "(0)\t 1095\t [ 1.7231243  -0.04969484 -1.9526751 ] \t0\ttrue\n",
            "(0)\t 1096\t [-0.4177611  -0.44534203  0.90761936] \t2\tfalse\n",
            "(1)\t 1097\t [-1.0113465  -0.51344746  1.9033444 ] \t2\tfalse\n",
            "(1)\t 1098\t [ 1.887191    0.08612254 -1.9910357 ] \t0\tfalse\n",
            "(1)\t 1099\t [ 0.4775998   0.10186303 -0.7296976 ] \t0\tfalse\n",
            "(0)\t 1100\t [ 1.3464489  0.5730856 -2.0734038] \t0\ttrue\n",
            "(0)\t 1101\t [-0.8060762  -0.69197303  2.102513  ] \t2\tfalse\n",
            "(0)\t 1102\t [ 0.45089918 -0.7775532  -0.20983921] \t0\ttrue\n",
            "(2)\t 1103\t [-0.09152199 -1.2597721   0.9452605 ] \t2\ttrue\n",
            "(2)\t 1104\t [-1.3982165  -0.46996948  2.3755589 ] \t2\ttrue\n",
            "(2)\t 1105\t [-0.6171419 -1.1063085  1.9344507] \t2\ttrue\n",
            "(1)\t 1106\t [ 0.3805545  1.1594759 -1.5824679] \t1\ttrue\n",
            "(1)\t 1107\t [ 0.21738942  1.372883   -1.7453262 ] \t1\ttrue\n",
            "(1)\t 1108\t [-0.5931833 -0.4905614  1.3725369] \t2\tfalse\n",
            "(1)\t 1109\t [ 0.46160477 -0.14768706 -0.73636925] \t0\tfalse\n",
            "(0)\t 1110\t [ 2.3066509 -0.7943879 -1.5486238] \t0\ttrue\n",
            "(1)\t 1111\t [ 1.9739883  0.0704751 -2.0045109] \t0\tfalse\n",
            "(0)\t 1112\t [ 2.0188758 -0.385303  -1.8382049] \t0\ttrue\n",
            "(2)\t 1113\t [ 1.83222    -0.99786776 -1.3174758 ] \t0\tfalse\n",
            "(1)\t 1114\t [ 2.0786147  -0.82771426 -1.6556216 ] \t0\tfalse\n",
            "(2)\t 1115\t [ 1.1021322 -1.016201  -0.4214887] \t0\tfalse\n",
            "(0)\t 1116\t [ 0.380642  -1.0250667  0.2668319] \t0\ttrue\n",
            "(2)\t 1117\t [ 0.26502693 -0.563477   -0.08730838] \t0\tfalse\n",
            "(1)\t 1118\t [ 2.3254488 -0.5582339 -1.875534 ] \t0\tfalse\n",
            "(1)\t 1119\t [ 1.7002307   0.15240431 -2.1465755 ] \t0\tfalse\n",
            "(1)\t 1120\t [-0.79440373  1.5516062  -0.7134881 ] \t1\ttrue\n",
            "(0)\t 1121\t [-0.79440373  1.5516062  -0.7134881 ] \t1\tfalse\n",
            "(1)\t 1122\t [ 2.3558528  -0.58918774 -1.7718958 ] \t0\tfalse\n",
            "(0)\t 1123\t [ 2.0571563 -0.7848839 -1.7039224] \t0\ttrue\n",
            "(0)\t 1124\t [-0.36752832 -0.1872229   0.63195693] \t2\tfalse\n",
            "(0)\t 1125\t [-0.06924457  0.48164818 -0.16198406] \t1\tfalse\n",
            "(0)\t 1126\t [ 1.885153  -0.8877799 -1.3288162] \t0\ttrue\n",
            "(0)\t 1127\t [ 0.29639792  0.9559027  -0.92180514] \t1\tfalse\n",
            "(0)\t 1128\t [ 2.1061027  -0.19820173 -2.1153765 ] \t0\ttrue\n",
            "(1)\t 1129\t [ 1.9211673   0.17807584 -2.0414824 ] \t0\tfalse\n",
            "(1)\t 1130\t [ 1.1407238  0.7967093 -2.0797186] \t0\tfalse\n",
            "(1)\t 1131\t [-1.453025    1.3200922   0.15292494] \t1\ttrue\n",
            "(0)\t 1132\t [ 1.2795528   0.30172488 -1.505553  ] \t0\ttrue\n",
            "(1)\t 1133\t [ 0.53039247 -1.3718323   0.20804867] \t0\tfalse\n",
            "(2)\t 1134\t [-1.3383993  -0.80697256  2.3829732 ] \t2\ttrue\n",
            "(2)\t 1135\t [ 0.15029559 -1.0098889   0.76731527] \t2\ttrue\n",
            "(2)\t 1136\t [-0.18685555  1.3682543  -1.2922904 ] \t1\tfalse\n",
            "(1)\t 1137\t [-0.74694884  1.7060026  -0.5746727 ] \t1\ttrue\n",
            "(0)\t 1138\t [ 1.2196637   0.76604766 -1.8968836 ] \t0\ttrue\n",
            "(0)\t 1139\t [ 1.5927955   0.45814148 -2.146676  ] \t0\ttrue\n",
            "(0)\t 1140\t [ 0.10167212  0.44590777 -0.69246864] \t1\tfalse\n",
            "(1)\t 1141\t [-0.8148833   1.7105566  -0.82528734] \t1\ttrue\n",
            "(2)\t 1142\t [ 0.8432396   0.43827647 -1.3243418 ] \t0\tfalse\n",
            "(0)\t 1143\t [ 0.9579315   0.12901713 -1.2191393 ] \t0\ttrue\n",
            "(2)\t 1144\t [ 1.4887824  -0.39272016 -1.4798763 ] \t0\tfalse\n",
            "(1)\t 1145\t [ 1.5486981   0.27066228 -1.9599144 ] \t0\tfalse\n",
            "(0)\t 1146\t [ 1.4159647  0.5616798 -1.9913659] \t0\ttrue\n",
            "(1)\t 1147\t [ 1.4227043   0.48197004 -2.1899357 ] \t0\tfalse\n",
            "(2)\t 1148\t [-0.6566788  -0.59495914  1.6033065 ] \t2\ttrue\n",
            "(1)\t 1149\t [ 1.7964872  -0.03990997 -2.009461  ] \t0\tfalse\n",
            "(2)\t 1150\t [ 0.08301503 -1.1330236   0.973291  ] \t2\ttrue\n",
            "(0)\t 1151\t [ 1.141489   -1.5778087   0.18492171] \t0\ttrue\n",
            "(1)\t 1152\t [ 0.45344603  0.88603187 -1.506187  ] \t1\ttrue\n",
            "(0)\t 1153\t [ 1.0503834  -1.3954257   0.05435143] \t0\ttrue\n",
            "(0)\t 1154\t [ 2.3207035 -0.9123695 -1.4522097] \t0\ttrue\n",
            "(1)\t 1155\t [ 0.3872713  -0.44760054 -0.14920875] \t0\tfalse\n",
            "(1)\t 1156\t [ 1.8048996  -0.08559504 -1.8918531 ] \t0\tfalse\n",
            "(2)\t 1157\t [-0.70950365 -1.1583416   2.1481209 ] \t2\ttrue\n",
            "(0)\t 1158\t [ 0.6750106 -0.4447609 -0.4705345] \t0\ttrue\n",
            "(2)\t 1159\t [ 0.17143409 -0.85708743  0.51525253] \t2\ttrue\n",
            "(0)\t 1160\t [-0.62423736 -0.44974998  1.4081938 ] \t2\tfalse\n",
            "(1)\t 1161\t [ 0.7419034  1.1157644 -1.6794434] \t1\ttrue\n",
            "(0)\t 1162\t [ 2.3531148  -0.70750684 -1.7202616 ] \t0\ttrue\n",
            "(0)\t 1163\t [ 0.83871496 -0.05231254 -0.83051723] \t0\ttrue\n",
            "(0)\t 1164\t [ 2.1256762 -1.0772743 -1.0540011] \t0\ttrue\n",
            "(0)\t 1165\t [ 2.187249   -0.50669676 -1.6741686 ] \t0\ttrue\n",
            "(2)\t 1166\t [-0.27709743  0.35853103  0.3318998 ] \t1\tfalse\n",
            "(0)\t 1167\t [-0.13326421 -0.619327    0.67164314] \t2\tfalse\n",
            "(0)\t 1168\t [ 2.2092345 -0.9413844 -1.49902  ] \t0\ttrue\n",
            "(0)\t 1169\t [ 0.98136216  0.26047435 -1.2918471 ] \t0\ttrue\n",
            "(0)\t 1170\t [-0.5753502   1.052404   -0.09390806] \t1\tfalse\n",
            "(2)\t 1171\t [-0.2899389 -0.7835228  1.1108191] \t2\ttrue\n",
            "(2)\t 1172\t [-0.5808447   0.1250834   0.56654906] \t2\ttrue\n",
            "(1)\t 1173\t [ 1.9803389   0.05339656 -2.007011  ] \t0\tfalse\n",
            "(0)\t 1174\t [ 2.1499648  -0.36977872 -1.9619056 ] \t0\ttrue\n",
            "(2)\t 1175\t [-0.7106984 -1.0152234  2.222783 ] \t2\ttrue\n",
            "(1)\t 1176\t [ 1.6896324   0.34946027 -1.9795226 ] \t0\tfalse\n",
            "(1)\t 1177\t [-0.9570988  1.6546787 -0.539581 ] \t1\ttrue\n",
            "(0)\t 1178\t [ 0.78293854  0.7119928  -1.5744824 ] \t0\ttrue\n",
            "(2)\t 1179\t [-0.7630652  -0.07553035  0.83492196] \t2\ttrue\n",
            "(0)\t 1180\t [ 0.23457499  1.130974   -1.1614473 ] \t1\tfalse\n",
            "(0)\t 1181\t [ 0.54612464 -0.89149034  0.4139096 ] \t0\ttrue\n",
            "(2)\t 1182\t [-0.5991575 -1.1064157  2.10196  ] \t2\ttrue\n",
            "(2)\t 1183\t [-1.254841  -0.8685104  2.5105932] \t2\ttrue\n",
            "(0)\t 1184\t [-0.24768762  0.8398741  -0.38647816] \t1\tfalse\n",
            "(0)\t 1185\t [-0.7580115 -1.0222137  1.926072 ] \t2\tfalse\n",
            "(2)\t 1186\t [-0.91718984 -1.0033641   2.324589  ] \t2\ttrue\n",
            "(2)\t 1187\t [-0.8136769 -1.0475831  2.1197433] \t2\ttrue\n",
            "(0)\t 1188\t [-0.87210447 -1.1812304   2.2418685 ] \t2\tfalse\n",
            "(0)\t 1189\t [ 2.1086533 -0.6302684 -1.7107589] \t0\ttrue\n",
            "(1)\t 1190\t [ 0.6881117  1.116971  -1.7358503] \t1\ttrue\n",
            "(1)\t 1191\t [ 0.37173948  1.1852095  -1.6539323 ] \t1\ttrue\n",
            "(2)\t 1192\t [ 1.1757066   0.26460502 -1.6921093 ] \t0\tfalse\n",
            "(2)\t 1193\t [-0.48136222 -1.4257735   2.0296278 ] \t2\ttrue\n",
            "(1)\t 1194\t [-1.1084574 -0.6399265  2.0634553] \t2\tfalse\n",
            "(2)\t 1195\t [ 0.8421833   0.47565246 -1.5496677 ] \t0\tfalse\n",
            "(2)\t 1196\t [-0.58804655 -1.1665356   1.9507786 ] \t2\ttrue\n",
            "(1)\t 1197\t [ 1.3711377   0.37579817 -1.7973686 ] \t0\tfalse\n",
            "(0)\t 1198\t [-0.34952986  1.1227157  -0.5861531 ] \t1\tfalse\n",
            "(0)\t 1199\t [ 2.2534003  -0.85580236 -1.639452  ] \t0\ttrue\n",
            "(0)\t 1200\t [ 2.1046655 -0.8776737 -1.59907  ] \t0\ttrue\n",
            "(2)\t 1201\t [-1.0227003  -0.96514326  2.3553653 ] \t2\ttrue\n",
            "(2)\t 1202\t [-0.7298054 -0.9933271  1.9931824] \t2\ttrue\n",
            "(2)\t 1203\t [-0.98287207 -1.0670193   2.3430023 ] \t2\ttrue\n",
            "(2)\t 1204\t [-1.0514603 -1.1768603  2.3738468] \t2\ttrue\n",
            "(2)\t 1205\t [-1.144485  -1.0334852  2.4249802] \t2\ttrue\n",
            "(2)\t 1206\t [ 0.05786929 -1.1306567   0.9127148 ] \t2\ttrue\n",
            "(0)\t 1207\t [ 0.00140965  1.0189204  -1.0367286 ] \t1\tfalse\n",
            "(2)\t 1208\t [-0.3436627 -1.263087   1.733877 ] \t2\ttrue\n",
            "(0)\t 1209\t [ 0.62269884  0.93906885 -1.8998677 ] \t1\tfalse\n",
            "(1)\t 1210\t [-0.11820546  1.4198434  -1.312058  ] \t1\ttrue\n",
            "(1)\t 1211\t [-0.11392983  0.17637797 -0.2908285 ] \t1\ttrue\n",
            "(2)\t 1212\t [-0.07104176  0.14207415 -0.2841455 ] \t1\tfalse\n",
            "(1)\t 1213\t [-1.669835   0.5169899  1.534473 ] \t2\tfalse\n",
            "(0)\t 1214\t [ 0.97355276  0.9040033  -2.1544394 ] \t0\ttrue\n",
            "(0)\t 1215\t [ 1.8465377   0.18827187 -2.2319963 ] \t0\ttrue\n",
            "(0)\t 1216\t [ 2.3849127 -0.7415834 -1.752218 ] \t0\ttrue\n",
            "(2)\t 1217\t [ 0.5841113  -0.64126074 -0.1916011 ] \t0\tfalse\n",
            "(0)\t 1218\t [ 1.4446685   0.47145808 -1.7789974 ] \t0\ttrue\n",
            "(2)\t 1219\t [-0.72847325 -0.3344896   1.2506222 ] \t2\ttrue\n",
            "(0)\t 1220\t [-0.596656   1.0248111 -0.280373 ] \t1\tfalse\n",
            "(2)\t 1221\t [-1.0649513  -0.89993984  2.295755  ] \t2\ttrue\n",
            "(0)\t 1222\t [ 1.7831903 -0.9071631 -1.172294 ] \t0\ttrue\n",
            "(2)\t 1223\t [-1.7209318   0.01901794  1.832305  ] \t2\ttrue\n",
            "(0)\t 1224\t [-0.28232777  1.221801   -0.49338636] \t1\tfalse\n",
            "(2)\t 1225\t [ 1.2073255  0.637577  -1.877034 ] \t0\tfalse\n",
            "(0)\t 1226\t [ 0.96721286  0.6793663  -1.6933177 ] \t0\ttrue\n",
            "(0)\t 1227\t [ 1.9750006 -0.9218791 -1.3674086] \t0\ttrue\n",
            "(0)\t 1228\t [ 2.0581496 -1.204148  -1.0345764] \t0\ttrue\n",
            "(1)\t 1229\t [-0.395542   1.3108233 -0.8592046] \t1\ttrue\n",
            "(1)\t 1230\t [-0.72550577  1.475402   -0.7318192 ] \t1\ttrue\n",
            "(1)\t 1231\t [ 0.94021565  0.9400107  -2.086526  ] \t0\tfalse\n",
            "(0)\t 1232\t [ 0.3255569  1.2519097 -1.5616419] \t1\tfalse\n",
            "(1)\t 1233\t [ 0.8499903  0.8260236 -2.0779643] \t0\tfalse\n",
            "(2)\t 1234\t [-1.6547143   0.44014373  1.0978951 ] \t2\ttrue\n",
            "(0)\t 1235\t [ 1.9942263  -0.24384986 -1.9591238 ] \t0\ttrue\n",
            "(0)\t 1236\t [ 1.9790663 -1.2844863 -1.0385056] \t0\ttrue\n",
            "(2)\t 1237\t [ 0.262978  -1.5599656  0.9680536] \t2\ttrue\n",
            "(1)\t 1238\t [ 0.71702886  0.47252756 -1.120106  ] \t0\tfalse\n",
            "(0)\t 1239\t [ 1.8722154  -0.17657457 -1.9840479 ] \t0\ttrue\n",
            "(1)\t 1240\t [ 1.3900794  -0.24867935 -1.664167  ] \t0\tfalse\n",
            "(0)\t 1241\t [ 1.1803235  -0.62699085 -0.70937294] \t0\ttrue\n",
            "(0)\t 1242\t [ 1.8834244 -1.2321361 -0.9841704] \t0\ttrue\n",
            "(2)\t 1243\t [-0.03065759  1.0251632  -1.1755109 ] \t1\tfalse\n",
            "(0)\t 1244\t [-0.01674246  0.19331776 -0.5708546 ] \t1\tfalse\n",
            "(2)\t 1245\t [ 0.9321602   0.34746167 -1.4112124 ] \t0\tfalse\n",
            "(0)\t 1246\t [ 2.2693098  -0.54057807 -1.8498468 ] \t0\ttrue\n",
            "(0)\t 1247\t [ 2.1931436  -0.74350554 -1.7321165 ] \t0\ttrue\n",
            "(2)\t 1248\t [-0.8089372 -1.1485674  2.247561 ] \t2\ttrue\n",
            "(1)\t 1249\t [ 0.42967027  0.7834031  -1.3296574 ] \t1\ttrue\n",
            "(2)\t 1250\t [-1.053607  -0.8456453  2.1147754] \t2\ttrue\n",
            "(0)\t 1251\t [-0.48532027 -1.2966487   1.928242  ] \t2\tfalse\n",
            "(2)\t 1252\t [-0.28180462 -1.0953865   1.6659988 ] \t2\ttrue\n",
            "(0)\t 1253\t [ 1.8675708 -0.823897  -1.5186648] \t0\ttrue\n",
            "(1)\t 1254\t [ 2.01594    -0.04230104 -2.0421703 ] \t0\tfalse\n",
            "(2)\t 1255\t [-0.99013966 -1.1626961   2.3012648 ] \t2\ttrue\n",
            "(2)\t 1256\t [-0.5758856 -1.0860505  1.9479467] \t2\ttrue\n",
            "(0)\t 1257\t [ 1.2447187  -1.1299667  -0.41335967] \t0\ttrue\n",
            "(2)\t 1258\t [-0.81604075 -1.1101801   2.2902837 ] \t2\ttrue\n",
            "(1)\t 1259\t [-1.3496796   1.0663657   0.39738268] \t1\ttrue\n",
            "(1)\t 1260\t [ 2.1040215 -0.2804343 -2.0273259] \t0\tfalse\n",
            "(2)\t 1261\t [-1.2157527 -0.9646353  2.3858595] \t2\ttrue\n",
            "(2)\t 1262\t [-0.6217096 -1.3847616  1.9802938] \t2\ttrue\n",
            "(1)\t 1263\t [ 2.2029574  -0.66184664 -1.691919  ] \t0\tfalse\n",
            "(1)\t 1264\t [ 2.2625902  -0.97596925 -1.4782025 ] \t0\tfalse\n",
            "(1)\t 1265\t [-0.60043687 -0.83615214  1.5044204 ] \t2\tfalse\n",
            "(2)\t 1266\t [ 0.47193402 -0.9306725  -0.16341716] \t0\tfalse\n",
            "(1)\t 1267\t [-0.36883956 -0.5717189   0.8790661 ] \t2\tfalse\n",
            "(1)\t 1268\t [ 1.732801  -1.2172147 -0.8776032] \t0\tfalse\n",
            "(2)\t 1269\t [-0.9539579 -1.049314   2.4104648] \t2\ttrue\n",
            "(1)\t 1270\t [ 1.8656485  -0.09407184 -1.8647313 ] \t0\tfalse\n",
            "(1)\t 1271\t [ 1.2333273  0.4160469 -1.9063227] \t0\tfalse\n",
            "(2)\t 1272\t [-0.3431216   0.1783587   0.15045698] \t1\tfalse\n",
            "(2)\t 1273\t [-0.33867413 -0.2988745   0.48895335] \t2\ttrue\n",
            "(0)\t 1274\t [ 2.4026446 -0.6874695 -1.7365868] \t0\ttrue\n",
            "(0)\t 1275\t [ 2.2939627  -0.40364796 -1.9852526 ] \t0\ttrue\n",
            "(2)\t 1276\t [ 1.0711211  -1.4265475  -0.21224749] \t0\tfalse\n",
            "(0)\t 1277\t [ 2.2453108  -0.92580354 -1.5866288 ] \t0\ttrue\n",
            "(1)\t 1278\t [ 1.4180048   0.48823807 -2.1043978 ] \t0\tfalse\n",
            "(2)\t 1279\t [ 2.391453  -0.7122119 -1.8383727] \t0\tfalse\n",
            "(2)\t 1280\t [ 1.3791277 -0.8261777 -1.1035058] \t0\tfalse\n",
            "(0)\t 1281\t [ 2.2062762  -0.83344215 -1.5963168 ] \t0\ttrue\n",
            "(1)\t 1282\t [ 2.2470033  -0.74397933 -1.7186329 ] \t0\tfalse\n",
            "(1)\t 1283\t [-1.0906017   1.72211    -0.58037007] \t1\ttrue\n",
            "(1)\t 1284\t [ 0.41168416  1.3727615  -1.6337233 ] \t1\ttrue\n",
            "(0)\t 1285\t [ 0.37619787  0.23612265 -1.0160979 ] \t0\ttrue\n",
            "(2)\t 1286\t [-1.4995795 -0.4976994  2.318302 ] \t2\ttrue\n",
            "(0)\t 1287\t [ 0.0865375   0.07795674 -0.0769814 ] \t0\ttrue\n",
            "(2)\t 1288\t [-0.55081385  0.53511256  0.11349721] \t1\tfalse\n",
            "(0)\t 1289\t [-0.32516277  0.6687241  -0.11712047] \t1\tfalse\n",
            "(2)\t 1290\t [-0.18132444  0.69317037 -0.5997872 ] \t1\tfalse\n",
            "(0)\t 1291\t [-0.5623116  -0.89775866  1.8984646 ] \t2\tfalse\n",
            "(0)\t 1292\t [-1.4278945   1.2869891   0.37773237] \t1\tfalse\n",
            "(2)\t 1293\t [ 0.6586866  0.5459346 -1.4631886] \t0\tfalse\n",
            "(2)\t 1294\t [-0.9511863 -1.0310588  2.471488 ] \t2\ttrue\n",
            "(2)\t 1295\t [-0.4679628 -1.1747117  1.7617059] \t2\ttrue\n",
            "(2)\t 1296\t [-0.9994691 -0.1994186  1.6736586] \t2\ttrue\n",
            "(0)\t 1297\t [-0.24769545  0.8520587  -0.40728548] \t1\tfalse\n",
            "(1)\t 1298\t [-0.39267495 -1.1636367   1.9973922 ] \t2\tfalse\n",
            "(0)\t 1299\t [-1.0951964 -1.0762974  2.4372096] \t2\tfalse\n",
            "(2)\t 1300\t [ 0.5865211  -0.91562265  0.06785206] \t0\tfalse\n",
            "(1)\t 1301\t [-1.2152852  1.5217474 -0.2521167] \t1\ttrue\n",
            "(2)\t 1302\t [-0.9008742 -0.9269813  2.1468754] \t2\ttrue\n",
            "(2)\t 1303\t [-1.580366    0.02448826  1.7770696 ] \t2\ttrue\n",
            "(1)\t 1304\t [ 0.15881622  1.3404753  -1.3675077 ] \t1\ttrue\n",
            "(0)\t 1305\t [ 2.3117847  -0.68546784 -1.6803083 ] \t0\ttrue\n",
            "(2)\t 1306\t [-0.94760126 -1.2030096   2.3397684 ] \t2\ttrue\n",
            "(2)\t 1307\t [-0.4952989   1.0743711  -0.38005862] \t1\tfalse\n",
            "(1)\t 1308\t [-0.33896887  0.8999856  -0.53942156] \t1\ttrue\n",
            "(0)\t 1309\t [-0.9364953 -1.1646142  2.2823048] \t2\tfalse\n",
            "(0)\t 1310\t [-0.09975077 -1.2912254   1.490654  ] \t2\tfalse\n",
            "(1)\t 1311\t [ 0.27525324  0.26933467 -0.6446225 ] \t0\tfalse\n",
            "(0)\t 1312\t [ 1.1475283 -1.2197418 -0.4474086] \t0\ttrue\n",
            "(0)\t 1313\t [ 1.8220117   0.10113533 -1.8698657 ] \t0\ttrue\n",
            "(0)\t 1314\t [ 2.0368881  -0.27638927 -2.0271149 ] \t0\ttrue\n",
            "(1)\t 1315\t [-0.6385663   1.5700606  -0.54114604] \t1\ttrue\n",
            "(1)\t 1316\t [ 0.8209039  0.6243659 -1.2434393] \t0\tfalse\n",
            "(2)\t 1317\t [-0.76169914  0.6730355   0.24695447] \t1\tfalse\n",
            "(2)\t 1318\t [-0.79963046  1.6463029  -0.63262165] \t1\tfalse\n",
            "(1)\t 1319\t [ 2.0159209  -0.07378032 -2.1122136 ] \t0\tfalse\n",
            "(1)\t 1320\t [ 2.2162373  -0.45999297 -1.8721125 ] \t0\tfalse\n",
            "(2)\t 1321\t [-0.42790562 -0.8459373   1.5817211 ] \t2\ttrue\n",
            "(1)\t 1322\t [-0.12614177  1.3629179  -1.3268138 ] \t1\ttrue\n",
            "(1)\t 1323\t [ 1.1301681   0.43797192 -1.5531793 ] \t0\tfalse\n",
            "(2)\t 1324\t [ 0.4756918 -1.1277914 -0.1535388] \t0\tfalse\n",
            "(1)\t 1325\t [-0.4256013  1.6051093 -1.3699317] \t1\ttrue\n",
            "(0)\t 1326\t [ 0.9196146  0.734966  -1.7445425] \t0\ttrue\n",
            "(0)\t 1327\t [ 1.9654459  -0.57543164 -1.658108  ] \t0\ttrue\n",
            "(2)\t 1328\t [ 2.024594   -0.24574283 -1.8616643 ] \t0\tfalse\n",
            "(2)\t 1329\t [-0.5300647 -1.2199578  1.6850522] \t2\ttrue\n",
            "(1)\t 1330\t [-1.0606855   1.223761    0.11635875] \t1\ttrue\n",
            "(2)\t 1331\t [-0.6851544 -1.0726135  2.0041993] \t2\ttrue\n",
            "(2)\t 1332\t [-0.19111711 -0.13515733  0.28564647] \t2\ttrue\n",
            "(2)\t 1333\t [-0.96702594 -1.1144357   2.3201852 ] \t2\ttrue\n",
            "(2)\t 1334\t [-1.0334723 -1.1187962  2.3653712] \t2\ttrue\n",
            "(0)\t 1335\t [ 1.5375427  0.3798102 -1.927177 ] \t0\ttrue\n",
            "(0)\t 1336\t [ 0.98302174  0.67829007 -1.9907668 ] \t0\ttrue\n",
            "(1)\t 1337\t [-0.04821358 -1.0346082   1.09872   ] \t2\tfalse\n",
            "(2)\t 1338\t [ 0.2097752  -0.55565053  0.08266072] \t0\tfalse\n",
            "(2)\t 1339\t [-0.86472744 -1.0906513   2.1064882 ] \t2\ttrue\n",
            "(2)\t 1340\t [-0.91278964 -0.29086757  1.3684332 ] \t2\ttrue\n",
            "(1)\t 1341\t [ 2.4038062 -0.6540509 -1.766469 ] \t0\tfalse\n",
            "(0)\t 1342\t [ 2.3148196 -0.6263762 -1.7901546] \t0\ttrue\n",
            "(1)\t 1343\t [ 2.2218063 -0.5314234 -1.8597187] \t0\tfalse\n",
            "(1)\t 1344\t [ 1.1944717 -0.4546801 -1.1545008] \t0\tfalse\n",
            "(1)\t 1345\t [-1.5307069   1.2519462   0.42783365] \t1\ttrue\n",
            "(1)\t 1346\t [-0.09521753 -1.3686494   1.4389541 ] \t2\tfalse\n",
            "(1)\t 1347\t [ 0.61200005 -0.5827841  -0.03470824] \t0\tfalse\n",
            "(1)\t 1348\t [-0.89637786 -0.83637667  2.0809693 ] \t2\tfalse\n",
            "(0)\t 1349\t [ 1.9833183 -0.8232522 -1.7075822] \t0\ttrue\n",
            "(0)\t 1350\t [ 1.2486473  -0.9552687  -0.49616075] \t0\ttrue\n",
            "(2)\t 1351\t [-1.0184563 -1.0159848  2.3186955] \t2\ttrue\n",
            "(2)\t 1352\t [-1.025006  -0.8658698  2.2604468] \t2\ttrue\n",
            "(2)\t 1353\t [ 0.1030339   0.58829445 -0.5274757 ] \t1\tfalse\n",
            "(0)\t 1354\t [ 1.2532485   0.24738361 -1.6790786 ] \t0\ttrue\n",
            "(1)\t 1355\t [ 1.2532485   0.24738361 -1.6790786 ] \t0\tfalse\n",
            "(0)\t 1356\t [-1.1408303 -1.0330749  2.436168 ] \t2\tfalse\n",
            "(1)\t 1357\t [-0.193876    1.0708114  -0.83728504] \t1\ttrue\n",
            "(0)\t 1358\t [ 2.2689002  -0.49763474 -1.9643983 ] \t0\ttrue\n",
            "(1)\t 1359\t [ 0.3082561   0.80336785 -1.2244353 ] \t1\ttrue\n",
            "(0)\t 1360\t [ 1.7984985 -1.4488925 -0.6276883] \t0\ttrue\n",
            "(0)\t 1361\t [ 2.2566807  -0.41480348 -2.0341792 ] \t0\ttrue\n",
            "(1)\t 1362\t [ 0.5281429   0.91515905 -1.4233332 ] \t1\ttrue\n",
            "(0)\t 1363\t [ 2.316623  -0.6865762 -1.7478373] \t0\ttrue\n",
            "(0)\t 1364\t [ 0.37140405  0.9240883  -1.3306156 ] \t1\tfalse\n",
            "(1)\t 1365\t [-0.64064986  1.3711044  -0.73796546] \t1\ttrue\n",
            "(1)\t 1366\t [ 1.3368725   0.63099855 -1.9582329 ] \t0\tfalse\n",
            "(0)\t 1367\t [ 2.0886726  -0.39614734 -1.8462193 ] \t0\ttrue\n",
            "(1)\t 1368\t [-0.12244679 -0.08392894  0.05650356] \t2\tfalse\n",
            "(1)\t 1369\t [ 0.30030358  1.3150153  -1.6431795 ] \t1\ttrue\n",
            "(2)\t 1370\t [-0.7109931  -0.74301594  1.7270067 ] \t2\ttrue\n",
            "(2)\t 1371\t [-1.1906292  0.3895765  1.0342689] \t2\ttrue\n",
            "(0)\t 1372\t [ 1.9062102   0.02299091 -1.9153881 ] \t0\ttrue\n",
            "(0)\t 1373\t [ 1.962494   -0.70318705 -1.5094249 ] \t0\ttrue\n",
            "(0)\t 1374\t [ 2.0003788  -0.60094243 -1.5321324 ] \t0\ttrue\n",
            "(0)\t 1375\t [ 1.8995107  -0.11344935 -2.0374606 ] \t0\ttrue\n",
            "(1)\t 1376\t [ 0.16148013 -0.6148199  -0.0583699 ] \t0\tfalse\n",
            "(2)\t 1377\t [ 0.670077   -1.1280985  -0.01054576] \t0\tfalse\n",
            "(0)\t 1378\t [ 1.0579662  0.6716122 -1.6779592] \t0\ttrue\n",
            "(1)\t 1379\t [ 1.5997279  -0.84377486 -1.0123239 ] \t0\tfalse\n",
            "(2)\t 1380\t [-1.0366803 -0.9934386  2.3549633] \t2\ttrue\n",
            "(1)\t 1381\t [ 2.1044223  -0.13581517 -2.1440926 ] \t0\tfalse\n",
            "(0)\t 1382\t [ 0.2863778  1.030638  -1.5010049] \t1\tfalse\n",
            "(2)\t 1383\t [ 1.2417096  0.0758187 -1.5732598] \t0\tfalse\n",
            "(2)\t 1384\t [ 0.08809312  0.06320015 -0.33665475] \t0\tfalse\n",
            "(0)\t 1385\t [ 1.0863204  0.7889082 -1.8892435] \t0\ttrue\n",
            "(2)\t 1386\t [-1.1272188 -0.7333208  2.2716396] \t2\ttrue\n",
            "(1)\t 1387\t [ 1.0899421  0.6701206 -1.8975103] \t0\tfalse\n",
            "(2)\t 1388\t [ 0.42332548  0.6372455  -1.4919298 ] \t1\tfalse\n",
            "(1)\t 1389\t [-0.30370486  0.9678713  -0.7016608 ] \t1\ttrue\n",
            "(0)\t 1390\t [ 1.9331479  -0.30516508 -1.7045262 ] \t0\ttrue\n",
            "(0)\t 1391\t [ 2.2231014  -0.29299942 -2.0643349 ] \t0\ttrue\n",
            "(1)\t 1392\t [ 1.5418843  -0.40640852 -1.67031   ] \t0\tfalse\n",
            "(0)\t 1393\t [ 2.2400491  -0.33692354 -1.910847  ] \t0\ttrue\n",
            "(2)\t 1394\t [-0.79033715 -0.81094426  1.8844883 ] \t2\ttrue\n",
            "(0)\t 1395\t [ 0.3684628  1.1248732 -1.5789952] \t1\tfalse\n",
            "(0)\t 1396\t [ 1.3681926  -0.9974036  -0.68502265] \t0\ttrue\n",
            "(1)\t 1397\t [-0.02016496  0.07275557 -0.48212573] \t1\ttrue\n",
            "(1)\t 1398\t [-0.0601881  1.0846586 -1.2153516] \t1\ttrue\n",
            "(2)\t 1399\t [-0.7277134   0.5722302   0.24098127] \t1\tfalse\n",
            "(0)\t 1400\t [ 0.00674923  1.2181687  -1.3602896 ] \t1\tfalse\n",
            "Number of true predictions: 814\n",
            "Number of false predictions: 586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRMcHi1uLQdO",
        "colab_type": "code",
        "outputId": "0c662849-9830-4dc5-bd3c-dc7dad72e266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Accuracy:\",true_count/count_line*100,\"%\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 58.10135617416131 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgrPoBuDDz_d",
        "colab_type": "code",
        "outputId": "98b226b3-900e-4a7b-f5ad-e699311aae59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "scores = [3.0, 1.0, 0.2]\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    print(softmax(predictions[i][j]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5476175  0.4270147  0.02536778]\n",
            "[0.18809274 0.774864   0.03704327]\n",
            "[0.4138124  0.26937333 0.31681424]\n",
            "[0.13897587 0.70983696 0.15118718]\n",
            "[0.9020098  0.07699259 0.02099761]\n",
            "[0.02485779 0.04989033 0.92525184]\n",
            "[0.05099613 0.647508   0.30149582]\n",
            "[0.05819229 0.06476133 0.87704635]\n",
            "[0.62208974 0.3384505  0.03945982]\n",
            "[0.5114298  0.19576332 0.2928069 ]\n",
            "[0.89403164 0.08807144 0.01789689]\n",
            "[0.7504881  0.170001   0.07951094]\n",
            "[0.32353064 0.24535032 0.431119  ]\n",
            "[0.03327349 0.02879807 0.93792844]\n",
            "[0.2420419  0.555098   0.20286007]\n",
            "[0.10747742 0.27828273 0.6142399 ]\n",
            "[0.9295263  0.04283845 0.02763527]\n",
            "[0.6045635  0.35345703 0.04197955]\n",
            "[0.7289948  0.1914387  0.07956649]\n",
            "[0.9331061  0.05235291 0.01454096]\n",
            "[0.93808335 0.04839701 0.01351956]\n",
            "[0.846135   0.0790918  0.07477323]\n",
            "[0.51058644 0.44968137 0.03973221]\n",
            "[0.9300025  0.05568332 0.01431405]\n",
            "[0.64172477 0.31931072 0.03896454]\n",
            "[0.91130143 0.07471356 0.01398503]\n",
            "[0.34351104 0.5992411  0.05724791]\n",
            "[0.55195105 0.40634555 0.0417034 ]\n",
            "[0.16420336 0.04417377 0.7916228 ]\n",
            "[0.27329376 0.4560177  0.27068856]\n",
            "[0.94175816 0.03482534 0.02341656]\n",
            "[0.12596898 0.46057868 0.41345242]\n",
            "[0.04363132 0.02771836 0.9286503 ]\n",
            "[0.8382793  0.14522806 0.01649267]\n",
            "[0.94012123 0.04289024 0.01698853]\n",
            "[0.90179294 0.05874906 0.03945799]\n",
            "[0.5528678  0.06427239 0.38285977]\n",
            "[0.91551524 0.04999421 0.03449049]\n",
            "[0.74391717 0.23656976 0.01951301]\n",
            "[0.87332743 0.10134257 0.02532995]\n",
            "[0.7105007  0.14690742 0.14259182]\n",
            "[0.9348934  0.04866393 0.01644257]\n",
            "[0.8502499  0.1252669  0.02448313]\n",
            "[0.9318141  0.05433325 0.01385264]\n",
            "[0.9023635  0.08389686 0.0137397 ]\n",
            "[0.8306635  0.09908429 0.07025227]\n",
            "[0.9402706 0.0352763 0.0244531]\n",
            "[0.80560255 0.14986975 0.04452773]\n",
            "[0.89759797 0.08495975 0.01744231]\n",
            "[0.11834016 0.03610111 0.8455587 ]\n",
            "[0.89292175 0.09396103 0.01311718]\n",
            "[0.9031498  0.07825921 0.01859092]\n",
            "[0.886897   0.09225956 0.0208434 ]\n",
            "[0.14507617 0.81546265 0.03946117]\n",
            "[0.04083516 0.5644571  0.39470774]\n",
            "[0.5346746  0.33177823 0.13354719]\n",
            "[0.8556693  0.12647302 0.01785774]\n",
            "[0.18130267 0.39471522 0.4239821 ]\n",
            "[0.02300245 0.02941364 0.9475839 ]\n",
            "[0.8751471  0.05757048 0.0672824 ]\n",
            "[0.2445192  0.714694   0.04078673]\n",
            "[0.6130705  0.36627212 0.02065737]\n",
            "[0.93129677 0.05467905 0.01402413]\n",
            "[0.28358632 0.6783802  0.03803345]\n",
            "[0.27389562 0.69263214 0.03347221]\n",
            "[0.2543356  0.68398523 0.06167923]\n",
            "[0.92737955 0.04345826 0.02916208]\n",
            "[0.13526565 0.11389255 0.7508418 ]\n",
            "[0.0968745  0.08933504 0.81379044]\n",
            "[0.32099938 0.56024677 0.11875389]\n",
            "[0.89672714 0.08857979 0.01469307]\n",
            "[0.9364694  0.04577985 0.01775073]\n",
            "[0.780622   0.19793858 0.02143937]\n",
            "[0.83020854 0.0804261  0.08936532]\n",
            "[0.34654015 0.5959193  0.05754057]\n",
            "[0.84712106 0.13755006 0.01532882]\n",
            "[0.20517361 0.26547807 0.5293483 ]\n",
            "[0.24435592 0.72545916 0.03018495]\n",
            "[0.885772   0.09010694 0.02412108]\n",
            "[0.93345237 0.05110426 0.01544335]\n",
            "[0.15254775 0.21753787 0.62991434]\n",
            "[0.4783249  0.49172908 0.02994606]\n",
            "[0.74918854 0.22827084 0.02254059]\n",
            "[0.88845104 0.08983196 0.02171697]\n",
            "[0.34935004 0.62526536 0.02538461]\n",
            "[0.02803194 0.07980058 0.89216745]\n",
            "[0.9387457  0.04044674 0.02080757]\n",
            "[0.6848892  0.29484716 0.02026365]\n",
            "[0.6629036  0.3192905  0.01780592]\n",
            "[0.83810484 0.1346121  0.02728311]\n",
            "[0.6508642  0.297501   0.05163481]\n",
            "[0.8985126  0.04206178 0.05942566]\n",
            "[0.1737907  0.43007082 0.39613852]\n",
            "[0.9340281  0.04883517 0.01713672]\n",
            "[0.710447   0.26674655 0.02280641]\n",
            "[0.8030685  0.18049395 0.01643745]\n",
            "[0.82627875 0.15661532 0.01710593]\n",
            "[0.8611105  0.11908192 0.01980758]\n",
            "[0.17834868 0.07428327 0.74736804]\n",
            "[0.19751616 0.77134764 0.03113621]\n",
            "[0.93752646 0.04762474 0.0148488 ]\n",
            "[0.38840127 0.5689075  0.04269122]\n",
            "[0.34185126 0.6139976  0.04415115]\n",
            "[0.06634863 0.03414255 0.89950883]\n",
            "[0.11182729 0.47125286 0.4169199 ]\n",
            "[0.04508308 0.77708244 0.17783447]\n",
            "[0.09531868 0.43000808 0.4746732 ]\n",
            "[0.12303472 0.77676654 0.10019877]\n",
            "[0.23704305 0.06602848 0.6969284 ]\n",
            "[0.03600887 0.0290358  0.9349553 ]\n",
            "[0.05316917 0.02843412 0.9183967 ]\n",
            "[0.23811424 0.5039501  0.25793564]\n",
            "[0.93964803 0.04364208 0.0167099 ]\n",
            "[0.03373073 0.02966685 0.93660235]\n",
            "[0.09898144 0.05296844 0.8480501 ]\n",
            "[0.55081093 0.418838   0.03035107]\n",
            "[0.9392499  0.04519966 0.01555048]\n",
            "[0.0369223  0.11522941 0.84784836]\n",
            "[0.12157751 0.82703257 0.05138995]\n",
            "[0.51918465 0.39788556 0.08292975]\n",
            "[0.89270115 0.07165886 0.03564   ]\n",
            "[0.0833061  0.03484774 0.8818462 ]\n",
            "[0.09603047 0.06539808 0.8385714 ]\n",
            "[0.1503918  0.6537442  0.19586392]\n",
            "[0.06816121 0.0498294  0.8820094 ]\n",
            "[0.0438849  0.03372252 0.9223926 ]\n",
            "[0.5876689  0.06831662 0.34401447]\n",
            "[0.9219459  0.06416921 0.01388489]\n",
            "[0.94514775 0.03749459 0.01735763]\n",
            "[0.16276613 0.05095746 0.78627634]\n",
            "[0.88822544 0.09883942 0.0129351 ]\n",
            "[0.04004192 0.5975672  0.36239082]\n",
            "[0.9147763  0.07223946 0.01298423]\n",
            "[0.8955721  0.09147137 0.01295661]\n",
            "[0.70060754 0.28001416 0.01937832]\n",
            "[0.9374504  0.04759651 0.01495309]\n",
            "[0.11400687 0.6626074  0.22338569]\n",
            "[0.17905748 0.7246192  0.09632328]\n",
            "[0.29464182 0.6528832  0.05247499]\n",
            "[0.897056   0.08946196 0.01348218]\n",
            "[0.17546454 0.7447481  0.07978742]\n",
            "[0.45558047 0.5182293  0.02619022]\n",
            "[0.5464389  0.42970318 0.02385793]\n",
            "[0.21034552 0.08253703 0.70711744]\n",
            "[0.71665746 0.26545852 0.01788402]\n",
            "[0.3703383  0.3069611  0.32270062]\n",
            "[0.28762186 0.6215462  0.09083191]\n",
            "[0.3209025  0.43525037 0.24384712]\n",
            "[0.39380503 0.57695687 0.02923804]\n",
            "[0.9059974  0.06808507 0.02591751]\n",
            "[0.7557461  0.1497421  0.09451179]\n",
            "[0.8916006  0.07348567 0.03491367]\n",
            "[0.93504214 0.0497419  0.01521601]\n",
            "[0.9309066  0.05235903 0.01673437]\n",
            "[0.9397874  0.04504251 0.01517004]\n",
            "[0.5540851 0.3548034 0.0911115]\n",
            "[0.2959771  0.63652736 0.06749552]\n",
            "[0.3016114 0.5602413 0.1381473]\n",
            "[0.10782278 0.13557163 0.75660557]\n",
            "[0.52428925 0.23744158 0.23826922]\n",
            "[0.9256564  0.05950755 0.01483612]\n",
            "[0.47137287 0.24973191 0.2788952 ]\n",
            "[0.9325242  0.05134952 0.01612635]\n",
            "[0.07426727 0.85213464 0.073598  ]\n",
            "[0.9445986  0.03522524 0.02017611]\n",
            "[0.93576247 0.04714169 0.01709579]\n",
            "[0.4065528 0.5526936 0.0407536]\n",
            "[0.2441225  0.7096033  0.04627417]\n",
            "[0.940248   0.04299403 0.0167579 ]\n",
            "[0.39739436 0.5722524  0.03035324]\n",
            "[0.4169887  0.47059384 0.11241749]\n",
            "[0.8544528  0.12281778 0.02272942]\n",
            "[0.9469231  0.03474635 0.01833063]\n",
            "[0.6476618  0.30940032 0.04293793]\n",
            "[0.20941277 0.7492734  0.04131376]\n",
            "[0.3019124  0.64992243 0.04816513]\n",
            "[0.7059229  0.27217025 0.02190689]\n",
            "[0.6107884  0.18001224 0.20919941]\n",
            "[0.05927173 0.02927292 0.9114553 ]\n",
            "[0.0511046  0.03633618 0.9125593 ]\n",
            "[0.63314974 0.05873645 0.3081138 ]\n",
            "[0.25005153 0.63967675 0.11027175]\n",
            "[0.50237584 0.41935003 0.07827408]\n",
            "[0.82316065 0.15918857 0.01765071]\n",
            "[0.86735666 0.11039253 0.02225087]\n",
            "[0.1349665  0.24305137 0.6219821 ]\n",
            "[0.22537544 0.71922326 0.05540133]\n",
            "[0.14309585 0.7484928  0.10841136]\n",
            "[0.8307484  0.13290666 0.03634501]\n",
            "[0.05751541 0.5911061  0.3513784 ]\n",
            "[0.11989328 0.81112725 0.06897945]\n",
            "[0.48944685 0.4034788  0.10707433]\n",
            "[0.05698907 0.03757132 0.90543956]\n",
            "[0.8629763  0.12152977 0.01549392]\n",
            "[0.684219   0.29056194 0.02521901]\n",
            "[0.80791473 0.17378989 0.01829533]\n",
            "[0.16206789 0.5730507  0.2648815 ]\n",
            "[0.264624   0.28389862 0.4514774 ]\n",
            "[0.91988957 0.06033424 0.01977615]\n",
            "[0.9344498  0.04680333 0.01874695]\n",
            "[0.8248676  0.11030166 0.06483079]\n",
            "[0.12332677 0.33918747 0.5374858 ]\n",
            "[0.30966508 0.6002576  0.09007735]\n",
            "[0.9304019  0.0420363  0.02756174]\n",
            "[0.35330078 0.3959125  0.25078672]\n",
            "[0.9370864  0.04679549 0.01611813]\n",
            "[0.94461447 0.03941208 0.01597346]\n",
            "[0.04502408 0.08032737 0.8746485 ]\n",
            "[0.09800982 0.83873063 0.06325962]\n",
            "[0.537429   0.4311215  0.03144958]\n",
            "[0.12924902 0.82567    0.04508095]\n",
            "[0.07929359 0.05768453 0.86302185]\n",
            "[0.03533374 0.34289157 0.6217747 ]\n",
            "[0.03557082 0.02794876 0.93648046]\n",
            "[0.9277507  0.05795903 0.01429025]\n",
            "[0.03455956 0.02831919 0.9371212 ]\n",
            "[0.78825516 0.19147322 0.02027167]\n",
            "[0.8475421  0.07499432 0.07746352]\n",
            "[0.9408835  0.04415784 0.01495855]\n",
            "[0.02927264 0.02794496 0.9427824 ]\n",
            "[0.03811295 0.03308266 0.92880434]\n",
            "[0.15058665 0.07400939 0.7754039 ]\n",
            "[0.85674536 0.08525133 0.05800336]\n",
            "[0.12995398 0.4593369  0.4107091 ]\n",
            "[0.02018635 0.06615534 0.9136584 ]\n",
            "[0.04317864 0.7921831  0.1646382 ]\n",
            "[0.9137305  0.06733374 0.01893581]\n",
            "[0.04957294 0.02901616 0.9214109 ]\n",
            "[0.07457306 0.86118454 0.06424236]\n",
            "[0.21487218 0.06519026 0.71993756]\n",
            "[0.05745282 0.03013729 0.9124099 ]\n",
            "[0.92619044 0.05541017 0.01839933]\n",
            "[0.3735811  0.39005163 0.2363673 ]\n",
            "[0.26256087 0.05379154 0.68364763]\n",
            "[0.9323681  0.04894876 0.01868316]\n",
            "[0.4756118  0.20726392 0.31712422]\n",
            "[0.09869568 0.7815645  0.11973991]\n",
            "[0.03430574 0.0313998  0.9342945 ]\n",
            "[0.7111061  0.26796052 0.0209334 ]\n",
            "[0.91644704 0.03840607 0.04514693]\n",
            "[0.04909163 0.03438693 0.91652143]\n",
            "[0.86406183 0.11187204 0.02406608]\n",
            "[0.1217528  0.24330655 0.6349407 ]\n",
            "[0.36087838 0.05549297 0.58362865]\n",
            "[0.87522656 0.10336736 0.02140617]\n",
            "[0.92449963 0.03467412 0.04082627]\n",
            "[0.8421429  0.06495372 0.09290339]\n",
            "[0.34854975 0.44084117 0.2106091 ]\n",
            "[0.920402   0.04637256 0.03322544]\n",
            "[0.28653693 0.05269879 0.6607642 ]\n",
            "[0.04498418 0.0474084  0.90760744]\n",
            "[0.9360123  0.03938901 0.02459871]\n",
            "[0.06832704 0.02895558 0.9027174 ]\n",
            "[0.41453928 0.5361881  0.04927259]\n",
            "[0.5670977  0.40230384 0.0305984 ]\n",
            "[0.04036846 0.03057153 0.92906   ]\n",
            "[0.5226619  0.05690855 0.42042947]\n",
            "[0.49481496 0.45580378 0.04938134]\n",
            "[0.84448105 0.13913193 0.01638692]\n",
            "[0.87403995 0.04220511 0.08375491]\n",
            "[0.87050354 0.07202797 0.05746844]\n",
            "[0.03123172 0.31914532 0.649623  ]\n",
            "[0.43185592 0.37505132 0.19309278]\n",
            "[0.7933584  0.16715014 0.03949149]\n",
            "[0.20503056 0.68158555 0.11338388]\n",
            "[0.9018417  0.05610036 0.04205791]\n",
            "[0.58118016 0.38862637 0.0301935 ]\n",
            "[0.02829684 0.26910347 0.70259964]\n",
            "[0.7818867  0.07912829 0.13898504]\n",
            "[0.09543719 0.09478728 0.80977553]\n",
            "[0.03215126 0.02751024 0.94033843]\n",
            "[0.39252847 0.13572502 0.47174653]\n",
            "[0.8139371  0.15349533 0.03256754]\n",
            "[0.5737874  0.3785913  0.04762134]\n",
            "[0.08159004 0.03683063 0.88157934]\n",
            "[0.14519778 0.7369324  0.11786988]\n",
            "[0.08334804 0.05379158 0.8628604 ]\n",
            "[0.02160566 0.04717859 0.9312158 ]\n",
            "[0.03083607 0.02805125 0.9411127 ]\n",
            "[0.9170764  0.05931007 0.02361358]\n",
            "[0.12242031 0.8164303  0.06114939]\n",
            "[0.5196743  0.4554595  0.02486619]\n",
            "[0.14364958 0.12412392 0.7322265 ]\n",
            "[0.08018715 0.59926075 0.3205521 ]\n",
            "[0.32104808 0.12824869 0.5507032 ]\n",
            "[0.03157549 0.02898439 0.9394402 ]\n",
            "[0.04541008 0.7213195  0.23327048]\n",
            "[0.44018883 0.4371471  0.12266413]\n",
            "[0.9435756  0.03759452 0.01882986]\n",
            "[0.12862824 0.78884125 0.08253052]\n",
            "[0.09796529 0.09514424 0.8068904 ]\n",
            "[0.89694184 0.08821789 0.01484031]\n",
            "[0.14284596 0.79412186 0.06303211]\n",
            "[0.20990977 0.06374563 0.72634465]\n",
            "[0.05295791 0.06042835 0.8866137 ]\n",
            "[0.6244858  0.06491397 0.31060022]\n",
            "[0.8896522  0.08116918 0.02917863]\n",
            "[0.38549513 0.49603456 0.11847029]\n",
            "[0.16815016 0.7708119  0.06103791]\n",
            "[0.10213684 0.85734016 0.04052299]\n",
            "[0.40925136 0.46885088 0.12189776]\n",
            "[0.03326212 0.02899043 0.9377475 ]\n",
            "[0.02137557 0.04625278 0.9323716 ]\n",
            "[0.31599498 0.5226461  0.16135888]\n",
            "[0.38692522 0.12123593 0.4918388 ]\n",
            "[0.25452146 0.12269647 0.62278205]\n",
            "[0.3498084  0.6143617  0.03582989]\n",
            "[0.897608   0.05934724 0.04304479]\n",
            "[0.02737654 0.03881157 0.9338119 ]\n",
            "[0.04628566 0.02443154 0.9292828 ]\n",
            "[0.74886674 0.2332753  0.01785805]\n",
            "[0.05068799 0.03510248 0.9142095 ]\n",
            "[0.2696938  0.6756933  0.05461295]\n",
            "[0.06430846 0.0328407  0.9028508 ]\n",
            "[0.8978063  0.08836045 0.01383336]\n",
            "[0.49450275 0.3583739  0.14712335]\n",
            "[0.0242784  0.03351768 0.9422039 ]\n",
            "[0.0239126  0.0491001  0.92698723]\n",
            "[0.02620976 0.12185942 0.8519308 ]\n",
            "[0.92310715 0.04663847 0.03025431]\n",
            "[0.3260124  0.6387015  0.03528607]\n",
            "[0.02394494 0.10466781 0.87138724]\n",
            "[0.8117681  0.03993314 0.14829879]\n",
            "[0.02514427 0.03223006 0.9426257 ]\n",
            "[0.56858915 0.05161808 0.37979275]\n",
            "[0.49668497 0.07320549 0.43010944]\n",
            "[0.81083107 0.16027708 0.02889187]\n",
            "[0.04245158 0.3557078  0.6018406 ]\n",
            "[0.03237171 0.03048884 0.93713945]\n",
            "[0.05400669 0.6677565  0.2782368 ]\n",
            "[0.41864523 0.5426516  0.03870318]\n",
            "[0.5418469  0.05871062 0.39944252]\n",
            "[0.06154592 0.02651929 0.9119348 ]\n",
            "[0.03955041 0.06977656 0.89067304]\n",
            "[0.11717999 0.06347507 0.819345  ]\n",
            "[0.16798292 0.04516296 0.78685415]\n",
            "[0.03463141 0.03982671 0.9255419 ]\n",
            "[0.06495307 0.05111875 0.88392824]\n",
            "[0.02016504 0.07095598 0.90887904]\n",
            "[0.62772155 0.33887917 0.03339928]\n",
            "[0.81757873 0.06533068 0.11709058]\n",
            "[0.04121226 0.02906163 0.92972606]\n",
            "[0.06036169 0.03129636 0.90834194]\n",
            "[0.07806184 0.60381085 0.31812721]\n",
            "[0.30786994 0.09930261 0.59282744]\n",
            "[0.04093298 0.02785651 0.9312105 ]\n",
            "[0.06322441 0.5913039  0.3454717 ]\n",
            "[0.06937607 0.06505192 0.86557204]\n",
            "[0.06174595 0.03883965 0.8994144 ]\n",
            "[0.04990082 0.7174002  0.23269889]\n",
            "[0.5936205  0.34334785 0.06303164]\n",
            "[0.04235239 0.4816794  0.4759682 ]\n",
            "[0.03292786 0.03376842 0.93330365]\n",
            "[0.18851034 0.71663576 0.09485392]\n",
            "[0.23363288 0.66464984 0.10171731]\n",
            "[0.06411117 0.04039799 0.8954908 ]\n",
            "[0.11112686 0.46255282 0.42632034]\n",
            "[0.4153792  0.39409685 0.19052388]\n",
            "[0.0914182  0.08022811 0.8283537 ]\n",
            "[0.04055596 0.0412695  0.91817456]\n",
            "[0.02879623 0.02735329 0.94385046]\n",
            "[0.1336806  0.62134135 0.24497803]\n",
            "[0.02178624 0.03777313 0.9404406 ]\n",
            "[0.03042805 0.02651355 0.9430584 ]\n",
            "[0.0688776  0.6190265  0.31209594]\n",
            "[0.43060407 0.4854276  0.08396842]\n",
            "[0.9140779  0.04397848 0.04194363]\n",
            "[0.8721754  0.11308122 0.01474345]\n",
            "[0.1908752  0.07063907 0.7384857 ]\n",
            "[0.13904062 0.09768443 0.76327497]\n",
            "[0.7614658  0.17369081 0.06484339]\n",
            "[0.14354238 0.07986192 0.7765957 ]\n",
            "[0.25455257 0.69763106 0.04781638]\n",
            "[0.90428936 0.08162113 0.01408938]\n",
            "[0.30337927 0.64885104 0.04776969]\n",
            "[0.17290574 0.7286701  0.09842414]\n",
            "[0.40524587 0.5272948  0.06745934]\n",
            "[0.15528983 0.74823296 0.09647726]\n",
            "[0.8682235  0.11601382 0.01576265]\n",
            "[0.06268774 0.09280758 0.8445046 ]\n",
            "[0.8889551  0.09620184 0.01484302]\n",
            "[0.08611349 0.80676854 0.10711801]\n",
            "[0.5686774  0.28379992 0.14752266]\n",
            "[0.27395076 0.6596279  0.06642132]\n",
            "[0.04245384 0.7183345  0.23921172]\n",
            "[0.19151072 0.7081506  0.10033862]\n",
            "[0.69720775 0.2731543  0.02963787]\n",
            "[0.6314072  0.08363023 0.28496262]\n",
            "[0.04642725 0.05951659 0.89405614]\n",
            "[0.10808265 0.10230118 0.7896162 ]\n",
            "[0.0508538 0.570811  0.3783352]\n",
            "[0.72203964 0.25078803 0.0271724 ]\n",
            "[0.14842966 0.79934865 0.05222171]\n",
            "[0.13354881 0.8038594  0.06259178]\n",
            "[0.07077422 0.8516054  0.07762031]\n",
            "[0.3707327  0.55242157 0.07684573]\n",
            "[0.28669754 0.33563402 0.37766847]\n",
            "[0.05183516 0.6467778  0.301387  ]\n",
            "[0.56066096 0.0966211  0.3427179 ]\n",
            "[0.2346106  0.2064523  0.55893713]\n",
            "[0.1381278  0.22582078 0.6360514 ]\n",
            "[0.8684334  0.03316357 0.09840295]\n",
            "[0.16295686 0.7810201  0.05602303]\n",
            "[0.25759596 0.7098271  0.03257693]\n",
            "[0.5162708  0.11593469 0.36779448]\n",
            "[0.04192779 0.53406066 0.42401153]\n",
            "[0.05088597 0.03119563 0.9179183 ]\n",
            "[0.53090805 0.33032596 0.13876599]\n",
            "[0.05915737 0.54700786 0.39383486]\n",
            "[0.24366562 0.6932307  0.06310366]\n",
            "[0.06646323 0.85588163 0.07765515]\n",
            "[0.92419285 0.06196334 0.01384386]\n",
            "[0.08540107 0.03304756 0.8815513 ]\n",
            "[0.03762661 0.02583934 0.9365341 ]\n",
            "[0.02718947 0.09130407 0.8815065 ]\n",
            "[0.03857619 0.04344498 0.9179788 ]\n",
            "[0.609312   0.28623474 0.10445328]\n",
            "[0.14565533 0.12819472 0.72615   ]\n",
            "[0.41564745 0.5372175  0.04713502]\n",
            "[0.65843594 0.15864253 0.18292153]\n",
            "[0.28939277 0.06345349 0.6471537 ]\n",
            "[0.5496031  0.3762204  0.07417649]\n",
            "[0.60011876 0.31447285 0.08540833]\n",
            "[0.87524325 0.09741782 0.02733895]\n",
            "[0.86164343 0.09672736 0.04162922]\n",
            "[0.8209911  0.16077694 0.01823199]\n",
            "[0.06406628 0.04996642 0.8859673 ]\n",
            "[0.1499156  0.03647387 0.8136105 ]\n",
            "[0.10243703 0.12008847 0.7774745 ]\n",
            "[0.9431852  0.03604282 0.02077198]\n",
            "[0.04210312 0.03455815 0.9233387 ]\n",
            "[0.02195474 0.11500084 0.86304444]\n",
            "[0.03542428 0.02789569 0.9366801 ]\n",
            "[0.04080174 0.37823075 0.58096755]\n",
            "[0.32288978 0.06950646 0.6076038 ]\n",
            "[0.04868178 0.02965223 0.92166597]\n",
            "[0.02304029 0.04859236 0.9283674 ]\n",
            "[0.91845685 0.04817411 0.03336909]\n",
            "[0.37985727 0.57602465 0.04411811]\n",
            "[0.05830239 0.05977585 0.88192177]\n",
            "[0.93410283 0.05266501 0.01323219]\n",
            "[0.15650742 0.47099212 0.37250045]\n",
            "[0.02032793 0.07195901 0.9077131 ]\n",
            "[0.0720906  0.06977706 0.8581323 ]\n",
            "[0.06192768 0.09839143 0.8396809 ]\n",
            "[0.63317925 0.04630097 0.32051975]\n",
            "[0.17439793 0.70236105 0.12324107]\n",
            "[0.1293608  0.7367749  0.13386425]\n",
            "[0.8042432  0.17753768 0.01821911]\n",
            "[0.19629046 0.7286177  0.07509175]\n",
            "[0.3347681  0.12084882 0.5443831 ]\n",
            "[0.25046918 0.68325174 0.0662791 ]\n",
            "[0.63715947 0.32671815 0.0361224 ]\n",
            "[0.02646184 0.0358864  0.9376518 ]\n",
            "[0.02711971 0.03371904 0.93916124]\n",
            "[0.11311079 0.07092526 0.815964  ]\n",
            "[0.8860911  0.0747058  0.03920306]\n",
            "[0.5461574  0.36810476 0.08573785]\n",
            "[0.0541524  0.04374119 0.9021064 ]\n",
            "[0.75017565 0.22709541 0.02272898]\n",
            "[0.18051489 0.74643457 0.0730505 ]\n",
            "[0.15921395 0.11568885 0.7250972 ]\n",
            "[0.93730855 0.04700055 0.01569082]\n",
            "[0.27401295 0.5285114  0.19747564]\n",
            "[0.06439997 0.03864624 0.8969538 ]\n",
            "[0.72123057 0.0595581  0.21921133]\n",
            "[0.2883836  0.64041054 0.07120582]\n",
            "[0.15732843 0.05520281 0.78746873]\n",
            "[0.04362282 0.6931874  0.26318976]\n",
            "[0.09285582 0.0810364  0.82610774]\n",
            "[0.838861   0.06637096 0.09476801]\n",
            "[0.93639016 0.04933295 0.0142769 ]\n",
            "[0.8399187  0.08944614 0.07063513]\n",
            "[0.05318043 0.46195197 0.4848676 ]\n",
            "[0.9397214  0.04360672 0.01667186]\n",
            "[0.02699653 0.02925046 0.943753  ]\n",
            "[0.0406922  0.02879433 0.9305135 ]\n",
            "[0.21488702 0.1551374  0.62997556]\n",
            "[0.05943056 0.87425727 0.06631214]\n",
            "[0.24332698 0.4619908  0.29468223]\n",
            "[0.9323742  0.04904771 0.01857808]\n",
            "[0.03873091 0.03024087 0.93102825]\n",
            "[0.77645284 0.08499862 0.13854857]\n",
            "[0.33396965 0.6372164  0.02881393]\n",
            "[0.84831595 0.11982366 0.03186046]\n",
            "[0.7319459  0.05389337 0.21416073]\n",
            "[0.7514069  0.14949524 0.09909787]\n",
            "[0.41927668 0.3171395  0.2635838 ]\n",
            "[0.06097024 0.5533029  0.38572687]\n",
            "[0.04925572 0.04452274 0.9062215 ]\n",
            "[0.900541   0.07835053 0.02110851]\n",
            "[0.29291353 0.06040426 0.6466822 ]\n",
            "[0.8478061  0.13356052 0.01863336]\n",
            "[0.44741383 0.07372659 0.4788596 ]\n",
            "[0.26969862 0.68709475 0.04320656]\n",
            "[0.09497368 0.07816921 0.82685715]\n",
            "[0.84657913 0.13603461 0.01738618]\n",
            "[0.26510996 0.35684183 0.37804818]\n",
            "[0.6111472  0.18018968 0.20866306]\n",
            "[0.6111472  0.18018968 0.20866306]\n",
            "[0.11180507 0.07428824 0.81390667]\n",
            "[0.38329425 0.23003185 0.38667393]\n",
            "[0.18304476 0.71499634 0.10195897]\n",
            "[0.0509656  0.819062   0.12997238]\n",
            "[0.27331    0.08749586 0.63919413]\n",
            "[0.0488399  0.7830535  0.16810653]\n",
            "[0.03726538 0.04048585 0.9222488 ]\n",
            "[0.03682567 0.03345558 0.9297188 ]\n",
            "[0.03147548 0.02750985 0.94101465]\n",
            "[0.04438306 0.0366828  0.91893417]\n",
            "[0.03109955 0.02892927 0.93997115]\n",
            "[0.02633268 0.02899772 0.94466966]\n",
            "[0.63758993 0.05825302 0.30415705]\n",
            "[0.03481606 0.02860491 0.93657905]\n",
            "[0.02711965 0.02764521 0.9452351 ]\n",
            "[0.02857366 0.02823613 0.94319016]\n",
            "[0.0571492  0.02941109 0.9134397 ]\n",
            "[0.02941898 0.04328565 0.9272954 ]\n",
            "[0.06847683 0.731137   0.20038617]\n",
            "[0.04831878 0.7434772  0.208204  ]\n",
            "[0.05565254 0.80628633 0.1380611 ]\n",
            "[0.03660145 0.5318384  0.43156013]\n",
            "[0.25089845 0.5749865  0.174115  ]\n",
            "[0.08399119 0.869548   0.04646073]\n",
            "[0.4102096  0.06713984 0.52265054]\n",
            "[0.06491015 0.04690896 0.88818085]\n",
            "[0.9209625  0.04851285 0.03052467]\n",
            "[0.8718549  0.10838539 0.01975967]\n",
            "[0.9077632  0.07760061 0.01463625]\n",
            "[0.8876235  0.09533697 0.01703957]\n",
            "[0.33194613 0.55943763 0.1086162 ]\n",
            "[0.9442947  0.03920674 0.01649857]\n",
            "[0.5442267  0.42429996 0.03147328]\n",
            "[0.06744629 0.03921951 0.89333415]\n",
            "[0.7609393  0.13967317 0.09938743]\n",
            "[0.9023686  0.08332906 0.01430236]\n",
            "[0.8573463  0.12771219 0.01494143]\n",
            "[0.943273   0.04064467 0.01608221]\n",
            "[0.21147111 0.7122781  0.07625069]\n",
            "[0.31040412 0.6352058  0.0543901 ]\n",
            "[0.02201858 0.06852206 0.9094594 ]\n",
            "[0.12386678 0.8328944  0.04323884]\n",
            "[0.232319   0.72547644 0.04220458]\n",
            "[0.91617244 0.06279615 0.02103136]\n",
            "[0.44299677 0.52589005 0.0311132 ]\n",
            "[0.277673   0.5675136  0.15481347]\n",
            "[0.94382316 0.0393606  0.01681624]\n",
            "[0.80604744 0.17425035 0.01970228]\n",
            "[0.7946321  0.07359176 0.13177626]\n",
            "[0.85283077 0.12749754 0.01967175]\n",
            "[0.09882949 0.07839842 0.8227721 ]\n",
            "[0.5487362  0.41617262 0.03509121]\n",
            "[0.56266975 0.37519282 0.06213741]\n",
            "[0.33206916 0.51340246 0.1545284 ]\n",
            "[0.05295667 0.60437715 0.34266615]\n",
            "[0.08129099 0.8412799  0.07742916]\n",
            "[0.8487558  0.05457152 0.09667276]\n",
            "[0.11765394 0.07249046 0.8098556 ]\n",
            "[0.4966203  0.42052555 0.08285421]\n",
            "[0.299195   0.23654228 0.46426266]\n",
            "[0.2111284  0.05594707 0.7329245 ]\n",
            "[0.07385959 0.03657391 0.8895664 ]\n",
            "[0.78207535 0.0833829  0.13454181]\n",
            "[0.03315532 0.02905928 0.93778545]\n",
            "[0.17578277 0.3597274  0.46448982]\n",
            "[0.17578277 0.3597274  0.46448982]\n",
            "[0.5373366  0.42109698 0.04156642]\n",
            "[0.15419412 0.8107932  0.03501267]\n",
            "[0.5122263  0.44444513 0.0433286 ]\n",
            "[0.8969924  0.08824215 0.01476555]\n",
            "[0.6309942  0.19926225 0.16974358]\n",
            "[0.73761034 0.24262303 0.01976665]\n",
            "[0.5954456  0.36608794 0.03846646]\n",
            "[0.10762341 0.794156   0.09822054]\n",
            "[0.04497325 0.04194195 0.9130848 ]\n",
            "[0.16146739 0.7609308  0.0776019 ]\n",
            "[0.20024504 0.71886456 0.08089039]\n",
            "[0.02770757 0.02591855 0.9463739 ]\n",
            "[0.67814106 0.2839351  0.03792393]\n",
            "[0.12361567 0.23631877 0.64006555]\n",
            "[0.51153    0.11310916 0.37536085]\n",
            "[0.21516559 0.04917588 0.7356585 ]\n",
            "[0.15088068 0.6355688  0.2135506 ]\n",
            "[0.93737864 0.03979637 0.022825  ]\n",
            "[0.87122154 0.1043065  0.02447194]\n",
            "[0.03129322 0.03197173 0.9367351 ]\n",
            "[0.02648937 0.0321704  0.94134015]\n",
            "[0.5818255 0.2749047 0.1432698]\n",
            "[0.8713743  0.0791336  0.04949212]\n",
            "[0.03459043 0.24216577 0.7232438 ]\n",
            "[0.9235695  0.06110861 0.01532193]\n",
            "[0.35074067 0.6111727  0.03808668]\n",
            "[0.1299856  0.7793663  0.09064808]\n",
            "[0.08888494 0.05505097 0.8560641 ]\n",
            "[0.19183227 0.08499397 0.72317374]\n",
            "[0.3687565  0.35991886 0.2713246 ]\n",
            "[0.50872725 0.08935383 0.40191895]\n",
            "[0.4037447  0.5111549  0.08510038]\n",
            "[0.0287932  0.03012772 0.94107914]\n",
            "[0.08305126 0.03202219 0.88492656]\n",
            "[0.8338429  0.14275302 0.0234041 ]\n",
            "[0.02875252 0.28588864 0.6853588 ]\n",
            "[0.79973334 0.1742669  0.02599973]\n",
            "[0.03867678 0.18150441 0.77981883]\n",
            "[0.9392826  0.04558862 0.01512878]\n",
            "[0.4221971  0.13488747 0.4429154 ]\n",
            "[0.8895158  0.08447853 0.02600563]\n",
            "[0.10932519 0.7363937  0.15428108]\n",
            "[0.03901236 0.6882398  0.27274787]\n",
            "[0.06162996 0.03845845 0.89991164]\n",
            "[0.7593789  0.18269973 0.05792132]\n",
            "[0.05169537 0.02785313 0.92045146]\n",
            "[0.09291252 0.6073101  0.29977733]\n",
            "[0.76417655 0.2204423  0.01538119]\n",
            "[0.5756982  0.39028925 0.03401257]\n",
            "[0.9417423  0.0411901  0.01706762]\n",
            "[0.9338947  0.04523428 0.02087101]\n",
            "[0.03341276 0.0553076  0.9112796 ]\n",
            "[0.88999325 0.08899716 0.02100962]\n",
            "[0.04137084 0.06438805 0.89424103]\n",
            "[0.04286317 0.04205251 0.9150843 ]\n",
            "[0.04891559 0.03026975 0.9208147 ]\n",
            "[0.8170436  0.16411923 0.01883715]\n",
            "[0.10659537 0.08152645 0.8118782 ]\n",
            "[0.05005492 0.02951487 0.92043024]\n",
            "[0.94102615 0.0411828  0.01779102]\n",
            "[0.77521515 0.20232742 0.02245745]\n",
            "[0.02840297 0.02879291 0.9428041 ]\n",
            "[0.10294924 0.0958909  0.8011599 ]\n",
            "[0.10294924 0.0958909  0.8011599 ]\n",
            "[0.3154847  0.5774494  0.10706595]\n",
            "[0.19516623 0.7587038  0.04612995]\n",
            "[0.5221634  0.05158029 0.42625633]\n",
            "[0.13933282 0.73977226 0.12089499]\n",
            "[0.7621848  0.05315268 0.1846626 ]\n",
            "[0.02124176 0.05540121 0.923357  ]\n",
            "[0.922185   0.05840433 0.01941065]\n",
            "[0.14587276 0.04982271 0.8043045 ]\n",
            "[0.12696654 0.05167032 0.82136315]\n",
            "[0.69606626 0.26458886 0.03934478]\n",
            "[0.8426702  0.14249435 0.01483549]\n",
            "[0.94245845 0.0335919  0.02394965]\n",
            "[0.8365698  0.13263316 0.03079705]\n",
            "[0.33482817 0.51801515 0.14715663]\n",
            "[0.8946382  0.05868732 0.04667452]\n",
            "[0.09432894 0.14331365 0.7623575 ]\n",
            "[0.4684386  0.5092324  0.02232902]\n",
            "[0.22453229 0.11998203 0.6554857 ]\n",
            "[0.0493633  0.83297527 0.11766148]\n",
            "[0.81432164 0.16853395 0.0171445 ]\n",
            "[0.91550577 0.0699768  0.0145175 ]\n",
            "[0.8299259  0.1061812  0.06389295]\n",
            "[0.9419431  0.04351021 0.01454675]\n",
            "[0.90743816 0.04797293 0.04458885]\n",
            "[0.9129501  0.06270777 0.02434221]\n",
            "[0.33533585 0.59685004 0.0678141 ]\n",
            "[0.6444063  0.3318818  0.02371192]\n",
            "[0.80728364 0.16926575 0.02345063]\n",
            "[0.02584467 0.14698733 0.82716805]\n",
            "[0.09853498 0.6719405  0.22952451]\n",
            "[0.10387801 0.07369778 0.82242423]\n",
            "[0.12244681 0.04751696 0.83003616]\n",
            "[0.821736   0.06423484 0.11402911]\n",
            "[0.04518791 0.03441986 0.9203923 ]\n",
            "[0.25667572 0.26975566 0.47356868]\n",
            "[0.9458967  0.03400065 0.02010267]\n",
            "[0.3339509  0.61630654 0.04974255]\n",
            "[0.25050408 0.68195    0.06754599]\n",
            "[0.05269481 0.05434033 0.89296484]\n",
            "[0.05007619 0.02964328 0.9202805 ]\n",
            "[0.03798479 0.02890713 0.9331081 ]\n",
            "[0.07278864 0.029297   0.8979144 ]\n",
            "[0.0305311  0.02603722 0.94343174]\n",
            "[0.03261637 0.02776388 0.9396198 ]\n",
            "[0.0378705  0.02828264 0.93384683]\n",
            "[0.02160425 0.05659966 0.9217961 ]\n",
            "[0.02345762 0.0282271  0.94831526]\n",
            "[0.03116125 0.02610917 0.9427296 ]\n",
            "[0.02858542 0.02650814 0.9449064 ]\n",
            "[0.01950648 0.05979308 0.9207005 ]\n",
            "[0.8412049  0.1413429  0.01745226]\n",
            "[0.92805576 0.0341992  0.03774501]\n",
            "[0.07091301 0.03106577 0.89802116]\n",
            "[0.9180446  0.06956092 0.01239448]\n",
            "[0.75254315 0.22432521 0.0231317 ]\n",
            "[0.9453658  0.03323643 0.02139781]\n",
            "[0.9385458  0.04678666 0.01466763]\n",
            "[0.9350978  0.03754426 0.02735795]\n",
            "[0.02986176 0.22747655 0.74266165]\n",
            "[0.3928405  0.38622108 0.22093837]\n",
            "[0.27977186 0.6638832  0.05634497]\n",
            "[0.91859514 0.05355578 0.0278491 ]\n",
            "[0.8794144  0.07707352 0.04351211]\n",
            "[0.05629674 0.05180908 0.89189416]\n",
            "[0.1036746  0.08553791 0.8107875 ]\n",
            "[0.03128969 0.03067585 0.9380345 ]\n",
            "[0.02845451 0.03189101 0.9396545 ]\n",
            "[0.0295363  0.03421298 0.93625075]\n",
            "[0.03553587 0.07423113 0.89023304]\n",
            "[0.9236376  0.05466167 0.0217007 ]\n",
            "[0.9205329  0.06530908 0.01415803]\n",
            "[0.929287   0.05318699 0.01752604]\n",
            "[0.9082814  0.07550471 0.01621395]\n",
            "[0.84259933 0.11804444 0.03935621]\n",
            "[0.05493578 0.65023303 0.2948312 ]\n",
            "[0.9118882  0.0719811  0.01613072]\n",
            "[0.22356746 0.53551495 0.24091758]\n",
            "[0.04051575 0.5016544  0.45782992]\n",
            "[0.47643882 0.36274332 0.16081782]\n",
            "[0.94060594 0.04029795 0.01909618]\n",
            "[0.13580218 0.3947928  0.469405  ]\n",
            "[0.29863003 0.6556484  0.04572151]\n",
            "[0.18339248 0.75857574 0.05803179]\n",
            "[0.14188506 0.21910049 0.6390144 ]\n",
            "[0.41185707 0.4590531  0.1290898 ]\n",
            "[0.41185707 0.4590531  0.1290898 ]\n",
            "[0.07577604 0.6962645  0.22795948]\n",
            "[0.11347242 0.21954101 0.6669865 ]\n",
            "[0.5282412  0.41756654 0.05419225]\n",
            "[0.6783674  0.12051733 0.20111533]\n",
            "[0.31857654 0.6037025  0.07772097]\n",
            "[0.07571702 0.05272942 0.87155354]\n",
            "[0.05238776 0.04071812 0.9068941 ]\n",
            "[0.09739428 0.05843251 0.8441732 ]\n",
            "[0.8055641  0.15166783 0.04276801]\n",
            "[0.8055641  0.15166783 0.04276801]\n",
            "[0.18237108 0.6799734  0.13765544]\n",
            "[0.16224629 0.03669712 0.80105656]\n",
            "[0.33688274 0.17269117 0.49042603]\n",
            "[0.06868407 0.05757343 0.8737425 ]\n",
            "[0.46664166 0.14829065 0.38506767]\n",
            "[0.5468638  0.07902556 0.3741107 ]\n",
            "[0.61722356 0.337319   0.04545749]\n",
            "[0.24631444 0.65550137 0.09818418]\n",
            "[0.8673963  0.09804537 0.03455831]\n",
            "[0.5963267  0.37741208 0.0262613 ]\n",
            "[0.03637358 0.03006694 0.9335595 ]\n",
            "[0.14059533 0.1536139  0.7057908 ]\n",
            "[0.9424831  0.03809321 0.01942364]\n",
            "[0.9360741  0.03396309 0.02996285]\n",
            "[0.9420132  0.03982646 0.01816034]\n",
            "[0.35439277 0.13945584 0.5061514 ]\n",
            "[0.03443952 0.02767838 0.9378821 ]\n",
            "[0.81452966 0.08504477 0.10042554]\n",
            "[0.9307449  0.04811445 0.02114071]\n",
            "[0.8994135  0.08770926 0.01287715]\n",
            "[0.07634916 0.06155479 0.862096  ]\n",
            "[0.88000876 0.08149183 0.03849938]\n",
            "[0.25639227 0.12168793 0.62191975]\n",
            "[0.05786061 0.4750808  0.46705854]\n",
            "[0.02816118 0.02719801 0.9446408 ]\n",
            "[0.08669315 0.19801947 0.7152874 ]\n",
            "[0.80765384 0.17307284 0.01927333]\n",
            "[0.1152803  0.80979127 0.07492843]\n",
            "[0.5223543 0.1349302 0.3427155]\n",
            "[0.9113535  0.07072607 0.01792051]\n",
            "[0.02473512 0.03609472 0.9391702 ]\n",
            "[0.13504626 0.48780948 0.37714428]\n",
            "[0.6037825  0.04848694 0.34773055]\n",
            "[0.0824459  0.55271816 0.36483595]\n",
            "[0.06002548 0.09521402 0.84476054]\n",
            "[0.15199402 0.1499199  0.6980861 ]\n",
            "[0.6542135  0.29010594 0.05568052]\n",
            "[0.65467024 0.15077728 0.19455244]\n",
            "[0.03322629 0.02814002 0.93863374]\n",
            "[0.18734194 0.05088928 0.7617688 ]\n",
            "[0.07368205 0.0336886  0.8926293 ]\n",
            "[0.26298702 0.7073335  0.0296795 ]\n",
            "[0.90238714 0.0444719  0.05314093]\n",
            "[0.08484444 0.08050992 0.8346457 ]\n",
            "[0.6937429  0.23651172 0.06974536]\n",
            "[0.56399536 0.15365653 0.28234813]\n",
            "[0.92504704 0.05867264 0.01628036]\n",
            "[0.03045533 0.11559237 0.8539523 ]\n",
            "[0.10168087 0.80963194 0.0886872 ]\n",
            "[0.10427903 0.45029965 0.44542137]\n",
            "[0.38448268 0.42154413 0.19397314]\n",
            "[0.8591748  0.11123492 0.02959029]\n",
            "[0.03418618 0.05895868 0.90685517]\n",
            "[0.46603194 0.0475448  0.48642322]\n",
            "[0.1772275 0.2603405 0.562432 ]\n",
            "[0.03970868 0.02839158 0.9318997 ]\n",
            "[0.2101732  0.06077398 0.72905284]\n",
            "[0.02414961 0.04246086 0.93338954]\n",
            "[0.03943943 0.02872566 0.93183494]\n",
            "[0.88863295 0.09584405 0.01552305]\n",
            "[0.02258738 0.04399994 0.93341273]\n",
            "[0.03099694 0.03315138 0.93585175]\n",
            "[0.93419534 0.05086651 0.0149381 ]\n",
            "[0.3941739  0.52274805 0.08307806]\n",
            "[0.87530637 0.09420232 0.03049132]\n",
            "[0.8105992  0.16827399 0.02112681]\n",
            "[0.23887587 0.06304535 0.69807875]\n",
            "[0.55879587 0.39985093 0.04135319]\n",
            "[0.07497627 0.85735977 0.06766398]\n",
            "[0.10513636 0.13233855 0.7625251 ]\n",
            "[0.9436428  0.03929966 0.01705753]\n",
            "[0.19887902 0.4289242  0.37219676]\n",
            "[0.9186152  0.05849019 0.02289456]\n",
            "[0.09666172 0.6601709  0.24316736]\n",
            "[0.08041982 0.03902172 0.88055843]\n",
            "[0.1358804  0.69695324 0.16716638]\n",
            "[0.11899743 0.31133604 0.5696665 ]\n",
            "[0.02994139 0.0257812  0.9442774 ]\n",
            "[0.9347286  0.05088031 0.0143911 ]\n",
            "[0.45169348 0.5204867  0.02781983]\n",
            "[0.87806666 0.0391575  0.08277587]\n",
            "[0.27420324 0.57096875 0.15482797]\n",
            "[0.9388428  0.04181323 0.01934406]\n",
            "[0.8747462  0.07226004 0.05299371]\n",
            "[0.93519473 0.04382596 0.02097928]\n",
            "[0.9062736  0.08008071 0.01364569]\n",
            "[0.02445966 0.04117707 0.9343633 ]\n",
            "[0.08052871 0.33370298 0.58576834]\n",
            "[0.24472836 0.64012724 0.11514439]\n",
            "[0.16394378 0.08272041 0.7533358 ]\n",
            "[0.03039594 0.0290265  0.94057757]\n",
            "[0.3489578  0.12969136 0.52135086]\n",
            "[0.48870632 0.41026363 0.10103004]\n",
            "[0.11820169 0.23835135 0.643447  ]\n",
            "[0.9389319  0.04423056 0.01683757]\n",
            "[0.92785877 0.0587103  0.01343083]\n",
            "[0.02062532 0.05141249 0.92796224]\n",
            "[0.9227824  0.05415033 0.02306726]\n",
            "[0.936543   0.04407467 0.01938239]\n",
            "[0.06229033 0.03383162 0.9038781 ]\n",
            "[0.09934574 0.11758641 0.7830678 ]\n",
            "[0.3573527  0.567716   0.07493133]\n",
            "[0.37469012 0.51275337 0.11255651]\n",
            "[0.9322985  0.04798705 0.01971452]\n",
            "[0.7187182  0.25983924 0.02144258]\n",
            "[0.65663505 0.3252304  0.01813462]\n",
            "[0.0530352  0.02915666 0.9178082 ]\n",
            "[0.07084037 0.05481829 0.8743413 ]\n",
            "[0.11541211 0.04540063 0.83918726]\n",
            "[0.07298913 0.84839886 0.07861198]\n",
            "[0.93088615 0.03872339 0.03039046]\n",
            "[0.86474824 0.12039989 0.01485177]\n",
            "[0.90763414 0.07759305 0.01477273]\n",
            "[0.7034429  0.07959192 0.21696524]\n",
            "[0.5499357  0.25728536 0.1927789 ]\n",
            "[0.17146154 0.6954999  0.13303852]\n",
            "[0.35804424 0.10409543 0.5378603 ]\n",
            "[0.03275813 0.02844661 0.93879527]\n",
            "[0.81880355 0.16724361 0.01395277]\n",
            "[0.9159304  0.06881914 0.01525054]\n",
            "[0.5349952  0.42098093 0.04402383]\n",
            "[0.7628073  0.0675949  0.16959776]\n",
            "[0.7933177  0.18872945 0.01795285]\n",
            "[0.89508945 0.08936205 0.01554857]\n",
            "[0.05208284 0.5913542  0.35656297]\n",
            "[0.10412515 0.1461196  0.74975526]\n",
            "[0.10164525 0.84685445 0.05150033]\n",
            "[0.08589341 0.05752998 0.8565766 ]\n",
            "[0.06314276 0.04025044 0.89660674]\n",
            "[0.8419457  0.10094047 0.05711386]\n",
            "[0.06857992 0.06274422 0.8686758 ]\n",
            "[0.9275822  0.0508405  0.02157729]\n",
            "[0.9424009  0.04192749 0.01567165]\n",
            "[0.04320191 0.0334397  0.9233583 ]\n",
            "[0.03716255 0.03591676 0.92692065]\n",
            "[0.03106677 0.35693738 0.6119958 ]\n",
            "[0.5099785  0.45526206 0.0347595 ]\n",
            "[0.21935636 0.7194731  0.06117056]\n",
            "[0.25127164 0.7056784  0.04304997]\n",
            "[0.444832   0.5238963  0.03127166]\n",
            "[0.06111129 0.08472858 0.8541602 ]\n",
            "[0.8422024  0.1330104  0.02478713]\n",
            "[0.06810125 0.8557357  0.07616305]\n",
            "[0.7630893  0.17374615 0.06316458]\n",
            "[0.911978   0.07534481 0.01267715]\n",
            "[0.77836317 0.07776096 0.14387582]\n",
            "[0.70371974 0.23680378 0.05947646]\n",
            "[0.1533977  0.349937   0.49666527]\n",
            "[0.40552774 0.13652003 0.45795223]\n",
            "[0.17632078 0.5638987  0.25978053]\n",
            "[0.4915449  0.45461488 0.05384017]\n",
            "[0.48645166 0.48611984 0.02742852]\n",
            "[0.02097325 0.09203073 0.88699603]\n",
            "[0.7990164  0.08543701 0.11554652]\n",
            "[0.8854453  0.05003365 0.06452108]\n",
            "[0.9350832  0.05051491 0.01440193]\n",
            "[0.92959666 0.05473026 0.01567303]\n",
            "[0.02163252 0.03254459 0.9458229 ]\n",
            "[0.02885638 0.03097554 0.940168  ]\n",
            "[0.40464354 0.15773751 0.43761894]\n",
            "[0.91723466 0.05286216 0.02990317]\n",
            "[0.5998075  0.21622053 0.183972  ]\n",
            "[0.8575977  0.11118129 0.03122102]\n",
            "[0.04173832 0.02831578 0.92994595]\n",
            "[0.0561852  0.0301285  0.91368634]\n",
            "[0.13240924 0.0542383  0.81335247]\n",
            "[0.5611872  0.22192746 0.21688534]\n",
            "[0.07383586 0.06816493 0.85799915]\n",
            "[0.1347518  0.74671084 0.11853737]\n",
            "[0.8763899  0.07808046 0.04552958]\n",
            "[0.14182001 0.6185328  0.23964721]\n",
            "[0.05220112 0.03156668 0.9162322 ]\n",
            "[0.53479016 0.39590085 0.06930903]\n",
            "[0.893837   0.08884014 0.01732282]\n",
            "[0.90983254 0.05266419 0.03750324]\n",
            "[0.64327    0.33049786 0.02623213]\n",
            "[0.05632044 0.04915085 0.89452875]\n",
            "[0.6888108 0.0530341 0.2581551]\n",
            "[0.03314842 0.03201663 0.93483496]\n",
            "[0.2774698  0.15709321 0.565437  ]\n",
            "[0.0785815  0.06126594 0.8601526 ]\n",
            "[0.27771866 0.07263269 0.64964867]\n",
            "[0.15762322 0.64867944 0.19369726]\n",
            "[0.540444   0.37993294 0.07962303]\n",
            "[0.1351287  0.82429045 0.04058076]\n",
            "[0.9404533  0.04284523 0.0167015 ]\n",
            "[0.39818603 0.5593419  0.04247207]\n",
            "[0.92830646 0.05326796 0.01842555]\n",
            "[0.87800443 0.08594471 0.03605083]\n",
            "[0.78398454 0.04923101 0.1667845 ]\n",
            "[0.81667435 0.05791308 0.1254125 ]\n",
            "[0.13317251 0.13545844 0.731369  ]\n",
            "[0.9268108  0.05479049 0.01839878]\n",
            "[0.42093354 0.55429286 0.02477361]\n",
            "[0.9408546  0.0428101  0.01633519]\n",
            "[0.8834882  0.102162   0.01434985]\n",
            "[0.5541692  0.41521534 0.0306155 ]\n",
            "[0.05692599 0.02924489 0.91382915]\n",
            "[0.7146818  0.26446635 0.02085182]\n",
            "[0.18215625 0.2626092  0.5552345 ]\n",
            "[0.51240456 0.44625822 0.04133719]\n",
            "[0.90672606 0.07036702 0.02290687]\n",
            "[0.5065529  0.4524674  0.04097977]\n",
            "[0.73409146 0.24641497 0.01949362]\n",
            "[0.35619578 0.61144334 0.03236092]\n",
            "[0.34385547 0.5987968  0.05734779]\n",
            "[0.0285769  0.03486671 0.93655634]\n",
            "[0.02013837 0.09794132 0.8819203 ]\n",
            "[0.02718393 0.0273133  0.94550276]\n",
            "[0.87817055 0.10622551 0.01560402]\n",
            "[0.33047503 0.63124865 0.0382763 ]\n",
            "[0.30208415 0.17457798 0.5233379 ]\n",
            "[0.27819994 0.67233646 0.04946364]\n",
            "[0.05172717 0.09468104 0.85359174]\n",
            "[0.3662006  0.56969345 0.06410592]\n",
            "[0.5691145  0.05160955 0.37927595]\n",
            "[0.04618401 0.0387497  0.91506624]\n",
            "[0.853048   0.0608155  0.08613648]\n",
            "[0.6988699  0.06912125 0.23200886]\n",
            "[0.6222843  0.3371184  0.04059733]\n",
            "[0.8069832  0.09438468 0.09863213]\n",
            "[0.0557677  0.05790551 0.8863268 ]\n",
            "[0.054386  0.8131957 0.1324183]\n",
            "[0.05731501 0.13718174 0.8055033 ]\n",
            "[0.93319994 0.05081318 0.01598683]\n",
            "[0.8896041  0.09275203 0.01764392]\n",
            "[0.16966961 0.74362695 0.08670346]\n",
            "[0.04373173 0.04848691 0.90778136]\n",
            "[0.03070985 0.0301832  0.939107  ]\n",
            "[0.93690294 0.04878414 0.01431303]\n",
            "[0.8306742  0.14555939 0.02376644]\n",
            "[0.88961333 0.09746289 0.01292379]\n",
            "[0.9179838  0.06712544 0.01489072]\n",
            "[0.18488161 0.7498936  0.06522482]\n",
            "[0.13782696 0.28828782 0.57388526]\n",
            "[0.8232227  0.15987152 0.01690578]\n",
            "[0.08456079 0.6262257  0.28921354]\n",
            "[0.03935995 0.02460881 0.9360312 ]\n",
            "[0.15158926 0.06092342 0.7874873 ]\n",
            "[0.9063116  0.07979187 0.01389652]\n",
            "[0.9380539  0.04389305 0.01805313]\n",
            "[0.27037188 0.6941648  0.03546328]\n",
            "[0.22004998 0.75118756 0.02876244]\n",
            "[0.15241297 0.23401357 0.61357343]\n",
            "[0.20513108 0.1342632  0.6606057 ]\n",
            "[0.04565693 0.23429094 0.72005206]\n",
            "[0.9372381  0.04160459 0.02115729]\n",
            "[0.70723    0.23524098 0.05752909]\n",
            "[0.91213846 0.04872193 0.03913964]\n",
            "[0.826003   0.15686856 0.01712846]\n",
            "[0.03595806 0.02683433 0.93720764]\n",
            "[0.41519645 0.49509743 0.0897061 ]\n",
            "[0.94162947 0.04208041 0.01629006]\n",
            "[0.02571495 0.12200047 0.85228455]\n",
            "[0.10847186 0.51077276 0.3807554 ]\n",
            "[0.03768859 0.04506839 0.91724294]\n",
            "[0.04681707 0.7580435  0.19513936]\n",
            "[0.20817691 0.55319566 0.2386274 ]\n",
            "[0.04358649 0.04719942 0.9092141 ]\n",
            "[0.3238739  0.5955488  0.08057726]\n",
            "[0.23953651 0.7109303  0.0495332 ]\n",
            "[0.31293637 0.63261455 0.05444909]\n",
            "[0.253988   0.6901074  0.05590462]\n",
            "[0.91829705 0.06771589 0.01398698]\n",
            "[0.05502203 0.03797484 0.9070031 ]\n",
            "[0.5650959 0.1472963 0.2876078]\n",
            "[0.44481885 0.5188078  0.03637326]\n",
            "[0.16545323 0.09008991 0.7444568 ]\n",
            "[0.8588814  0.12555148 0.01556711]\n",
            "[0.04808527 0.6406359  0.31127885]\n",
            "[0.9227566  0.04664899 0.03059442]\n",
            "[0.14100921 0.26564303 0.5933477 ]\n",
            "[0.13667245 0.03614231 0.8271853 ]\n",
            "[0.9393857  0.04422555 0.01638883]\n",
            "[0.31139538 0.14309597 0.5455087 ]\n",
            "[0.17874064 0.11237308 0.7088862 ]\n",
            "[0.83096415 0.05446733 0.11456857]\n",
            "[0.05850142 0.3147009  0.62679774]\n",
            "[0.8965022  0.08382769 0.01967013]\n",
            "[0.27661762 0.69498616 0.02839627]\n",
            "[0.02199499 0.04876665 0.9292383 ]\n",
            "[0.032823   0.02947884 0.9376981 ]\n",
            "[0.08076327 0.57791    0.3413267 ]\n",
            "[0.02926379 0.02868848 0.9420477 ]\n",
            "[0.02402299 0.04952832 0.92644864]\n",
            "[0.20770486 0.5635662  0.22872894]\n",
            "[0.82083005 0.1034524  0.07571758]\n",
            "[0.23336405 0.6996728  0.06696317]\n",
            "[0.92482996 0.04689121 0.02827879]\n",
            "[0.33163437 0.46909463 0.19927104]\n",
            "[0.86328167 0.0530276  0.08369076]\n",
            "[0.52891034 0.43722686 0.03386283]\n",
            "[0.20038535 0.04822164 0.751393  ]\n",
            "[0.72951066 0.20661415 0.06387522]\n",
            "[0.02723444 0.02951754 0.943248  ]\n",
            "[0.9376332  0.04832152 0.01404522]\n",
            "[0.7714968  0.12309592 0.10540724]\n",
            "[0.15978841 0.07293274 0.76727885]\n",
            "[0.1403438  0.06158936 0.7980668 ]\n",
            "[0.03708433 0.02986233 0.9330534 ]\n",
            "[0.9444618  0.03938352 0.01615467]\n",
            "[0.9173388  0.05771521 0.02494602]\n",
            "[0.08551355 0.10300639 0.8114801 ]\n",
            "[0.25193065 0.51159143 0.23647793]\n",
            "[0.9101453  0.06150674 0.02834802]\n",
            "[0.8945109  0.09286697 0.01262212]\n",
            "[0.9140964  0.06929146 0.01661202]\n",
            "[0.2687472  0.03540774 0.69584507]\n",
            "[0.8903331  0.0550881  0.05457887]\n",
            "[0.21508959 0.06040677 0.72450364]\n",
            "[0.88441646 0.0985625  0.01702103]\n",
            "[0.9340104  0.03975385 0.02623574]\n",
            "[0.12684903 0.15882449 0.71432656]\n",
            "[0.2467671  0.09811453 0.65511835]\n",
            "[0.04604296 0.02716977 0.92678726]\n",
            "[0.10494502 0.19481228 0.7002427 ]\n",
            "[0.9356918  0.04984039 0.01446781]\n",
            "[0.78560096 0.10960962 0.10478935]\n",
            "[0.89302605 0.04485481 0.0621192 ]\n",
            "[0.10408605 0.71701384 0.17890008]\n",
            "[0.64902204 0.33341384 0.01756407]\n",
            "[0.27752823 0.4954179  0.2270538 ]\n",
            "[0.72398734 0.23382744 0.04218527]\n",
            "[0.26686186 0.55312407 0.18001407]\n",
            "[0.23179702 0.40801078 0.36019215]\n",
            "[0.046212  0.0283466 0.9254414]\n",
            "[0.03510663 0.03205322 0.93284017]\n",
            "[0.05630817 0.03549833 0.90819347]\n",
            "[0.20845631 0.62180454 0.16973914]\n",
            "[0.37903053 0.59202766 0.02894181]\n",
            "[0.2057578  0.7464095  0.04783276]\n",
            "[0.23750485 0.7004847  0.06201043]\n",
            "[0.12096996 0.16791633 0.7111137 ]\n",
            "[0.25025728 0.39273617 0.35700658]\n",
            "[0.9211485  0.05847483 0.02037667]\n",
            "[0.06455519 0.03078187 0.9046629 ]\n",
            "[0.03051857 0.02728159 0.9421999 ]\n",
            "[0.9316158  0.04107255 0.02731163]\n",
            "[0.13786355 0.12079873 0.74133766]\n",
            "[0.06727316 0.03204099 0.90068585]\n",
            "[0.07852119 0.06863491 0.8528439 ]\n",
            "[0.91085625 0.07448588 0.01465793]\n",
            "[0.09499875 0.7724729  0.13252836]\n",
            "[0.03691862 0.03191441 0.931167  ]\n",
            "[0.87850004 0.10043474 0.02106519]\n",
            "[0.02983556 0.02960079 0.9405637 ]\n",
            "[0.5986587  0.27400845 0.12733285]\n",
            "[0.06308967 0.05939934 0.877511  ]\n",
            "[0.19496964 0.46167383 0.34335652]\n",
            "[0.6270759  0.31528875 0.05763535]\n",
            "[0.64573425 0.32475895 0.02950682]\n",
            "[0.07333267 0.05187697 0.8747904 ]\n",
            "[0.03485168 0.0896162  0.8755321 ]\n",
            "[0.03304889 0.0340388  0.93291235]\n",
            "[0.03577792 0.02869266 0.9355294 ]\n",
            "[0.08079367 0.09349015 0.8257162 ]\n",
            "[0.7538375  0.21862715 0.02753536]\n",
            "[0.9399293  0.04175753 0.01831322]\n",
            "[0.2567558  0.69673663 0.04650759]\n",
            "[0.05218536 0.03341487 0.9143998 ]\n",
            "[0.10206691 0.40084842 0.49708468]\n",
            "[0.09692056 0.17390178 0.7291776 ]\n",
            "[0.92544025 0.0456964  0.0288633 ]\n",
            "[0.17783827 0.6111106  0.21105114]\n",
            "[0.66666687 0.30810726 0.0252259 ]\n",
            "[0.94564223 0.03965838 0.01469938]\n",
            "[0.08932696 0.09536501 0.81530803]\n",
            "[0.9164365  0.06999766 0.01356582]\n",
            "[0.8366923  0.14211507 0.0211927 ]\n",
            "[0.17432497 0.1695826  0.6560924 ]\n",
            "[0.0474195  0.07801745 0.8745631 ]\n",
            "[0.8433055  0.1392486  0.01744586]\n",
            "[0.5035786  0.34584925 0.15057215]\n",
            "[0.66926533 0.30883816 0.02189652]\n",
            "[0.04889547 0.05480537 0.8962991 ]\n",
            "[0.5527259  0.16180788 0.28546625]\n",
            "[0.24206986 0.07526207 0.6826681 ]\n",
            "[0.02124305 0.0537464  0.92501056]\n",
            "[0.06924894 0.0424591  0.88829195]\n",
            "[0.3012453  0.65644985 0.04230488]\n",
            "[0.23169245 0.7357603  0.03254733]\n",
            "[0.10813002 0.11981589 0.772054  ]\n",
            "[0.54184663 0.2946214  0.16353205]\n",
            "[0.93793654 0.04220943 0.01985404]\n",
            "[0.856342   0.1276327  0.01602533]\n",
            "[0.89971    0.08127948 0.01901051]\n",
            "[0.90754575 0.05355217 0.0389021 ]\n",
            "[0.9271557  0.05069324 0.02215106]\n",
            "[0.74729854 0.08984908 0.16285235]\n",
            "[0.46780986 0.11470379 0.41748634]\n",
            "[0.4673451  0.2040906  0.32856435]\n",
            "[0.9337859  0.05222517 0.0139889 ]\n",
            "[0.810335   0.1723662  0.01729888]\n",
            "[0.0798206  0.8336316  0.08654784]\n",
            "[0.0798206  0.8336316  0.08654784]\n",
            "[0.93569964 0.04921772 0.01508266]\n",
            "[0.92458594 0.05390944 0.02150461]\n",
            "[0.2034809  0.24368529 0.5528338 ]\n",
            "[0.27425572 0.47577912 0.24996515]\n",
            "[0.90688527 0.05666082 0.03645384]\n",
            "[0.3096363  0.59878534 0.09157839]\n",
            "[0.8972592  0.08957179 0.013169  ]\n",
            "[0.83752704 0.14654933 0.01592362]\n",
            "[0.5718024  0.40536135 0.0228363 ]\n",
            "[0.04547305 0.7279534  0.22657356]\n",
            "[0.69548297 0.26159003 0.04292699]\n",
            "[0.53370756 0.0796485  0.38664395]\n",
            "[0.02271569 0.03864753 0.9386368 ]\n",
            "[0.31577373 0.09897245 0.58525383]\n",
            "[0.16483498 0.78059363 0.05457139]\n",
            "[0.07240812 0.84157056 0.08602126]\n",
            "[0.5953669  0.37825245 0.02638064]\n",
            "[0.74332863 0.23900495 0.01766644]\n",
            "[0.34929854 0.49282917 0.15787224]\n",
            "[0.06903197 0.8626506  0.0683175 ]\n",
            "[0.5613387  0.37441373 0.06424753]\n",
            "[0.64520454 0.28164658 0.07314885]\n",
            "[0.83074886 0.12657373 0.04267737]\n",
            "[0.7642207  0.21289966 0.02287956]\n",
            "[0.68553394 0.2917546  0.02271141]\n",
            "[0.7055562  0.27540758 0.01903628]\n",
            "[0.08586186 0.0913282  0.82280993]\n",
            "[0.84628946 0.13489062 0.01881987]\n",
            "[0.26793823 0.07941742 0.6526444 ]\n",
            "[0.6895931  0.04545868 0.26494822]\n",
            "[0.37283552 0.5746282  0.0525363 ]\n",
            "[0.6868141  0.05951656 0.25366935]\n",
            "[0.9412464  0.03711911 0.02163455]\n",
            "[0.4953602  0.2149517  0.28968817]\n",
            "[0.85048395 0.1284206  0.02109536]\n",
            "[0.05247012 0.03349532 0.91403455]\n",
            "[0.6081227  0.1984635  0.19341375]\n",
            "[0.36129025 0.12917398 0.5095358 ]\n",
            "[0.10179924 0.12120581 0.7769949 ]\n",
            "[0.39336982 0.5716982  0.034932  ]\n",
            "[0.939957   0.04404503 0.0159979 ]\n",
            "[0.62553734 0.25661668 0.11784602]\n",
            "[0.9240084  0.03755366 0.0384379 ]\n",
            "[0.91856736 0.06210767 0.01932496]\n",
            "[0.21155982 0.39946905 0.38897112]\n",
            "[0.2596369  0.15968792 0.5806751 ]\n",
            "[0.9369034  0.04012347 0.02297314]\n",
            "[0.6292073  0.3059963  0.06479649]\n",
            "[0.12968768 0.6604249  0.20988742]\n",
            "[0.17640696 0.10768494 0.71590805]\n",
            "[0.16192502 0.32801566 0.5100593 ]\n",
            "[0.85900205 0.12506442 0.01593346]\n",
            "[0.9116956  0.0733735  0.01493094]\n",
            "[0.04870822 0.03592102 0.91537076]\n",
            "[0.77682054 0.20337208 0.01980737]\n",
            "[0.06195236 0.8439923  0.09405538]\n",
            "[0.49354044 0.45973903 0.04672054]\n",
            "[0.12607352 0.25073588 0.6231906 ]\n",
            "[0.27039143 0.6626651  0.06694346]\n",
            "[0.47311613 0.11236202 0.4145219 ]\n",
            "[0.06061152 0.03649689 0.90289164]\n",
            "[0.02190387 0.03223311 0.94586307]\n",
            "[0.20672087 0.6133472  0.17993197]\n",
            "[0.06092884 0.04678228 0.8922889 ]\n",
            "[0.03636811 0.03336536 0.93026656]\n",
            "[0.04858325 0.03845053 0.91296625]\n",
            "[0.04124666 0.03027869 0.92847466]\n",
            "[0.9203182  0.05948938 0.02019242]\n",
            "[0.38108668 0.5851605  0.03375285]\n",
            "[0.29519188 0.6658708  0.03893734]\n",
            "[0.6854461  0.27560487 0.03894903]\n",
            "[0.0729606  0.02837499 0.8986644 ]\n",
            "[0.03780617 0.06040085 0.90179294]\n",
            "[0.56035125 0.38839892 0.05124985]\n",
            "[0.07029618 0.03941822 0.8902857 ]\n",
            "[0.70838374 0.26181716 0.02979914]\n",
            "[0.16264655 0.70897835 0.12837508]\n",
            "[0.93894625 0.04191131 0.0191424 ]\n",
            "[0.9299682  0.04712536 0.02290637]\n",
            "[0.03187428 0.03376269 0.93436295]\n",
            "[0.05884399 0.04521225 0.8959437 ]\n",
            "[0.0336218  0.03090837 0.93546987]\n",
            "[0.03066147 0.02704783 0.94229066]\n",
            "[0.02658514 0.02970609 0.9437087 ]\n",
            "[0.27354684 0.08334152 0.64311165]\n",
            "[0.2426941  0.6713648  0.08594122]\n",
            "[0.1065695  0.04249443 0.8509361 ]\n",
            "[0.40776527 0.5595102  0.03272454]\n",
            "[0.16782609 0.78131396 0.05085995]\n",
            "[0.31499004 0.42109093 0.26391903]\n",
            "[0.32834247 0.40633303 0.26532444]\n",
            "[0.02894747 0.2578319  0.71322066]\n",
            "[0.5059142  0.47192386 0.02216191]\n",
            "[0.8282251  0.1577512  0.01402373]\n",
            "[0.9435388  0.04139423 0.015067  ]\n",
            "[0.5701176  0.16741413 0.26246828]\n",
            "[0.70537937 0.2665403  0.02808035]\n",
            "[0.10289049 0.15257388 0.74453557]\n",
            "[0.13454373 0.6808598  0.18459648]\n",
            "[0.03226958 0.03805896 0.92967147]\n",
            "[0.8929286  0.06059141 0.04648001]\n",
            "[0.02402504 0.13687202 0.839103  ]\n",
            "[0.15847966 0.71319515 0.1283252 ]\n",
            "[0.620568   0.35103527 0.02839678]\n",
            "[0.54951465 0.4120682  0.03841719]\n",
            "[0.91697115 0.05061239 0.03241648]\n",
            "[0.922783   0.03534286 0.04187413]\n",
            "[0.14009765 0.77178425 0.08811802]\n",
            "[0.09068719 0.8191964  0.09011643]\n",
            "[0.4882173  0.48811725 0.02366552]\n",
            "[0.27197725 0.6868193  0.04120335]\n",
            "[0.49265343 0.4809865  0.02636009]\n",
            "[0.04030991 0.32748935 0.6322008 ]\n",
            "[0.8882148  0.0947401  0.01704511]\n",
            "[0.9198176  0.0351851  0.04499735]\n",
            "[0.3139176  0.05071324 0.6353692 ]\n",
            "[0.5148355  0.40316507 0.08199945]\n",
            "[0.86953676 0.11207526 0.01838798]\n",
            "[0.8055556  0.15645579 0.03798859]\n",
            "[0.7603338  0.12476639 0.11489987]\n",
            "[0.9081093  0.04027795 0.05161282]\n",
            "[0.23851524 0.6855723  0.07591239]\n",
            "[0.35608295 0.43931815 0.2045989 ]\n",
            "[0.60485923 0.33707222 0.05806849]\n",
            "[0.92896223 0.05593444 0.01510327]\n",
            "[0.93215746 0.04944459 0.01839799]\n",
            "[0.04354446 0.03100511 0.9254504 ]\n",
            "[0.38512862 0.5485674  0.06630397]\n",
            "[0.03846128 0.04735223 0.9141865 ]\n",
            "[0.0792521  0.03520913 0.8855388 ]\n",
            "[0.11825177 0.05241716 0.8293311 ]\n",
            "[0.90775645 0.06152898 0.03071467]\n",
            "[0.87339294 0.11151339 0.01509367]\n",
            "[0.0348164  0.02929837 0.93588525]\n",
            "[0.0710393  0.04265176 0.8863089 ]\n",
            "[0.77909017 0.07248949 0.14842035]\n",
            "[0.04152141 0.03094062 0.927538  ]\n",
            "[0.05574387 0.6244134  0.3198428 ]\n",
            "[0.90236396 0.083143   0.01449306]\n",
            "[0.02567873 0.03300899 0.9413123 ]\n",
            "[0.06685843 0.03117216 0.90196943]\n",
            "[0.92821187 0.05290278 0.01888529]\n",
            "[0.94077307 0.03689745 0.02232951]\n",
            "[0.10004065 0.07903266 0.82092667]\n",
            "[0.5631568  0.13851126 0.29833198]\n",
            "[0.18869998 0.15405029 0.65724975]\n",
            "[0.8882228  0.0464886  0.06528868]\n",
            "[0.0324403  0.02948983 0.9380698 ]\n",
            "[0.85845643 0.12095463 0.02058898]\n",
            "[0.6734328  0.29740888 0.02915826]\n",
            "[0.23133758 0.38969263 0.37896985]\n",
            "[0.23102763 0.24040788 0.5285645 ]\n",
            "[0.94212365 0.04286358 0.01501282]\n",
            "[0.92488134 0.06230582 0.01281287]\n",
            "[0.7356301  0.06052513 0.20384479]\n",
            "[0.94018155 0.03944702 0.02037143]\n",
            "[0.7021613 0.277105  0.0207337]\n",
            "[0.9438954  0.04236618 0.01373832]\n",
            "[0.8377035  0.09232903 0.06996749]\n",
            "[0.93443865 0.04471136 0.02084998]\n",
            "[0.935284   0.04698684 0.01772922]\n",
            "[0.05175797 0.86203    0.08621204]\n",
            "[0.26710546 0.69835037 0.03454408]\n",
            "[0.4721888  0.41047037 0.11734086]\n",
            "[0.02031237 0.05531864 0.924369  ]\n",
            "[0.3520375 0.3490297 0.2989328]\n",
            "[0.16933843 0.50161135 0.32905018]\n",
            "[0.2027172  0.5476842  0.24959865]\n",
            "[0.24656528 0.5911806  0.16225417]\n",
            "[0.07446617 0.05324468 0.8722892 ]\n",
            "[0.04507218 0.6807184  0.2742094 ]\n",
            "[0.4967268  0.44376194 0.05951122]\n",
            "[0.03069885 0.02834222 0.94095886]\n",
            "[0.09267815 0.04571305 0.8616088 ]\n",
            "[0.05646255 0.12566605 0.81787145]\n",
            "[0.20593418 0.61850834 0.17555746]\n",
            "[0.08079637 0.03737381 0.8818298 ]\n",
            "[0.02760506 0.02813173 0.9442632 ]\n",
            "[0.5500657  0.12247342 0.3274609 ]\n",
            "[0.05246293 0.81008506 0.13745205]\n",
            "[0.04339881 0.04228045 0.91432077]\n",
            "[0.0288246 0.1434639 0.8277115]\n",
            "[0.2233583  0.7280985  0.04854316]\n",
            "[0.9359922  0.04672852 0.01727938]\n",
            "[0.03503001 0.02713425 0.93783575]\n",
            "[0.14435835 0.6936509  0.16199072]\n",
            "[0.18974026 0.6549838  0.15527588]\n",
            "[0.0373216  0.0297091  0.93296933]\n",
            "[0.16104338 0.04892063 0.790036  ]\n",
            "[0.41794357 0.41547725 0.16657917]\n",
            "[0.7712136  0.07229069 0.15649569]\n",
            "[0.830679   0.14861621 0.02070481]\n",
            "[0.8959638  0.08864348 0.01539276]\n",
            "[0.08924164 0.81238526 0.09837317]\n",
            "[0.51322275 0.42164847 0.06512879]\n",
            "[0.12593764 0.52875304 0.3453093 ]\n",
            "[0.07286993 0.841015   0.08611512]\n",
            "[0.8773184  0.10854543 0.01413615]\n",
            "[0.9211589  0.0633961  0.01544496]\n",
            "[0.10966268 0.07219548 0.8181419 ]\n",
            "[0.17440085 0.773106   0.05249324]\n",
            "[0.6374259  0.31901622 0.04355789]\n",
            "[0.576636   0.11601599 0.30734798]\n",
            "[0.11100701 0.8458179  0.04317507]\n",
            "[0.52602386 0.43733433 0.03664179]\n",
            "[0.9045805  0.07127843 0.02414114]\n",
            "[0.8898385  0.09190019 0.01826126]\n",
            "[0.09377248 0.04703906 0.8591885 ]\n",
            "[0.07109838 0.6982038  0.23069786]\n",
            "[0.06097212 0.04138662 0.89764124]\n",
            "[0.27259782 0.28828725 0.4391149 ]\n",
            "[0.03492711 0.03014002 0.9349328 ]\n",
            "[0.03139946 0.02883144 0.9397691 ]\n",
            "[0.74322945 0.23352107 0.02324953]\n",
            "[0.5591495  0.41227278 0.02857775]\n",
            "[0.22116838 0.08247785 0.6963538 ]\n",
            "[0.42629948 0.19828719 0.37541336]\n",
            "[0.04691882 0.03743085 0.91565037]\n",
            "[0.07904422 0.14722021 0.77373564]\n",
            "[0.941233   0.04422692 0.01454017]\n",
            "[0.93519735 0.04938081 0.01542182]\n",
            "[0.92540884 0.05896865 0.01562248]\n",
            "[0.77659047 0.14927068 0.07413892]\n",
            "[0.04123572 0.66644526 0.29231894]\n",
            "[0.1689945  0.04729642 0.78370905]\n",
            "[0.54748434 0.16576146 0.28675422]\n",
            "[0.04608827 0.04893827 0.90497345]\n",
            "[0.92135215 0.05566056 0.02298729]\n",
            "[0.7781808  0.08588788 0.13593145]\n",
            "[0.03317701 0.03325912 0.9335638 ]\n",
            "[0.03460976 0.04057987 0.92481035]\n",
            "[0.31676456 0.5146152  0.16862027]\n",
            "[0.7047211  0.25773638 0.03754256]\n",
            "[0.7047211  0.25773638 0.03754256]\n",
            "[0.0263993  0.02940289 0.9441978 ]\n",
            "[0.19733661 0.6989634  0.10369998]\n",
            "[0.9281742  0.05836314 0.01346268]\n",
            "[0.3500622  0.5743406  0.07559721]\n",
            "[0.8871157  0.03448707 0.07839724]\n",
            "[0.92349523 0.06385925 0.01264555]\n",
            "[0.3824612  0.56320477 0.05433405]\n",
            "[0.93738264 0.04652047 0.01609697]\n",
            "[0.34243917 0.595129   0.06243177]\n",
            "[0.10656787 0.7967464  0.0966858 ]\n",
            "[0.6532784  0.32250848 0.0242132 ]\n",
            "[0.9067101  0.07556573 0.0177242 ]\n",
            "[0.309097   0.321235   0.36966807]\n",
            "[0.2562938  0.7070039  0.03670237]\n",
            "[0.07452343 0.07217478 0.8533018 ]\n",
            "[0.06618793 0.3214056  0.6124065 ]\n",
            "[0.8517943  0.12955762 0.01864815]\n",
            "[0.90858763 0.06319406 0.02821834]\n",
            "[0.906284   0.06722408 0.02649196]\n",
            "[0.8672276  0.11585522 0.01691719]\n",
            "[0.4419412  0.20333946 0.35471934]\n",
            "[0.59812105 0.09904928 0.30282962]\n",
            "[0.57327485 0.38955742 0.03716769]\n",
            "[0.8618907  0.07486045 0.06324884]\n",
            "[0.0314872  0.03287862 0.9356342 ]\n",
            "[0.8922846  0.09496872 0.01274667]\n",
            "[0.30559722 0.6432466  0.05115628]\n",
            "[0.7291013  0.22722068 0.04367794]\n",
            "[0.38032228 0.37097177 0.24870592]\n",
            "[0.55748934 0.41406837 0.02844235]\n",
            "[0.03085214 0.04574599 0.92340183]\n",
            "[0.58562416 0.38485116 0.02952465]\n",
            "[0.41914174 0.51911694 0.06174136]\n",
            "[0.19090669 0.6808629  0.12823044]\n",
            "[0.8826502  0.09412428 0.0232256 ]\n",
            "[0.91364753 0.07379891 0.01255361]\n",
            "[0.8454619  0.12049283 0.03404519]\n",
            "[0.9159572  0.06961617 0.0144266 ]\n",
            "[0.06064495 0.05940801 0.879947  ]\n",
            "[0.3055067  0.650917   0.04357631]\n",
            "[0.8181867  0.07682224 0.10499106]\n",
            "[0.36664665 0.4023487  0.23100464]\n",
            "[0.22436789 0.70495486 0.07067724]\n",
            "[0.1369189  0.5023678  0.36071333]\n",
            "[0.21677355 0.7279794  0.05524702]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PmWUtXdLW1I",
        "colab_type": "code",
        "outputId": "2b1e1159-fe89-41f0-ac19-a9284ce3441b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  \n",
        "\n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "                 \n",
        "  matthews_set.append(matthews)\n",
        "  \n",
        " # print(pred_labels_i)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb--na-oLbVM",
        "colab_type": "code",
        "outputId": "c11b8808-c679-4c87-b243-1568bd0fb973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matthews_set\n",
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6aNsEuZMvjI",
        "colab_type": "code",
        "outputId": "fa30aecb-74b1-4aa6-e53f-5abf76dcf98b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/My Drive/FYP/bert/model-colab-task2malayalam'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/My Drive/FYP/bert/model-colab-task2malayalam\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/FYP/bert/model-colab-task2malayalam/vocab.txt',\n",
              " '/content/drive/My Drive/FYP/bert/model-colab-task2malayalam/special_tokens_map.json',\n",
              " '/content/drive/My Drive/FYP/bert/model-colab-task2malayalam/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}