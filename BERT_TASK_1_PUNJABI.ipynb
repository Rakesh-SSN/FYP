{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT TASK 1 PUNJABI",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0dd2d21b03194e0ba7d01e7328163de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2336f283e1194d5a924e699a84fb29ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0bc788450bd54d99a9ac686090f513bc",
              "IPY_MODEL_39b3da33c4cb43df96ed8bb9ebf44035"
            ]
          }
        },
        "2336f283e1194d5a924e699a84fb29ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bc788450bd54d99a9ac686090f513bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a89556249e464594825632717536b160",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_491079a27c4246f6a7b18360ef2e73c9"
          }
        },
        "39b3da33c4cb43df96ed8bb9ebf44035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_625c1b8cfd7b46ed8b78afc007e4c482",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 996k/996k [00:01&lt;00:00, 761kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74e23c8be4a04a788a62092e998aef8f"
          }
        },
        "a89556249e464594825632717536b160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "491079a27c4246f6a7b18360ef2e73c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "625c1b8cfd7b46ed8b78afc007e4c482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74e23c8be4a04a788a62092e998aef8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "681cb274a4344139ab68d369c69da450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4cf9a575cc2c43748980697e02e59426",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bb783446760e4b37b295cf69345aa58d",
              "IPY_MODEL_2464702b677e49978e124fdd4466ebc8"
            ]
          }
        },
        "4cf9a575cc2c43748980697e02e59426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb783446760e4b37b295cf69345aa58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e3a9edf7d69d4488a3b4cf26088ceef0",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 569,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 569,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2be50a8b2e9471cafaa22817202a776"
          }
        },
        "2464702b677e49978e124fdd4466ebc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a25dba9ce7347589585e655dd53dca4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 569/569 [00:00&lt;00:00, 18.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e25d05391934e32b073604ae411e318"
          }
        },
        "e3a9edf7d69d4488a3b4cf26088ceef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2be50a8b2e9471cafaa22817202a776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a25dba9ce7347589585e655dd53dca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e25d05391934e32b073604ae411e318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91fb6665a33e4fc280cf71550d814acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a5bd622766546708015866ca7bfc089",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4bdb0195860a441091c3bfae21d17697",
              "IPY_MODEL_dc5cabf180e64120888f58ce7ffd74bf"
            ]
          }
        },
        "5a5bd622766546708015866ca7bfc089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bdb0195860a441091c3bfae21d17697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b5eab7b8a2a84d6da4faea3fd918f144",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b350b3d95a8c47ad8a5e6a0a1fc92e3b"
          }
        },
        "dc5cabf180e64120888f58ce7ffd74bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9778dc4945bf4783bfac229177fb9383",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 714M/714M [01:13&lt;00:00, 9.67MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35cf037115ba4ad78356d28798d3147a"
          }
        },
        "b5eab7b8a2a84d6da4faea3fd918f144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b350b3d95a8c47ad8a5e6a0a1fc92e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9778dc4945bf4783bfac229177fb9383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35cf037115ba4ad78356d28798d3147a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakesh-SSN/FYP/blob/master/BERT_TASK_1_PUNJABI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN2gN6gr8nOJ",
        "colab_type": "code",
        "outputId": "d6ad82ae-9958-4a0b-e16d-f430552a28e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P4\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 31.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 64.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 65.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=9c889fe0a2ebaa9e3b6be303e0a7a9801aae65a9fde7066b82e4e5cee29c54f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agL2oUFJO9BM",
        "colab_type": "code",
        "outputId": "c57ad44e-6cb9-4000-ba9a-5215365b6234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roq3nEGz9wvH",
        "colab_type": "code",
        "outputId": "424b92c1-7688-4e24-8c7d-7c1d7840c01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/punjabi/task1punjabi.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 1,700\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>819</th>\n",
              "      <td>PUN0820</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ਬਠਿੰਡਾ, ਮਾਨਸਾ ਵਿੱਚ ਤਾਂ ਪਹਿਲਾਂ ਦਰਖ਼ਤ ਘੱਟ ਸਨ, ਉਪ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1573</th>\n",
              "      <td>PUN1574</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ਪੰਜਾਬ ਵਿੱਚ ਨਸ਼ਿਆਂ ਦੀ ਵਰਤੋਂ ਦੀ ਅਸਲ ਸਥਿਤੀ ਸਿਆਸਤ ਦ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>PUN0324</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>17ਵੀਂ ਏਸ਼ੀਅਨ ਜੂਨੀਅਰ ਅਥਲੈਟਿਕਸ ਚੈਂਪੀਅਨਸ਼ਿਪ ਲਈ ਭਾ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1052</th>\n",
              "      <td>PUN1053</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ਸਰਕਾਰ ਮਹਿੰਗਾਈ ਉੱਤੇ ਕਾਬੂ ਪਾਉਣ ਲਈ ਵਚਨਬੱਧ&lt;eol&gt;ਦਿੱ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>PUN0329</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ਤਲਵੰਡੀ ਸਾਬੋ ਨੇੜੇ ਹਰਿਆਣਾ ਦਾ ਖ਼ਤਰਨਾਕ ਗੈਂਗਸਟਰ ਪੁਲ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>PUN0262</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ਪੰਜਾਬ ਦੇ 2 ਅਪਰਾਧੀ ਦਿੱਲੀ ਪੁਲਿਸ ਵੱਲੋਂ ਕਾਬੂ&lt;eol&gt;ਦ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>PUN1200</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ਅਮਰੀਕੀ ਰਾਸ਼ਟਰਪਤੀ ਚੋਣਾਂ ਵਿਚ ਹਿਲੇਰੀ ਨੇ ਹਾਸਲ ਕੀਤੀ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1083</th>\n",
              "      <td>PUN1084</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ਕਸ਼ਮੀਰ ਦੇ ਹਾਲਾਤ ਖ਼ਰਾਬ ਕਰਨ 'ਚ ਪਾਕਿ ਨੇ ਅਹਿਮ ਭੂਮਿ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>PUN0715</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ਇਹ ਸਮਾਗਮ ਸੁਪਰ ਸਿੱਖ ਸਪੋਰਟਸ ਐਂਡ ਕਲਚਰ ਨੇ ਹੋਰ ਸੰਸਥ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1425</th>\n",
              "      <td>PUN1426</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ਜ਼ਿਲ੍ਹਾ ਗੁਰਦਾਸਪੁਰ ਦੇ ਸਰਹੱਦੀ ਪਿੰਡ ਮਰਾੜਾ ਵਿਖੇ ਮਕਾ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "819          PUN0820  ...  ਬਠਿੰਡਾ, ਮਾਨਸਾ ਵਿੱਚ ਤਾਂ ਪਹਿਲਾਂ ਦਰਖ਼ਤ ਘੱਟ ਸਨ, ਉਪ...\n",
              "1573         PUN1574  ...  ਪੰਜਾਬ ਵਿੱਚ ਨਸ਼ਿਆਂ ਦੀ ਵਰਤੋਂ ਦੀ ਅਸਲ ਸਥਿਤੀ ਸਿਆਸਤ ਦ...\n",
              "323          PUN0324  ...  17ਵੀਂ ਏਸ਼ੀਅਨ ਜੂਨੀਅਰ ਅਥਲੈਟਿਕਸ ਚੈਂਪੀਅਨਸ਼ਿਪ ਲਈ ਭਾ...\n",
              "1052         PUN1053  ...  ਸਰਕਾਰ ਮਹਿੰਗਾਈ ਉੱਤੇ ਕਾਬੂ ਪਾਉਣ ਲਈ ਵਚਨਬੱਧ<eol>ਦਿੱ...\n",
              "328          PUN0329  ...  ਤਲਵੰਡੀ ਸਾਬੋ ਨੇੜੇ ਹਰਿਆਣਾ ਦਾ ਖ਼ਤਰਨਾਕ ਗੈਂਗਸਟਰ ਪੁਲ...\n",
              "261          PUN0262  ...  ਪੰਜਾਬ ਦੇ 2 ਅਪਰਾਧੀ ਦਿੱਲੀ ਪੁਲਿਸ ਵੱਲੋਂ ਕਾਬੂ<eol>ਦ...\n",
              "1199         PUN1200  ...  ਅਮਰੀਕੀ ਰਾਸ਼ਟਰਪਤੀ ਚੋਣਾਂ ਵਿਚ ਹਿਲੇਰੀ ਨੇ ਹਾਸਲ ਕੀਤੀ ...\n",
              "1083         PUN1084  ...  ਕਸ਼ਮੀਰ ਦੇ ਹਾਲਾਤ ਖ਼ਰਾਬ ਕਰਨ 'ਚ ਪਾਕਿ ਨੇ ਅਹਿਮ ਭੂਮਿ...\n",
              "714          PUN0715  ...  ਇਹ ਸਮਾਗਮ ਸੁਪਰ ਸਿੱਖ ਸਪੋਰਟਸ ਐਂਡ ਕਲਚਰ ਨੇ ਹੋਰ ਸੰਸਥ...\n",
              "1425         PUN1426  ...  ਜ਼ਿਲ੍ਹਾ ਗੁਰਦਾਸਪੁਰ ਦੇ ਸਰਹੱਦੀ ਪਿੰਡ ਮਰਾੜਾ ਵਿਖੇ ਮਕਾ...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK0Dm2839_fM",
        "colab_type": "code",
        "outputId": "ec1b855f-23df-456c-c947-dc4f3811f9d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1319</th>\n",
              "      <td>ਮੋਦੀ ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਹਨ, ਸ਼ਹਿਨਸ਼ਾਹ ਨਹੀਂ, ਸੋਨੀਆ ਗਾ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1081</th>\n",
              "      <td>ਜਰਮਨੀ ਦੇ ਮਿਊਨਿਖ ਸ਼ਹਿਰ 'ਚ ਗੋਲੀਬਾਰੀ-6 ਮੌਤਾਂ&lt;eol&gt;...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>ਉਹ ਦਿੱਲੀ ਤੋਂ ਇਥੇ ਆ ਕੇ ਦਿਨੇ ਵੱਖ-ਵੱਖ ਸੈਕਟਰਾਂ ਦੀ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>ਮਹਿਲਾ ਨਾਲ ਬਦਸਲੂਕੀ ਦੇ ਮਾਮਲੇ 'ਚ 'ਆਪ' ਵਿਧਾਇਕ ਅਮਾਨ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1332</th>\n",
              "      <td>ਸੀHਬੀHਆਈ ਜਾਂਚ ਲਈ ਸੰਤ ਢੱਡਰੀਆਂ ਵਾਲਿਆਂ ਵੱਲੋਂ ਹਾਈਕ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "1319  ਮੋਦੀ ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਹਨ, ਸ਼ਹਿਨਸ਼ਾਹ ਨਹੀਂ, ਸੋਨੀਆ ਗਾ...      0\n",
              "1081  ਜਰਮਨੀ ਦੇ ਮਿਊਨਿਖ ਸ਼ਹਿਰ 'ਚ ਗੋਲੀਬਾਰੀ-6 ਮੌਤਾਂ<eol>...      0\n",
              "838    ਉਹ ਦਿੱਲੀ ਤੋਂ ਇਥੇ ਆ ਕੇ ਦਿਨੇ ਵੱਖ-ਵੱਖ ਸੈਕਟਰਾਂ ਦੀ...      0\n",
              "1068  ਮਹਿਲਾ ਨਾਲ ਬਦਸਲੂਕੀ ਦੇ ਮਾਮਲੇ 'ਚ 'ਆਪ' ਵਿਧਾਇਕ ਅਮਾਨ...      0\n",
              "1332  ਸੀHਬੀHਆਈ ਜਾਂਚ ਲਈ ਸੰਤ ਢੱਡਰੀਆਂ ਵਾਲਿਆਂ ਵੱਲੋਂ ਹਾਈਕ...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64AfSL-V-Ij5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60lFABu1-KAE",
        "colab_type": "code",
        "outputId": "58f5af70-1b2b-4810-a91e-36546b13d93c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "0dd2d21b03194e0ba7d01e7328163de4",
            "2336f283e1194d5a924e699a84fb29ec",
            "0bc788450bd54d99a9ac686090f513bc",
            "39b3da33c4cb43df96ed8bb9ebf44035",
            "a89556249e464594825632717536b160",
            "491079a27c4246f6a7b18360ef2e73c9",
            "625c1b8cfd7b46ed8b78afc007e4c482",
            "74e23c8be4a04a788a62092e998aef8f"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dd2d21b03194e0ba7d01e7328163de4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqawKMwS-o5b",
        "colab_type": "code",
        "outputId": "4081c0da-96fc-4f71-9732-1fc558ff06dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  ਰੀਓ ਉਲੰਪਿਕ ਜਾਵੇਗਾ ਨਰਸਿੰਘ<eol>ਨਰਸਿੰਘ ਜਾਵੇਗਾ ਰੀਓ ਉਲਪਿੰਕ\n",
            "Tokenized:  ['ਰ', '##ੀ', '##ਓ', 'ਉ', '##ਲ', '##ਪ', '##ਿਕ', 'ਜਾ', '##ਵ', '##ਗ', '##ਾ', 'ਨ', '##ਰ', '##ਸ', '##ਿ', '##ਘ', '<', 'eo', '##l', '>', 'ਨ', '##ਰ', '##ਸ', '##ਿ', '##ਘ', 'ਜਾ', '##ਵ', '##ਗ', '##ਾ', 'ਰ', '##ੀ', '##ਓ', 'ਉ', '##ਲ', '##ਪ', '##ਿਕ']\n",
            "Token IDs:  [1041, 13094, 111248, 1011, 15423, 31948, 26674, 62130, 32143, 48874, 13768, 1034, 13475, 19836, 45378, 111250, 133, 13934, 10161, 135, 1034, 13475, 19836, 45378, 111250, 62130, 32143, 48874, 13768, 1041, 13094, 111248, 1011, 15423, 31948, 26674]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKGzPxF1AUUM",
        "colab_type": "code",
        "outputId": "3a91e378-5305-4a1e-ab9b-56efc9b9582b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  ਰੀਓ ਉਲੰਪਿਕ ਜਾਵੇਗਾ ਨਰਸਿੰਘ<eol>ਨਰਸਿੰਘ ਜਾਵੇਗਾ ਰੀਓ ਉਲਪਿੰਕ\n",
            "Token IDs: [101, 1041, 13094, 111248, 1011, 15423, 31948, 26674, 62130, 32143, 48874, 13768, 1034, 13475, 19836, 45378, 111250, 133, 13934, 10161, 135, 1034, 13475, 19836, 45378, 111250, 62130, 32143, 48874, 13768, 1041, 13094, 111248, 1011, 15423, 31948, 26674, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv39u2kLAo9b",
        "colab_type": "code",
        "outputId": "89f2b3a0-632d-4738-e5ac-10eac4b87b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH_GkPkFAsKR",
        "colab_type": "code",
        "outputId": "88a1d165-d85d-46c9-ed5d-516be82bd9b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUKKZrYgAuTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfmeSm3zAxOP",
        "colab_type": "code",
        "outputId": "32c8f894-def6-448c-d043-873bf2412864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.2)\n",
        "print(train_inputs)\n",
        "print(train_labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.2)\n",
        "#print(train_masks)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   101   1035  72497 ...  14673  15423   1041]\n",
            " [   101   1039  22236 ...    102      0      0]\n",
            " [   101  46043   1035 ...   1037  48560   1032]\n",
            " ...\n",
            " [   101   1044  21205 ...      0      0      0]\n",
            " [   101   1032  19836 ... 108041   1041  14673]\n",
            " [   101   1032  64812 ...  12666   1044  72497]]\n",
            "[0 1 0 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6BSzcZ-A8JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2ab-k8GgLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvYAxocaGzaO",
        "colab_type": "code",
        "outputId": "92878993-be16-40a7-9756-3c548fcc6116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "681cb274a4344139ab68d369c69da450",
            "4cf9a575cc2c43748980697e02e59426",
            "bb783446760e4b37b295cf69345aa58d",
            "2464702b677e49978e124fdd4466ebc8",
            "e3a9edf7d69d4488a3b4cf26088ceef0",
            "e2be50a8b2e9471cafaa22817202a776",
            "8a25dba9ce7347589585e655dd53dca4",
            "8e25d05391934e32b073604ae411e318",
            "91fb6665a33e4fc280cf71550d814acf",
            "5a5bd622766546708015866ca7bfc089",
            "4bdb0195860a441091c3bfae21d17697",
            "dc5cabf180e64120888f58ce7ffd74bf",
            "b5eab7b8a2a84d6da4faea3fd918f144",
            "b350b3d95a8c47ad8a5e6a0a1fc92e3b",
            "9778dc4945bf4783bfac229177fb9383",
            "35cf037115ba4ad78356d28798d3147a"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "681cb274a4344139ab68d369c69da450",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91fb6665a33e4fc280cf71550d814acf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xB1woJrHCZ0",
        "colab_type": "code",
        "outputId": "d3ca442f-31d9-4d75-b9d9-24ba39d6fc96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NhjDCrtHGh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBK2E_PaHKQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOO83LgEHQYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2jmuLjzHUP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6dh8MSXHXCv",
        "colab_type": "code",
        "outputId": "dcfae05c-b9fa-47c4-f6b2-0dda7d2edecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     43.    Elapsed: 0:00:19.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     43.    Elapsed: 0:00:19.\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     43.    Elapsed: 0:00:19.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     43.    Elapsed: 0:00:19.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epcoh took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3sCgA3MK9B2",
        "colab_type": "code",
        "outputId": "f9b52721-97e5-406b-98ee-984149a8eb5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/testdata/task1punjabi-test.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHsFeNFSLIkL",
        "colab_type": "code",
        "outputId": "e662ecec-49b4-4144-c4f9-72fd1797d7c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "  # # print(predictions)\n",
        "  #print(true_labels)\n",
        "print('    DONE.')\n",
        "\n",
        "#print(true_labels)\n",
        "print(\"*************************\")\n",
        "\n",
        "#print(len(predictions))\n",
        "#print(outputs)\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 500 test sentences...\n",
            "    DONE.\n",
            "*************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCGGtb-jicKL",
        "colab_type": "code",
        "outputId": "e66459b2-4930-46a5-f805-c4ef0abbdee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "count_NP=0\n",
        "count_P=0\n",
        "count_line=1\n",
        "x=-1\n",
        "true_count,false_count=0,0\n",
        "print(\"label \\t sno\\tlogit\\t\\t\\t\\t\\tindex\")\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    print(\"(\",end=\"\")\n",
        "    print(true_labels[i][j],end=\"\")\n",
        "    print(\")\",end=\"\")\n",
        "    print(\"\\t\",count_line,end=\"\")\n",
        "    # print(\"-  \",end=\"\")\n",
        "    if(predictions[i][j][0]>predictions[i][j][1] ):\n",
        "      #count_P+=1 \n",
        "      #print(\" Non Paraphrase         \",end=\"\")\n",
        "      print(\"\\t\",predictions[i][j],\"\\t0\\t\",end=\"\")\n",
        "      x=0\n",
        "    elif(predictions[i][j][1]>predictions[i][j][0] ):\n",
        "      #print(\" Paraphrase     \",end=\"\")\n",
        "     # count_NP+=1      \n",
        "      print(\"\\t\",predictions[i][j],\"\\t1\\t\",end=\"\")\n",
        "      x=1\n",
        "    # elif(predictions[i][j][2]>predictions[i][j][0] and predictions[i][j][2]>predictions[i][j][1]):\n",
        "    #   #print(\" Semi Paraphrase     \",end=\"\")\n",
        "    #   #count_NP+=1      \n",
        "    #   print(\"\\t\",predictions[i][j][2],\"\\t2\\t\",end=\"\")\n",
        "    #   x=1\n",
        "    count_line+=1\n",
        "    #print(\"\\t\",predictions[i][j],\"\\t2\\t\",end=\"\")\n",
        "\n",
        "    if(true_labels[i][j]==x):\n",
        "      true_count+=1\n",
        "      print(\"true\")\n",
        "    else:\n",
        "      print(\"false\")\n",
        "      false_count+=1\n",
        "\n",
        "print(\"Number of true predictions:\",true_count)\n",
        "print(\"Number of false predictions:\",false_count)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label \t sno\tlogit\t\t\t\t\tindex\n",
            "(1)\t 1\t [ 0.815205  -1.2494777] \t0\tfalse\n",
            "(0)\t 2\t [ 1.1755286 -1.5860173] \t0\ttrue\n",
            "(0)\t 3\t [ 0.4184287  -0.83817226] \t0\ttrue\n",
            "(0)\t 4\t [-1.5518073  1.7753322] \t1\tfalse\n",
            "(0)\t 5\t [ 1.0977429 -1.4792423] \t0\ttrue\n",
            "(0)\t 6\t [-0.05669916 -0.22205506] \t0\ttrue\n",
            "(1)\t 7\t [-2.3028834  2.3088787] \t1\ttrue\n",
            "(0)\t 8\t [ 1.2524835 -1.7057382] \t0\ttrue\n",
            "(0)\t 9\t [ 1.1917516 -1.6559652] \t0\ttrue\n",
            "(1)\t 10\t [-1.3332999  1.3699228] \t1\ttrue\n",
            "(1)\t 11\t [-2.3018987  2.2976005] \t1\ttrue\n",
            "(1)\t 12\t [-2.146681   2.2956073] \t1\ttrue\n",
            "(0)\t 13\t [ 0.6221114 -0.9595655] \t0\ttrue\n",
            "(1)\t 14\t [-2.3409266  2.371152 ] \t1\ttrue\n",
            "(0)\t 15\t [ 1.1449639 -1.5539193] \t0\ttrue\n",
            "(0)\t 16\t [ 0.6580428 -1.0122856] \t0\ttrue\n",
            "(0)\t 17\t [ 0.730109  -1.1436015] \t0\ttrue\n",
            "(0)\t 18\t [ 0.5726571  -0.88918996] \t0\ttrue\n",
            "(0)\t 19\t [ 1.1286972 -1.5622047] \t0\ttrue\n",
            "(0)\t 20\t [ 1.2445334 -1.6770216] \t0\ttrue\n",
            "(0)\t 21\t [ 0.5479057 -0.8497313] \t0\ttrue\n",
            "(0)\t 22\t [ 0.78008354 -1.180256  ] \t0\ttrue\n",
            "(0)\t 23\t [ 0.8325389 -1.2254782] \t0\ttrue\n",
            "(0)\t 24\t [-0.6949252   0.54436874] \t1\tfalse\n",
            "(1)\t 25\t [-2.1938708  2.3046095] \t1\ttrue\n",
            "(0)\t 26\t [ 0.2906229 -0.6204201] \t0\ttrue\n",
            "(0)\t 27\t [ 0.8699055 -1.3093965] \t0\ttrue\n",
            "(0)\t 28\t [ 0.7170627 -1.0501817] \t0\ttrue\n",
            "(0)\t 29\t [ 0.85605407 -1.2807567 ] \t0\ttrue\n",
            "(0)\t 30\t [ 1.2219547 -1.6421493] \t0\ttrue\n",
            "(0)\t 31\t [ 1.2354441 -1.6500568] \t0\ttrue\n",
            "(1)\t 32\t [-2.27159    2.3477762] \t1\ttrue\n",
            "(0)\t 33\t [ 0.72230405 -1.053922  ] \t0\ttrue\n",
            "(0)\t 34\t [ 1.2393686 -1.6607441] \t0\ttrue\n",
            "(0)\t 35\t [ 1.0332528 -1.4606894] \t0\ttrue\n",
            "(0)\t 36\t [ 0.6329602 -1.0197563] \t0\ttrue\n",
            "(0)\t 37\t [ 0.57088536 -0.9162941 ] \t0\ttrue\n",
            "(1)\t 38\t [-2.3464828  2.3722088] \t1\ttrue\n",
            "(0)\t 39\t [ 0.06156512 -0.3602854 ] \t0\ttrue\n",
            "(0)\t 40\t [ 1.105071  -1.5017279] \t0\ttrue\n",
            "(1)\t 41\t [-2.3042722  2.222345 ] \t1\ttrue\n",
            "(1)\t 42\t [-2.3494523  2.3283424] \t1\ttrue\n",
            "(1)\t 43\t [-0.9671953  0.8249725] \t1\ttrue\n",
            "(0)\t 44\t [ 0.8086959 -1.1988889] \t0\ttrue\n",
            "(1)\t 45\t [-2.312075  2.403764] \t1\ttrue\n",
            "(1)\t 46\t [-2.3111608  2.2757633] \t1\ttrue\n",
            "(0)\t 47\t [ 0.37384245 -0.6883655 ] \t0\ttrue\n",
            "(0)\t 48\t [ 1.2002078 -1.6001636] \t0\ttrue\n",
            "(0)\t 49\t [ 0.81493044 -1.2115153 ] \t0\ttrue\n",
            "(1)\t 50\t [-1.9937483  2.170068 ] \t1\ttrue\n",
            "(0)\t 51\t [ 1.1240476 -1.5467736] \t0\ttrue\n",
            "(0)\t 52\t [ 1.167795  -1.5650982] \t0\ttrue\n",
            "(1)\t 53\t [ 0.10389978 -0.4638015 ] \t0\tfalse\n",
            "(1)\t 54\t [-1.8036385  2.0212872] \t1\ttrue\n",
            "(1)\t 55\t [ 0.5000829 -0.784533 ] \t0\tfalse\n",
            "(0)\t 56\t [ 1.1598762 -1.5916301] \t0\ttrue\n",
            "(0)\t 57\t [ 0.49461037 -0.80223745] \t0\ttrue\n",
            "(0)\t 58\t [ 0.28611273 -0.59841967] \t0\ttrue\n",
            "(0)\t 59\t [ 0.21773785 -0.47521323] \t0\ttrue\n",
            "(0)\t 60\t [ 1.0433217 -1.443091 ] \t0\ttrue\n",
            "(1)\t 61\t [-2.2567508  2.3688066] \t1\ttrue\n",
            "(0)\t 62\t [ 0.82333475 -1.1407691 ] \t0\ttrue\n",
            "(0)\t 63\t [ 1.2153431 -1.6927571] \t0\ttrue\n",
            "(0)\t 64\t [ 0.7847711 -1.1256716] \t0\ttrue\n",
            "(0)\t 65\t [-0.96015  0.83806] \t1\tfalse\n",
            "(0)\t 66\t [ 0.41283205 -0.7170289 ] \t0\ttrue\n",
            "(0)\t 67\t [ 0.6427201 -0.925563 ] \t0\ttrue\n",
            "(0)\t 68\t [ 0.6005312 -0.9708709] \t0\ttrue\n",
            "(0)\t 69\t [ 1.2473682 -1.6840197] \t0\ttrue\n",
            "(0)\t 70\t [ 1.1702808 -1.5600305] \t0\ttrue\n",
            "(1)\t 71\t [-2.287122   2.4030716] \t1\ttrue\n",
            "(0)\t 72\t [ 0.8338393 -1.2597607] \t0\ttrue\n",
            "(1)\t 73\t [-2.3284645  2.3688095] \t1\ttrue\n",
            "(0)\t 74\t [ 1.1377757 -1.580321 ] \t0\ttrue\n",
            "(0)\t 75\t [ 0.6253309 -1.0212487] \t0\ttrue\n",
            "(0)\t 76\t [ 1.1353201 -1.5593919] \t0\ttrue\n",
            "(1)\t 77\t [-1.3007591  1.2046003] \t1\ttrue\n",
            "(0)\t 78\t [ 0.07287698 -0.29355   ] \t0\ttrue\n",
            "(1)\t 79\t [-2.084898   2.2625277] \t1\ttrue\n",
            "(1)\t 80\t [-1.2969896  1.1395289] \t1\ttrue\n",
            "(0)\t 81\t [ 0.7211031 -1.0438461] \t0\ttrue\n",
            "(1)\t 82\t [-2.2266917  2.3089788] \t1\ttrue\n",
            "(1)\t 83\t [-1.7014995  1.8688825] \t1\ttrue\n",
            "(1)\t 84\t [-2.2797902  2.320689 ] \t1\ttrue\n",
            "(0)\t 85\t [-0.11442512 -0.18748519] \t0\ttrue\n",
            "(1)\t 86\t [-2.2511137  2.3441274] \t1\ttrue\n",
            "(1)\t 87\t [-2.1841943  2.2980683] \t1\ttrue\n",
            "(1)\t 88\t [-2.2321608  2.3776536] \t1\ttrue\n",
            "(1)\t 89\t [ 0.24613339 -0.54672956] \t0\tfalse\n",
            "(1)\t 90\t [-1.4077927  1.4872798] \t1\ttrue\n",
            "(1)\t 91\t [-2.3056824  2.3580754] \t1\ttrue\n",
            "(1)\t 92\t [-2.240126  2.412579] \t1\ttrue\n",
            "(1)\t 93\t [-2.2233646  2.3931272] \t1\ttrue\n",
            "(1)\t 94\t [-2.1841323  2.3483055] \t1\ttrue\n",
            "(1)\t 95\t [-2.27888    2.3187673] \t1\ttrue\n",
            "(1)\t 96\t [-2.0044296  2.178706 ] \t1\ttrue\n",
            "(1)\t 97\t [-2.2515574  2.3453119] \t1\ttrue\n",
            "(1)\t 98\t [-0.7319385   0.30436495] \t1\ttrue\n",
            "(0)\t 99\t [ 1.0796207 -1.5076177] \t0\ttrue\n",
            "(1)\t 100\t [-1.9811054  2.1992903] \t1\ttrue\n",
            "(1)\t 101\t [-1.9664804  2.20474  ] \t1\ttrue\n",
            "(1)\t 102\t [-1.0251206  1.2976589] \t1\ttrue\n",
            "(1)\t 103\t [ 0.426063  -0.7358277] \t0\tfalse\n",
            "(1)\t 104\t [-2.3115246  2.3578818] \t1\ttrue\n",
            "(1)\t 105\t [-1.9626573  2.164684 ] \t1\ttrue\n",
            "(0)\t 106\t [ 0.4937383  -0.88013184] \t0\ttrue\n",
            "(1)\t 107\t [-2.1805868  2.3380134] \t1\ttrue\n",
            "(0)\t 108\t [ 0.5048752 -0.8547909] \t0\ttrue\n",
            "(1)\t 109\t [-1.6632735  1.8251185] \t1\ttrue\n",
            "(1)\t 110\t [-1.9845741  2.1285224] \t1\ttrue\n",
            "(0)\t 111\t [ 0.07886511 -0.3690049 ] \t0\ttrue\n",
            "(0)\t 112\t [-1.4392297  1.4718045] \t1\tfalse\n",
            "(0)\t 113\t [ 0.45841843 -0.7271995 ] \t0\ttrue\n",
            "(0)\t 114\t [ 1.1021672 -1.4750026] \t0\ttrue\n",
            "(0)\t 115\t [ 0.63982195 -0.9486041 ] \t0\ttrue\n",
            "(0)\t 116\t [ 0.01246014 -0.33356637] \t0\ttrue\n",
            "(1)\t 117\t [-2.2774065  2.3167298] \t1\ttrue\n",
            "(0)\t 118\t [ 0.9346007 -1.293177 ] \t0\ttrue\n",
            "(0)\t 119\t [ 0.5976387 -0.9246618] \t0\ttrue\n",
            "(1)\t 120\t [-1.8086214  1.9840752] \t1\ttrue\n",
            "(1)\t 121\t [-2.2864327  2.3136427] \t1\ttrue\n",
            "(1)\t 122\t [-1.0186921  0.8195713] \t1\ttrue\n",
            "(1)\t 123\t [ 0.55562055 -0.87311006] \t0\tfalse\n",
            "(1)\t 124\t [-1.993714   2.1004925] \t1\ttrue\n",
            "(0)\t 125\t [ 1.198264  -1.5753334] \t0\ttrue\n",
            "(0)\t 126\t [ 0.5233792 -0.8597647] \t0\ttrue\n",
            "(1)\t 127\t [-2.1654606  2.3067043] \t1\ttrue\n",
            "(0)\t 128\t [ 0.65154886 -0.9431832 ] \t0\ttrue\n",
            "(0)\t 129\t [-0.47244087  0.18098356] \t1\tfalse\n",
            "(0)\t 130\t [-1.3817159  1.3007741] \t1\tfalse\n",
            "(0)\t 131\t [-0.45105892  0.26903516] \t1\tfalse\n",
            "(1)\t 132\t [-2.1089003  2.2829897] \t1\ttrue\n",
            "(1)\t 133\t [-0.6020042   0.29724914] \t1\ttrue\n",
            "(0)\t 134\t [ 1.0491335 -1.4785348] \t0\ttrue\n",
            "(0)\t 135\t [ 0.4713984 -0.7843363] \t0\ttrue\n",
            "(0)\t 136\t [ 1.1530265 -1.535957 ] \t0\ttrue\n",
            "(0)\t 137\t [ 1.0322518 -1.4196334] \t0\ttrue\n",
            "(0)\t 138\t [ 1.0974537 -1.5139376] \t0\ttrue\n",
            "(0)\t 139\t [ 1.2242529 -1.6201066] \t0\ttrue\n",
            "(0)\t 140\t [ 1.2154696 -1.6189312] \t0\ttrue\n",
            "(1)\t 141\t [-1.3037472  1.23811  ] \t1\ttrue\n",
            "(0)\t 142\t [ 0.9239693 -1.2922597] \t0\ttrue\n",
            "(0)\t 143\t [ 1.1679413 -1.5634247] \t0\ttrue\n",
            "(1)\t 144\t [-2.3068175  2.30494  ] \t1\ttrue\n",
            "(1)\t 145\t [-2.3275478  2.3866885] \t1\ttrue\n",
            "(1)\t 146\t [ 0.23829143 -0.5114298 ] \t0\tfalse\n",
            "(1)\t 147\t [ 0.76187193 -1.138745  ] \t0\tfalse\n",
            "(1)\t 148\t [ 0.60130453 -0.9449627 ] \t0\tfalse\n",
            "(0)\t 149\t [ 0.61333984 -0.8655627 ] \t0\ttrue\n",
            "(1)\t 150\t [-1.2690672  1.367889 ] \t1\ttrue\n",
            "(1)\t 151\t [-2.2766645  2.3829744] \t1\ttrue\n",
            "(1)\t 152\t [ 0.15818591 -0.46433896] \t0\tfalse\n",
            "(1)\t 153\t [-2.2838426  2.3962736] \t1\ttrue\n",
            "(1)\t 154\t [-2.135043  2.288681] \t1\ttrue\n",
            "(0)\t 155\t [-0.5820141   0.43016058] \t1\tfalse\n",
            "(1)\t 156\t [-2.2941632  2.3982818] \t1\ttrue\n",
            "(0)\t 157\t [ 0.57361716 -0.94356143] \t0\ttrue\n",
            "(1)\t 158\t [-1.957263   2.1097467] \t1\ttrue\n",
            "(1)\t 159\t [-2.2874842  2.3312123] \t1\ttrue\n",
            "(1)\t 160\t [-2.044669  2.179499] \t1\ttrue\n",
            "(1)\t 161\t [-1.5147948  1.6833497] \t1\ttrue\n",
            "(0)\t 162\t [-2.1694777  2.3046396] \t1\tfalse\n",
            "(0)\t 163\t [ 0.26765412 -0.5578195 ] \t0\ttrue\n",
            "(1)\t 164\t [ 0.2686609 -0.6558137] \t0\tfalse\n",
            "(0)\t 165\t [ 0.68597615 -1.0293578 ] \t0\ttrue\n",
            "(1)\t 166\t [-2.322827   2.3484013] \t1\ttrue\n",
            "(1)\t 167\t [-2.164779   2.3163655] \t1\ttrue\n",
            "(1)\t 168\t [-2.3236568  2.328494 ] \t1\ttrue\n",
            "(1)\t 169\t [-2.315439   2.4012904] \t1\ttrue\n",
            "(1)\t 170\t [ 0.9963871 -1.4317616] \t0\tfalse\n",
            "(0)\t 171\t [ 0.5906482 -0.9833533] \t0\ttrue\n",
            "(0)\t 172\t [ 0.6020434  -0.89015514] \t0\ttrue\n",
            "(0)\t 173\t [ 1.2235149 -1.6238356] \t0\ttrue\n",
            "(1)\t 174\t [ 0.07213227 -0.4099535 ] \t0\tfalse\n",
            "(1)\t 175\t [-1.2180625  1.3468089] \t1\ttrue\n",
            "(0)\t 176\t [ 0.8782891 -1.3199493] \t0\ttrue\n",
            "(1)\t 177\t [-2.222944   2.3198543] \t1\ttrue\n",
            "(0)\t 178\t [ 1.1922306 -1.5780691] \t0\ttrue\n",
            "(0)\t 179\t [-0.17528036 -0.10749666] \t1\tfalse\n",
            "(0)\t 180\t [ 0.46338826 -0.77630544] \t0\ttrue\n",
            "(0)\t 181\t [ 0.7692583 -1.1872894] \t0\ttrue\n",
            "(1)\t 182\t [-2.210219   2.3612857] \t1\ttrue\n",
            "(0)\t 183\t [ 1.0790166 -1.4568714] \t0\ttrue\n",
            "(0)\t 184\t [ 0.2650065  -0.51626337] \t0\ttrue\n",
            "(1)\t 185\t [-1.3839699  1.4941899] \t1\ttrue\n",
            "(0)\t 186\t [ 0.6303645 -1.0117625] \t0\ttrue\n",
            "(1)\t 187\t [-2.2608316  2.2658293] \t1\ttrue\n",
            "(1)\t 188\t [-2.2487137  2.4019158] \t1\ttrue\n",
            "(1)\t 189\t [-1.5977131  1.7152766] \t1\ttrue\n",
            "(1)\t 190\t [-1.7467607  1.8657602] \t1\ttrue\n",
            "(0)\t 191\t [ 0.49516666 -0.8308645 ] \t0\ttrue\n",
            "(0)\t 192\t [-1.4478942  1.5394515] \t1\tfalse\n",
            "(0)\t 193\t [ 0.7501486 -1.1592187] \t0\ttrue\n",
            "(1)\t 194\t [-1.7114295  1.921296 ] \t1\ttrue\n",
            "(0)\t 195\t [ 0.18077372 -0.46477595] \t0\ttrue\n",
            "(0)\t 196\t [-1.198697   1.1482989] \t1\tfalse\n",
            "(0)\t 197\t [ 0.06119362 -0.40365636] \t0\ttrue\n",
            "(1)\t 198\t [ 0.81087947 -1.2265323 ] \t0\tfalse\n",
            "(0)\t 199\t [ 0.7626654 -1.1128699] \t0\ttrue\n",
            "(1)\t 200\t [-2.1937873  2.3769693] \t1\ttrue\n",
            "(0)\t 201\t [-2.3010585  2.2827156] \t1\tfalse\n",
            "(0)\t 202\t [ 0.7722626 -1.1291107] \t0\ttrue\n",
            "(0)\t 203\t [ 0.676654  -1.0391163] \t0\ttrue\n",
            "(0)\t 204\t [ 1.1011167 -1.4970895] \t0\ttrue\n",
            "(0)\t 205\t [ 0.48990557 -0.8245994 ] \t0\ttrue\n",
            "(1)\t 206\t [-2.1763422  2.309631 ] \t1\ttrue\n",
            "(0)\t 207\t [ 0.75804895 -1.115637  ] \t0\ttrue\n",
            "(1)\t 208\t [-2.334421  2.327614] \t1\ttrue\n",
            "(1)\t 209\t [-2.2957752  2.3063061] \t1\ttrue\n",
            "(0)\t 210\t [ 0.44350842 -0.7320832 ] \t0\ttrue\n",
            "(0)\t 211\t [ 0.4124618  -0.74072933] \t0\ttrue\n",
            "(1)\t 212\t [-2.2396553  2.342375 ] \t1\ttrue\n",
            "(1)\t 213\t [ 0.83182764 -1.2275333 ] \t0\tfalse\n",
            "(1)\t 214\t [-2.222898   2.2996676] \t1\ttrue\n",
            "(0)\t 215\t [-0.00425563 -0.23778854] \t0\ttrue\n",
            "(0)\t 216\t [ 0.57577544 -0.9193878 ] \t0\ttrue\n",
            "(1)\t 217\t [-2.3139272  2.3728724] \t1\ttrue\n",
            "(0)\t 218\t [ 0.53304183 -0.89279217] \t0\ttrue\n",
            "(1)\t 219\t [-1.9663016  2.164498 ] \t1\ttrue\n",
            "(1)\t 220\t [-1.9219526  2.1349318] \t1\ttrue\n",
            "(1)\t 221\t [-1.4603462  1.2942172] \t1\ttrue\n",
            "(1)\t 222\t [ 0.52610326 -0.8692345 ] \t0\tfalse\n",
            "(1)\t 223\t [ 0.76405466 -1.0992718 ] \t0\tfalse\n",
            "(0)\t 224\t [ 0.7557494 -1.0961281] \t0\ttrue\n",
            "(1)\t 225\t [-1.2162936  1.3136228] \t1\ttrue\n",
            "(0)\t 226\t [-0.19547111 -0.07802907] \t1\tfalse\n",
            "(1)\t 227\t [-2.1538217  2.3038607] \t1\ttrue\n",
            "(1)\t 228\t [ 1.072386  -1.4641017] \t0\tfalse\n",
            "(1)\t 229\t [-2.166475   2.2990558] \t1\ttrue\n",
            "(1)\t 230\t [-2.2375567  2.3242524] \t1\ttrue\n",
            "(0)\t 231\t [ 0.9670222 -1.3704053] \t0\ttrue\n",
            "(0)\t 232\t [ 0.4106043  -0.68694335] \t0\ttrue\n",
            "(1)\t 233\t [ 0.7633239 -1.133642 ] \t0\tfalse\n",
            "(0)\t 234\t [ 0.15137914 -0.45424896] \t0\ttrue\n",
            "(0)\t 235\t [ 0.9802398 -1.3972412] \t0\ttrue\n",
            "(1)\t 236\t [-2.2862866  2.3656685] \t1\ttrue\n",
            "(1)\t 237\t [-2.307761   2.3640573] \t1\ttrue\n",
            "(0)\t 238\t [ 0.6201639 -0.8854492] \t0\ttrue\n",
            "(0)\t 239\t [-2.0342858  2.190697 ] \t1\tfalse\n",
            "(1)\t 240\t [-2.293789   2.3153274] \t1\ttrue\n",
            "(1)\t 241\t [-1.9200634  2.1086874] \t1\ttrue\n",
            "(1)\t 242\t [ 0.07759204 -0.36494204] \t0\tfalse\n",
            "(1)\t 243\t [ 0.14666203 -0.47578818] \t0\tfalse\n",
            "(1)\t 244\t [-1.7346603  1.9223152] \t1\ttrue\n",
            "(0)\t 245\t [ 0.23266214 -0.5109685 ] \t0\ttrue\n",
            "(0)\t 246\t [ 0.78200114 -1.204239  ] \t0\ttrue\n",
            "(0)\t 247\t [ 0.9868068 -1.4386977] \t0\ttrue\n",
            "(0)\t 248\t [ 1.211332  -1.6290455] \t0\ttrue\n",
            "(1)\t 249\t [ 0.08984331 -0.3906793 ] \t0\tfalse\n",
            "(1)\t 250\t [-2.1231272  2.2580035] \t1\ttrue\n",
            "(1)\t 251\t [-2.204806  2.349533] \t1\ttrue\n",
            "(0)\t 252\t [-0.10299294 -0.19543111] \t0\ttrue\n",
            "(0)\t 253\t [ 0.5431076 -0.8830819] \t0\ttrue\n",
            "(0)\t 254\t [ 1.0099841 -1.4014255] \t0\ttrue\n",
            "(1)\t 255\t [ 0.7981703 -1.2202276] \t0\tfalse\n",
            "(0)\t 256\t [ 1.1840693 -1.5889333] \t0\ttrue\n",
            "(1)\t 257\t [-2.3140213  2.32013  ] \t1\ttrue\n",
            "(0)\t 258\t [ 1.0181574 -1.4445511] \t0\ttrue\n",
            "(0)\t 259\t [ 0.48093423 -0.81839275] \t0\ttrue\n",
            "(0)\t 260\t [ 0.48599887 -0.8172142 ] \t0\ttrue\n",
            "(1)\t 261\t [-2.3060217  2.3156106] \t1\ttrue\n",
            "(0)\t 262\t [ 1.1414039 -1.5773743] \t0\ttrue\n",
            "(0)\t 263\t [ 0.55123997 -0.8808243 ] \t0\ttrue\n",
            "(1)\t 264\t [-2.2467744  2.3187184] \t1\ttrue\n",
            "(1)\t 265\t [-1.746812   1.9571459] \t1\ttrue\n",
            "(1)\t 266\t [-2.2043712  2.3457654] \t1\ttrue\n",
            "(1)\t 267\t [-2.0117743  2.1917741] \t1\ttrue\n",
            "(0)\t 268\t [ 1.1938767 -1.5462496] \t0\ttrue\n",
            "(0)\t 269\t [ 1.1404113 -1.5639303] \t0\ttrue\n",
            "(1)\t 270\t [ 0.66489094 -1.053623  ] \t0\tfalse\n",
            "(1)\t 271\t [-1.5592531  1.7274972] \t1\ttrue\n",
            "(1)\t 272\t [ 0.43073806 -0.74673647] \t0\tfalse\n",
            "(1)\t 273\t [-2.209614   2.3333986] \t1\ttrue\n",
            "(0)\t 274\t [ 1.2622792 -1.6294206] \t0\ttrue\n",
            "(1)\t 275\t [-1.8192277  1.9527355] \t1\ttrue\n",
            "(1)\t 276\t [-2.292057   2.3537827] \t1\ttrue\n",
            "(1)\t 277\t [-2.3122272  2.3344343] \t1\ttrue\n",
            "(0)\t 278\t [ 1.1697332 -1.6048844] \t0\ttrue\n",
            "(1)\t 279\t [-1.8035871  1.9974226] \t1\ttrue\n",
            "(0)\t 280\t [ 0.14529519 -0.43432486] \t0\ttrue\n",
            "(0)\t 281\t [ 0.18827239 -0.4579379 ] \t0\ttrue\n",
            "(1)\t 282\t [-2.1562455  2.3440592] \t1\ttrue\n",
            "(0)\t 283\t [ 1.2080442 -1.6713754] \t0\ttrue\n",
            "(1)\t 284\t [-2.288254   2.4074323] \t1\ttrue\n",
            "(1)\t 285\t [ 0.16010846 -0.46211535] \t0\tfalse\n",
            "(1)\t 286\t [ 0.3919809  -0.71407473] \t0\tfalse\n",
            "(0)\t 287\t [ 0.8630397 -1.2211908] \t0\ttrue\n",
            "(1)\t 288\t [-2.1615798  2.3052833] \t1\ttrue\n",
            "(0)\t 289\t [-0.24548079  0.12626529] \t1\tfalse\n",
            "(0)\t 290\t [ 1.1753439 -1.5747613] \t0\ttrue\n",
            "(1)\t 291\t [-0.8214647   0.67773855] \t1\ttrue\n",
            "(1)\t 292\t [-2.3440013  2.3576472] \t1\ttrue\n",
            "(1)\t 293\t [-1.9005836  2.1064327] \t1\ttrue\n",
            "(1)\t 294\t [-1.7799109  1.9218153] \t1\ttrue\n",
            "(1)\t 295\t [-1.9224426  2.0901883] \t1\ttrue\n",
            "(0)\t 296\t [ 0.63143647 -0.9162122 ] \t0\ttrue\n",
            "(1)\t 297\t [ 0.37164354 -0.6472791 ] \t0\tfalse\n",
            "(0)\t 298\t [ 0.7458533 -1.1088026] \t0\ttrue\n",
            "(0)\t 299\t [ 0.7189383 -1.1538733] \t0\ttrue\n",
            "(1)\t 300\t [-1.4451939  1.5379082] \t1\ttrue\n",
            "(0)\t 301\t [ 0.04443414 -0.3206852 ] \t0\ttrue\n",
            "(0)\t 302\t [ 0.07144568 -0.34737277] \t0\ttrue\n",
            "(0)\t 303\t [ 1.1467829 -1.5650982] \t0\ttrue\n",
            "(1)\t 304\t [-2.3326263  2.3155746] \t1\ttrue\n",
            "(0)\t 305\t [-0.18993866 -0.08544979] \t1\tfalse\n",
            "(0)\t 306\t [ 0.7184567 -1.103114 ] \t0\ttrue\n",
            "(1)\t 307\t [-0.10117084 -0.13866171] \t0\tfalse\n",
            "(0)\t 308\t [-0.47726515  0.31908083] \t1\tfalse\n",
            "(1)\t 309\t [-2.3139436  2.3290515] \t1\ttrue\n",
            "(0)\t 310\t [ 1.2170962 -1.6288136] \t0\ttrue\n",
            "(0)\t 311\t [ 0.85932857 -1.2670673 ] \t0\ttrue\n",
            "(0)\t 312\t [ 1.172227  -1.5766245] \t0\ttrue\n",
            "(1)\t 313\t [-2.3217041  2.3583767] \t1\ttrue\n",
            "(0)\t 314\t [ 0.70617473 -1.0466529 ] \t0\ttrue\n",
            "(1)\t 315\t [-1.5831395  1.7682251] \t1\ttrue\n",
            "(0)\t 316\t [ 1.2284535 -1.687697 ] \t0\ttrue\n",
            "(0)\t 317\t [ 0.6914873 -1.0218763] \t0\ttrue\n",
            "(1)\t 318\t [-2.0092895  2.1952567] \t1\ttrue\n",
            "(0)\t 319\t [ 0.25252336 -0.61907643] \t0\ttrue\n",
            "(0)\t 320\t [ 1.2267979 -1.6664933] \t0\ttrue\n",
            "(0)\t 321\t [ 0.9026206 -1.2742969] \t0\ttrue\n",
            "(0)\t 322\t [ 0.19528514 -0.58307046] \t0\ttrue\n",
            "(1)\t 323\t [-0.28666663  0.06743424] \t1\ttrue\n",
            "(1)\t 324\t [ 0.6833904 -1.0306233] \t0\tfalse\n",
            "(0)\t 325\t [ 0.82241505 -1.2076027 ] \t0\ttrue\n",
            "(1)\t 326\t [-1.8961667  2.0917747] \t1\ttrue\n",
            "(0)\t 327\t [ 1.1840316 -1.5689949] \t0\ttrue\n",
            "(0)\t 328\t [ 0.68919075 -1.0231614 ] \t0\ttrue\n",
            "(1)\t 329\t [-2.3204246  2.3606257] \t1\ttrue\n",
            "(0)\t 330\t [ 0.8439628 -1.217856 ] \t0\ttrue\n",
            "(1)\t 331\t [-1.444904   1.4978017] \t1\ttrue\n",
            "(0)\t 332\t [ 0.67832255 -1.0862826 ] \t0\ttrue\n",
            "(1)\t 333\t [-2.1444705  2.3196106] \t1\ttrue\n",
            "(0)\t 334\t [ 0.6400928 -0.960592 ] \t0\ttrue\n",
            "(0)\t 335\t [ 0.6799109 -1.0775558] \t0\ttrue\n",
            "(1)\t 336\t [ 0.00903828 -0.24783573] \t0\tfalse\n",
            "(0)\t 337\t [ 0.55843997 -0.9546159 ] \t0\ttrue\n",
            "(0)\t 338\t [-0.27138555  0.01090092] \t1\tfalse\n",
            "(1)\t 339\t [-2.1012876  2.272384 ] \t1\ttrue\n",
            "(1)\t 340\t [-0.08686753 -0.21755674] \t0\tfalse\n",
            "(0)\t 341\t [ 0.26771867 -0.5731361 ] \t0\ttrue\n",
            "(1)\t 342\t [ 0.4248857  -0.75085723] \t0\tfalse\n",
            "(1)\t 343\t [-2.3249254  2.4043114] \t1\ttrue\n",
            "(1)\t 344\t [-1.4138297  1.3263787] \t1\ttrue\n",
            "(1)\t 345\t [-1.2005317  1.1833779] \t1\ttrue\n",
            "(1)\t 346\t [ 0.48290488 -0.75897276] \t0\tfalse\n",
            "(1)\t 347\t [-2.2760513  2.2908177] \t1\ttrue\n",
            "(1)\t 348\t [-2.2991912  2.3663948] \t1\ttrue\n",
            "(1)\t 349\t [ 0.02220204 -0.3431614 ] \t0\tfalse\n",
            "(0)\t 350\t [ 0.6169125  -0.94136703] \t0\ttrue\n",
            "(0)\t 351\t [ 1.0865558 -1.5071286] \t0\ttrue\n",
            "(1)\t 352\t [-2.1343832  2.2080498] \t1\ttrue\n",
            "(1)\t 353\t [-2.2171357  2.3482912] \t1\ttrue\n",
            "(1)\t 354\t [-2.195412  2.330733] \t1\ttrue\n",
            "(1)\t 355\t [-1.8912255  2.0443017] \t1\ttrue\n",
            "(0)\t 356\t [ 0.38034225 -0.6848176 ] \t0\ttrue\n",
            "(0)\t 357\t [ 0.75860053 -1.2135429 ] \t0\ttrue\n",
            "(0)\t 358\t [ 0.3579845  -0.67100763] \t0\ttrue\n",
            "(1)\t 359\t [-0.26209027 -0.01379879] \t1\ttrue\n",
            "(0)\t 360\t [ 0.07163993 -0.4039954 ] \t0\ttrue\n",
            "(0)\t 361\t [ 0.8044918 -1.2178363] \t0\ttrue\n",
            "(0)\t 362\t [ 0.40798396 -0.7077639 ] \t0\ttrue\n",
            "(1)\t 363\t [ 0.32102686 -0.6213889 ] \t0\tfalse\n",
            "(1)\t 364\t [-2.1862104  2.32435  ] \t1\ttrue\n",
            "(0)\t 365\t [ 1.1589063 -1.5557591] \t0\ttrue\n",
            "(1)\t 366\t [-2.3603632  2.3524868] \t1\ttrue\n",
            "(1)\t 367\t [-2.2900035  2.3261602] \t1\ttrue\n",
            "(1)\t 368\t [-2.0759146  2.296223 ] \t1\ttrue\n",
            "(1)\t 369\t [-2.0491076  2.2500153] \t1\ttrue\n",
            "(1)\t 370\t [-2.1664293  2.366975 ] \t1\ttrue\n",
            "(0)\t 371\t [ 0.8090671 -1.2132989] \t0\ttrue\n",
            "(0)\t 372\t [ 0.761248  -1.1377281] \t0\ttrue\n",
            "(0)\t 373\t [ 0.05336747 -0.2962619 ] \t0\ttrue\n",
            "(1)\t 374\t [-2.324931   2.3032162] \t1\ttrue\n",
            "(1)\t 375\t [ 0.6634325 -1.0159615] \t0\tfalse\n",
            "(1)\t 376\t [ 0.3759509  -0.72597367] \t0\tfalse\n",
            "(1)\t 377\t [-1.807195   1.9939867] \t1\ttrue\n",
            "(0)\t 378\t [ 1.2095848 -1.6135052] \t0\ttrue\n",
            "(1)\t 379\t [-2.1188743  2.2436116] \t1\ttrue\n",
            "(1)\t 380\t [-2.1690166  2.373358 ] \t1\ttrue\n",
            "(1)\t 381\t [-2.3001742  2.4252965] \t1\ttrue\n",
            "(0)\t 382\t [ 1.1481439 -1.566414 ] \t0\ttrue\n",
            "(1)\t 383\t [-2.1463797  2.3048916] \t1\ttrue\n",
            "(0)\t 384\t [ 0.7035512 -1.045153 ] \t0\ttrue\n",
            "(1)\t 385\t [-2.1340544  2.2808194] \t1\ttrue\n",
            "(1)\t 386\t [-2.0398333  2.2047307] \t1\ttrue\n",
            "(1)\t 387\t [-2.2291377  2.3750107] \t1\ttrue\n",
            "(0)\t 388\t [ 1.2597786 -1.6598399] \t0\ttrue\n",
            "(0)\t 389\t [ 0.5594963  -0.94677335] \t0\ttrue\n",
            "(1)\t 390\t [-2.295466   2.3268123] \t1\ttrue\n",
            "(1)\t 391\t [-2.3648655  2.3601034] \t1\ttrue\n",
            "(1)\t 392\t [-0.5556665   0.27928197] \t1\ttrue\n",
            "(0)\t 393\t [ 0.9166297 -1.3915344] \t0\ttrue\n",
            "(0)\t 394\t [ 1.1967145 -1.6040083] \t0\ttrue\n",
            "(0)\t 395\t [ 0.12702587 -0.44630194] \t0\ttrue\n",
            "(0)\t 396\t [-0.41820246  0.1665932 ] \t1\tfalse\n",
            "(0)\t 397\t [ 0.5507556  -0.85518664] \t0\ttrue\n",
            "(0)\t 398\t [ 0.35468227 -0.62441087] \t0\ttrue\n",
            "(0)\t 399\t [ 0.24439344 -0.57125545] \t0\ttrue\n",
            "(0)\t 400\t [-2.2694957  2.3635788] \t1\tfalse\n",
            "(0)\t 401\t [ 0.7958003 -1.1715478] \t0\ttrue\n",
            "(1)\t 402\t [-2.1221247  2.245941 ] \t1\ttrue\n",
            "(0)\t 403\t [ 0.6379101 -1.0415175] \t0\ttrue\n",
            "(0)\t 404\t [ 0.64917314 -1.031089  ] \t0\ttrue\n",
            "(0)\t 405\t [ 1.2160584 -1.6554192] \t0\ttrue\n",
            "(1)\t 406\t [ 0.6984701 -1.0819199] \t0\tfalse\n",
            "(0)\t 407\t [ 0.798082  -1.1528013] \t0\ttrue\n",
            "(0)\t 408\t [ 0.05831262 -0.36969823] \t0\ttrue\n",
            "(0)\t 409\t [ 1.2032449 -1.572004 ] \t0\ttrue\n",
            "(0)\t 410\t [ 1.1861216 -1.6124477] \t0\ttrue\n",
            "(1)\t 411\t [ 0.23085596 -0.4886816 ] \t0\tfalse\n",
            "(0)\t 412\t [ 1.0888926 -1.5047518] \t0\ttrue\n",
            "(0)\t 413\t [ 0.6354985 -0.9921325] \t0\ttrue\n",
            "(0)\t 414\t [ 0.6501015 -1.0608262] \t0\ttrue\n",
            "(0)\t 415\t [ 0.6271305 -0.9684013] \t0\ttrue\n",
            "(0)\t 416\t [ 1.1911447 -1.5751158] \t0\ttrue\n",
            "(0)\t 417\t [ 1.0833029 -1.4521061] \t0\ttrue\n",
            "(0)\t 418\t [ 1.1658721 -1.554461 ] \t0\ttrue\n",
            "(1)\t 419\t [ 0.04225814 -0.36794633] \t0\tfalse\n",
            "(1)\t 420\t [-2.3110197  2.383678 ] \t1\ttrue\n",
            "(1)\t 421\t [ 0.2777171 -0.5646056] \t0\tfalse\n",
            "(0)\t 422\t [ 1.2013513 -1.5737773] \t0\ttrue\n",
            "(1)\t 423\t [-2.1643794  2.2743356] \t1\ttrue\n",
            "(1)\t 424\t [-2.0086098  2.2470982] \t1\ttrue\n",
            "(0)\t 425\t [ 0.86871576 -1.2308754 ] \t0\ttrue\n",
            "(0)\t 426\t [ 1.2334708 -1.6100048] \t0\ttrue\n",
            "(1)\t 427\t [ 0.11317267 -0.42991054] \t0\tfalse\n",
            "(1)\t 428\t [-2.1943283  2.370819 ] \t1\ttrue\n",
            "(0)\t 429\t [ 0.5107727 -0.8809255] \t0\ttrue\n",
            "(0)\t 430\t [ 1.2535114 -1.6424996] \t0\ttrue\n",
            "(0)\t 431\t [ 0.158127   -0.45438713] \t0\ttrue\n",
            "(0)\t 432\t [ 0.42991877 -0.7659902 ] \t0\ttrue\n",
            "(0)\t 433\t [ 0.7019198 -1.0522476] \t0\ttrue\n",
            "(1)\t 434\t [-2.2744606  2.311149 ] \t1\ttrue\n",
            "(0)\t 435\t [ 0.9998309 -1.362348 ] \t0\ttrue\n",
            "(1)\t 436\t [-2.2683256  2.4028568] \t1\ttrue\n",
            "(1)\t 437\t [-2.3338544  2.3448255] \t1\ttrue\n",
            "(0)\t 438\t [ 0.4568051 -0.7291676] \t0\ttrue\n",
            "(1)\t 439\t [-1.9112682  2.1616113] \t1\ttrue\n",
            "(0)\t 440\t [ 1.2416371 -1.6625532] \t0\ttrue\n",
            "(0)\t 441\t [ 1.0969415 -1.4770099] \t0\ttrue\n",
            "(1)\t 442\t [-1.888955   2.0513136] \t1\ttrue\n",
            "(1)\t 443\t [-1.7775744  1.967163 ] \t1\ttrue\n",
            "(1)\t 444\t [ 0.47680792 -0.7978803 ] \t0\tfalse\n",
            "(1)\t 445\t [-2.3234916  2.3368192] \t1\ttrue\n",
            "(0)\t 446\t [ 0.41452974 -0.7182573 ] \t0\ttrue\n",
            "(1)\t 447\t [-2.3372784  2.407792 ] \t1\ttrue\n",
            "(1)\t 448\t [-2.1321323  2.3140962] \t1\ttrue\n",
            "(1)\t 449\t [-0.6758379   0.44685078] \t1\ttrue\n",
            "(1)\t 450\t [-2.2931721  2.2642787] \t1\ttrue\n",
            "(1)\t 451\t [ 0.07099693 -0.35106298] \t0\tfalse\n",
            "(1)\t 452\t [ 0.11423654 -0.4002992 ] \t0\tfalse\n",
            "(0)\t 453\t [ 0.6424989 -1.0063921] \t0\ttrue\n",
            "(0)\t 454\t [ 0.3845987 -0.6869788] \t0\ttrue\n",
            "(0)\t 455\t [ 0.8362291 -1.2408673] \t0\ttrue\n",
            "(0)\t 456\t [ 1.3331553 -1.7052945] \t0\ttrue\n",
            "(1)\t 457\t [-2.3183186  2.4320073] \t1\ttrue\n",
            "(1)\t 458\t [-1.4428939  1.5387211] \t1\ttrue\n",
            "(1)\t 459\t [ 0.7511132 -1.1092453] \t0\tfalse\n",
            "(1)\t 460\t [-2.298775   2.3128426] \t1\ttrue\n",
            "(1)\t 461\t [-2.3473694  2.3321435] \t1\ttrue\n",
            "(1)\t 462\t [-2.14731    2.2532523] \t1\ttrue\n",
            "(1)\t 463\t [-2.2990923  2.3874278] \t1\ttrue\n",
            "(1)\t 464\t [-2.1755314  2.3023155] \t1\ttrue\n",
            "(0)\t 465\t [ 1.0686727 -1.5078064] \t0\ttrue\n",
            "(0)\t 466\t [ 0.81026006 -1.2544411 ] \t0\ttrue\n",
            "(1)\t 467\t [-1.2667693  1.3620092] \t1\ttrue\n",
            "(0)\t 468\t [ 1.1909325 -1.5942197] \t0\ttrue\n",
            "(1)\t 469\t [-2.1560237  2.326976 ] \t1\ttrue\n",
            "(0)\t 470\t [ 1.0394998 -1.4363791] \t0\ttrue\n",
            "(1)\t 471\t [-1.144898   1.1652735] \t1\ttrue\n",
            "(1)\t 472\t [-2.3050656  2.3632233] \t1\ttrue\n",
            "(0)\t 473\t [ 1.0243253 -1.3964797] \t0\ttrue\n",
            "(1)\t 474\t [-1.7475485  1.9214829] \t1\ttrue\n",
            "(1)\t 475\t [-2.2600405  2.3678634] \t1\ttrue\n",
            "(1)\t 476\t [-1.1649181  1.0328574] \t1\ttrue\n",
            "(0)\t 477\t [ 0.6346575 -1.0455788] \t0\ttrue\n",
            "(1)\t 478\t [-0.11361095 -0.11857822] \t0\tfalse\n",
            "(0)\t 479\t [ 0.91345465 -1.2809585 ] \t0\ttrue\n",
            "(1)\t 480\t [ 0.8119264 -1.2226192] \t0\tfalse\n",
            "(0)\t 481\t [ 0.3548437 -0.6363564] \t0\ttrue\n",
            "(0)\t 482\t [ 0.3835591 -0.6557631] \t0\ttrue\n",
            "(0)\t 483\t [ 1.1378785 -1.5490894] \t0\ttrue\n",
            "(1)\t 484\t [-2.3170123  2.3930469] \t1\ttrue\n",
            "(1)\t 485\t [ 0.6591469 -0.9879354] \t0\tfalse\n",
            "(0)\t 486\t [ 0.60478497 -0.97809   ] \t0\ttrue\n",
            "(1)\t 487\t [-2.2910323  2.3089845] \t1\ttrue\n",
            "(0)\t 488\t [ 0.95273745 -1.3365339 ] \t0\ttrue\n",
            "(1)\t 489\t [-1.6850955  1.8615621] \t1\ttrue\n",
            "(1)\t 490\t [-2.2949572  2.2823708] \t1\ttrue\n",
            "(1)\t 491\t [ 0.49228424 -0.8180723 ] \t0\tfalse\n",
            "(0)\t 492\t [ 0.7221999 -1.0758694] \t0\ttrue\n",
            "(1)\t 493\t [ 0.38239062 -0.70654804] \t0\tfalse\n",
            "(1)\t 494\t [-2.2556977  2.3571947] \t1\ttrue\n",
            "(1)\t 495\t [-2.3078935  2.3524444] \t1\ttrue\n",
            "(1)\t 496\t [-1.9094247  2.0500836] \t1\ttrue\n",
            "(1)\t 497\t [-2.1082885  2.2582006] \t1\ttrue\n",
            "(0)\t 498\t [ 0.0031839  -0.35213608] \t0\ttrue\n",
            "(1)\t 499\t [-2.2022586  2.3528388] \t1\ttrue\n",
            "(1)\t 500\t [-0.4357314  0.2064741] \t1\ttrue\n",
            "Number of true predictions: 427\n",
            "Number of false predictions: 73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KIgsWWCTKdY",
        "colab_type": "code",
        "outputId": "b57b61d7-1b86-47e9-a606-9c3fa606ad1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Accuracy:\",true_count/count_line*100,\"%\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 85.22954091816366 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRMcHi1uLQdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "27b46173-7f47-4c95-fe7d-4253f5ae158f"
      },
      "source": [
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "scores = [3.0, 1.0, 0.2]\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    predictions[i][j]=softmax(predictions[i][j])\n",
        "    print(predictions[i][j])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.88742286 0.11257716]\n",
            "[0.94056207 0.05943788]\n",
            "[0.7784404  0.22155957]\n",
            "[0.03465179 0.96534824]\n",
            "[0.9293656  0.07063437]\n",
            "[0.54124504 0.45875496]\n",
            "[0.00983658 0.9901634 ]\n",
            "[0.9506507  0.04934937]\n",
            "[0.9452006  0.05479946]\n",
            "[0.06278345 0.9372165 ]\n",
            "[0.00995674 0.9900433 ]\n",
            "[0.01163208 0.988368  ]\n",
            "[0.8294419  0.17055812]\n",
            "[0.00890605 0.99109393]\n",
            "[0.9369607 0.0630393]\n",
            "[0.8416196 0.1583804]\n",
            "[0.866887   0.13311297]\n",
            "[0.811815   0.18818498]\n",
            "[0.9364877  0.06351236]\n",
            "[0.9489017  0.05109825]\n",
            "[0.80180866 0.19819134]\n",
            "[0.8765697 0.1234303]\n",
            "[0.88675517 0.1132448 ]\n",
            "[0.2245589 0.7754411]\n",
            "[0.01100347 0.9889965 ]\n",
            "[0.71321356 0.28678647]\n",
            "[0.8983754  0.10162465]\n",
            "[0.8541147  0.14588535]\n",
            "[0.89442986 0.10557015]\n",
            "[0.94604313 0.05395682]\n",
            "[0.9471251  0.05287498]\n",
            "[0.00976279 0.9902372 ]\n",
            "[0.8552303  0.14476976]\n",
            "[0.947852 0.052148]\n",
            "[0.923716   0.07628394]\n",
            "[0.83925784 0.16074215]\n",
            "[0.8156545  0.18434544]\n",
            "[0.00884787 0.9911521 ]\n",
            "[0.603926   0.39607403]\n",
            "[0.9312979  0.06870214]\n",
            "[0.01070145 0.9892986 ]\n",
            "[0.00921382 0.9907862 ]\n",
            "[0.14280716 0.8571928 ]\n",
            "[0.8815912  0.11840887]\n",
            "[0.00887292 0.9911271 ]\n",
            "[0.01008146 0.98991853]\n",
            "[0.74311227 0.25688776]\n",
            "[0.9426959  0.05730411]\n",
            "[0.8835459  0.11645412]\n",
            "[0.01531006 0.98468995]\n",
            "[0.93528277 0.06471725]\n",
            "[0.93893987 0.06106009]\n",
            "[0.6382326 0.3617674]\n",
            "[0.02135411 0.97864586]\n",
            "[0.7832345  0.21676551]\n",
            "[0.9399983  0.06000163]\n",
            "[0.785304   0.21469602]\n",
            "[0.7077606  0.29223943]\n",
            "[0.6666231 0.3333769]\n",
            "[0.92318374 0.0768162 ]\n",
            "[0.00970312 0.9902969 ]\n",
            "[0.8769764  0.12302358]\n",
            "[0.94824535 0.05175459]\n",
            "[0.8710689  0.12893113]\n",
            "[0.1420691 0.8579309]\n",
            "[0.75581324 0.24418674]\n",
            "[0.8275387 0.1724613]\n",
            "[0.82798344 0.1720166 ]\n",
            "[0.9493764  0.05062358]\n",
            "[0.9387917  0.06120826]\n",
            "[0.00910131 0.99089867]\n",
            "[0.8902796  0.10972043]\n",
            "[0.00903768 0.9909623 ]\n",
            "[0.9380861  0.06191392]\n",
            "[0.83842826 0.16157176]\n",
            "[0.9367139  0.06328612]\n",
            "[0.07548332 0.92451674]\n",
            "[0.5905953  0.40940464]\n",
            "[0.01277478 0.98722523]\n",
            "[0.08043004 0.91956997]\n",
            "[0.85382843 0.14617157]\n",
            "[0.01060603 0.9893939 ]\n",
            "[0.02737464 0.9726254 ]\n",
            "[0.00994708 0.9900529 ]\n",
            "[0.5182569  0.48174313]\n",
            "[0.0099988 0.9900012]\n",
            "[0.01118136 0.9888186 ]\n",
            "[0.00985556 0.9901445 ]\n",
            "[0.68844575 0.31155425]\n",
            "[0.05239769 0.94760233]\n",
            "[0.00934284 0.9906571 ]\n",
            "[0.0094457 0.9905543]\n",
            "[0.00979062 0.99020934]\n",
            "[0.01064 0.98936]\n",
            "[0.00997501 0.9900249 ]\n",
            "[0.01502153 0.9849785 ]\n",
            "[0.00998269 0.99001735]\n",
            "[0.2618639  0.73813605]\n",
            "[0.9300357  0.06996427]\n",
            "[0.01506212 0.9849379 ]\n",
            "[0.01519884 0.9848011 ]\n",
            "[0.08925385 0.91074616]\n",
            "[0.76167613 0.2383239 ]\n",
            "[0.00929071 0.9907093 ]\n",
            "[0.01586979 0.9841302 ]\n",
            "[0.7980047  0.20199528]\n",
            "[0.01078665 0.9892133 ]\n",
            "[0.7957054  0.20429458]\n",
            "[0.02964433 0.97035563]\n",
            "[0.0160938 0.9839062]\n",
            "[0.6101327  0.38986728]\n",
            "[0.0516108  0.94838923]\n",
            "[0.76595646 0.2340436 ]\n",
            "[0.92937773 0.07062226]\n",
            "[0.83039457 0.16960545]\n",
            "[0.58565366 0.4143463 ]\n",
            "[0.01000974 0.98999023]\n",
            "[0.90271634 0.09728362]\n",
            "[0.820877   0.17912303]\n",
            "[0.02203813 0.9779619 ]\n",
            "[0.00995106 0.9900489 ]\n",
            "[0.13725679 0.8627432 ]\n",
            "[0.80670345 0.19329654]\n",
            "[0.01639567 0.9836044 ]\n",
            "[0.9412322  0.05876771]\n",
            "[0.7994954  0.20050454]\n",
            "[0.01129356 0.98870647]\n",
            "[0.8312808  0.16871917]\n",
            "[0.34221828 0.6577818 ]\n",
            "[0.06401453 0.9359855 ]\n",
            "[0.32737225 0.67262775]\n",
            "[0.01222599 0.9877741 ]\n",
            "[0.28920397 0.71079606]\n",
            "[0.9260589  0.07394114]\n",
            "[0.778291   0.22170901]\n",
            "[0.9363734  0.06362656]\n",
            "[0.9206992  0.07930079]\n",
            "[0.9315911  0.06840888]\n",
            "[0.9450264  0.05497362]\n",
            "[0.9445067  0.05549329]\n",
            "[0.07297543 0.92702454]\n",
            "[0.90169746 0.09830257]\n",
            "[0.9388523  0.06114769]\n",
            "[0.00983663 0.9901634 ]\n",
            "[0.00888702 0.991113  ]\n",
            "[0.6791179  0.32088205]\n",
            "[0.8699613  0.13003866]\n",
            "[0.8243739  0.17562604]\n",
            "[0.81440675 0.18559325]\n",
            "[0.06679752 0.93320245]\n",
            "[0.00938104 0.99061894]\n",
            "[0.65079254 0.3492074 ]\n",
            "[0.00919265 0.99080735]\n",
            "[0.01184745 0.98815256]\n",
            "[0.26655447 0.73344547]\n",
            "[0.00908103 0.990919  ]\n",
            "[0.82012266 0.17987737]\n",
            "[0.01684008 0.98315996]\n",
            "[0.00976927 0.99023074]\n",
            "[0.01442635 0.9855737 ]\n",
            "[0.03923561 0.9607644 ]\n",
            "[0.01127178 0.9887283 ]\n",
            "[0.695397 0.304603]\n",
            "[0.71595293 0.28404704]\n",
            "[0.84752685 0.15247317]\n",
            "[0.00927395 0.990726  ]\n",
            "[0.01119373 0.98880625]\n",
            "[0.00945088 0.99054915]\n",
            "[0.00886509 0.9911349 ]\n",
            "[0.91894877 0.08105125]\n",
            "[0.8283533  0.17164668]\n",
            "[0.81640804 0.18359198]\n",
            "[0.94518155 0.05481843]\n",
            "[0.6182403  0.38175973]\n",
            "[0.07143375 0.9285662 ]\n",
            "[0.90009123 0.0999088 ]\n",
            "[0.01053149 0.9894685 ]\n",
            "[0.9410496  0.05895038]\n",
            "[0.48306054 0.51693946]\n",
            "[0.7755107  0.22448932]\n",
            "[0.8761589  0.12384116]\n",
            "[0.01023652 0.9897635 ]\n",
            "[0.92661977 0.07338029]\n",
            "[0.68595374 0.31404626]\n",
            "[0.05324382 0.9467562 ]\n",
            "[0.83782417 0.16217583]\n",
            "[0.01070098 0.98929906]\n",
            "[0.00946514 0.99053484]\n",
            "[0.03512825 0.9648718 ]\n",
            "[0.02627474 0.97372526]\n",
            "[0.79018337 0.2098166 ]\n",
            "[0.04800084 0.9519991 ]\n",
            "[0.8709481  0.12905195]\n",
            "[0.02576275 0.9742373 ]\n",
            "[0.6560069  0.34399313]\n",
            "[0.08730485 0.9126951 ]\n",
            "[0.61416405 0.3858359 ]\n",
            "[0.8846694  0.11533055]\n",
            "[0.8670975  0.13290256]\n",
            "[0.0102441 0.9897559]\n",
            "[0.01011295 0.98988706]\n",
            "[0.87004685 0.12995313]\n",
            "[0.8475832  0.15241678]\n",
            "[0.930746   0.06925397]\n",
            "[0.788266   0.21173398]\n",
            "[0.01114041 0.98885965]\n",
            "[0.86688423 0.13311581]\n",
            "[0.0093588 0.9906412]\n",
            "[0.00993132 0.9900686 ]\n",
            "[0.76415426 0.23584577]\n",
            "[0.76009333 0.2399067 ]\n",
            "[0.01013042 0.98986953]\n",
            "[0.88689005 0.11310992]\n",
            "[0.01074442 0.98925555]\n",
            "[0.5581193  0.44188064]\n",
            "[0.816852   0.18314801]\n",
            "[0.00913197 0.990868  ]\n",
            "[0.8062514  0.19374864]\n",
            "[0.01581586 0.98418415]\n",
            "[0.01700855 0.9829914 ]\n",
            "[0.05982945 0.9401706 ]\n",
            "[0.80144304 0.19855697]\n",
            "[0.8656842 0.1343158]\n",
            "[0.8643474 0.1356526]\n",
            "[0.07378737 0.92621267]\n",
            "[0.47067317 0.5293268 ]\n",
            "[0.01145642 0.9885436 ]\n",
            "[0.9266605  0.07333952]\n",
            "[0.01136788 0.98863214]\n",
            "[0.01033522 0.98966485]\n",
            "[0.9119297 0.0880703]\n",
            "[0.7498003  0.25019968]\n",
            "[0.8695477  0.13045226]\n",
            "[0.64694285 0.35305712]\n",
            "[0.9150939  0.08490608]\n",
            "[0.00945272 0.99054724]\n",
            "[0.00926854 0.99073154]\n",
            "[0.8184101  0.18158984]\n",
            "[0.01441476 0.9855853 ]\n",
            "[0.00986238 0.9901376 ]\n",
            "[0.01748537 0.9825147 ]\n",
            "[0.6088627  0.39113733]\n",
            "[0.6507756  0.34922436]\n",
            "[0.02516104 0.9748389 ]\n",
            "[0.6777893  0.32221073]\n",
            "[0.87934476 0.12065521]\n",
            "[0.9187516  0.08124842]\n",
            "[0.94481915 0.05518086]\n",
            "[0.6178712  0.38212872]\n",
            "[0.01235661 0.98764336]\n",
            "[0.0104119  0.98958814]\n",
            "[0.5230931 0.4769069]\n",
            "[0.8063069  0.19369309]\n",
            "[0.9176932  0.08230678]\n",
            "[0.8827152  0.11728476]\n",
            "[0.94119936 0.05880062]\n",
            "[0.00962089 0.9903791 ]\n",
            "[0.92148584 0.07851415]\n",
            "[0.78572166 0.2142783 ]\n",
            "[0.7863753  0.21362476]\n",
            "[0.00974091 0.9902592 ]\n",
            "[0.93812567 0.06187436]\n",
            "[0.8072227  0.19277725]\n",
            "[0.01029761 0.98970246]\n",
            "[0.024034 0.975966]\n",
            "[0.01045529 0.9895447 ]\n",
            "[0.01472247 0.9852776 ]\n",
            "[0.9393533 0.0606467]\n",
            "[0.9372824  0.06271767]\n",
            "[0.8479373  0.15206267]\n",
            "[0.03602854 0.9639715 ]\n",
            "[0.7644934 0.2355066]\n",
            "[0.01052925 0.9894707 ]\n",
            "[0.9474346 0.0525654]\n",
            "[0.02248945 0.97751063]\n",
            "[0.00951015 0.99048984]\n",
            "[0.00950241 0.9904975 ]\n",
            "[0.9412887 0.0587113]\n",
            "[0.02185967 0.97814035]\n",
            "[0.64098    0.35902002]\n",
            "[0.65615594 0.34384406]\n",
            "[0.01098363 0.98901635]\n",
            "[0.94681966 0.05318036]\n",
            "[0.00905191 0.990948  ]\n",
            "[0.6507242  0.34927586]\n",
            "[0.751393   0.24860698]\n",
            "[0.889361   0.11063902]\n",
            "[0.01135291 0.98864704]\n",
            "[0.40811917 0.5918808 ]\n",
            "[0.93991935 0.06008071]\n",
            "[0.1825444 0.8174556]\n",
            "[0.00899858 0.9910014 ]\n",
            "[0.0178627 0.9821374]\n",
            "[0.02408641 0.97591364]\n",
            "[0.01776447 0.98223555]\n",
            "[0.8245739  0.17542614]\n",
            "[0.7347627  0.26523733]\n",
            "[0.86467284 0.13532718]\n",
            "[0.86678326 0.13321674]\n",
            "[0.04819513 0.95180494]\n",
            "[0.59027916 0.4097209 ]\n",
            "[0.6032005  0.39679953]\n",
            "[0.9377241  0.06227591]\n",
            "[0.00948794 0.9905121 ]\n",
            "[0.47390154 0.5260985 ]\n",
            "[0.86075455 0.13924551]\n",
            "[0.50937164 0.49062836]\n",
            "[0.3108077 0.6891923]\n",
            "[0.00953699 0.9904631 ]\n",
            "[0.94510686 0.05489313]\n",
            "[0.89344233 0.10655762]\n",
            "[0.9398485  0.06015154]\n",
            "[0.00919297 0.990807  ]\n",
            "[0.8523091 0.1476909]\n",
            "[0.03385051 0.96614945]\n",
            "[0.94863904 0.05136093]\n",
            "[0.847272   0.15272795]\n",
            "[0.01470801 0.985292  ]\n",
            "[0.7050785  0.29492155]\n",
            "[0.9475138 0.0524862]\n",
            "[0.8981574  0.10184253]\n",
            "[0.6853256 0.3146744]\n",
            "[0.41238832 0.5876117 ]\n",
            "[0.84735614 0.15264383]\n",
            "[0.883913   0.11608709]\n",
            "[0.01820044 0.98179954]\n",
            "[0.9400841  0.05991596]\n",
            "[0.8471411  0.15285888]\n",
            "[0.00918414 0.9908159 ]\n",
            "[0.88713646 0.11286359]\n",
            "[0.0500824  0.94991755]\n",
            "[0.85378546 0.14621451]\n",
            "[0.01138418 0.9886158 ]\n",
            "[0.8321141  0.16788593]\n",
            "[0.85289204 0.1471079 ]\n",
            "[0.5638677 0.4361323]\n",
            "[0.8195136  0.18048637]\n",
            "[0.4298933 0.5701067]\n",
            "[0.01244797 0.98755205]\n",
            "[0.53262585 0.46737412]\n",
            "[0.69864523 0.3013548 ]\n",
            "[0.7641815 0.2358185]\n",
            "[0.00875587 0.9912442 ]\n",
            "[0.06064203 0.939358  ]\n",
            "[0.08440792 0.9155921 ]\n",
            "[0.77589065 0.22410932]\n",
            "[0.01028359 0.9897165 ]\n",
            "[0.00932594 0.9906741 ]\n",
            "[0.5903381  0.40966183]\n",
            "[0.82610637 0.17389368]\n",
            "[0.930454   0.06954599]\n",
            "[0.01283789 0.98716205]\n",
            "[0.01029828 0.98970175]\n",
            "[0.01070645 0.9892936 ]\n",
            "[0.01916108 0.9808389 ]\n",
            "[0.74367535 0.25632465]\n",
            "[0.8778412  0.12215886]\n",
            "[0.7367205  0.26327956]\n",
            "[0.43824407 0.56175596]\n",
            "[0.61671674 0.38328332]\n",
            "[0.88312155 0.11687847]\n",
            "[0.75319916 0.24680087]\n",
            "[0.7195874  0.28041264]\n",
            "[0.01087278 0.9891272 ]\n",
            "[0.93788654 0.06211351]\n",
            "[0.00889924 0.9911007 ]\n",
            "[0.0097938 0.9902062]\n",
            "[0.01246684 0.9875331 ]\n",
            "[0.01339851 0.98660153]\n",
            "[0.01062983 0.9893701 ]\n",
            "[0.8831254  0.11687455]\n",
            "[0.8697756 0.1302244]\n",
            "[0.5865277 0.4134723]\n",
            "[0.00967827 0.9903217 ]\n",
            "[0.8428243  0.15717572]\n",
            "[0.75062054 0.24937947]\n",
            "[0.02185599 0.978144  ]\n",
            "[0.9439109  0.05608911]\n",
            "[0.01258623 0.98741376]\n",
            "[0.0105359  0.98946404]\n",
            "[0.00878862 0.99121135]\n",
            "[0.9378802  0.06211977]\n",
            "[0.01152926 0.9884708 ]\n",
            "[0.85178924 0.1482107 ]\n",
            "[0.01195151 0.9880485 ]\n",
            "[0.0141392 0.9858608]\n",
            "[0.00991101 0.99008894]\n",
            "[0.9488078  0.05119222]\n",
            "[0.81850773 0.18149228]\n",
            "[0.00973468 0.9902653 ]\n",
            "[0.00879299 0.99120706]\n",
            "[0.30259976 0.6974003 ]\n",
            "[0.9095509  0.09044906]\n",
            "[0.94271487 0.05728513]\n",
            "[0.6395307 0.3604693]\n",
            "[0.35782987 0.64217013]\n",
            "[0.8031251  0.19687486]\n",
            "[0.72692823 0.27307177]\n",
            "[0.6933119  0.30668804]\n",
            "[0.00963115 0.9903688 ]\n",
            "[0.877326   0.12267402]\n",
            "[0.01251707 0.9874829 ]\n",
            "[0.84282875 0.15717128]\n",
            "[0.84293926 0.15706077]\n",
            "[0.9464183  0.05358167]\n",
            "[0.855745   0.14425497]\n",
            "[0.8755429  0.12445708]\n",
            "[0.6053986 0.3946014]\n",
            "[0.9413236  0.05867642]\n",
            "[0.94259846 0.05740154]\n",
            "[0.6725052  0.32749483]\n",
            "[0.93045145 0.06954858]\n",
            "[0.8358448  0.16415516]\n",
            "[0.8469566  0.15304343]\n",
            "[0.831393   0.16860703]\n",
            "[0.94082516 0.05917485]\n",
            "[0.9265871  0.07341286]\n",
            "[0.9382159  0.06178416]\n",
            "[0.60113686 0.39886308]\n",
            "[0.00906079 0.99093926]\n",
            "[0.6989542  0.30104584]\n",
            "[0.94131696 0.05868307]\n",
            "[0.01167323 0.9883267 ]\n",
            "[0.0139847 0.9860153]\n",
            "[0.8908634  0.10913655]\n",
            "[0.9449804  0.05501955]\n",
            "[0.6325293  0.36747065]\n",
            "[0.01030113 0.9896988 ]\n",
            "[0.8008632 0.1991368]\n",
            "[0.9476489  0.05235111]\n",
            "[0.64851415 0.3514859 ]\n",
            "[0.7677962  0.23220377]\n",
            "[0.85247767 0.14752233]\n",
            "[0.01009459 0.9899054 ]\n",
            "[0.91389745 0.0861026 ]\n",
            "[0.00927437 0.9907257 ]\n",
            "[0.00920574 0.99079424]\n",
            "[0.76602006 0.23397999]\n",
            "[0.01674317 0.98325676]\n",
            "[0.9480532  0.05194681]\n",
            "[0.9291662 0.0708338]\n",
            "[0.01907217 0.98092777]\n",
            "[0.02309581 0.9769042 ]\n",
            "[0.7815442  0.21845576]\n",
            "[0.0093748  0.99062514]\n",
            "[0.75635284 0.24364714]\n",
            "[0.00861951 0.9913805 ]\n",
            "[0.01158687 0.98841316]\n",
            "[0.24551292 0.7544871 ]\n",
            "[0.01037989 0.98962015]\n",
            "[0.6039761  0.39602393]\n",
            "[0.62586915 0.37413085]\n",
            "[0.8387411 0.1612589]\n",
            "[0.7448968 0.2551032]\n",
            "[0.88865703 0.11134294]\n",
            "[0.9542812  0.04571876]\n",
            "[0.00857471 0.9914253 ]\n",
            "[0.04826339 0.95173657]\n",
            "[0.8653387  0.13466127]\n",
            "[0.00983799 0.990162  ]\n",
            "[0.00919814 0.9908019 ]\n",
            "[0.0121217  0.98787826]\n",
            "[0.0091345 0.9908655]\n",
            "[0.01123029 0.98876977]\n",
            "[0.92933244 0.07066763]\n",
            "[0.88742465 0.11257533]\n",
            "[0.0673091 0.9326909]\n",
            "[0.94186825 0.05813182]\n",
            "[0.01117321 0.98882675]\n",
            "[0.92243344 0.07756657]\n",
            "[0.09028405 0.90971595]\n",
            "[0.009301 0.990699]\n",
            "[0.9184001  0.08159991]\n",
            "[0.02486702 0.975133  ]\n",
            "[0.0096806 0.9903194]\n",
            "[0.09995044 0.90004957]\n",
            "[0.8429358  0.15706417]\n",
            "[0.5012418 0.4987582]\n",
            "[0.89974666 0.10025331]\n",
            "[0.88437665 0.11562329]\n",
            "[0.7293249 0.2706751]\n",
            "[0.7387192 0.2612808]\n",
            "[0.93625325 0.06374675]\n",
            "[0.00892389 0.9910761 ]\n",
            "[0.8384963  0.16150367]\n",
            "[0.8296113  0.17038868]\n",
            "[0.00995164 0.9900483 ]\n",
            "[0.90798455 0.09201541]\n",
            "[0.02801344 0.9719866 ]\n",
            "[0.01017769 0.9898224 ]\n",
            "[0.7875728  0.21242718]\n",
            "[0.8579138  0.14208625]\n",
            "[0.7481818  0.25181818]\n",
            "[0.00982558 0.9901744 ]\n",
            "[0.00937455 0.9906254 ]\n",
            "[0.01871554 0.98128444]\n",
            "[0.01253657 0.98746336]\n",
            "[0.587907   0.41209292]\n",
            "[0.01040409 0.98959595]\n",
            "[0.34474817 0.65525186]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgpMTRW-jMtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.savetxt(\"/content/drive/My Drive/FYP/bert/glue/cola/task1punjabi-results.txt\",predictions, fmt=\"%s\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PmWUtXdLW1I",
        "colab_type": "code",
        "outputId": "6edf6d67-94da-4385-f48f-c3a1267fb770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  \n",
        "\n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)\n",
        "  \n",
        " # print(pred_labels_i)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI2K1bqaR5ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb--na-oLbVM",
        "colab_type": "code",
        "outputId": "4efca53a-c6fb-4678-8bd8-efc33878fb3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matthews_set\n",
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6aNsEuZMvjI",
        "colab_type": "code",
        "outputId": "9d5ce162-1d76-4037-fa3c-f4237a1d1f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/My Drive/FYP/bert/model-colab-task1punjabi'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/My Drive/FYP/bert/model-colab-task1punjabi\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}