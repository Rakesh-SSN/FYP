{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT TASK 1 PUNJABI",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4729035602ef47768c8131a69ee83991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_59dfbad9acc94b41b0a78ac1d980f79f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca45941d0e2f4641a83229617f9402ab",
              "IPY_MODEL_4e1e0d3d40c446ffa6846f96cfa34241"
            ]
          }
        },
        "59dfbad9acc94b41b0a78ac1d980f79f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca45941d0e2f4641a83229617f9402ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_904e06758288499fb3c36120c53ccc77",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ca486b0b55346448d6554fc93c73451"
          }
        },
        "4e1e0d3d40c446ffa6846f96cfa34241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15094c6ac2274b2fa957f9af583f136b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 996k/996k [00:00&lt;00:00, 10.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca5a29439526446d8b32e8b879eec3dd"
          }
        },
        "904e06758288499fb3c36120c53ccc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ca486b0b55346448d6554fc93c73451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15094c6ac2274b2fa957f9af583f136b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca5a29439526446d8b32e8b879eec3dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bb3a7080d8c4f5ab6509eb0185f13ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3cb0ac8149584038875c36c4b973c47f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b6748e83a49d466fb33f8d3653a59666",
              "IPY_MODEL_5ee5c96bb41045bbabc6b80d7fcf6b30"
            ]
          }
        },
        "3cb0ac8149584038875c36c4b973c47f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6748e83a49d466fb33f8d3653a59666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ff4692675284d0fbb269cae591aa390",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 569,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 569,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27e59249112b458a8053dc549cb8d11e"
          }
        },
        "5ee5c96bb41045bbabc6b80d7fcf6b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_abffc252e14043b6b97fc6a8765f1283",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 569/569 [00:00&lt;00:00, 23.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff4c622facf241db84fb6512b3682363"
          }
        },
        "8ff4692675284d0fbb269cae591aa390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27e59249112b458a8053dc549cb8d11e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abffc252e14043b6b97fc6a8765f1283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff4c622facf241db84fb6512b3682363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "974f6807ed3b458fbfa74e2a22e92d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a413961eff3844c6b5333adb052fb230",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3c77b31c2b044b7fb9f6a3fa4edb7061",
              "IPY_MODEL_1a70d2c8947f4c41842b5d3ebe9c598b"
            ]
          }
        },
        "a413961eff3844c6b5333adb052fb230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c77b31c2b044b7fb9f6a3fa4edb7061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_48313c3fed7841eaa29824cd377e26f7",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e58cdee18b2d4e43b47a04b1808490dc"
          }
        },
        "1a70d2c8947f4c41842b5d3ebe9c598b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f310dbd6193a4cc6b119d2f4af22704d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 714M/714M [00:13&lt;00:00, 51.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86274736f10044d6b70d39cfc78a0023"
          }
        },
        "48313c3fed7841eaa29824cd377e26f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e58cdee18b2d4e43b47a04b1808490dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f310dbd6193a4cc6b119d2f4af22704d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86274736f10044d6b70d39cfc78a0023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakesh-SSN/FYP/blob/master/BERT_TASK_1_PUNJABI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN2gN6gr8nOJ",
        "colab_type": "code",
        "outputId": "6396afc9-5a79-433c-c778-316292fa37bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 2.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 14.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 19.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 20.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=29f325d1037c81dd93f688e3bbc8c2d280abc6eb5fb6c5b5f935e42c2fadfafd\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agL2oUFJO9BM",
        "colab_type": "code",
        "outputId": "33078117-c81e-4185-d8e5-e4a5dff1757e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roq3nEGz9wvH",
        "colab_type": "code",
        "outputId": "f29639a9-17ba-48d6-894a-ea07d0541c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/punjabi/task1punjabi.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 1,700\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>PUN0319</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ਹੁਣ 10ਵੀਂ ਤੋਂ ਬਾਅਦ ਆਈਟੀਆਈ ਨੂੰ ਮੰਨਿਆ ਜਾਵੇਗਾ 12ਵ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>605</th>\n",
              "      <td>PUN0606</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ਸਹੁੰ ਚੁੱਕ ਸਮਾਗਮ ਦੌਰਾਨ ਭਾਜਪਾ ਦੇ ਕੌਮੀ ਪ੍ਰਧਾਨ ਅਮ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>PUN0636</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ਰਾਜ ਵਿਚ ਆਰ. ਐੱਸ. ਐੱਸ. ਦੇ ਕਈ ਆਗੂ ਆਪਣਾ ਕੰਮ ਬਿਨਾਂ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>PUN0777</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ਪ੍ਰਾਂਤ ਸੰਘ ਚਾਲਕ ਸੂਰਿਆ ਪ੍ਰਸ਼ਾਂਤ ਨੇ ਕਾਂਵੜ ਯਾਤਰਾ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>PUN0098</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ਬਰਾਜ਼ੀਲ 'ਚ ਉਲੰਪਿਕ ਟਾਰਚ ਨੂੰ ਬੁਝਾਉਣ ਦੀ ਕੀਤੀ ਗਈ ਕੋ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>PUN0510</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ਬਾਬਾ ਸੇਵਾ ਸਿੰਘ ਦੀ ਇਸ ਮੁਹਿੰਮ ਨੇ ਜਿਥੇ ਉਨ੍ਹਾਂ ਨੂੰ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>587</th>\n",
              "      <td>PUN0588</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ਇਸ ਸੰਬੰਧ ਵਿਚ ਪਿੰਡ ਫਤਾਹਪੁਰ ਦੇ ਲੋਕਾਂ ਨੇ ਸਾਮੂਹਿਕ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>674</th>\n",
              "      <td>PUN0675</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ਅੰਮਿ੍ਤਸਰ ਵਿਚ  34.8 ਮਿਲੀਮੀਟਰ, ਲੁਧਿਆਣਾ ਵਿਚ 0.2 ਤ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1269</th>\n",
              "      <td>PUN1270</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>ਖਤਰਨਾਕ ਨਸ਼ਾ ਕਰਦੇ ਚਾਰ ਨੌਜਵਾਨ ਗ੍ਰਿਫਤਾਰ!&lt;eol&gt;ਰਾਜਨਾ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>PUN0173</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਡਾ. ਮਨਮੋਹਨ ਸਿੰਘ ਨੇ ਅੱਜ ਦੱਖਣੀ ਕੋਰੀ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "318          PUN0319  ...  ਹੁਣ 10ਵੀਂ ਤੋਂ ਬਾਅਦ ਆਈਟੀਆਈ ਨੂੰ ਮੰਨਿਆ ਜਾਵੇਗਾ 12ਵ...\n",
              "605          PUN0606  ...   ਸਹੁੰ ਚੁੱਕ ਸਮਾਗਮ ਦੌਰਾਨ ਭਾਜਪਾ ਦੇ ਕੌਮੀ ਪ੍ਰਧਾਨ ਅਮ...\n",
              "635          PUN0636  ...  ਰਾਜ ਵਿਚ ਆਰ. ਐੱਸ. ਐੱਸ. ਦੇ ਕਈ ਆਗੂ ਆਪਣਾ ਕੰਮ ਬਿਨਾਂ...\n",
              "776          PUN0777  ...   ਪ੍ਰਾਂਤ ਸੰਘ ਚਾਲਕ ਸੂਰਿਆ ਪ੍ਰਸ਼ਾਂਤ ਨੇ ਕਾਂਵੜ ਯਾਤਰਾ ...\n",
              "97           PUN0098  ...  ਬਰਾਜ਼ੀਲ 'ਚ ਉਲੰਪਿਕ ਟਾਰਚ ਨੂੰ ਬੁਝਾਉਣ ਦੀ ਕੀਤੀ ਗਈ ਕੋ...\n",
              "509          PUN0510  ...  ਬਾਬਾ ਸੇਵਾ ਸਿੰਘ ਦੀ ਇਸ ਮੁਹਿੰਮ ਨੇ ਜਿਥੇ ਉਨ੍ਹਾਂ ਨੂੰ...\n",
              "587          PUN0588  ...  ਇਸ ਸੰਬੰਧ ਵਿਚ ਪਿੰਡ ਫਤਾਹਪੁਰ ਦੇ ਲੋਕਾਂ ਨੇ ਸਾਮੂਹਿਕ ...\n",
              "674          PUN0675  ...  ਅੰਮਿ੍ਤਸਰ ਵਿਚ  34.8 ਮਿਲੀਮੀਟਰ, ਲੁਧਿਆਣਾ ਵਿਚ 0.2 ਤ...\n",
              "1269         PUN1270  ...  ਖਤਰਨਾਕ ਨਸ਼ਾ ਕਰਦੇ ਚਾਰ ਨੌਜਵਾਨ ਗ੍ਰਿਫਤਾਰ!<eol>ਰਾਜਨਾ...\n",
              "172          PUN0173  ...  ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਡਾ. ਮਨਮੋਹਨ ਸਿੰਘ ਨੇ ਅੱਜ ਦੱਖਣੀ ਕੋਰੀ...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK0Dm2839_fM",
        "colab_type": "code",
        "outputId": "713ad31f-9cdb-4d95-cef6-43e3384d212c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1423</th>\n",
              "      <td>ਜਾਟ ਨੇਤਾਵਾਂ ਨੇ ਸਰਕਾਰ ਨੂੰ 31 ਮਾਰਚ ਤੱਕ ਦਾ ਅਲਟੀਮੇ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1118</th>\n",
              "      <td>ਜੰਤਰ ਮੰਤਰ ਵਿਖੇ ਪਰਲਜ਼ ਕੰਪਨੀ ਦੇ ਮਾਲਕ ਖਿਲਾਫ ਰੋਸ ਪ੍...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1355</th>\n",
              "      <td>ਲੁਧਿਆਣਾ ਵਿਖੇ ਇਕ ਕਰੋੜ ਦੀ ਹਵਾਲਾ ਰਕਮ ਸਮੇਤ ਦੋ ਕਾਬੂ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931</th>\n",
              "      <td>ਹਾਊਸਿੰਗ ਡਿਵੈਲਪਮੈਂਟ ਫਾਇਨਾਂਸ ਕਾਰਪੋਰੇਸ਼ਨ (ਐਚਡੀਐਫਸੀ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1207</th>\n",
              "      <td>ਮਾਹੂਤ ਅਤੇ ਹਰਬਰਟ ਬਣੇ ਵਿੰਬਲਡਨ ਡਬਲਜ਼ ਚੈਂਪੀਅਨ&lt;eol&gt;ਟ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "1423  ਜਾਟ ਨੇਤਾਵਾਂ ਨੇ ਸਰਕਾਰ ਨੂੰ 31 ਮਾਰਚ ਤੱਕ ਦਾ ਅਲਟੀਮੇ...      0\n",
              "1118  ਜੰਤਰ ਮੰਤਰ ਵਿਖੇ ਪਰਲਜ਼ ਕੰਪਨੀ ਦੇ ਮਾਲਕ ਖਿਲਾਫ ਰੋਸ ਪ੍...      0\n",
              "1355  ਲੁਧਿਆਣਾ ਵਿਖੇ ਇਕ ਕਰੋੜ ਦੀ ਹਵਾਲਾ ਰਕਮ ਸਮੇਤ ਦੋ ਕਾਬੂ...      0\n",
              "931   ਹਾਊਸਿੰਗ ਡਿਵੈਲਪਮੈਂਟ ਫਾਇਨਾਂਸ ਕਾਰਪੋਰੇਸ਼ਨ (ਐਚਡੀਐਫਸੀ...      0\n",
              "1207  ਮਾਹੂਤ ਅਤੇ ਹਰਬਰਟ ਬਣੇ ਵਿੰਬਲਡਨ ਡਬਲਜ਼ ਚੈਂਪੀਅਨ<eol>ਟ...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64AfSL-V-Ij5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60lFABu1-KAE",
        "colab_type": "code",
        "outputId": "8c3a685e-1436-4237-f668-ddc413d65bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "4729035602ef47768c8131a69ee83991",
            "59dfbad9acc94b41b0a78ac1d980f79f",
            "ca45941d0e2f4641a83229617f9402ab",
            "4e1e0d3d40c446ffa6846f96cfa34241",
            "904e06758288499fb3c36120c53ccc77",
            "9ca486b0b55346448d6554fc93c73451",
            "15094c6ac2274b2fa957f9af583f136b",
            "ca5a29439526446d8b32e8b879eec3dd"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4729035602ef47768c8131a69ee83991",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqawKMwS-o5b",
        "colab_type": "code",
        "outputId": "a826f0fe-b93a-4c7d-bfd3-1e39353446d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  ਰੀਓ ਉਲੰਪਿਕ ਜਾਵੇਗਾ ਨਰਸਿੰਘ<eol>ਨਰਸਿੰਘ ਜਾਵੇਗਾ ਰੀਓ ਉਲਪਿੰਕ\n",
            "Tokenized:  ['ਰ', '##ੀ', '##ਓ', 'ਉ', '##ਲ', '##ਪ', '##ਿਕ', 'ਜਾ', '##ਵ', '##ਗ', '##ਾ', 'ਨ', '##ਰ', '##ਸ', '##ਿ', '##ਘ', '<', 'eo', '##l', '>', 'ਨ', '##ਰ', '##ਸ', '##ਿ', '##ਘ', 'ਜਾ', '##ਵ', '##ਗ', '##ਾ', 'ਰ', '##ੀ', '##ਓ', 'ਉ', '##ਲ', '##ਪ', '##ਿਕ']\n",
            "Token IDs:  [1041, 13094, 111248, 1011, 15423, 31948, 26674, 62130, 32143, 48874, 13768, 1034, 13475, 19836, 45378, 111250, 133, 13934, 10161, 135, 1034, 13475, 19836, 45378, 111250, 62130, 32143, 48874, 13768, 1041, 13094, 111248, 1011, 15423, 31948, 26674]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKGzPxF1AUUM",
        "colab_type": "code",
        "outputId": "565d2f7b-b8d4-4387-ea0f-89028a8ea304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  ਰੀਓ ਉਲੰਪਿਕ ਜਾਵੇਗਾ ਨਰਸਿੰਘ<eol>ਨਰਸਿੰਘ ਜਾਵੇਗਾ ਰੀਓ ਉਲਪਿੰਕ\n",
            "Token IDs: [101, 1041, 13094, 111248, 1011, 15423, 31948, 26674, 62130, 32143, 48874, 13768, 1034, 13475, 19836, 45378, 111250, 133, 13934, 10161, 135, 1034, 13475, 19836, 45378, 111250, 62130, 32143, 48874, 13768, 1041, 13094, 111248, 1011, 15423, 31948, 26674, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv39u2kLAo9b",
        "colab_type": "code",
        "outputId": "a93285dd-665c-470c-88df-ea674a30ba57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH_GkPkFAsKR",
        "colab_type": "code",
        "outputId": "bce01d33-54e9-4d1c-9710-3aa2a43c1207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUKKZrYgAuTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfmeSm3zAxOP",
        "colab_type": "code",
        "outputId": "4139d4e8-2346-4325-f55e-ca428141f0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.2)\n",
        "print(train_inputs)\n",
        "print(train_labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.2)\n",
        "#print(train_masks)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   101   1035  72497 ...  14673  15423   1041]\n",
            " [   101   1039  22236 ...    102      0      0]\n",
            " [   101  46043   1035 ...   1037  48560   1032]\n",
            " ...\n",
            " [   101   1044  21205 ...      0      0      0]\n",
            " [   101   1032  19836 ... 108041   1041  14673]\n",
            " [   101   1032  64812 ...  12666   1044  72497]]\n",
            "[0 1 0 ... 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6BSzcZ-A8JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2ab-k8GgLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvYAxocaGzaO",
        "colab_type": "code",
        "outputId": "0de876d7-9f32-4c3b-e2ca-8d25d4572325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6bb3a7080d8c4f5ab6509eb0185f13ec",
            "3cb0ac8149584038875c36c4b973c47f",
            "b6748e83a49d466fb33f8d3653a59666",
            "5ee5c96bb41045bbabc6b80d7fcf6b30",
            "8ff4692675284d0fbb269cae591aa390",
            "27e59249112b458a8053dc549cb8d11e",
            "abffc252e14043b6b97fc6a8765f1283",
            "ff4c622facf241db84fb6512b3682363",
            "974f6807ed3b458fbfa74e2a22e92d9b",
            "a413961eff3844c6b5333adb052fb230",
            "3c77b31c2b044b7fb9f6a3fa4edb7061",
            "1a70d2c8947f4c41842b5d3ebe9c598b",
            "48313c3fed7841eaa29824cd377e26f7",
            "e58cdee18b2d4e43b47a04b1808490dc",
            "f310dbd6193a4cc6b119d2f4af22704d",
            "86274736f10044d6b70d39cfc78a0023"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bb3a7080d8c4f5ab6509eb0185f13ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "974f6807ed3b458fbfa74e2a22e92d9b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xB1woJrHCZ0",
        "colab_type": "code",
        "outputId": "ba92e779-876d-48d6-b77f-6dadf3ceac21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NhjDCrtHGh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBK2E_PaHKQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOO83LgEHQYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2jmuLjzHUP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6dh8MSXHXCv",
        "colab_type": "code",
        "outputId": "2795fe46-c638-4566-ede2-0e1d390a5cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     43.    Elapsed: 0:00:31.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     43.    Elapsed: 0:00:31.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     43.    Elapsed: 0:00:31.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     43.    Elapsed: 0:00:31.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epcoh took: 0:00:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3sCgA3MK9B2",
        "colab_type": "code",
        "outputId": "584c2dde-aa22-45ed-e47a-2515477669e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/FYP/bert/glue/cola/testdata/task1punjabi-test.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHsFeNFSLIkL",
        "colab_type": "code",
        "outputId": "8f7a7960-505d-4f0a-a5bc-cd12f7b0473a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "  # # print(predictions)\n",
        "  #print(true_labels)\n",
        "print('    DONE.')\n",
        "\n",
        "#print(true_labels)\n",
        "print(\"*************************\")\n",
        "\n",
        "#print(len(predictions))\n",
        "#print(outputs)\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 500 test sentences...\n",
            "    DONE.\n",
            "*************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCGGtb-jicKL",
        "colab_type": "code",
        "outputId": "537ec9f5-f45e-46a6-b4b4-106812b31239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "count_NP=0\n",
        "count_P=0\n",
        "count_line=1\n",
        "x=-1\n",
        "true_count,false_count=0,0\n",
        "print(\"label \\t sno\\tlogit\\t\\t\\t\\t\\tindex\")\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    print(\"(\",end=\"\")\n",
        "    print(true_labels[i][j],end=\"\")\n",
        "    print(\")\",end=\"\")\n",
        "    print(\"\\t\",count_line,end=\"\")\n",
        "    # print(\"-  \",end=\"\")\n",
        "    if(predictions[i][j][0]>predictions[i][j][1] ):\n",
        "      #count_P+=1 \n",
        "      #print(\" Non Paraphrase         \",end=\"\")\n",
        "      print(\"\\t\",predictions[i][j],\"\\t0\\t\",end=\"\")\n",
        "      x=0\n",
        "    elif(predictions[i][j][1]>predictions[i][j][0] ):\n",
        "      #print(\" Paraphrase     \",end=\"\")\n",
        "     # count_NP+=1      \n",
        "      print(\"\\t\",predictions[i][j],\"\\t1\\t\",end=\"\")\n",
        "      x=1\n",
        "    # elif(predictions[i][j][2]>predictions[i][j][0] and predictions[i][j][2]>predictions[i][j][1]):\n",
        "    #   #print(\" Semi Paraphrase     \",end=\"\")\n",
        "    #   #count_NP+=1      \n",
        "    #   print(\"\\t\",predictions[i][j][2],\"\\t2\\t\",end=\"\")\n",
        "    #   x=1\n",
        "    count_line+=1\n",
        "    #print(\"\\t\",predictions[i][j],\"\\t2\\t\",end=\"\")\n",
        "\n",
        "    if(true_labels[i][j]==x):\n",
        "      true_count+=1\n",
        "      print(\"true\")\n",
        "    else:\n",
        "      print(\"false\")\n",
        "      false_count+=1\n",
        "\n",
        "print(\"Number of true predictions:\",true_count)\n",
        "print(\"Number of false predictions:\",false_count)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label \t sno\tlogit\t\t\t\t\tindex\n",
            "(1)\t 1\t [ 0.0581192 -0.6187233] \t0\tfalse\n",
            "(0)\t 2\t [ 2.5161643 -2.8488414] \t0\ttrue\n",
            "(0)\t 3\t [-0.17654401 -0.45397618] \t0\ttrue\n",
            "(0)\t 4\t [-1.6933911  1.4749947] \t1\tfalse\n",
            "(0)\t 5\t [ 2.547475  -2.8779964] \t0\ttrue\n",
            "(0)\t 6\t [-0.2147169 -0.3077682] \t0\ttrue\n",
            "(1)\t 7\t [-2.6854837  2.6970983] \t1\ttrue\n",
            "(0)\t 8\t [ 2.570915  -2.8508482] \t0\ttrue\n",
            "(0)\t 9\t [ 2.6034906 -2.8771486] \t0\ttrue\n",
            "(1)\t 10\t [-1.6616409  1.718705 ] \t1\ttrue\n",
            "(1)\t 11\t [-2.7752883  2.6412165] \t1\ttrue\n",
            "(1)\t 12\t [-2.7496517  2.660605 ] \t1\ttrue\n",
            "(0)\t 13\t [ 0.06346288 -0.7067107 ] \t0\ttrue\n",
            "(1)\t 14\t [-2.660318   2.6572685] \t1\ttrue\n",
            "(0)\t 15\t [ 2.5746536 -2.8823972] \t0\ttrue\n",
            "(0)\t 16\t [ 0.06223417 -0.68862116] \t0\ttrue\n",
            "(0)\t 17\t [ 0.13318855 -0.68150455] \t0\ttrue\n",
            "(0)\t 18\t [ 0.37081572 -0.85588425] \t0\ttrue\n",
            "(0)\t 19\t [ 2.587765  -2.8670342] \t0\ttrue\n",
            "(0)\t 20\t [ 2.5743768 -2.9105806] \t0\ttrue\n",
            "(0)\t 21\t [-0.04722058 -0.55615497] \t0\ttrue\n",
            "(0)\t 22\t [ 0.12775604 -0.7164631 ] \t0\ttrue\n",
            "(0)\t 23\t [ 0.6220503 -1.1609815] \t0\ttrue\n",
            "(0)\t 24\t [-0.11257616 -0.4921314 ] \t0\ttrue\n",
            "(1)\t 25\t [-2.7607067  2.70286  ] \t1\ttrue\n",
            "(0)\t 26\t [-0.23655994 -0.28867286] \t0\ttrue\n",
            "(0)\t 27\t [ 0.13120574 -0.6886663 ] \t0\ttrue\n",
            "(0)\t 28\t [ 0.43530783 -0.99402815] \t0\ttrue\n",
            "(0)\t 29\t [ 0.22244965 -0.90178835] \t0\ttrue\n",
            "(0)\t 30\t [ 2.5334506 -2.8781557] \t0\ttrue\n",
            "(0)\t 31\t [ 2.5711818 -2.862084 ] \t0\ttrue\n",
            "(1)\t 32\t [-2.7467654  2.6966095] \t1\ttrue\n",
            "(0)\t 33\t [ 0.18804713 -0.7693767 ] \t0\ttrue\n",
            "(0)\t 34\t [ 2.5527775 -2.8308918] \t0\ttrue\n",
            "(0)\t 35\t [ 0.18149504 -0.7468868 ] \t0\ttrue\n",
            "(0)\t 36\t [ 0.2401053 -0.7725025] \t0\ttrue\n",
            "(0)\t 37\t [ 0.11998217 -0.7822284 ] \t0\ttrue\n",
            "(1)\t 38\t [-2.7637866  2.6879528] \t1\ttrue\n",
            "(0)\t 39\t [ 0.14679691 -0.71436244] \t0\ttrue\n",
            "(0)\t 40\t [ 2.4070325 -2.6740794] \t0\ttrue\n",
            "(1)\t 41\t [-2.8320563  2.6504886] \t1\ttrue\n",
            "(1)\t 42\t [-2.7508104  2.7433465] \t1\ttrue\n",
            "(1)\t 43\t [-1.9690474  1.9604598] \t1\ttrue\n",
            "(0)\t 44\t [ 0.39332756 -0.9545888 ] \t0\ttrue\n",
            "(1)\t 45\t [-2.788594  2.746203] \t1\ttrue\n",
            "(1)\t 46\t [-2.7405288  2.6249428] \t1\ttrue\n",
            "(0)\t 47\t [-0.0947786  -0.49693224] \t0\ttrue\n",
            "(0)\t 48\t [ 2.5593655 -2.8225994] \t0\ttrue\n",
            "(0)\t 49\t [ 0.08791753 -0.66092414] \t0\ttrue\n",
            "(1)\t 50\t [-2.721733  2.631464] \t1\ttrue\n",
            "(0)\t 51\t [ 2.410804  -2.8305748] \t0\ttrue\n",
            "(0)\t 52\t [ 2.5506883 -2.8882723] \t0\ttrue\n",
            "(1)\t 53\t [-0.01154661 -0.56304795] \t0\tfalse\n",
            "(1)\t 54\t [-2.4955075  2.5421345] \t1\ttrue\n",
            "(1)\t 55\t [ 0.08957395 -0.65596676] \t0\tfalse\n",
            "(0)\t 56\t [ 2.5752442 -2.8183472] \t0\ttrue\n",
            "(0)\t 57\t [ 0.02819471 -0.59386015] \t0\ttrue\n",
            "(0)\t 58\t [ 0.07870195 -0.6338829 ] \t0\ttrue\n",
            "(0)\t 59\t [-0.12177473 -0.424705  ] \t0\ttrue\n",
            "(0)\t 60\t [ 2.0276816 -2.5111325] \t0\ttrue\n",
            "(1)\t 61\t [-2.671022   2.7436895] \t1\ttrue\n",
            "(0)\t 62\t [ 0.0941492  -0.65500516] \t0\ttrue\n",
            "(0)\t 63\t [ 2.5322666 -2.8942327] \t0\ttrue\n",
            "(0)\t 64\t [ 0.11016537 -0.7714595 ] \t0\ttrue\n",
            "(0)\t 65\t [-0.55374914 -0.02603552] \t1\tfalse\n",
            "(0)\t 66\t [ 0.11118456 -0.69931185] \t0\ttrue\n",
            "(0)\t 67\t [-0.06811357 -0.61049247] \t0\ttrue\n",
            "(0)\t 68\t [ 0.12996621 -0.7004057 ] \t0\ttrue\n",
            "(0)\t 69\t [ 2.5325787 -2.9188993] \t0\ttrue\n",
            "(0)\t 70\t [ 2.5125349 -2.8339267] \t0\ttrue\n",
            "(1)\t 71\t [-2.6407654  2.66782  ] \t1\ttrue\n",
            "(0)\t 72\t [ 0.6600235 -1.1764914] \t0\ttrue\n",
            "(1)\t 73\t [-2.7668278  2.693955 ] \t1\ttrue\n",
            "(0)\t 74\t [ 2.3418067 -2.8202572] \t0\ttrue\n",
            "(0)\t 75\t [-0.06200998 -0.6255693 ] \t0\ttrue\n",
            "(0)\t 76\t [ 2.5183005 -2.8274987] \t0\ttrue\n",
            "(1)\t 77\t [-2.2571006  2.2960024] \t1\ttrue\n",
            "(0)\t 78\t [-0.14057375 -0.4142633 ] \t0\ttrue\n",
            "(1)\t 79\t [-2.6982238  2.7312307] \t1\ttrue\n",
            "(1)\t 80\t [-2.235196   2.4231591] \t1\ttrue\n",
            "(0)\t 81\t [ 0.06712233 -0.6565951 ] \t0\ttrue\n",
            "(1)\t 82\t [-2.6966097  2.7095478] \t1\ttrue\n",
            "(1)\t 83\t [-1.9740628  1.850864 ] \t1\ttrue\n",
            "(1)\t 84\t [-2.8452363  2.6520228] \t1\ttrue\n",
            "(0)\t 85\t [-1.0989466  0.7507754] \t1\tfalse\n",
            "(1)\t 86\t [-2.8400855  2.722881 ] \t1\ttrue\n",
            "(1)\t 87\t [-2.7866564  2.7258925] \t1\ttrue\n",
            "(1)\t 88\t [-2.5846872  2.7030563] \t1\ttrue\n",
            "(1)\t 89\t [ 0.02072784 -0.5960084 ] \t0\tfalse\n",
            "(1)\t 90\t [-1.6714171  1.5697471] \t1\ttrue\n",
            "(1)\t 91\t [-2.797734  2.682143] \t1\ttrue\n",
            "(1)\t 92\t [-2.7532306  2.7682998] \t1\ttrue\n",
            "(1)\t 93\t [-2.6942422  2.7338824] \t1\ttrue\n",
            "(1)\t 94\t [-2.730591   2.7577388] \t1\ttrue\n",
            "(1)\t 95\t [-2.6828146  2.6579194] \t1\ttrue\n",
            "(1)\t 96\t [-2.7273932  2.748256 ] \t1\ttrue\n",
            "(1)\t 97\t [-2.617338  2.732808] \t1\ttrue\n",
            "(1)\t 98\t [-2.2290776  2.1413705] \t1\ttrue\n",
            "(0)\t 99\t [ 2.4938216 -2.8845618] \t0\ttrue\n",
            "(1)\t 100\t [-2.6530895  2.717276 ] \t1\ttrue\n",
            "(1)\t 101\t [-2.6642506  2.658833 ] \t1\ttrue\n",
            "(1)\t 102\t [-0.79819745  0.59144866] \t1\ttrue\n",
            "(1)\t 103\t [-0.02350105 -0.58190227] \t0\tfalse\n",
            "(1)\t 104\t [-2.7023478  2.660245 ] \t1\ttrue\n",
            "(1)\t 105\t [-1.9423336  1.9047267] \t1\ttrue\n",
            "(0)\t 106\t [-0.08116589 -0.47374868] \t0\ttrue\n",
            "(1)\t 107\t [-2.7551153  2.7274556] \t1\ttrue\n",
            "(0)\t 108\t [-0.11918816 -0.4739065 ] \t0\ttrue\n",
            "(1)\t 109\t [-2.5201118  2.4476147] \t1\ttrue\n",
            "(1)\t 110\t [-2.4769833  2.463286 ] \t1\ttrue\n",
            "(0)\t 111\t [-1.15538525e-04 -6.19852424e-01] \t0\ttrue\n",
            "(0)\t 112\t [-1.6433327  1.4772565] \t1\tfalse\n",
            "(0)\t 113\t [ 0.2086481  -0.81883496] \t0\ttrue\n",
            "(0)\t 114\t [ 2.4196317 -2.8048038] \t0\ttrue\n",
            "(0)\t 115\t [-0.05474401 -0.6076096 ] \t0\ttrue\n",
            "(0)\t 116\t [-0.0184204 -0.6037542] \t0\ttrue\n",
            "(1)\t 117\t [-2.71751    2.7075622] \t1\ttrue\n",
            "(0)\t 118\t [ 0.38360944 -0.9413908 ] \t0\ttrue\n",
            "(0)\t 119\t [ 0.0096613 -0.6218775] \t0\ttrue\n",
            "(1)\t 120\t [-2.5373397  2.502967 ] \t1\ttrue\n",
            "(1)\t 121\t [-2.7474525  2.6445885] \t1\ttrue\n",
            "(1)\t 122\t [-2.1434247  1.9601952] \t1\ttrue\n",
            "(1)\t 123\t [-0.00080348 -0.65058976] \t0\tfalse\n",
            "(1)\t 124\t [-2.4963036  2.6047587] \t1\ttrue\n",
            "(0)\t 125\t [ 2.5833912 -2.8530204] \t0\ttrue\n",
            "(0)\t 126\t [ 0.33612862 -0.80838984] \t0\ttrue\n",
            "(1)\t 127\t [-2.68388   2.627464] \t1\ttrue\n",
            "(0)\t 128\t [ 0.02896917 -0.5969549 ] \t0\ttrue\n",
            "(0)\t 129\t [-0.90594226  0.80544287] \t1\tfalse\n",
            "(0)\t 130\t [-0.53338635 -0.03684691] \t1\tfalse\n",
            "(0)\t 131\t [-0.3218171  -0.24776576] \t1\tfalse\n",
            "(1)\t 132\t [-2.7817116  2.6451178] \t1\ttrue\n",
            "(1)\t 133\t [-0.2629765  -0.10909755] \t1\ttrue\n",
            "(0)\t 134\t [ 2.539353  -2.7190113] \t0\ttrue\n",
            "(0)\t 135\t [ 0.02336197 -0.59417087] \t0\ttrue\n",
            "(0)\t 136\t [ 2.4561183 -2.784398 ] \t0\ttrue\n",
            "(0)\t 137\t [ 2.4866776 -2.8929772] \t0\ttrue\n",
            "(0)\t 138\t [ 2.5769086 -2.8997998] \t0\ttrue\n",
            "(0)\t 139\t [ 2.4315188 -2.7163246] \t0\ttrue\n",
            "(0)\t 140\t [ 2.4137518 -2.6834137] \t0\ttrue\n",
            "(1)\t 141\t [-1.1689565  1.2268479] \t1\ttrue\n",
            "(0)\t 142\t [ 0.53541255 -1.0600107 ] \t0\ttrue\n",
            "(0)\t 143\t [ 2.5170105 -2.8525524] \t0\ttrue\n",
            "(1)\t 144\t [-2.7399554  2.6175518] \t1\ttrue\n",
            "(1)\t 145\t [-2.8018463  2.6965222] \t1\ttrue\n",
            "(1)\t 146\t [ 0.12057248 -0.71330005] \t0\tfalse\n",
            "(1)\t 147\t [ 0.00437907 -0.6738464 ] \t0\tfalse\n",
            "(1)\t 148\t [ 0.01277478 -0.5982606 ] \t0\tfalse\n",
            "(0)\t 149\t [ 0.20548497 -0.76511097] \t0\ttrue\n",
            "(1)\t 150\t [-1.6808069  1.6482483] \t1\ttrue\n",
            "(1)\t 151\t [-2.6801822  2.739527 ] \t1\ttrue\n",
            "(1)\t 152\t [-0.03946254 -0.55229956] \t0\tfalse\n",
            "(1)\t 153\t [-2.6655545  2.590705 ] \t1\ttrue\n",
            "(1)\t 154\t [-2.6637335  2.6484704] \t1\ttrue\n",
            "(0)\t 155\t [-1.0922841   0.70491385] \t1\tfalse\n",
            "(1)\t 156\t [-2.81704   2.703543] \t1\ttrue\n",
            "(0)\t 157\t [ 0.02758973 -0.5829492 ] \t0\ttrue\n",
            "(1)\t 158\t [-2.5913408  2.4614685] \t1\ttrue\n",
            "(1)\t 159\t [-2.7425745  2.674042 ] \t1\ttrue\n",
            "(1)\t 160\t [-2.1916158  2.0868316] \t1\ttrue\n",
            "(1)\t 161\t [-1.5709361  1.5005809] \t1\ttrue\n",
            "(0)\t 162\t [-2.7188678  2.8044922] \t1\tfalse\n",
            "(0)\t 163\t [ 0.06598376 -0.68938464] \t0\ttrue\n",
            "(1)\t 164\t [ 0.00521937 -0.6637492 ] \t0\tfalse\n",
            "(0)\t 165\t [-1.0737387  0.9050479] \t1\tfalse\n",
            "(1)\t 166\t [-2.7158704  2.6832075] \t1\ttrue\n",
            "(1)\t 167\t [-2.501191   2.6570399] \t1\ttrue\n",
            "(1)\t 168\t [-2.776264   2.6578355] \t1\ttrue\n",
            "(1)\t 169\t [-2.8035562  2.7689648] \t1\ttrue\n",
            "(1)\t 170\t [ 0.48970816 -0.9748502 ] \t0\tfalse\n",
            "(0)\t 171\t [-0.9669564  0.6893732] \t1\tfalse\n",
            "(0)\t 172\t [ 0.11716834 -0.7191306 ] \t0\ttrue\n",
            "(0)\t 173\t [ 2.607365  -2.8888505] \t0\ttrue\n",
            "(1)\t 174\t [-0.01833188 -0.5502035 ] \t0\tfalse\n",
            "(1)\t 175\t [-1.5662425  1.293833 ] \t1\ttrue\n",
            "(0)\t 176\t [ 2.5573359 -2.8074121] \t0\ttrue\n",
            "(1)\t 177\t [-2.7562492  2.7201972] \t1\ttrue\n",
            "(0)\t 178\t [ 2.520556  -2.8298893] \t0\ttrue\n",
            "(0)\t 179\t [-0.11566931 -0.46894413] \t0\ttrue\n",
            "(0)\t 180\t [ 0.14363076 -0.7513328 ] \t0\ttrue\n",
            "(0)\t 181\t [ 0.24470876 -0.7800077 ] \t0\ttrue\n",
            "(1)\t 182\t [-2.616716   2.6387093] \t1\ttrue\n",
            "(0)\t 183\t [ 2.5835989 -2.8138838] \t0\ttrue\n",
            "(0)\t 184\t [-0.04923328 -0.5378821 ] \t0\ttrue\n",
            "(1)\t 185\t [-1.0489382   0.84309816] \t1\ttrue\n",
            "(0)\t 186\t [-0.11818486 -0.44939405] \t0\ttrue\n",
            "(1)\t 187\t [-2.686378   2.6855097] \t1\ttrue\n",
            "(1)\t 188\t [-2.7581306  2.7955868] \t1\ttrue\n",
            "(1)\t 189\t [-2.525222   2.4342604] \t1\ttrue\n",
            "(1)\t 190\t [-2.4197967  2.4729693] \t1\ttrue\n",
            "(0)\t 191\t [-0.06049386 -0.5206169 ] \t0\ttrue\n",
            "(0)\t 192\t [-2.2529812  2.1766286] \t1\tfalse\n",
            "(0)\t 193\t [ 0.11812215 -0.6804252 ] \t0\ttrue\n",
            "(1)\t 194\t [-2.549515  2.583429] \t1\ttrue\n",
            "(0)\t 195\t [ 0.03732954 -0.622044  ] \t0\ttrue\n",
            "(0)\t 196\t [-1.2887269  0.9476063] \t1\tfalse\n",
            "(0)\t 197\t [ 0.03771334 -0.6138206 ] \t0\ttrue\n",
            "(1)\t 198\t [ 2.290432  -2.7621768] \t0\tfalse\n",
            "(0)\t 199\t [ 0.20778479 -0.75222343] \t0\ttrue\n",
            "(1)\t 200\t [-2.4580803  2.600034 ] \t1\ttrue\n",
            "(0)\t 201\t [-2.683184   2.8187976] \t1\tfalse\n",
            "(0)\t 202\t [ 0.12143683 -0.7124624 ] \t0\ttrue\n",
            "(0)\t 203\t [-0.01866985 -0.63940257] \t0\ttrue\n",
            "(0)\t 204\t [ 2.4777756 -2.783795 ] \t0\ttrue\n",
            "(0)\t 205\t [ 0.1087914 -0.6717041] \t0\ttrue\n",
            "(1)\t 206\t [-2.7354648  2.745199 ] \t1\ttrue\n",
            "(0)\t 207\t [ 0.09096498 -0.665106  ] \t0\ttrue\n",
            "(1)\t 208\t [-2.7746348  2.7242484] \t1\ttrue\n",
            "(1)\t 209\t [-2.7284443  2.6575224] \t1\ttrue\n",
            "(0)\t 210\t [ 0.059956   -0.65876555] \t0\ttrue\n",
            "(0)\t 211\t [ 0.16445845 -0.70040685] \t0\ttrue\n",
            "(1)\t 212\t [-2.6803079  2.748089 ] \t1\ttrue\n",
            "(1)\t 213\t [ 0.21868615 -0.8195348 ] \t0\tfalse\n",
            "(1)\t 214\t [-2.458001   2.5309162] \t1\ttrue\n",
            "(0)\t 215\t [ 0.08860688 -0.616771  ] \t0\ttrue\n",
            "(0)\t 216\t [ 0.11646417 -0.6859811 ] \t0\ttrue\n",
            "(1)\t 217\t [-2.6567438  2.6839263] \t1\ttrue\n",
            "(0)\t 218\t [ 0.0908473 -0.6385803] \t0\ttrue\n",
            "(1)\t 219\t [-2.5836074  2.6095014] \t1\ttrue\n",
            "(1)\t 220\t [-2.4752119  2.689815 ] \t1\ttrue\n",
            "(1)\t 221\t [-2.3600714  2.4417067] \t1\ttrue\n",
            "(1)\t 222\t [-0.01941689 -0.656018  ] \t0\tfalse\n",
            "(1)\t 223\t [ 0.03617027 -0.6687046 ] \t0\tfalse\n",
            "(0)\t 224\t [ 0.11114731 -0.69672227] \t0\ttrue\n",
            "(1)\t 225\t [-0.7628443  0.6384786] \t1\ttrue\n",
            "(0)\t 226\t [-0.16497831 -0.44001386] \t0\ttrue\n",
            "(1)\t 227\t [-2.7115133  2.7477248] \t1\ttrue\n",
            "(1)\t 228\t [ 2.3853421 -2.7738695] \t0\tfalse\n",
            "(1)\t 229\t [-2.677014  2.766772] \t1\ttrue\n",
            "(1)\t 230\t [-2.7811584  2.7331092] \t1\ttrue\n",
            "(0)\t 231\t [ 1.7194265 -2.094104 ] \t0\ttrue\n",
            "(0)\t 232\t [ 0.07122037 -0.6509301 ] \t0\ttrue\n",
            "(1)\t 233\t [ 0.00155733 -0.607165  ] \t0\tfalse\n",
            "(0)\t 234\t [ 0.09128083 -0.55849504] \t0\ttrue\n",
            "(0)\t 235\t [ 0.14830755 -0.7384508 ] \t0\ttrue\n",
            "(1)\t 236\t [-2.7413929  2.7351074] \t1\ttrue\n",
            "(1)\t 237\t [-2.8025396  2.723035 ] \t1\ttrue\n",
            "(0)\t 238\t [ 0.21712658 -0.794047  ] \t0\ttrue\n",
            "(0)\t 239\t [-2.7310736  2.7874045] \t1\tfalse\n",
            "(1)\t 240\t [-2.7548187  2.6453207] \t1\ttrue\n",
            "(1)\t 241\t [-2.5948424  2.4921498] \t1\ttrue\n",
            "(1)\t 242\t [ 0.18291847 -0.73824435] \t0\tfalse\n",
            "(1)\t 243\t [-0.00414905 -0.5835327 ] \t0\tfalse\n",
            "(1)\t 244\t [-2.5732613  2.5160544] \t1\ttrue\n",
            "(0)\t 245\t [ 0.10022398 -0.6673642 ] \t0\ttrue\n",
            "(0)\t 246\t [ 2.5314274 -2.7376783] \t0\ttrue\n",
            "(0)\t 247\t [ 2.4057772 -2.669637 ] \t0\ttrue\n",
            "(0)\t 248\t [ 2.5350711 -2.824558 ] \t0\ttrue\n",
            "(1)\t 249\t [-0.02228205 -0.60429174] \t0\tfalse\n",
            "(1)\t 250\t [-2.6448164  2.7736394] \t1\ttrue\n",
            "(1)\t 251\t [-2.6449292  2.6460352] \t1\ttrue\n",
            "(0)\t 252\t [-0.06380236 -0.60043144] \t0\ttrue\n",
            "(0)\t 253\t [-0.13254945 -0.3628971 ] \t0\ttrue\n",
            "(0)\t 254\t [ 2.0190237 -2.3947167] \t0\ttrue\n",
            "(1)\t 255\t [ 0.0239085  -0.61631334] \t0\tfalse\n",
            "(0)\t 256\t [ 2.5832448 -2.876826 ] \t0\ttrue\n",
            "(1)\t 257\t [-2.792705   2.7104516] \t1\ttrue\n",
            "(0)\t 258\t [ 2.0760002 -2.5198753] \t0\ttrue\n",
            "(0)\t 259\t [ 0.01059996 -0.6059382 ] \t0\ttrue\n",
            "(0)\t 260\t [ 0.26173416 -0.8422746 ] \t0\ttrue\n",
            "(1)\t 261\t [-2.7911327  2.630912 ] \t1\ttrue\n",
            "(0)\t 262\t [ 2.5034816 -2.8646994] \t0\ttrue\n",
            "(0)\t 263\t [-0.02756512 -0.63179743] \t0\ttrue\n",
            "(1)\t 264\t [-2.7801256  2.691168 ] \t1\ttrue\n",
            "(1)\t 265\t [-2.566539   2.4899569] \t1\ttrue\n",
            "(1)\t 266\t [-2.761097   2.6654472] \t1\ttrue\n",
            "(1)\t 267\t [-2.6736646  2.6810784] \t1\ttrue\n",
            "(0)\t 268\t [ 2.4228911 -2.5877657] \t0\ttrue\n",
            "(0)\t 269\t [ 2.5139792 -2.7597954] \t0\ttrue\n",
            "(1)\t 270\t [-0.09777718 -0.4580602 ] \t0\tfalse\n",
            "(1)\t 271\t [-2.426349  2.303113] \t1\ttrue\n",
            "(1)\t 272\t [-0.04774827 -0.52654517] \t0\tfalse\n",
            "(1)\t 273\t [-2.6237686  2.751182 ] \t1\ttrue\n",
            "(0)\t 274\t [ 2.597934  -2.8220434] \t0\ttrue\n",
            "(1)\t 275\t [-2.3303795  2.378184 ] \t1\ttrue\n",
            "(1)\t 276\t [-2.7768505  2.7460923] \t1\ttrue\n",
            "(1)\t 277\t [-2.7493882  2.6582348] \t1\ttrue\n",
            "(0)\t 278\t [ 2.4715765 -2.8355775] \t0\ttrue\n",
            "(1)\t 279\t [-2.2634003  2.4832127] \t1\ttrue\n",
            "(0)\t 280\t [ 0.10248931 -0.6844946 ] \t0\ttrue\n",
            "(0)\t 281\t [ 0.02707445 -0.6295445 ] \t0\ttrue\n",
            "(1)\t 282\t [-2.3016043  2.3331068] \t1\ttrue\n",
            "(0)\t 283\t [ 2.3415606 -2.6935532] \t0\ttrue\n",
            "(1)\t 284\t [-2.602588   2.6148841] \t1\ttrue\n",
            "(1)\t 285\t [ 0.18809056 -0.77637243] \t0\tfalse\n",
            "(1)\t 286\t [ 0.08865935 -0.6643732 ] \t0\tfalse\n",
            "(0)\t 287\t [ 0.20933178 -0.7786581 ] \t0\ttrue\n",
            "(1)\t 288\t [-2.6399539  2.65429  ] \t1\ttrue\n",
            "(0)\t 289\t [-0.33864507 -0.19342333] \t1\tfalse\n",
            "(0)\t 290\t [ 2.500876  -2.7991116] \t0\ttrue\n",
            "(1)\t 291\t [-1.26504    1.0241796] \t1\ttrue\n",
            "(1)\t 292\t [-2.7138147  2.7225614] \t1\ttrue\n",
            "(1)\t 293\t [-2.3605897  2.612664 ] \t1\ttrue\n",
            "(1)\t 294\t [-2.5475516  2.5023472] \t1\ttrue\n",
            "(1)\t 295\t [-2.6440587  2.6350157] \t1\ttrue\n",
            "(0)\t 296\t [ 0.19463894 -0.80877626] \t0\ttrue\n",
            "(1)\t 297\t [ 0.12052094 -0.6885577 ] \t0\tfalse\n",
            "(0)\t 298\t [ 0.02416575 -0.66320586] \t0\ttrue\n",
            "(0)\t 299\t [ 0.09123797 -0.76380193] \t0\ttrue\n",
            "(1)\t 300\t [-2.3452878  2.2262466] \t1\ttrue\n",
            "(0)\t 301\t [-0.02494329 -0.5966511 ] \t0\ttrue\n",
            "(0)\t 302\t [-0.01923179 -0.5641559 ] \t0\ttrue\n",
            "(0)\t 303\t [ 2.5998676 -2.822048 ] \t0\ttrue\n",
            "(1)\t 304\t [-2.7251081  2.62852  ] \t1\ttrue\n",
            "(0)\t 305\t [-0.11046787 -0.47938675] \t0\ttrue\n",
            "(0)\t 306\t [-0.00705413 -0.5681498 ] \t0\ttrue\n",
            "(1)\t 307\t [-0.2616445  -0.27706435] \t0\tfalse\n",
            "(0)\t 308\t [-0.31498688 -0.24148363] \t1\tfalse\n",
            "(1)\t 309\t [-2.726876   2.7094061] \t1\ttrue\n",
            "(0)\t 310\t [ 2.486979 -2.801115] \t0\ttrue\n",
            "(0)\t 311\t [ 0.18803646 -0.77172893] \t0\ttrue\n",
            "(0)\t 312\t [ 2.4403558 -2.7890103] \t0\ttrue\n",
            "(1)\t 313\t [-2.7067676  2.6809444] \t1\ttrue\n",
            "(0)\t 314\t [ 0.02581809 -0.66377753] \t0\ttrue\n",
            "(1)\t 315\t [-2.4795418  2.3945248] \t1\ttrue\n",
            "(0)\t 316\t [ 2.6319768 -2.8747525] \t0\ttrue\n",
            "(0)\t 317\t [ 0.14314127 -0.72020227] \t0\ttrue\n",
            "(1)\t 318\t [-2.5782208  2.6175473] \t1\ttrue\n",
            "(0)\t 319\t [ 0.11723291 -0.7406094 ] \t0\ttrue\n",
            "(0)\t 320\t [ 2.601388  -2.8587046] \t0\ttrue\n",
            "(0)\t 321\t [ 0.36011645 -0.9203836 ] \t0\ttrue\n",
            "(0)\t 322\t [-0.03042366 -0.5743564 ] \t0\ttrue\n",
            "(1)\t 323\t [-2.3574915  2.4595492] \t1\ttrue\n",
            "(1)\t 324\t [ 0.04562546 -0.69655734] \t0\tfalse\n",
            "(0)\t 325\t [ 0.15239914 -0.8034051 ] \t0\ttrue\n",
            "(1)\t 326\t [-2.6582386  2.5701118] \t1\ttrue\n",
            "(0)\t 327\t [ 2.5265272 -2.7608972] \t0\ttrue\n",
            "(0)\t 328\t [-0.0236113  -0.57637966] \t0\ttrue\n",
            "(1)\t 329\t [-2.7192678  2.6918755] \t1\ttrue\n",
            "(0)\t 330\t [ 0.92632914 -1.4930124 ] \t0\ttrue\n",
            "(1)\t 331\t [-2.0447385  2.0018246] \t1\ttrue\n",
            "(0)\t 332\t [ 2.2671344 -2.4776323] \t0\ttrue\n",
            "(1)\t 333\t [-2.4892764  2.6350214] \t1\ttrue\n",
            "(0)\t 334\t [ 0.3483951 -0.9508696] \t0\ttrue\n",
            "(0)\t 335\t [ 0.32177415 -0.8380923 ] \t0\ttrue\n",
            "(1)\t 336\t [-0.11380211 -0.4291127 ] \t0\tfalse\n",
            "(0)\t 337\t [-0.02293096 -0.5924535 ] \t0\ttrue\n",
            "(0)\t 338\t [ 0.29513997 -0.9098773 ] \t0\ttrue\n",
            "(1)\t 339\t [-2.6337616  2.694855 ] \t1\ttrue\n",
            "(1)\t 340\t [-0.2010748  -0.44952908] \t0\tfalse\n",
            "(0)\t 341\t [ 0.05519301 -0.6386768 ] \t0\ttrue\n",
            "(1)\t 342\t [-0.10207731 -0.52004856] \t0\tfalse\n",
            "(1)\t 343\t [-2.765432  2.725205] \t1\ttrue\n",
            "(1)\t 344\t [-2.0397933  2.223813 ] \t1\ttrue\n",
            "(1)\t 345\t [-1.7113559  1.691778 ] \t1\ttrue\n",
            "(1)\t 346\t [-0.07546059 -0.49338886] \t0\tfalse\n",
            "(1)\t 347\t [-2.7614694  2.7123127] \t1\ttrue\n",
            "(1)\t 348\t [-2.7302885  2.7079582] \t1\ttrue\n",
            "(1)\t 349\t [-1.0920031  1.4806641] \t1\ttrue\n",
            "(0)\t 350\t [-0.00361389 -0.5700109 ] \t0\ttrue\n",
            "(0)\t 351\t [ 2.5886955 -2.8594503] \t0\ttrue\n",
            "(1)\t 352\t [-2.119982   2.3123589] \t1\ttrue\n",
            "(1)\t 353\t [-2.6832066  2.7232463] \t1\ttrue\n",
            "(1)\t 354\t [-2.809886   2.7014577] \t1\ttrue\n",
            "(1)\t 355\t [-2.6158373  2.5526109] \t1\ttrue\n",
            "(0)\t 356\t [ 0.68880504 -1.2411577 ] \t0\ttrue\n",
            "(0)\t 357\t [ 0.18475285 -0.85553515] \t0\ttrue\n",
            "(0)\t 358\t [-0.09495813 -0.4474887 ] \t0\ttrue\n",
            "(1)\t 359\t [-0.07762296 -0.53178215] \t0\tfalse\n",
            "(0)\t 360\t [-0.03755459 -0.5129093 ] \t0\ttrue\n",
            "(0)\t 361\t [ 1.7297295 -2.1974363] \t0\ttrue\n",
            "(0)\t 362\t [-0.04878593 -0.54666877] \t0\ttrue\n",
            "(1)\t 363\t [-0.06257191 -0.399351  ] \t0\tfalse\n",
            "(1)\t 364\t [-2.6056805  2.759445 ] \t1\ttrue\n",
            "(0)\t 365\t [ 2.4780316 -2.8011696] \t0\ttrue\n",
            "(1)\t 366\t [-2.734837   2.6921465] \t1\ttrue\n",
            "(1)\t 367\t [-2.7043324  2.683505 ] \t1\ttrue\n",
            "(1)\t 368\t [-2.648892   2.6631815] \t1\ttrue\n",
            "(1)\t 369\t [-2.605362   2.4667742] \t1\ttrue\n",
            "(1)\t 370\t [-2.6651406  2.6417472] \t1\ttrue\n",
            "(0)\t 371\t [ 0.04511428 -0.6130194 ] \t0\ttrue\n",
            "(0)\t 372\t [-0.11019872 -0.49450654] \t0\ttrue\n",
            "(0)\t 373\t [ 0.8605203 -1.3341161] \t0\ttrue\n",
            "(1)\t 374\t [-2.7281044  2.6511266] \t1\ttrue\n",
            "(1)\t 375\t [ 0.1109211 -0.6991075] \t0\tfalse\n",
            "(1)\t 376\t [ 0.02097782 -0.63157815] \t0\tfalse\n",
            "(1)\t 377\t [-2.4522612  2.517515 ] \t1\ttrue\n",
            "(0)\t 378\t [ 2.454163  -2.8432274] \t0\ttrue\n",
            "(1)\t 379\t [-2.6600456  2.7210965] \t1\ttrue\n",
            "(1)\t 380\t [-2.602381   2.7736752] \t1\ttrue\n",
            "(1)\t 381\t [-2.669007  2.65658 ] \t1\ttrue\n",
            "(0)\t 382\t [ 2.2401638 -2.621527 ] \t0\ttrue\n",
            "(1)\t 383\t [-2.8302264  2.717432 ] \t1\ttrue\n",
            "(0)\t 384\t [ 0.00848333 -0.59479785] \t0\ttrue\n",
            "(1)\t 385\t [-2.7400076  2.7348912] \t1\ttrue\n",
            "(1)\t 386\t [-2.631239  2.664496] \t1\ttrue\n",
            "(1)\t 387\t [-2.793704  2.755779] \t1\ttrue\n",
            "(0)\t 388\t [ 2.596817  -2.9048603] \t0\ttrue\n",
            "(0)\t 389\t [ 0.65062314 -1.2490585 ] \t0\ttrue\n",
            "(1)\t 390\t [-2.7160094  2.7025902] \t1\ttrue\n",
            "(1)\t 391\t [-2.5429854  2.6383593] \t1\ttrue\n",
            "(1)\t 392\t [-0.36968306 -0.30249023] \t1\ttrue\n",
            "(0)\t 393\t [ 2.6022274 -2.822781 ] \t0\ttrue\n",
            "(0)\t 394\t [ 2.3524623 -2.7973433] \t0\ttrue\n",
            "(0)\t 395\t [ 0.00740291 -0.6321433 ] \t0\ttrue\n",
            "(0)\t 396\t [-0.2686389  -0.35938388] \t0\ttrue\n",
            "(0)\t 397\t [ 0.06581508 -0.6005167 ] \t0\ttrue\n",
            "(0)\t 398\t [ 0.02350914 -0.63386494] \t0\ttrue\n",
            "(0)\t 399\t [ 0.05046533 -0.6210911 ] \t0\ttrue\n",
            "(0)\t 400\t [-2.7458951  2.7265618] \t1\tfalse\n",
            "(0)\t 401\t [ 0.07151465 -0.6711944 ] \t0\ttrue\n",
            "(1)\t 402\t [-2.7026212  2.6256418] \t1\ttrue\n",
            "(0)\t 403\t [-0.0655067 -0.5661482] \t0\ttrue\n",
            "(0)\t 404\t [-0.01784188 -0.5146333 ] \t0\ttrue\n",
            "(0)\t 405\t [ 2.5096881 -2.928924 ] \t0\ttrue\n",
            "(1)\t 406\t [ 0.02778746 -0.60148436] \t0\tfalse\n",
            "(0)\t 407\t [ 0.18933049 -0.7638627 ] \t0\ttrue\n",
            "(0)\t 408\t [-0.05230996 -0.5408176 ] \t0\ttrue\n",
            "(0)\t 409\t [ 2.465456 -2.791438] \t0\ttrue\n",
            "(0)\t 410\t [ 2.4119442 -2.7892303] \t0\ttrue\n",
            "(1)\t 411\t [ 0.2633103 -0.8003944] \t0\tfalse\n",
            "(0)\t 412\t [ 2.3686283 -2.6411083] \t0\ttrue\n",
            "(0)\t 413\t [ 0.04641374 -0.60477227] \t0\ttrue\n",
            "(0)\t 414\t [ 0.02808055 -0.55945385] \t0\ttrue\n",
            "(0)\t 415\t [ 0.032358  -0.6823991] \t0\ttrue\n",
            "(0)\t 416\t [ 2.5643153 -2.8777568] \t0\ttrue\n",
            "(0)\t 417\t [ 2.4254456 -2.7982056] \t0\ttrue\n",
            "(0)\t 418\t [ 2.6090043 -2.8937974] \t0\ttrue\n",
            "(1)\t 419\t [ 0.08361566 -0.6737343 ] \t0\tfalse\n",
            "(1)\t 420\t [-2.7075267  2.676789 ] \t1\ttrue\n",
            "(1)\t 421\t [ 0.14352676 -0.73842555] \t0\tfalse\n",
            "(0)\t 422\t [ 2.5424783 -2.8237653] \t0\ttrue\n",
            "(1)\t 423\t [-2.7939212  2.6700542] \t1\ttrue\n",
            "(1)\t 424\t [-2.7563498  2.6159446] \t1\ttrue\n",
            "(0)\t 425\t [ 0.17544164 -0.7709398 ] \t0\ttrue\n",
            "(0)\t 426\t [ 2.5507467 -2.896873 ] \t0\ttrue\n",
            "(1)\t 427\t [ 0.02121712 -0.63060176] \t0\tfalse\n",
            "(1)\t 428\t [-2.6090703  2.5950994] \t1\ttrue\n",
            "(0)\t 429\t [-0.01631311 -0.5604464 ] \t0\ttrue\n",
            "(0)\t 430\t [ 2.4796617 -2.9033508] \t0\ttrue\n",
            "(0)\t 431\t [ 0.31463823 -0.90688026] \t0\ttrue\n",
            "(0)\t 432\t [ 0.14396343 -0.718707  ] \t0\ttrue\n",
            "(0)\t 433\t [ 0.17226465 -0.754436  ] \t0\ttrue\n",
            "(1)\t 434\t [-2.7191522  2.6564288] \t1\ttrue\n",
            "(0)\t 435\t [ 0.4347191 -1.0170575] \t0\ttrue\n",
            "(1)\t 436\t [-2.708216   2.8005652] \t1\ttrue\n",
            "(1)\t 437\t [-2.7578948  2.6754382] \t1\ttrue\n",
            "(0)\t 438\t [ 0.03497056 -0.6599534 ] \t0\ttrue\n",
            "(1)\t 439\t [-2.6161122  2.6692455] \t1\ttrue\n",
            "(0)\t 440\t [ 2.557072 -2.917415] \t0\ttrue\n",
            "(0)\t 441\t [ 2.5502613 -2.8471537] \t0\ttrue\n",
            "(1)\t 442\t [-2.602887   2.6727295] \t1\ttrue\n",
            "(1)\t 443\t [-2.5236034  2.4195428] \t1\ttrue\n",
            "(1)\t 444\t [-0.03333632 -0.5456618 ] \t0\tfalse\n",
            "(1)\t 445\t [-2.7057567  2.6346002] \t1\ttrue\n",
            "(0)\t 446\t [ 0.0438134  -0.67070913] \t0\ttrue\n",
            "(1)\t 447\t [-2.763931  2.795053] \t1\ttrue\n",
            "(1)\t 448\t [-2.7290058  2.6910148] \t1\ttrue\n",
            "(1)\t 449\t [-1.5791448  1.3094429] \t1\ttrue\n",
            "(1)\t 450\t [-2.7273574  2.6327074] \t1\ttrue\n",
            "(1)\t 451\t [-0.10769199 -0.45070532] \t0\tfalse\n",
            "(1)\t 452\t [ 0.05491511 -0.64357567] \t0\tfalse\n",
            "(0)\t 453\t [-0.02156095 -0.55308896] \t0\ttrue\n",
            "(0)\t 454\t [ 0.05425796 -0.6190316 ] \t0\ttrue\n",
            "(0)\t 455\t [ 0.13342641 -0.71519923] \t0\ttrue\n",
            "(0)\t 456\t [ 2.5480266 -2.8515892] \t0\ttrue\n",
            "(1)\t 457\t [-2.8268902  2.7490747] \t1\ttrue\n",
            "(1)\t 458\t [-2.0830846  1.9637741] \t1\ttrue\n",
            "(1)\t 459\t [ 0.16276859 -0.71264863] \t0\tfalse\n",
            "(1)\t 460\t [-2.7591956  2.6353383] \t1\ttrue\n",
            "(1)\t 461\t [-2.766712  2.732246] \t1\ttrue\n",
            "(1)\t 462\t [-2.6759517  2.6574411] \t1\ttrue\n",
            "(1)\t 463\t [-2.813605  2.677192] \t1\ttrue\n",
            "(1)\t 464\t [-2.6721833  2.7155397] \t1\ttrue\n",
            "(0)\t 465\t [ 2.2352357 -2.537757 ] \t0\ttrue\n",
            "(0)\t 466\t [ 0.00955001 -0.5522037 ] \t0\ttrue\n",
            "(1)\t 467\t [-1.5565633  1.4365069] \t1\ttrue\n",
            "(0)\t 468\t [ 2.407049  -2.8173149] \t0\ttrue\n",
            "(1)\t 469\t [-2.592367   2.7296088] \t1\ttrue\n",
            "(0)\t 470\t [ 2.372937 -2.795242] \t0\ttrue\n",
            "(1)\t 471\t [-1.8008788  1.597526 ] \t1\ttrue\n",
            "(1)\t 472\t [-2.6976497  2.7231143] \t1\ttrue\n",
            "(0)\t 473\t [ 0.2841885  -0.79611975] \t0\ttrue\n",
            "(1)\t 474\t [-1.9445772  1.831388 ] \t1\ttrue\n",
            "(1)\t 475\t [-2.734396  2.778732] \t1\ttrue\n",
            "(1)\t 476\t [-2.3913457  2.3541405] \t1\ttrue\n",
            "(0)\t 477\t [ 0.12583707 -0.7004625 ] \t0\ttrue\n",
            "(1)\t 478\t [ 0.07348288 -0.6874232 ] \t0\tfalse\n",
            "(0)\t 479\t [ 2.2597578 -2.7581031] \t0\ttrue\n",
            "(1)\t 480\t [ 0.36720228 -0.8866193 ] \t0\tfalse\n",
            "(0)\t 481\t [ 0.10356696 -0.5864525 ] \t0\ttrue\n",
            "(0)\t 482\t [-0.02506191 -0.5621853 ] \t0\ttrue\n",
            "(0)\t 483\t [ 2.5625372 -2.828283 ] \t0\ttrue\n",
            "(1)\t 484\t [-2.8343666  2.6765363] \t1\ttrue\n",
            "(1)\t 485\t [-0.01894916 -0.5934778 ] \t0\tfalse\n",
            "(0)\t 486\t [-0.19795907 -0.36183268] \t0\ttrue\n",
            "(1)\t 487\t [-2.8355582  2.6697953] \t1\ttrue\n",
            "(0)\t 488\t [ 2.183029  -2.5948515] \t0\ttrue\n",
            "(1)\t 489\t [-2.670311  2.711446] \t1\ttrue\n",
            "(1)\t 490\t [-2.6559212  2.6333816] \t1\ttrue\n",
            "(1)\t 491\t [-0.03905849 -0.61978495] \t0\tfalse\n",
            "(0)\t 492\t [ 0.06923958 -0.66221195] \t0\ttrue\n",
            "(1)\t 493\t [-0.00106636 -0.6033857 ] \t0\tfalse\n",
            "(1)\t 494\t [-2.8186328  2.7218904] \t1\ttrue\n",
            "(1)\t 495\t [-2.7112906  2.7097619] \t1\ttrue\n",
            "(1)\t 496\t [-2.4160025  2.5258248] \t1\ttrue\n",
            "(1)\t 497\t [-2.7245455  2.6638806] \t1\ttrue\n",
            "(0)\t 498\t [-1.0804796  0.8282058] \t1\tfalse\n",
            "(1)\t 499\t [-2.6946828  2.725345 ] \t1\ttrue\n",
            "(1)\t 500\t [-0.21676216 -0.34823513] \t0\tfalse\n",
            "Number of true predictions: 428\n",
            "Number of false predictions: 72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KIgsWWCTKdY",
        "colab_type": "code",
        "outputId": "30de0e10-8a43-4e67-e5ca-b7717b48cd78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Accuracy:\",true_count/count_line*100,\"%\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 85.42914171656687 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRMcHi1uLQdO",
        "colab_type": "code",
        "outputId": "af9ae417-9b86-4137-dccb-999c45a7b875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "scores = [3.0, 1.0, 0.2]\n",
        "for i in range(len(predictions)):\n",
        "  for j in range(len(predictions[i])):\n",
        "    predictions[i][j]=softmax(predictions[i][j])\n",
        "    print(predictions[i][j])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6630336 0.3369664]\n",
            "[0.99534434 0.00465566]\n",
            "[0.5689166  0.43108344]\n",
            "[0.04037291 0.9596271 ]\n",
            "[0.9956163  0.00438369]\n",
            "[0.52324605 0.47675395]\n",
            "[0.00457491 0.99542505]\n",
            "[0.9956001 0.0043999]\n",
            "[0.99585056 0.00414938]\n",
            "[0.03291538 0.9670846 ]\n",
            "[0.004423 0.995577]\n",
            "[0.0044506  0.99554944]\n",
            "[0.68355846 0.31644157]\n",
            "[0.00488064 0.99511933]\n",
            "[0.995752 0.004248]\n",
            "[0.67936504 0.32063496]\n",
            "[0.6931086  0.30689132]\n",
            "[0.77324045 0.22675954]\n",
            "[0.9957425  0.00425753]\n",
            "[0.99586844 0.00413157]\n",
            "[0.6245566  0.37544337]\n",
            "[0.6993531  0.30064693]\n",
            "[0.8560708  0.14392917]\n",
            "[0.59376585 0.40623417]\n",
            "[0.00422052 0.9957795 ]\n",
            "[0.5130253  0.48697475]\n",
            "[0.6942092  0.30579084]\n",
            "[0.80679786 0.19320218]\n",
            "[0.754774   0.24522603]\n",
            "[0.99555534 0.00444462]\n",
            "[0.99565023 0.0043498 ]\n",
            "[0.00430624 0.9956937 ]\n",
            "[0.7226057  0.27739426]\n",
            "[0.99543    0.00456996]\n",
            "[0.7167469  0.28325313]\n",
            "[0.73353016 0.2664698 ]\n",
            "[0.7114036  0.28859645]\n",
            "[0.00427052 0.9957295 ]\n",
            "[0.7029028 0.2970972]\n",
            "[0.99382544 0.00617463]\n",
            "[0.00414151 0.9958585 ]\n",
            "[0.00409389 0.9959061 ]\n",
            "[0.01927455 0.98072547]\n",
            "[0.79378873 0.20621121]\n",
            "[0.00393149 0.9960685 ]\n",
            "[0.0046535 0.9953465]\n",
            "[0.599205 0.400795]\n",
            "[0.9954223  0.00457773]\n",
            "[0.6789263  0.32107377]\n",
            "[0.0047107 0.9952893]\n",
            "[0.9947349  0.00526509]\n",
            "[0.9956748  0.00432521]\n",
            "[0.6344839  0.36551616]\n",
            "[0.0064472 0.9935528]\n",
            "[0.67820626 0.32179374]\n",
            "[0.995475   0.00452505]\n",
            "[0.6506857 0.3493142]\n",
            "[0.67097205 0.32902792]\n",
            "[0.5751587  0.42484134]\n",
            "[0.989427   0.01057309]\n",
            "[0.0044309  0.99556905]\n",
            "[0.6789944 0.3210056]\n",
            "[0.9956208 0.0043792]\n",
            "[0.7071588 0.2928412]\n",
            "[0.37105033 0.6289497 ]\n",
            "[0.69221526 0.30778474]\n",
            "[0.6323656  0.36763436]\n",
            "[0.6964336  0.30356643]\n",
            "[0.9957283  0.00427163]\n",
            "[0.99525756 0.00474239]\n",
            "[0.00492455 0.9950754 ]\n",
            "[0.862536   0.13746399]\n",
            "[0.00423224 0.99576783]\n",
            "[0.99430275 0.00569722]\n",
            "[0.6372757  0.36272433]\n",
            "[0.9952545  0.00474551]\n",
            "[0.01042465 0.98957527]\n",
            "[0.56799847 0.43200153]\n",
            "[0.00436634 0.99563366]\n",
            "[0.00939298 0.990607  ]\n",
            "[0.6734251 0.3265749]\n",
            "[0.0044688  0.99553126]\n",
            "[0.02135408 0.97864586]\n",
            "[0.00408126 0.9959188 ]\n",
            "[0.13590555 0.86409444]\n",
            "[0.00382271 0.9961773 ]\n",
            "[0.00401958 0.9959804 ]\n",
            "[0.00502774 0.9949722 ]\n",
            "[0.6494759 0.3505241]\n",
            "[0.03764569 0.96235436]\n",
            "[0.00415253 0.9958475 ]\n",
            "[0.00398379 0.9960162 ]\n",
            "[0.00437213 0.9956279 ]\n",
            "[0.00411772 0.9958823 ]\n",
            "[0.00476949 0.9952305 ]\n",
            "[0.00417005 0.99583   ]\n",
            "[0.00472502 0.9952749 ]\n",
            "[0.01248766 0.9875123 ]\n",
            "[0.9954059  0.00459407]\n",
            "[0.00463089 0.99536914]\n",
            "[0.00485401 0.995146  ]\n",
            "[0.19946426 0.80053574]\n",
            "[0.63608253 0.36391747]\n",
            "[0.00466685 0.99533314]\n",
            "[0.02089641 0.97910357]\n",
            "[0.59690434 0.40309572]\n",
            "[0.0041414 0.9958586]\n",
            "[0.5877613  0.41223872]\n",
            "[0.00691086 0.99308914]\n",
            "[0.00710187 0.9928981 ]\n",
            "[0.6501587 0.3498413]\n",
            "[0.04226591 0.9577341 ]\n",
            "[0.73642766 0.26357237]\n",
            "[0.9946455  0.00535457]\n",
            "[0.6348002  0.36519983]\n",
            "[0.6422938  0.35770622]\n",
            "[0.00438543 0.9956145 ]\n",
            "[0.7900124 0.2099876]\n",
            "[0.6528383  0.34716168]\n",
            "[0.00643015 0.99356985]\n",
            "[0.00453204 0.9954679 ]\n",
            "[0.01624455 0.98375547]\n",
            "[0.6569623 0.3430377]\n",
            "[0.00605341 0.9939466 ]\n",
            "[0.9956638 0.0043362]\n",
            "[0.7585083  0.24149172]\n",
            "[0.00491105 0.995089  ]\n",
            "[0.65156466 0.3484353 ]\n",
            "[0.15298414 0.84701586]\n",
            "[0.37835425 0.62164575]\n",
            "[0.48149562 0.5185044 ]\n",
            "[0.00437777 0.9956222 ]\n",
            "[0.46160597 0.538394  ]\n",
            "[0.9948231  0.00517687]\n",
            "[0.64965725 0.35034278]\n",
            "[0.99473035 0.0052696 ]\n",
            "[0.9954117  0.00458826]\n",
            "[0.99583435 0.00416565]\n",
            "[0.9942216  0.00577834]\n",
            "[0.9939231 0.0060769]\n",
            "[0.08349319 0.9165068 ]\n",
            "[0.83137774 0.16862226]\n",
            "[0.9953654  0.00463459]\n",
            "[0.00469053 0.99530953]\n",
            "[0.00407676 0.9959233 ]\n",
            "[0.6971731  0.30282685]\n",
            "[0.6633425  0.33665746]\n",
            "[0.6481769  0.35182306]\n",
            "[0.7252383  0.27476174]\n",
            "[0.03458776 0.96541226]\n",
            "[0.00440891 0.99559116]\n",
            "[0.6254713 0.3745287]\n",
            "[0.00518772 0.99481225]\n",
            "[0.00490685 0.9950931 ]\n",
            "[0.14219251 0.8578075 ]\n",
            "[0.00398755 0.99601245]\n",
            "[0.6480637  0.35193625]\n",
            "[0.00635076 0.9936492 ]\n",
            "[0.00442251 0.9955776 ]\n",
            "[0.01367459 0.98632544]\n",
            "[0.04429756 0.9557024 ]\n",
            "[0.00397653 0.9960234 ]\n",
            "[0.6803473  0.31965268]\n",
            "[0.66127217 0.33872786]\n",
            "[0.12144826 0.8785517 ]\n",
            "[0.0045004  0.99549955]\n",
            "[0.00571897 0.99428105]\n",
            "[0.00434619 0.99565375]\n",
            "[0.00378649 0.9962135 ]\n",
            "[0.81222886 0.18777113]\n",
            "[0.16025533 0.8397447 ]\n",
            "[0.6976852  0.30231485]\n",
            "[0.9959145  0.00408551]\n",
            "[0.6299195  0.37008044]\n",
            "[0.05416283 0.94583714]\n",
            "[0.9953432  0.00465685]\n",
            "[0.00416674 0.9958333 ]\n",
            "[0.99527633 0.00472362]\n",
            "[0.5874115 0.4125885]\n",
            "[0.70991343 0.29008657]\n",
            "[0.7358903 0.2641097]\n",
            "[0.00519203 0.994808  ]\n",
            "[0.99549246 0.00450755]\n",
            "[0.61978805 0.38021192]\n",
            "[0.13101247 0.86898756]\n",
            "[0.58205354 0.41794643]\n",
            "[0.00462387 0.9953761 ]\n",
            "[0.00385809 0.99614197]\n",
            "[0.00696767 0.99303234]\n",
            "[0.00744481 0.9925552 ]\n",
            "[0.61304337 0.38695663]\n",
            "[0.01177875 0.9882212 ]\n",
            "[0.68966365 0.31033632]\n",
            "[0.00586457 0.9941354 ]\n",
            "[0.65911967 0.34088033]\n",
            "[0.09653486 0.90346515]\n",
            "[0.657356   0.34264395]\n",
            "[0.993648   0.00635203]\n",
            "[0.72312343 0.27687654]\n",
            "[0.00631738 0.9936826 ]\n",
            "[0.00406211 0.99593794]\n",
            "[0.6971787  0.30282122]\n",
            "[0.65038514 0.3496148 ]\n",
            "[0.9948396  0.00516038]\n",
            "[0.6857869 0.3142131]\n",
            "[0.00414927 0.9958507 ]\n",
            "[0.68050015 0.3194999 ]\n",
            "[0.00407467 0.9959253 ]\n",
            "[0.00455953 0.9954405 ]\n",
            "[0.67232543 0.32767457]\n",
            "[0.70367616 0.29632387]\n",
            "[0.00437094 0.9956291 ]\n",
            "[0.7385066  0.26149344]\n",
            "[0.00676693 0.993233  ]\n",
            "[0.66937906 0.33062097]\n",
            "[0.6904973 0.3095027]\n",
            "[0.0047698 0.9952302]\n",
            "[0.67467964 0.32532033]\n",
            "[0.00552403 0.994476  ]\n",
            "[0.00568046 0.99431956]\n",
            "[0.00814819 0.99185187]\n",
            "[0.6539847  0.34601524]\n",
            "[0.6692677 0.3307323]\n",
            "[0.69165534 0.30834466]\n",
            "[0.19760627 0.8023937 ]\n",
            "[0.56832874 0.4316713 ]\n",
            "[0.00423875 0.9957612 ]\n",
            "[0.9942866 0.0057134]\n",
            "[0.00430448 0.9956955 ]\n",
            "[0.00401271 0.99598724]\n",
            "[0.9784064  0.02159355]\n",
            "[0.6730804  0.32691962]\n",
            "[0.64764935 0.3523507 ]\n",
            "[0.65695995 0.34304005]\n",
            "[0.7082208  0.29177922]\n",
            "[0.00416651 0.9958335 ]\n",
            "[0.00396777 0.9960322 ]\n",
            "[0.7332497  0.26675025]\n",
            "[0.00399592 0.99600405]\n",
            "[0.00449565 0.9955043 ]\n",
            "[0.00613865 0.9938613 ]\n",
            "[0.715279   0.28472102]\n",
            "[0.6409255 0.3590744]\n",
            "[0.0061245  0.99387544]\n",
            "[0.68299896 0.31700107]\n",
            "[0.9948782  0.00512184]\n",
            "[0.9937903 0.0062097]\n",
            "[0.9953193  0.00468064]\n",
            "[0.64152974 0.35847032]\n",
            "[0.00441441 0.99558556]\n",
            "[0.00501166 0.9949883 ]\n",
            "[0.63102794 0.3689721 ]\n",
            "[0.55733365 0.4426664 ]\n",
            "[0.98803514 0.01196491]\n",
            "[0.65480363 0.34519643]\n",
            "[0.99576473 0.00423524]\n",
            "[0.00405736 0.99594265]\n",
            "[0.9900075  0.00999252]\n",
            "[0.6494308 0.3505692]\n",
            "[0.7510105  0.24898951]\n",
            "[0.00439867 0.9956013 ]\n",
            "[0.995359   0.00464096]\n",
            "[0.646624   0.35337603]\n",
            "[0.00418817 0.9958118 ]\n",
            "[0.00632754 0.9936725 ]\n",
            "[0.00437901 0.995621  ]\n",
            "[0.00470346 0.99529654]\n",
            "[0.9933776  0.00662237]\n",
            "[0.9949019  0.00509811]\n",
            "[0.58910894 0.41089106]\n",
            "[0.00875392 0.99124604]\n",
            "[0.61746377 0.38253626]\n",
            "[0.0046098 0.9953902]\n",
            "[0.9955923  0.00440773]\n",
            "[0.00893713 0.9910629 ]\n",
            "[0.00397819 0.9960218 ]\n",
            "[0.00446228 0.99553776]\n",
            "[0.99506843 0.00493157]\n",
            "[0.00860634 0.9913936 ]\n",
            "[0.6871834  0.31281665]\n",
            "[0.6585005 0.3414995]\n",
            "[0.00961555 0.99038446]\n",
            "[0.99353653 0.00646341]\n",
            "[0.00539179 0.99460816]\n",
            "[0.72401446 0.2759855 ]\n",
            "[0.6798391  0.32016087]\n",
            "[0.7286907 0.2713093]\n",
            "[0.00499533 0.9950047 ]\n",
            "[0.46375823 0.53624177]\n",
            "[0.99503314 0.00496686]\n",
            "[0.09201973 0.90798026]\n",
            "[0.00433635 0.9956637 ]\n",
            "[0.00687303 0.993127  ]\n",
            "[0.00636915 0.9936308 ]\n",
            "[0.0050713 0.9949287]\n",
            "[0.7317295  0.26827046]\n",
            "[0.6919131  0.30808687]\n",
            "[0.665382   0.33461803]\n",
            "[0.70162326 0.29837668]\n",
            "[0.01023622 0.98976374]\n",
            "[0.6391572  0.36084288]\n",
            "[0.63295716 0.36704287]\n",
            "[0.9956007  0.00439924]\n",
            "[0.00470868 0.99529135]\n",
            "[0.59119767 0.40880227]\n",
            "[0.636706 0.363294]\n",
            "[0.5038549 0.4961451]\n",
            "[0.48163244 0.5183675 ]\n",
            "[0.00433676 0.9956632 ]\n",
            "[0.994974   0.00502599]\n",
            "[0.72307485 0.27692518]\n",
            "[0.99467164 0.00532838]\n",
            "[0.00455161 0.9954484 ]\n",
            "[0.665877   0.33412305]\n",
            "[0.00758426 0.99241567]\n",
            "[0.9959571  0.00404295]\n",
            "[0.7033587  0.29664126]\n",
            "[0.00550944 0.9944905 ]\n",
            "[0.70220965 0.29779035]\n",
            "[0.99576485 0.00423515]\n",
            "[0.7825349  0.21746512]\n",
            "[0.6327268  0.36727318]\n",
            "[0.00802576 0.9919742 ]\n",
            "[0.677473   0.32252702]\n",
            "[0.722281   0.27771905]\n",
            "[0.00533376 0.9946662 ]\n",
            "[0.99497074 0.00502934]\n",
            "[0.6347776  0.36522236]\n",
            "[0.00444667 0.9955533 ]\n",
            "[0.9182903  0.08170965]\n",
            "[0.01718197 0.982818  ]\n",
            "[0.99137795 0.0086221 ]\n",
            "[0.00591519 0.9940848 ]\n",
            "[0.7857112  0.21428879]\n",
            "[0.76130843 0.23869155]\n",
            "[0.57818097 0.421819  ]\n",
            "[0.638653   0.36134702]\n",
            "[0.76941615 0.23058388]\n",
            "[0.00482736 0.9951727 ]\n",
            "[0.561796 0.438204]\n",
            "[0.66682726 0.33317277]\n",
            "[0.60299766 0.3970023 ]\n",
            "[0.00410827 0.9958917 ]\n",
            "[0.01387621 0.9861238 ]\n",
            "[0.03219767 0.96780235]\n",
            "[0.6029874  0.39701262]\n",
            "[0.00417781 0.9958222 ]\n",
            "[0.00432828 0.99567175]\n",
            "[0.07091837 0.9290816 ]\n",
            "[0.6379314  0.36206862]\n",
            "[0.9957141  0.00428583]\n",
            "[0.011747   0.98825306]\n",
            "[0.00446748 0.9955325 ]\n",
            "[0.00402441 0.99597555]\n",
            "[0.00566116 0.9943388 ]\n",
            "[0.8732453  0.12675472]\n",
            "[0.73890555 0.26109442]\n",
            "[0.5872311 0.4127689]\n",
            "[0.61162764 0.38837233]\n",
            "[0.61665034 0.38334966]\n",
            "[0.9806811  0.01931885]\n",
            "[0.62196165 0.37803832]\n",
            "[0.58340794 0.4165921 ]\n",
            "[0.0046551  0.99534494]\n",
            "[0.9949293  0.00507066]\n",
            "[0.00437709 0.99562293]\n",
            "[0.00455104 0.995449  ]\n",
            "[0.00490749 0.9950925 ]\n",
            "[0.00622996 0.99377006]\n",
            "[0.00493288 0.9950671 ]\n",
            "[0.6588411 0.341159 ]\n",
            "[0.5949117  0.40508834]\n",
            "[0.8997668  0.10023318]\n",
            "[0.0045902 0.9954098]\n",
            "[0.6921156  0.30788442]\n",
            "[0.6575862 0.3424138]\n",
            "[0.00689681 0.99310327]\n",
            "[0.9950203  0.00497971]\n",
            "[0.00458148 0.99541855]\n",
            "[0.00460473 0.99539524]\n",
            "[0.00484193 0.995158  ]\n",
            "[0.992322   0.00767798]\n",
            "[0.00388145 0.99611855]\n",
            "[0.64640665 0.35359338]\n",
            "[0.00417316 0.9958268 ]\n",
            "[0.00498793 0.9950121 ]\n",
            "[0.0038744  0.99612564]\n",
            "[0.99593663 0.00406334]\n",
            "[0.86985546 0.13014452]\n",
            "[0.00441378 0.99558616]\n",
            "[0.00558903 0.99441093]\n",
            "[0.4832081 0.5167919]\n",
            "[0.9956143  0.00438571]\n",
            "[0.99423295 0.00576708]\n",
            "[0.65465087 0.34534913]\n",
            "[0.5226707 0.4773293]\n",
            "[0.66068125 0.3393187 ]\n",
            "[0.65867025 0.34132972]\n",
            "[0.66185164 0.33814842]\n",
            "[0.00418332 0.99581665]\n",
            "[0.6775879 0.322412 ]\n",
            "[0.00482906 0.9951709 ]\n",
            "[0.6226101 0.3773899]\n",
            "[0.621705   0.37829497]\n",
            "[0.99567324 0.00432671]\n",
            "[0.6523243  0.34767568]\n",
            "[0.7217569 0.2782431]\n",
            "[0.6197548  0.38024518]\n",
            "[0.9948155  0.00518445]\n",
            "[0.9945201  0.00547989]\n",
            "[0.7433979 0.2566021]\n",
            "[0.9933716  0.00662843]\n",
            "[0.6572777  0.34272233]\n",
            "[0.6427992  0.35720077]\n",
            "[0.67145145 0.32854855]\n",
            "[0.99568814 0.00431183]\n",
            "[0.9946412  0.00535875]\n",
            "[0.9959413 0.0040588]\n",
            "[0.68077815 0.3192219 ]\n",
            "[0.00456703 0.995433  ]\n",
            "[0.70722663 0.2927734 ]\n",
            "[0.99535    0.00464993]\n",
            "[0.00421881 0.9957812 ]\n",
            "[0.004622 0.995378]\n",
            "[0.72038686 0.2796131 ]\n",
            "[0.9957119  0.00428808]\n",
            "[0.6574202  0.34257978]\n",
            "[0.00546359 0.9945364 ]\n",
            "[0.6327734 0.3672266]\n",
            "[0.995427   0.00457295]\n",
            "[0.7723307  0.22766933]\n",
            "[0.7032183  0.29678172]\n",
            "[0.71640545 0.28359458]\n",
            "[0.00460691 0.99539316]\n",
            "[0.81027174 0.18972829]\n",
            "[0.0040347  0.99596524]\n",
            "[0.00434951 0.9956505 ]\n",
            "[0.6670614  0.33293858]\n",
            "[0.00503969 0.9949603 ]\n",
            "[0.9958252  0.00417488]\n",
            "[0.9954921  0.00450786]\n",
            "[0.00508877 0.99491125]\n",
            "[0.00708162 0.9929183 ]\n",
            "[0.6253514 0.3746485]\n",
            "[0.00477129 0.99522877]\n",
            "[0.6713997 0.3286003]\n",
            "[0.0038379  0.99616206]\n",
            "[0.00440754 0.9955924 ]\n",
            "[0.0527206 0.9472794]\n",
            "[0.00467861 0.99532133]\n",
            "[0.5849223 0.4150777]\n",
            "[0.66785306 0.3321469 ]\n",
            "[0.6298394  0.37016055]\n",
            "[0.6622393  0.33776063]\n",
            "[0.70027876 0.29972124]\n",
            "[0.99550205 0.00449799]\n",
            "[0.00377353 0.99622643]\n",
            "[0.01717698 0.9828231 ]\n",
            "[0.7058717  0.29412833]\n",
            "[0.00452081 0.9954792 ]\n",
            "[0.00407437 0.99592566]\n",
            "[0.00480447 0.99519557]\n",
            "[0.00410761 0.9958924 ]\n",
            "[0.00455156 0.9954484 ]\n",
            "[0.99161583 0.00838415]\n",
            "[0.6368582  0.36314178]\n",
            "[0.04773993 0.95226014]\n",
            "[0.9946451  0.00535495]\n",
            "[0.00485937 0.9951407 ]\n",
            "[0.99433726 0.00566268]\n",
            "[0.03234536 0.96765465]\n",
            "[0.00440428 0.99559575]\n",
            "[0.7465523 0.2534477]\n",
            "[0.02240163 0.9775983 ]\n",
            "[0.00401727 0.99598277]\n",
            "[0.00861595 0.991384  ]\n",
            "[0.69557196 0.30442807]\n",
            "[0.68155044 0.3184496 ]\n",
            "[0.9934249  0.00657515]\n",
            "[0.7779607  0.22203931]\n",
            "[0.6659712  0.33402875]\n",
            "[0.631143 0.368857]\n",
            "[0.9954625  0.00453755]\n",
            "[0.00402618 0.99597377]\n",
            "[0.63980746 0.3601925 ]\n",
            "[0.540877   0.45912305]\n",
            "[0.00404849 0.99595153]\n",
            "[0.9916564  0.00834361]\n",
            "[0.00457867 0.99542135]\n",
            "[0.00501995 0.99498004]\n",
            "[0.6412346  0.35876545]\n",
            "[0.6751237  0.32487628]\n",
            "[0.64618677 0.35381326]\n",
            "[0.00390913 0.9960908 ]\n",
            "[0.00440302 0.99559695]\n",
            "[0.0070909 0.9929091]\n",
            "[0.00454838 0.9954516 ]\n",
            "[0.12912862 0.8708714 ]\n",
            "[0.00440751 0.9955924 ]\n",
            "[0.532821   0.46717903]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgpMTRW-jMtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.savetxt(\"/content/drive/My Drive/FYP/bert/glue/cola/task1punjabi-results.txt\",predictions, fmt=\"%s\")\n",
        "np.savetxt(\"/content/drive/My Drive/FYP/bert/glue/cola/buffer/true labels/task1punjabi-labels.txt\",true_labels, fmt=\"%s\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PmWUtXdLW1I",
        "colab_type": "code",
        "outputId": "4dede920-5f69-4319-de38-c89c83b5e926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  \n",
        "\n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)\n",
        "  \n",
        " # print(pred_labels_i)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI2K1bqaR5ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb--na-oLbVM",
        "colab_type": "code",
        "outputId": "ef308cdd-d9fe-48be-d8c9-7828f847cb6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "matthews_set\n",
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6aNsEuZMvjI",
        "colab_type": "code",
        "outputId": "7486519b-45db-4623-be8c-59ee3d426ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/My Drive/FYP/bert/model-colab-task1punjabi'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/My Drive/FYP/bert/model-colab-task1punjabi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/FYP/bert/model-colab-task1punjabi/vocab.txt',\n",
              " '/content/drive/My Drive/FYP/bert/model-colab-task1punjabi/special_tokens_map.json',\n",
              " '/content/drive/My Drive/FYP/bert/model-colab-task1punjabi/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}